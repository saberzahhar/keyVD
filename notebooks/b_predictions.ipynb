{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e28a99-9e96-4d4e-b9c7-83f3e37e8320",
   "metadata": {},
   "source": [
    "This notebook was ran on a Google Cloud Workbench jupyter notebook instance with a Free Tier n2-highmem-8 (8 vCPUs, 64GB RAM) machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa5b5d-1f79-4332-a70c-371b1d6c8747",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [pke](#pke)\n",
    "* [keyVD](#keyVD)\n",
    "* [computation times](#timeit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fad8a3-c6dc-4d5c-b0cf-639d880e21d6",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "We will predict keywords from all our models, our benchmark is made using https://github.com/boudinfl/pke/\n",
    "\n",
    "The prediction cells can be re-run if, for any reason, it failed; it will continue from where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b09ec0ce-8cf6-43bd-9606-1d3ab6814d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n",
      "Requirement already satisfied: google-cloud-storage==2.10.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: google-cloud-bigquery==3.11.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.11.4)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.2.2)\n",
      "Requirement already satisfied: db-dtypes==1.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: numpy==1.25.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.25.2)\n",
      "Requirement already satisfied: gensim==4.3.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (4.3.1)\n",
      "Requirement already satisfied: pandas==1.5.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.5.3)\n",
      "Requirement already satisfied: nltk==3.8.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (3.8.1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (2.20.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery==3.11.4->-r requirements.txt (line 2)) (1.51.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery==3.11.4->-r requirements.txt (line 2)) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery==3.11.4->-r requirements.txt (line 2)) (23.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery==3.11.4->-r requirements.txt (line 2)) (3.20.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery==3.11.4->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 3)) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from db-dtypes==1.1.1->-r requirements.txt (line 4)) (12.0.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim==4.3.1->-r requirements.txt (line 6)) (6.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 7)) (2023.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk==3.8.1->-r requirements.txt (line 8)) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk==3.8.1->-r requirements.txt (line 8)) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk==3.8.1->-r requirements.txt (line 8)) (4.65.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (1.59.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (1.26.16)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (2023.5.7)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage==2.10.0->-r requirements.txt (line 1)) (0.5.0)\n",
      "/home/jupyter/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter\n",
    "!pip install -r requirements.txt\n",
    "%cd /home/jupyter/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b685af-1a05-431a-9194-afa88c6f5ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f5a53c5-51e1-4ea6-8989-c1982b86ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas\n",
    "import json\n",
    "import time\n",
    "\n",
    "with open('/home/jupyter/setup.json', 'r') as file :\n",
    "    variables = json.load(file)\n",
    "\n",
    "if variables[\"USE_GCP\"] != \"false\":\n",
    "    bq_client = bigquery.Client(\n",
    "        project = variables['PROJECT_ID'], \n",
    "        location = variables['REGION']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017991f1-47d2-4d49-aa1f-804f5bbbfbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk import ngrams\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    remove_words = stopwords.words()\n",
    "except:\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk import ngrams\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    remove_words = stopwords.words()\n",
    "tops = [5, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d6e2ad-c552-4c9f-a346-db40b39de58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make append work, we need to have at least the header columns in a file, we'll create it\n",
    "if variables[\"USE_GCP\"] == \"false\":\n",
    "    try:\n",
    "        results = pandas.read_csv(f\"{variables['TABLE_PREDICTIONS_ID']}.csv\", sep=\",\")\n",
    "    except:\n",
    "        result = {\"model_id\" : [''], \"dataset_id\" : [''], \"text_id\" : ['']}\n",
    "        for top in tops:\n",
    "            result.update({f\"predictions_{top}\" : ['']})\n",
    "        pandas.DataFrame(result).to_csv(f\"{variables['TABLE_PREDICTIONS_ID']}.csv\", sep=\",\", index=False, header=True)\n",
    "else:\n",
    "    try:    \n",
    "        bq_client.query(f\"\"\"\n",
    "            SELECT * FROM `{variables['PROJECT_ID']}.{variables['DATASET_ID']}.{variables['TABLE_INPUT_ID']}`\n",
    "            WHERE CONCAT(dataset_id, text_id) NOT IN \n",
    "            (SELECT CONCAT(dataset_id, text_id) FROM `{variables['PROJECT_ID']}.{variables['DATASET_ID']}.{variables['TABLE_PREDICTIONS_ID']}` WHERE model_id = '{model_id}')\n",
    "        \"\"\").to_dataframe()\n",
    "    except:\n",
    "        result = {\"model_id\" : [''], \"dataset_id\" : [''], \"text_id\" : ['']}\n",
    "        for top in tops:\n",
    "            result.update({f\"predictions_{top}\" : ['']})\n",
    "        job = bq_client.load_table_from_dataframe(\n",
    "            dataframe = pandas.DataFrame(result), \n",
    "            destination = f\"{variables['PROJECT_ID']}.{variables['DATASET_ID']}.{variables['TABLE_PREDICTIONS_ID']}\"\n",
    "        )\n",
    "        job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3d330-8723-4891-83be-2e92ec65b1ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# pke<a class=\"anchor\" id=\"pke\"></a>\n",
    "\n",
    "To compare our model we'll use the [Python Keyphrase Extraction open source](https://github.com/boudinfl/pke) toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "932d71e3-7f52-4c21-8fae-8e2a7e7b7c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/boudinfl/pke.git\n",
      "  Cloning https://github.com/boudinfl/pke.git to /var/tmp/pip-req-build-oqf1_0yx\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/boudinfl/pke.git /var/tmp/pip-req-build-oqf1_0yx\n",
      "  Resolved https://github.com/boudinfl/pke.git to commit 69871ffdb720b83df23684fea53ec8776fd87e63\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from pke==2.0.0) (3.8.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from pke==2.0.0) (3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pke==2.0.0) (1.25.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from pke==2.0.0) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pke==2.0.0) (1.2.2)\n",
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.10/site-packages (from pke==2.0.0) (1.3.6)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from pke==2.0.0) (0.18.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from pke==2.0.0) (1.2.0)\n",
      "Requirement already satisfied: spacy>=3.2.3 in /opt/conda/lib/python3.10/site-packages (from pke==2.0.0) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->pke==2.0.0) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk->pke==2.0.0) (2023.6.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pke==2.0.0) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.3->pke==2.0.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.3->pke==2.0.0) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.3)\n",
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.25.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting fr-core-news-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.6.0/fr_core_news_sm-3.6.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /opt/conda/lib/python3.10/site-packages (from fr-core-news-sm==3.6.0) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.25.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.10.9)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/boudinfl/pke.git\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6773a23-4e10-4e33-ad5b-316fe6991e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pke.unsupervised import *\n",
    "import spacy\n",
    "models = [MultipartiteRank, TfIdf, YAKE, TopicRank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100133e-a48a-4efb-9279-7025d6b61e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pandas.DataFrame()\n",
    "\n",
    "for model in models :\n",
    "    # We only take the remaining inputs to predict for each model.\n",
    "    model_id = str(model).split('\\'')[-2].split('.')[-1]\n",
    "    if variables[\"USE_GCP\"] != \"false\":    \n",
    "        documents = bq_client.query(f\"\"\"\n",
    "            SELECT * FROM `{variables['PROJECT_ID']}.{variables['DATASET_ID']}.{variables['TABLE_INPUT_ID']}`\n",
    "            WHERE CONCAT(dataset_id, text_id) NOT IN \n",
    "            (SELECT CONCAT(dataset_id, text_id) FROM `{variables['PROJECT_ID']}.{variables['DATASET_ID']}.{variables['TABLE_PREDICTIONS_ID']}` WHERE CAST(model_id AS STRING) = '{model_id}')\n",
    "        \"\"\").to_dataframe()\n",
    "    else:\n",
    "        results = pandas.read_csv(f\"{variables['TABLE_PREDICTIONS_ID']}.csv\", sep=\",\")\n",
    "        results = results[results[\"model_id\"] == model_id]\n",
    "        documents = pandas.read_csv(f\"{variables['TABLE_INPUT_ID']}.csv\", sep=\",\")\n",
    "        index_remove = documents.merge(results, left_on=[\"dataset_id\", \"text_id\"], right_on=[\"dataset_id\", \"text_id\"], how=\"left\")\n",
    "        index_remove = index_remove[\"model_id\"].isna()\n",
    "        documents = documents[index_remove]\n",
    "    results = pandas.DataFrame()\n",
    "    \n",
    "    for index in list(documents.index) :\n",
    "        dataset_id = documents.loc[index, 'dataset_id']\n",
    "        text_id = documents.loc[index, 'text_id']\n",
    "        text_input = documents.loc[index, 'input']\n",
    "        \n",
    "        if dataset_id == 'termith-eval':\n",
    "            spacy_model = spacy.load(\"fr_core_news_sm\")\n",
    "            language = \"fr\"\n",
    "        else:\n",
    "            spacy_model = spacy.load(\"en_core_web_sm\")\n",
    "            language = \"en\"\n",
    "\n",
    "        extractor = model()\n",
    "        extractor.load_document(input=text_input, language=language, spacy_model=spacy_model)\n",
    "\n",
    "        result = pandas.DataFrame({'model_id' : [model_id], 'dataset_id' : [dataset_id], 'text_id' : [text_id]})\n",
    "        for top in tops :\n",
    "            extractor.candidate_selection()\n",
    "            extractor.candidate_weighting()\n",
    "            predictions = extractor.get_n_best(n=top)\n",
    "            result[f\"predictions_{top}\"] = ';'.join([x[0] for x in set(sorted(predictions, key = lambda x : x[1], reverse = True))])     \n",
    "        \n",
    "        results = pandas.concat([results, result])\n",
    "        \n",
    "        # We take snapshots every 100 inputs or when the model has finished predicting all inputs.\n",
    "        if index%100 == 0 or index == list(documents.index)[-1]:\n",
    "            # Print current status of the pipeline, uncomment if interested\n",
    "            #print(f'model_id: {model_id}\\ninput: {dataset_id}_{text_id}\\nrows left: {len(documents) - index}')\n",
    "            if variables['USE_GCP'] != \"false\":\n",
    "                job = bq_client.load_table_from_dataframe(\n",
    "                    dataframe = results, \n",
    "                    destination = f\"{variables['PROJECT_ID']}.{variables['DATASET_ID']}.{variables['TABLE_PREDICTIONS_ID']}\"\n",
    "                )\n",
    "                job.result()\n",
    "            else:\n",
    "                results.to_csv(f\"{variables['TABLE_PREDICTIONS_ID']}.csv\", sep=\",\", mode='a', index=False, header=False)\n",
    "            results = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ad0d7-07d3-4775-92e5-f41c47d67a0c",
   "metadata": {},
   "source": [
    "# keyVD<a class=\"anchor\" id=\"keyVD\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e8909-57aa-4ea9-ad5e-0dd1faefd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/jupyter/\n",
    "from keyVD import *\n",
    "%cd /home/jupyter/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6db289-f902-4671-84d6-25de3570e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'keyVD'\n",
    "\n",
    "if variables[\"USE_GCP\"] != \"false\":    \n",
    "    documents = bq_client.query(f\"\"\"\n",
    "        SELECT * FROM `{variables['PROJECT_ID']}.{variables['DATASET_ID']}.{variables['TABLE_INPUT_ID']}`\n",
    "        WHERE CONCAT(dataset_id, text_id) NOT IN \n",
    "        (SELECT CONCAT(dataset_id, text_id) FROM `{variables['PROJECT_ID']}.{variables['DATASET_ID']}.{variables['TABLE_PREDICTIONS_ID']}` WHERE model_id = '{model_id}')\n",
    "    \"\"\").to_dataframe()\n",
    "else:\n",
    "    results = pandas.read_csv(f\"{variables['TABLE_PREDICTIONS_ID']}.csv\", sep=\",\")\n",
    "    results = results[results[\"model_id\"].apply(lambda x : model_id in str(x))]\n",
    "    documents = pandas.read_csv(f\"{variables['TABLE_INPUT_ID']}.csv\", sep=\",\")\n",
    "    index_remove = documents.merge(results, left_on=[\"dataset_id\", \"text_id\"], right_on=[\"dataset_id\", \"text_id\"], how=\"left\")\n",
    "    index_remove = index_remove[\"model_id\"].isna()\n",
    "    documents = documents[index_remove]\n",
    "    results = pandas.DataFrame()\n",
    "\n",
    "vocabularies = {}\n",
    "for subset_id in ['author', 'reader', 'controlled', 'uncontrolled', 'indexer']:\n",
    "    if variables[\"USE_GCP\"] != \"false\":\n",
    "        vocabulary = bq_client.query(f\"\"\"\n",
    "        SELECT * FROM `{variables['PROJECT_ID']}.{variables['DATASET_ID']}.{variables['TABLE_OUTPUT_ID']}`'\n",
    "    \"\"\").to_dataframe()\n",
    "    else:\n",
    "        vocabulary = pandas.read_csv(f\"{variables['TABLE_OUTPUT_ID']}.csv\", sep=\",\")\n",
    "    vocabulary = vocabulary[(vocabulary[\"subset_id\"] == subset_id)]\n",
    "    vocabularies[subset_id] = \";\".join(list(vocabulary.output.values))\n",
    "\n",
    "for index in list(documents.index) :\n",
    "    dataset_id = documents.loc[index, 'dataset_id']\n",
    "    text_id = documents.loc[index, 'text_id']\n",
    "    text_input = documents.loc[index, 'input']\n",
    "    if dataset_id == 'semeval':\n",
    "        subsets = ['author', 'reader']\n",
    "    elif dataset_id == 'inspec':\n",
    "        subsets = ['controlled', 'uncontrolled']\n",
    "    elif dataset_id == 'termith-eval':\n",
    "        subsets = ['indexer']\n",
    "    for subset_id in subsets:\n",
    "        vocabulary = vocabularies[subset_id]\n",
    "\n",
    "        generator = KeyVD()\n",
    "        generator.load_vocabulary(vocabulary=vocabulary)\n",
    "        generator.load_text(text=text_input)\n",
    "\n",
    "        result = pandas.DataFrame({'model_id' : [model_id + '_' + subset_id], 'dataset_id' : [dataset_id], 'text_id' : [text_id]})\n",
    "        for top in tops :\n",
    "            predictions = generator.keywords_generation(n_keys=top)\n",
    "            result[f\"predictions_{top}\"] = ';'.join(predictions)\n",
    "\n",
    "        results = pandas.concat([results, result])\n",
    "\n",
    "    # We take snapshots every 100 inputs or when the model has finished predicting all inputs.\n",
    "    if index%100 == 0 or index == list(documents.index)[-1]:\n",
    "        # Print current status of the pipeline, uncomment if interested\n",
    "        #print(f'model_id: {model_id}_{subset_id}\\ninput: {dataset_id}_{text_id}\\n% done: {100 * index/len(documents)}')\n",
    "        if variables['USE_GCP'] != \"false\":\n",
    "            job = bq_client.load_table_from_dataframe(\n",
    "                dataframe = results, \n",
    "                destination = f\"{variables['PROJECT_ID']}.{variables['DATASET_ID']}.{variables['TABLE_PREDICTIONS_ID']}\"\n",
    "            )\n",
    "            job.result()\n",
    "        else:\n",
    "            results.to_csv(f\"{variables['TABLE_PREDICTIONS_ID']}.csv\", sep=\",\", mode='a', index=False, header=False)\n",
    "        results = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9efaa71-ead6-4a66-a923-0dded5ba63df",
   "metadata": {},
   "source": [
    "# computation times<a class=\"anchor\" id=\"timeit\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1250296b-7ff7-4090-8387-86c5cbf368ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter/notebooks\n",
    "documents = pandas.read_csv(f\"{variables['TABLE_INPUT_ID']}.csv\", sep=\",\")\n",
    "documents[documents['dataset_id'] == 'inspec']\n",
    "vocabulary = vocabularies['controlled']\n",
    "spacy_model = spacy.load(\"en_core_web_sm\")\n",
    "language = \"en\"\n",
    "top = 5\n",
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f40dd18-b6b4-40a3-a596-757d7159881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202 ms ± 23.6 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 10\n",
    "numpy.random.seed(n)\n",
    "index = numpy.random.randint(0, len(documents))\n",
    "text_input = documents.loc[index, 'input']\n",
    "\n",
    "generator = KeyVD()\n",
    "generator.load_vocabulary(vocabulary=vocabulary)\n",
    "generator.load_text(text=text_input)\n",
    "predictions = generator.keywords_generation(n_keys=top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8f4dba5-c749-44e3-ae7c-1601f05519cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 ms ± 21.1 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 10\n",
    "numpy.random.seed(n)\n",
    "index = numpy.random.randint(0, len(documents))\n",
    "text_input = documents.loc[index, 'input']\n",
    "\n",
    "extractor = TopicRank()\n",
    "extractor.load_document(input=text_input, language=language, spacy_model=spacy_model)\n",
    "extractor.candidate_selection()\n",
    "extractor.candidate_weighting()\n",
    "predictions = extractor.get_n_best(n=top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39f8a551-c1a9-468d-b7b4-bbd07627c27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 ms ± 1.5 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 10\n",
    "numpy.random.seed(n)\n",
    "index = numpy.random.randint(0, len(documents))\n",
    "text_input = documents.loc[index, 'input']\n",
    "\n",
    "extractor = YAKE()\n",
    "extractor.load_document(input=text_input, language=language, spacy_model=spacy_model)\n",
    "extractor.candidate_selection()\n",
    "extractor.candidate_weighting()\n",
    "predictions = extractor.get_n_best(n=top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0b77f36f-178d-4a8b-a4c1-350d3abcdccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 ms ± 1.39 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 10\n",
    "numpy.random.seed(n)\n",
    "index = numpy.random.randint(0, len(documents))\n",
    "text_input = documents.loc[index, 'input']\n",
    "\n",
    "extractor = MultipartiteRank()\n",
    "extractor.load_document(input=text_input, language=language, spacy_model=spacy_model)\n",
    "extractor.candidate_selection()\n",
    "extractor.candidate_weighting()\n",
    "predictions = extractor.get_n_best(n=top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "da5d9d39-a110-4b85-9e0a-1ca74f2ba1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31 s ± 10.4 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 10\n",
    "numpy.random.seed(n)\n",
    "index = numpy.random.randint(0, len(documents))\n",
    "text_input = documents.loc[index, 'input']\n",
    "\n",
    "extractor = TfIdf()\n",
    "extractor.load_document(input=text_input, language=language, spacy_model=spacy_model)\n",
    "extractor.candidate_selection()\n",
    "extractor.candidate_weighting()\n",
    "predictions = extractor.get_n_best(n=top)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
