dataset_id,text_id,input
inspec,dev_1461,adaptive multiresolution approach for solution of hyperbolic pdes. this paper establishes an innovative and efficient multiresolution adaptive approach combined with high resolution methods for the numerical solution of a single or a system of partial differential equations. the proposed methodology is unconditionally bounded even for hyperbolic equations and dynamically adapts the grid so that higher spatial resolution is automatically allocated to domain regions where strong gradients are observed thus possessing the two desired properties of a numerical approach stability and accuracy. numerical results for five test problems are presented which clearly show the robustness and cost effectiveness of the proposed method.
inspec,dev_1462,non linear analysis of nearly saturated porous media theoretical and numerical formulation. a formulation for a porous medium saturated with a compressible fluid undergoing large elastic and plastic deformations is presented. a consistent thermodynamic formulation is proposed for the two phase mixture problem thus preserving a straightforward and robust numerical scheme. a novel feature is the specification of the fluid compressibility in terms of a volumetric logarithmic strain which is energy conjugated to the fluid pressure in the entropy inequality. as a result the entropy inequality is used to separate three different mechanisms representing the response effective stress response according to terzaghi in the solid skeleton fluid pressure response to compressibility of the fluid and dissipative darcy flow representing the interaction between the two phases. the paper is concluded with a couple of numerical examples that display the predictive capabilities of the proposed formulation. in particular we consider results for the kinematically linear theory as compared to the kinematically non linear theory.
inspec,dev_1463,computational complexity of probabilistic disambiguation. recent models of natural language processing employ statistical reasoning for dealing with the ambiguity of formal grammars. in this approach statistics concerning the various linguistic phenomena of interest are gathered from actual linguistic data and used to estimate the probabilities of the various entities that are generated by a given grammar e g derivations parse trees and sentences. the extension of grammars with probabilities makes it possible to state ambiguity resolution as a constrained optimization formula which aims at maximizing the probability of some entity that the grammar generates given the input e g maximum probability parse tree given some input sentence. the implementation of these optimization formulae in efficient algorithms however does not always proceed smoothly. in this paper we address the computational complexity of ambiguity resolution under various kinds of probabilistic models. we provide proofs that some frequently occurring problems of ambiguity resolution are np complete. these problems are encountered in various applications e g language understanding for textand speech based applications. assuming the common model of computation this result implies that for many existing probabilistic models it is not possible to devise tractable algorithms for solving these optimization problems.
inspec,dev_1464,lr parsing for conjunctive grammars. the generalized lr parsing algorithm for context free grammars introduced by tomita in 1986 is a polynomial time implementation of nondeterministic lr parsing that uses graph structured stack to represent the contents of the nondeterministic parser s pushdown for all possible branches of computation at a single computation step. it has been specifically developed as a solution for practical parsing tasks arising in computational linguistics and indeed has proved itself to be very suitable for natural language processing. conjunctive grammars extend context free grammars by allowing the use of an explicit intersection operation within grammar rules. this paper develops a new lr style parsing algorithm for these grammars which is based on the very same idea of a graph structured pushdown where the simultaneous existence of several paths in the graph is used to perform the mentioned intersection operation. the underlying finite automata are treated in the most general way instead of showing the algorithm s correctness for some particular way of constructing automata the paper defines a wide class of automata usable with a given grammar which includes not only the traditional lr k automata but also for instance a trivial automaton with a single reachable state. a modification of the slr k table construction method that makes use of specific properties of conjunctive grammars is provided as one possible way of making finite automata to use with the algorithm.
inspec,dev_1465,p systems with symport antiport rules the traces of objects. we continue the study of those p systems where the computation is performed by the communication of objects that is systems with symport and antiport rules. instead of the number of objects collected in a specified membrane as the result of a computation we consider the itineraries of a certain object through membranes during a halting computation written as a coding of the string of labels of the visited membranes. the family of languages generated in this way is investigated with respect to its place in the chomsky hierarchy. when the symport and antiport rules are applied in a conditional manner promoted or inhibited by certain objects which should be present in the membrane where a rule is applied then a characterization of recursively enumerable languages is obtained the power of systems with the rules applied freely is only partially described.
inspec,dev_1466,feldkamp type image reconstruction from equiangular data. the cone beam approach for image reconstruction attracts increasing attention in various applications especially medical imaging. previously the traditional practical cone beam reconstruction method the feldkamp algorithm was generalized into the case of spiral helical scanning loci with equispatial cone beam projection data. in this paper we formulated the generalized feldkamp algorithm in the case of equiangular cone beam projection data and performed numerical simulation to evaluate the image quality. because medical multi slice cone beam ct scanners typically use equiangular projection data our new formula may be useful in this area as a framework for further refinement and a benchmark for comparison.
inspec,dev_1467,utilizing web based case studies for cutting edge information services issues. this article reports on a pilot study conducted by the academic libraries of the 21st century project team to determine whether the benefits of the case study method as a training framework for change initiatives could successfully transfer from the traditional face to face format to a virtual format. methods of developing the training framework as well as the benefits challenges and recommendations for future strategies gained from participant feedback are outlined. the results of a survey administered to chat session registrants are presented in three sections 1 evaluation of the training framework 2 evaluation of participants experiences in the virtual environment and 3 a comparison of participants preference of format. the overall participant feedback regarding the utilization of the case study method in a virtual environment for professional development and collaborative problem solving is very positive.
inspec,dev_1468,developing web enhanced learning for information fluency a liberal arts college s perspective. learning is likely to take a new form in the twenty first century and a transformation is already in process. under the framework of information fluency efforts are being made at rollins college to develop a web enhanced course that encompasses information literacy basic computer literacy and critical thinking skills. computer based education can be successful when librarians use technology effectively to enhance their integrated library teaching. in an online learning environment students choose a time for learning that best suits their needs and motivational levels. they can learn at their own pace take a nonlinear approach to the subject and maintain constant communication with instructors and other students. the quality of a technology facilitated course can be upheld if the educational objectives and methods for achieving those objectives are carefully planned and explored.
inspec,dev_1469,the necessity of real time fact and fiction in digital reference systems. current discussions and trends in digital reference have emphasized the use of real time digital reference services. recent articles have questioned both the utility and use of asynchronous services such as e mail. this article uses data from the askeric digital reference service to demonstrate that asynchronous services are not only useful and used but may have greater utility than real time systems.
inspec,dev_147,embedded linux and the law. the rising popularity of linux combined with perceived cost savings has spurred many embedded developers to consider a real time linux variant as an alternative to a traditional rtos. the paper presents the legal implications for the proprietary parts of firmware.
inspec,dev_1470,when reference works are not books the new edition of the guide to reference books. the author considers the history of the guide to reference books grb and its importance in librarianship. he discusses the ways in which the new edition is taking advantage of changing times. grb has become a cornerstone of the literature of u s librarianship. the biggest change grb will undergo to become grs guide to reference sources will be designing it primarily as a web product.
inspec,dev_1471,e commerce resources for doing business on the internet. there are many different types of e commerce depending upon who or what is selling and who or what is buying. in addition e commerce is more than an exchange of funds and goods or services it encompasses an entire infrastructure of services computer hardware and software products technologies and communications formats. the paper discusses e commerce terminology types and information resources including books and web sites.
inspec,dev_1472,surface textures improve the robustness of stereoscopic depth cues. this research develops design recommendations for surface textures patterns of color on object surfaces rendered with stereoscopic displays. in 3 method of adjustment procedure experiments 8 participants matched the disparity of a circular probe and a planar stimulus rendered using a single visible edge. the experiments varied stimulus orientation and surface texture. participants more accurately matched the depth of vertical stimuli than that of horizontal stimuli consistent with previous studies and existing theory. participants matched the depth of surfaces with large pixel to pixel luminance variations more accurately than they did surfaces with a small pixel to pixel luminance variation. finally they matched the depth of surfaces with vertical line patterns more accurately than they did surfaces with horizontal striped texture patterns. these results suggest that designers can enhance depth perception in stereoscopic displays and also reduce undesirable sensitivity to orientation by rendering objects with surface textures using large pixel to pixel luminance variations.
inspec,dev_1473,control performance with three translational degrees of freedom. for multiple degree of freedom dof systems it is important to determine how accurately operators can control each dof and what influence perceptual information processing and psychomotor components have on performance. sixteen right handed male students participated in 2 experiments 1 involving positioning and 1 involving tracking with 3 translational dofs. to separate perceptual and psychomotor effects we used 2 control display mappings that differed in the coupling of vertical and depth dimensions to the up down and fore aft control axes. we observed information processing effects in the positioning task initial error correction on the vertical dimension lagged in time behind the horizontal dimension. the depth dimension error correction lagged behind both which was ascribed to the poorer perceptual information. we observed this perceptual effect also in the tracking experiment. motor effects were also present with tracking errors along the up down axis of the hand controller being 1 1 times larger than along the fore aft axis. these results indicate that all 3 components contribute to control performance. actual applications of this research include interface design.
inspec,dev_1474,contrast sensitivity in a dynamic environment effects of target conditions and visual impairment. contrast sensitivity was determined as a function of target velocity 0 degrees 120 degrees s over a variety of viewing conditions. in experiment 1 measurements of dynamic contrast sensitivity were determined for observers as a function of target velocity for letter stimuli. significant main effects were found for target velocity target size and target duration but significant interactions among the variables indicated especially pronounced adverse effects of increasing target velocity for small targets and brief durations. in experiment 2 the effects of simulated cataracts were determined. although the simulated impairment had no effect on traditional acuity scores dynamic contrast sensitivity was markedly reduced. results are discussed in terms of dynamic contrast sensitivity as a useful composite measure of visual functioning that may provide a better overall picture of an individual s visual functioning than does traditional static acuity dynamic acuity or contrast sensitivity alone. the measure of dynamic contrast sensitivity may increase understanding of the practical effects of various conditions such as aging or disease on the visual system or it may allow improved prediction of individuals performance in visually dynamic situations.
inspec,dev_1475,relation between glare and driving performance. the present study investigated the effects of discomfort glare on driving behavior. participants old and young us and europeans were exposed to a simulated low beam light source mounted on the hood of an instrumented vehicle. participants drove at night in actual traffic along a track consisting of urban rural and highway stretches. the results show that the relatively low glare source caused a significant drop in detecting simulated pedestrians along the roadside and made participants drive significantly slower on dark and winding roads. older participants showed the largest drop in pedestrian detection performance and reduced their driving speed the most. the results indicate that the de boer rating scale the most commonly used rating scale for discomfort glare is practically useless as a predictor of driving performance. furthermore the maximum us headlamp intensity 1380 cd per headlamp appears to be an acceptable upper limit.
inspec,dev_1476,the perceived utility of human and automated aids in a visual detection task. although increases in the use of automation have occurred across society research has found that human operators often underutilize disuse and overly rely on misuse automated aids parasuraman riley 1997. nearly 275 cameron university students participated in 1 of 3 experiments performed to examine the effects of perceived utility dzindolet et al 2001 on automation use in a visual detection task and to compare reliance on automated aids with reliance on humans. results revealed a bias for human operators to rely on themselves. although self report data indicate a bias toward automated aids over human aids performance data revealed that participants were more likely to disuse automated aids than to disuse human aids. this discrepancy was accounted for by assuming human operators have a perfect automation schema. actual or potential applications of this research include the design of future automated decision aids and training procedures for operators relying on such aids.
inspec,dev_1477,ecological interface design progress and challenges. ecological interface design eid is a theoretical framework for designing human computer interfaces for complex socio technical systems. its primary aim is to support knowledge workers in adapting to change and novelty. this literature review shows that in situations requiring problem solving eid improves performance when compared with current design approaches in industry. eid has been applied to industry scale problems in a broad variety of application domains e g process control aviation computer network management software engineering medicine command and control and information retrieval and has consistently led to the identification of new information requirements. an experimental evaluation of eid using a full fidelity simulator with professional workers has yet to be conducted although some are planned. several significant challenges remain as obstacles to the confident use of eid in industry. promising paths for addressing these outstanding issues are identified. actual or potential applications of this research include improving the safety and productivity of complex socio technical systems.
inspec,dev_1478,the effects of work pace on within participant and between participant keying force electromyography and fatigue. a laboratory study was conducted to determine the effects of work pace on typing force electromyographic emg activity and subjective discomfort. we found that as participants typed faster their typing force and finger flexor and extensor emg activity increased linearly. there was also an increase in subjective discomfort with a sharp threshold between participants self selected pace and their maximum typing speed. the results suggest that participants self select a typing pace that maximizes typing speed and minimizes discomfort. the fastest typists did not produce significantly more finger flexor emg activity but did produce proportionately less finger extensor emg activity compared with the slower typists. we hypothesize that fast typists may use different muscle recruitment patterns that allow them to be more efficient than slower typists at striking the keys. in addition faster typists do not experience more discomfort than slow typists. these findings show that the relative pace of typing is more important than actual typing speed with regard to discomfort and muscle activity. these results suggest that typists may benefit from skill training to increase maximum typing speed. potential applications of this research includes skill training for typists.
inspec,dev_1479,agreeing with automated diagnostic aids a study of users concurrence strategies. automated diagnostic aids that are less than perfectly reliable often produce unwarranted levels of disuse by operators. in the present study users tendencies to either agree or disagree with automated diagnostic aids were examined under conditions in which 1 the aids were less than perfectly reliable but aided diagnosis was still more accurate that unaided diagnosis and 2 the system was completely opaque affording users no additional information upon which to base a diagnosis. the results revealed that some users adopted a strategy of always agreeing with the aids thereby maximizing the number of correct diagnoses made over several trials. other users however adopted a probability matching strategy in which agreement and disagreement rates matched the rate of correct and incorrect diagnoses of the aids. the probability matching strategy therefore resulted in diagnostic accuracy scores that were lower than was maximally possible. users who adopted the maximization strategy had higher self ratings of problem solving and decision making skills were more accurate in estimating aid reliabilities and were more confident in their diagnosis on trials in which they agreed with the aids. the potential applications of these findings include the design of interface and training solutions that facilitate the adoption of the most effective concurrence strategies by users of automated diagnostic aids.
inspec,dev_148,axioms for branching time. logics of general branching time or historical necessity have long been studied but important axiomatization questions remain open. here the difficulties of finding axioms for such logics are considered and ideas for solving some of the main open problems are presented. a new more expressive logical account is also given to support peirce s prohibition on truth values being attached to the contingent future.
inspec,dev_1480,formal verification of human automation interaction. this paper discusses a formal and rigorous approach to the analysis of operator interaction with machines. it addresses the acute problem of detecting design errors in human machine interaction and focuses on verifying the correctness of the interaction in complex and automated control systems. the paper describes a systematic methodology for evaluating whether the interface provides the necessary information about the machine to enable the operator to perform a specified task successfully and unambiguously. it also addresses the adequacy of information provided to the user via training materials e g user manual about the machine s behavior. the essentials of the methodology which can be automated and applied to the verification of large systems are illustrated by several examples and through a case study of pilot interaction with an autopilot aboard a modern commercial aircraft. the expected application of this methodology is an augmentation and enhancement by formal verification of human automation interfaces.
inspec,dev_1481,impact of aviation highway in the sky displays on pilot situation awareness. thirty six pilots 31 men 5 women were tested in a flight simulator on their ability to intercept a pathway depicted on a highway in the sky hits display. while intercepting and flying the pathway pilots were required to watch for traffic outside the cockpit. additionally pilots were tested on their awareness of speed altitude and heading during the flight. results indicated that the presence of a flight guidance cue significantly improved flight path awareness while intercepting the pathway but significant practice effects suggest that a guidance cue might be unnecessary if pilots are given proper training. the amount of time spent looking outside the cockpit while using the hits display was significantly less than when using conventional aircraft instruments. additionally awareness of flight information present on the hits display was poor. actual or potential applications of this research include guidance for the development of perspective flight display standards and as a basis for flight training requirements.
inspec,dev_1482,a parareal in time procedure for the control of partial differential equations. we have proposed in a previous note a time discretization for partial differential evolution equation that allows for parallel implementations. this scheme is here reinterpreted as a preconditioning procedure on an algebraic setting of the time discretization. this allows for extending the parallel methodology to the problem of optimal control for partial differential equations. we report a first numerical implementation that reveals a large interest.
inspec,dev_1483,hypothesis based concept assignment in software maintenance. software maintenance accounts for a significant proportion of the lifetime cost of a software system. software comprehension is required in many parts of the maintenance process and is one of the most expensive activities. many tools have been developed to help the maintainer reduce the time and cost of this task but of the numerous tools and methods available one group has received relatively little attention those using plausible reasoning to address the concept assignment problem. we present a concept assignment method for cobol ii hypothesis based concept assignment hb ca. an implementation of a prototype tool is described and results from a comprehensive evaluation using commercial cobol ii sources are summarised. in particular we identify areas of a standard maintenance process where such methods would be appropriate and discuss the potential cost savings that may result.
inspec,dev_1484,portfolio optimization and the random magnet problem. diversification of an investment into independently fluctuating assets reduces its risk. in reality movements of assets are mutually correlated and therefore knowledge of cross correlations among asset price movements are of great importance. our results support the possibility that the problem of finding an investment in stocks which exposes invested funds to a minimum level of risk is analogous to the problem of finding the magnetization of a random magnet. the interactions for this random magnet problem are given by the cross correlation matrix c of stock returns. we find that random matrix theory allows us to make an estimate for c which outperforms the standard estimate in terms of constructing an investment which carries a minimum level of risk.
inspec,dev_1485,telemedicine in the management of a cervical dislocation by a mobile neurosurgeon. neurosurgical teams who are normally located in specialist centres frequently use teleradiology to make a decision about the transfer of a patient to the nearest neurosurgical department. this decision depends on the type of pathology the clinical status of the patient and the prognosis. if the transfer of the patient is not possible for example because of an unstable clinical status a mobile neurosurgical team may be used. we report a case which was dealt with in a remote french military airborne surgical unit in the republic of chad. the unit which provides health care to the french military personnel stationed there also provides free medical care for the local population. it conducts about 100 operations each month. the unit comprises two surgeons an orthopaedic and a general surgeon one anaesthetist two anaesthetic nurses one operating room nurse two nurses three paramedics and a secretary. the civilian patient presented with unstable cervical trauma. a mobile neurosurgeon operated on her and used telemedicine before during and after surgery.
inspec,dev_1486,hand held digital video camera for eye examination and follow up. we developed a hand held digital colour video camera for eye examination in primary care. the device weighed 550 g. it featured a charge coupled device ccd and corrective optics. both colour video and digital still images could be taken. the video camera was connected to a pc with software for database storage image processing and telecommunication. we studied 88 normal subjects 38 male 50 female aged 7 62 years. it was not necessary to use mydriatic eye drops for pupillary dilation. satisfactory digital images of the whole face and the anterior eye were obtained. the optic disc and the central part of the ocular fundus could also be recorded. image quality of the face and the anterior eye were excellent image quality of the optic disc and macula were good enough for tele ophthalmology. further studies are needed to evaluate the usefulness of the equipment in different clinical conditions.
inspec,dev_1487,assessment of prehospital chest pain using telecardiology. two hundred general practitioners were equipped with a portable electrocardiograph which could transmit a 12 lead electrocardiogram ecg via a telephone line. a cardiologist was available 24 h a day for an interactive teleconsultation. in a 13 month period there were 5073 calls to the telecardiology service and 952 subjects with chest pain were identified. the telecardiology service allowed the general practitioners to manage 700 cases 74 themselves further diagnostic tests were requested for 162 patients 17 and 83 patients 9 were sent to the hospital emergency department. in the last group a cardiological diagnosis was confirmed in 60 patients and refuted in 23. seven patients in whom the telecardiology service failed to detect a cardiac problem were hospitalized in the subsequent 48 h. the telecardiology service showed a sensitivity of 97 4  a specificity of 89 5 and a diagnostic accuracy of 86 9 for chest pain. telemedicine could be a useful tool in the diagnosis of chest pain in primary care.
inspec,dev_1488,social presence in telemedicine. we studied consultations between a doctor emergency nurse practitioners enps and their patients in a minor accident and treatment service mats. in the conventional consultations all three people were located at the main hospital. in the teleconsultations the doctor was located in a hospital 6 km away from the mats and used a videoconferencing link connected at 384 kbit s. there were 30 patients in the conventional group and 30 in the telemedical group. the presenting problems were similar in the two groups. the mean duration of teleconsultations was 951 s and the mean duration of face to face consultations was 247 s. in doctor nurse communication there was a higher rate of turn taking in teleconsultations than in face to face consultations there were also more interruptions more words and more backchannels e g mhm  uh huh per teleconsultation. in doctor patient communication there was a higher rate of turn taking more words more interruptions and more backchannels per teleconsultation. in patient nurse communication there was. relatively little difference between the two modes of consulting the doctor. telemedicine appeared to empower the patient to ask more questions of the doctor. it also seemed that the doctor took greater care in a teleconsultation to achieve coordination of beliefs with the patient than in a face to face consultation.
inspec,dev_1489,an eight year study of internet based remote medical counselling. we carried out a prospective study of an internet based remote counselling service. a total of 15 456 internet users visited the web site over eight years. from these 1500 users were randomly selected for analysis. medical counselling had been granted to 901 of the people requesting it 60. one hundred and sixty four physicians formed project groups to process the requests and responded using email. the distribution of patients using the service was similar to the availability of the internet 78 were from the european union north america and australia. sixty seven per cent of the patients lived in urban areas and the remainder were residents of remote rural areas with limited local medical coverage. sixty five per cent of the requests were about problems of internal medicine and 30 of the requests concerned surgical issues. the remaining 5 of the patients sought information about recent developments such as molecular medicine or aviation medicine. during the project our portal became inaccessible five times and counselling was not possible on 44 days. there was no hacking of the web site. internet based medical counselling is a helpful addition to conventional practice.
inspec,dev_149,extending kamp s theorem to model time granularity. in this paper a generalization of kamp s theorem relative to the functional completeness of the until operator is proved. such a generalization consists in showing the functional completeness of more expressive temporal operators with respect to the extension of the first order theory of linear orders mfo with an extra binary relational symbol. the result is motivated by the search of a modal language capable of expressing properties and operators suitable to model time granularity in omega layered temporal structures.
inspec,dev_1490,client satisfaction in a feasibility study comparing face to face interviews with telepsychiatry. we carried out a pilot study comparing satisfaction levels between psychiatric patients seen face to face ftf and those seen via videoconference. patients who consented were randomly assigned to one of two groups. one group received services in person ftf from the visiting psychiatrist while the other was seen using videoconferencing at 128 kbit s. one psychiatrist provided all the ftf and videoconferencing assessment and follow up visits. a total of 24 subjects were recruited. three of the subjects 13 did not attend their appointments and two subjects in each group were lost to follow up. thus there were nine in the ftf group and eight in the videoconferencing group. the two groups were similar in most respects. patient satisfaction with the services was assessed using the client satisfaction questionnaire csq 8 completed four months after the initial consultation. the mean scores were 25 3 in the ftf group and 21 6 in the videoconferencing group. although there was a trend in favour of the ftf service the difference was not significant. patient satisfaction is only one component of evaluation. the efficacy of telepsychiatry must also be measured relative to that of conventional ftf care before policy makers can decide how extensively telepsychiatry should be implemented.
inspec,dev_1491,evaluation of videoconferenced grand rounds. we evaluated various aspects of grand rounds videoconferenced from a tertiary care hospital to a regional hospital in nova scotia. during a five month study period 29 rounds were broadcast 19 in medicine and 10 in cardiology. the total recorded attendance at the remote site was 103 comprising 70 specialists nine family physicians and 24 other health care professionals. we received 55 evaluations a response rate of 53. on a five point likert scale on which higher scores indicated better quality mean ratings by remote site participants of the technical quality of the videoconference were 3 0 3 5 with the lowest ratings being for ability to hear the discussion 3 0 and to see visual aids 3 1. mean ratings for content presentation discussion and educational value were 3 8 or higher. of the 49 physicians who presented the rounds we received evaluations from 41 a response rate of 84. the presenters rated all aspects of the videoconference and interaction with remote sites at 3 8 or lower. the lowest ratings were for ability to see the remote sites 3 0 and the usefulness of the discussion 3 4. we received 278 evaluations from participants at the presenting site an estimated response rate of about 55. the results indicated no adverse opinions of the effect of videoconferencing mean scores 3 1 3 3. the estimated costs of videoconferencing one grand round to one site and four sites were c 723 and c 1515 respectively. the study confirmed that videoconferenced rounds can provide satisfactory continuing medical education to community specialists which is an especially important consideration as maintenance of certification becomes mandatory.
inspec,dev_1492,a systematic review of the efficacy of telemedicine for making diagnostic and management decisions. we conducted a systematic review of the literature to evaluate the efficacy of telemedicine for making diagnostic and management decisions in three classes of application office hospital based store and forward and home based telemedicine. we searched the medline embase cinahl and healthstar databases and printed resources and interviewed investigators in the field. we excluded studies where the service did not historically require face to face encounters e g radiology or pathology diagnosis. a total of 58 articles met the inclusion criteria. the articles were summarized and graded for the quality and direction of the evidence. there were very few high quality studies. the strongest evidence for the efficacy of telemedicine for diagnostic and management decisions came from the specialties of psychiatry and dermatology. there was also reasonable evidence that general medical history and physical examinations performed via telemedicine had relatively good sensitivity and specificity. other specialties in which some evidence for efficacy existed were cardiology and certain areas of ophthalmology. despite the widespread use of telemedicine in most major medical specialties there is strong evidence in only a few of them that the diagnostic and management decisions provided by telemedicine are comparable to face to face care.
inspec,dev_1493,research into telehealth applications in speech language pathology. a literature review was conducted to investigate the extent to which telehealth has been researched within the domain of speech language pathology and the outcomes of this research. a total of 13 studies were identified. three early studies demonstrated that telehealth was feasible although there was no discussion of the cost effectiveness of this process in terms of patient outcomes. the majority of the subsequent studies indicated positive or encouraging outcomes resulting from telehealth. however there were a number of shortcomings in the research including a lack of cost benefit information failure to evaluate the technology itself an absence of studies of the educational and informational aspects of telehealth in relation to speech language pathology and the use of telehealth in a limited range of communication disorders. future research into the application of telehealth to speech language pathology services must adopt a scientific approach and have a well defined development and evaluation framework that addresses the effectiveness of the technique patient outcomes and satisfaction and the cost benefit relationship.
inspec,dev_1494,where have all the pc makers gone. pc makers are dwindling. if you are planning to make a pc purchase soon here are a few things to look out for before you buy.
inspec,dev_1495,laptops zip to 2 ghz plus. intel s pentium 4 m processor has reached the coveted 2 ghz mark and speed hungry mobile users will be tempted to buy a laptop with the chip. however while our exclusive tests found 2 ghz p4 m notebooks among the fastest units we ve tested the new models failed to make dramatic gains compared with those based on intel s 1 8 ghz mobile chip. since 2 ghz notebooks carry a hefty price premium buyers seeking both good performance and a good price might prefer a 1 8 ghz unit instead.
inspec,dev_1496,web ad explosion. financed by advertising dollars from big names online marketers are embracing more aggressive tactics.
inspec,dev_1497,research challenges and perspectives of the semantic web. accessing documents and services on today s web requires human intelligence. the interface to these documents and services is the web page written in natural language which humans must understand and act upon. the paper discusses the semantic web which will augment the current web with formalized knowledge and data that computers can process. in the future some services will mix human readable and structured data so that both humans and computers can use them. others will support formalized knowledge that only machines will use.
inspec,dev_1498,john mccarthy father of ai. if john mccarthy the father of ai were to coin a new phrase for artificial intelligence today he would probably use computational intelligence. mccarthy is not just the father of ai he is also the inventor of the lisp list processing language. the author considers mccarthy s conception of lisp and discusses mccarthy s recent research that involves elaboration tolerance creativity by machines free will of machines and some improved ways of doing situation calculus.
inspec,dev_1499,a digital driving system for smart vehicles. in the wake of the computer and information technology revolutions vehicles are undergoing dramatic changes in their capabilities and how they interact with drivers. although some vehicles can decide to either generate warnings for the human driver or control the vehicle autonomously they must usually make these decisions in real time with only incomplete information. so human drivers must still maintain control over the vehicle. i sketch a digital driving behavior model. by simulating and analyzing driver behavior during different maneuvers such as lane changing lane following and traffic avoidance researchers participating in the beijing institute of technology s digital driving project will be able to examine the possible correlations or causal relations between the smart vehicle iviss the intelligent road traffic information network and the driver. we aim to successfully demonstrate that a digital driving system can provide a direction for developing human centered smart vehicles.
inspec,dev_15,optimal and safe ship control as a multi step matrix game. the paper describes the process of the safe ship control in a collision situation using a differential game model with j participants. as an approximated model of the manoeuvring process a model of a multi step matrix game is adopted here. risktraj computer program is designed in the matlab language in order to determine the ship s trajectory as a certain sequence of manoeuvres executed by altering the course and speed in the online navigator decision support system. these considerations are illustrated with examples of a computer simulation of the safe ship s trajectories in real situation at sea when passing twelve of the encountered objects.
inspec,dev_150,model checking games for branching time logics. this paper defines and examines model checking games for the branching time temporal logic ctl. the games employ a technique called focus which enriches sets by picking out one distinguished element. this is necessary to avoid ambiguities in the regeneration of temporal operators. the correctness of these games is proved and optimizations are considered to obtain model checking games for important fragments of ctl. a game based model checking algorithm that matches the known lower and upper complexity bounds is sketched.
inspec,dev_1500,daml oil an ontology language for the semantic web. by all measures the web is enormous and growing at a staggering rate which has made it increasingly difficult and important for both people and programs to have quick and accurate access to web information and services. the semantic web offers a solution capturing and exploiting the meaning of terms to transform the web from a platform that focuses on presenting information to a platform that focuses on understanding and reasoning with information. to support semantic web development the us defense advanced research projects agency launched the darpa agent markup language daml initiative to fund research in languages tools infrastructure and applications that make web content more accessible and understandable. although the us government funds daml several organizations including us and european businesses and universities and international consortia such as the world wide web consortium have contributed to work on issues related to daml s development and deployment. we focus on daml s current markup language daml oil which is a proposed starting point for the w3c s semantic web activity s ontology web language owl. we introduce daml oil syntax and usage through a set of examples drawn from a wine knowledge base used to teach novices how to build ontologies.
inspec,dev_1501,computational challenges in cell simulation a software engineering approach. molecular biology s advent in the 20th century has exponentially increased our knowledge about the inner workings of life. we have dozens of completed genomes and an array of high throughput methods to characterize gene encodings and gene product operation. the question now is how we will assemble the various pieces. in other words given sufficient information about a living cell s molecular components can we predict its behavior. we introduce the major classes of cellular processes relevant to modeling discuss software engineering s role in cell simulation and identify cell simulation requirements. our e cell project aims to develop the theories techniques and software platforms necessary for whole cell scale modeling simulation and analysis. since the project s launch in 1996 we have built a variety of cell models and we are currently developing new models that vary with respect to species target subsystem and overall scale.
inspec,dev_1502,mining open answers in questionnaire data. surveys are important tools for marketing and for managing customer relationships the answers to open ended questions in particular often contain valuable information and provide an important basis for business decisions. the summaries that human analysts make of these open answers however tend to rely too much on intuition and so are n t satisfactorily reliable. moreover because the web makes it so easy to take surveys and solicit comments companies are finding themselves inundated with data from questionnaires and other sources. handling it all manually would be not only cumbersome but also costly. thus devising a computer system that can automatically mine useful information from open answers has become an important issue. we have developed a survey analysis system that works on these principles. the system mines open answers through two statistical learning techniques rule learning which we call rule analysis and correspondence analysis.
inspec,dev_1503,neural networks for web content filtering. with the proliferation of harmful internet content such as pornography violence and hate messages effective content filtering systems are essential. many web filtering systems are commercially available and potential users can download trial versions from the internet. however the techniques these systems use are insufficiently accurate and do not adapt well to the ever changing web. to solve this problem we propose using artificial neural networks to classify web pages during content filtering. we focus on blocking pornography because it is among the most prolific and harmful web content. however our general framework is adaptable for filtering other objectionable web material.
inspec,dev_1504,designing human centered distributed information systems. many computer systems are designed according to engineering and technology principles and are typically difficult to learn and use. the fields of human computer interaction interface design and human factors have made significant contributions to ease of use and are primarily concerned with the interfaces between systems and users not with the structures that are often more fundamental for designing truly human centered systems. the emerging paradigm of human centered computing hcc which has taken many forms offers a new look at system design. hcc requires more than merely designing an artificial agent to supplement a human agent. the dynamic interactions in a distributed system composed of human and artificial agents and the context in which the system is situated are indispensable factors. while we have successfully applied our methodology in designing a prototype of a human centered intelligent flight surgeon console at nasa johnson space center this article presents a methodology for designing human centered computing systems using electronic medical records emr systems.
inspec,dev_1505,modeling and simulating practices a work method for work systems design. work systems involve people engaging in activities over time not just with each other but also with machines tools documents and other artifacts. these activities often produce goods services or as is the case in the work system described in this article scientific data. work systems and work practice evolve slowly over time. the integration and use of technology the distribution and collocation of people organizational roles and procedures and the facilities where the work occurs largely determine this evolution.
inspec,dev_1506,intelligent control of life support for space missions. future manned space operations will include a greater use of automation than we currently see. for example semiautonomous robots and software agents will perform difficult tasks while operating unattended most of the time. as these automated agents become more prevalent human contact with them will occur more often and become more routine so designing these automated agents according to the principles of human centered computing is important. we describe two cases of semiautonomous control software developed and fielded in test environments at the nasa johnson space center. this software operated continuously at the jsc and interacted closely with humans for months at a time.
inspec,dev_1507,ethnography customers and negotiated interactions at the airport. in the late 1990s tightly coordinated airline schedules unraveled owing to massive delays resulting from inclement weather overbooked flights and airline operational difficulties. as schedules slipped the delayed departures and late arrivals led to systemwide breakdowns customers missed their connections and airline work activities fell further out of sync. in offering possible answers we emphasize the need to consider the customer as participant following the human centered computing model. our study applied ethnographic methods to understand the airline system domain and the nature of airline delays and it revealed the deficiencies of the airline production system model of operations. the research insights that led us to shift from a production and marketing system perspective to a customer as participant view might appear obvious to some readers. however we do not know of any airline that designs its operations and technologies around any other model than the production and marketing system view. our human centered analysis used ethnographic methods to gather information offering new insight into airline delays and suggesting effective ways to improve operations reliability.
inspec,dev_1508,rats robots and rescue. in early may media inquiries started arriving at my office at the center for robot assisted search and rescue www crasar org. because i m crasar s director i thought the press was calling to follow up on the recent humanitarian award given to the center s founder john blitch for successfully using small backpackable robots at the world trade center disaster. instead i found they were asking me to comment on the roborats study in the 2 may 2002 nature. in this study rats with medial force brain implants underwent operant conditioning to force them into a form of guided behavior one aspect of which was thought useful for search and rescue. the article s closing comment suggested that a guided rat could serve as both a mobile robot and a biological sensor. although a roboticist by training i m committed to any technology that will help save lives while reducing the risk to rescuers. but rats.
inspec,dev_1509,mathematical modelling of the work of the system of wells in a layer with the exponential law of permeability variation and the mobile liquid interface. we construct and study a two dimensional model of the work of the system of wells in a layer with the mobile boundary between liquids of various viscosity. we use a plunger displacement model of liquids. the boundaries of the filtration region of these liquids are modelled by curves of the lyapunov class. unlike familiar work we solve two dimensonal problems in an inhomogeneous layer when the mobile boundary and the boundaries of the filtration region are modelled by curves of the lyapunov class. we show the practical convergence of the numerical solution of the problems studied.
inspec,dev_151,extending ctl with actions and real time. in this paper we present the logic atctl which is intended to be used for model checking models that have been specified in a lightweight version of the unified modelling language uml. elsewhere we have defined a formal semantics for luml to describe the models. this paper s goal is to give a specification language for properties that fits luml luml includes states actions and real time. atctl extends ctl with concurrent actions and real time. it is based on earlier extensions of ctl by r de nicola and f vaandrager actl 1990 and r alur et al tctl 1993. this makes it easier to adapt existing model checkers to atctl. to show that we can check properties specified in atctl in models specified in luml we give a small example using the kronos model checker.
inspec,dev_1510,estimation of the gradient of the solution of an adjoint diffusion equation by the monte carlo method. for the case of isotropic diffusion we consider the representation of the weighted concentration of trajectories and its space derivatives in the form of integrals with some weights of the solution to the corresponding boundary value problem and its directional derivative of a convective velocity. if the convective velocity at the domain boundary is degenerate and some other additional conditions are imposed this representation allows us to construct an efficient random walk by spheres and balls algorithm. when these conditions are violated transition to modelling the diffusion trajectories by the euler scheme is realized and the directional derivative of velocity is estimated by the dependent testing method using the parallel modelling of two closely spaced diffusion trajectories. we succeeded in justifying this method by statistically equivalent transition to modelling a single trajectory after the first step in the euler scheme using a suitable weight. this weight also admits direct differentiation with respect to the initial coordinate along a given direction. the resulting weight algorithm for calculating concentration derivatives is especially efficient if the initial point is in the subdomain in which the coefficients of the diffusion equation are constant.
inspec,dev_1511,efficient algorithms for stiff elliptic problems with large parameters. we consider a finite element approximation and iteration algorithms for solving stiff elliptic boundary value problems with large parameters in front of a higher derivative. the convergence rate of the algorithms is independent of the spread in coefficients and a discretization parameter.
inspec,dev_1512,mathematical aspects of computer aided share trading. we consider problems of statistical analysis of share prices and propose probabilistic characteristics to describe the price series. we discuss three methods of mathematical modelling of price series with given probabilistic characteristics.
inspec,dev_1513,solution of the reconstruction problem of a source function in the coagulation fragmentation equation. we study the problem of reconstructing a source function in the kinetic coagulation fragmentation equation. the study is based on optimal control methods the solvability theory of operator equations and the use of iteration algorithms.
inspec,dev_1514,universal parametrization in constructing smoothly connected b spline surfaces. in this paper we explore the feasibility of universal parametrization in generating b spline surfaces which was proposed recently in the literature lim 1999. we present an interesting property of the new parametrization that it guarantees go continuity on b spline surfaces when several independently constructed patches are put together without imposing any constraints. also a simple blending method of patchwork is proposed to construct c sup n 1 surfaces where overlapping control nets are utilized. it takes into account the semi localness property of universal parametrization. it effectively helps us construct very natural looking b spline surfaces while keeping the deviation from given data points very low. experimental results are shown with several sets of surface data points.
inspec,dev_1515,p bezier curves spirals and sectrix curves. we elucidate the connection between bezier curves in polar coordinates also called p bezier or focal bezier curves and certain families of spirals and sectrix curves. p bezier curves are the analogue in polar coordinates of nonparametric bezier curves in cartesian coordinates. such curves form a subset of rational bezier curves characterized by control points on radial directions regularly spaced with respect to the polar angle and weights equal to the inverse of the polar radius. we show that this subset encompasses several classical sectrix curves which solve geometrically the problem of dividing an angle into equal spans and also spirals defining the trajectories of particles in central fields. first we identify as p bezier curves a family of sinusoidal spirals that includes tschirnhausen s cubic. second the trisectrix of maclaurin and their generalizations called arachnidas. finally a special class of epi spirals that encompasses the trisectrix of delanges.
inspec,dev_1516,using duality to implicitize and find cusps and inflection points of bezier curves. a planar algebraic curve c has an implicit equation and a tangential equation. the tangential equation defines a dual curve to c starting with a parametrization of c we find a parametrization of the dual curve and the tangential equation and implicit equation of c in a novel way. we also find equations whose roots are the parameter values of the cusps and inflection points of c methods include polar reciprocation and the theory of envelopes.
inspec,dev_1517,minimizing blossoms under symmetric linear constraints. in this paper we show that there exists a close dependence between the control polygon of a polynomial and the minimum of its blossom under symmetric linear constraints. we consider a given minimization problem p for which a unique solution will be a point delta on the bezier curve. for the minimization function f two sufficient conditions exist that ensure the uniqueness of the solution namely the concavity of the control polygon of the polynomial and the characteristics of the polya frequency control polygon where the minimum coincides with a critical point of the polynomial. the use of the blossoming theory provides us with a useful geometrical interpretation of the minimization problem. in addition this minimization approach leads us to a new method of discovering inequalities about the elementary symmetric polynomials.
inspec,dev_1518,explicit matrix representation for nurbs curves and surfaces. the matrix forms for curves and surfaces were largely promoted in cad cam. in this paper we have presented two matrix representation formulations for arbitrary degree nurbs curves and surfaces explicitly other than recursively. the two approaches are derived from the computation of divided difference and the marsden identity respectively. the explicit coefficient matrix of b spline with equally spaced knot and bezier curves and surfaces can be obtained by these formulae. the coefficient formulae and the coefficient matrix formulae developed in this paper express non uniform b spline functions of arbitrary degree in explicit polynomial and matrix forms.. they are useful for the evaluation and the conversion of nurbs curves and surfaces in cad cam systems.
inspec,dev_1519,structural invariance of spatial pythagorean hodographs. the structural invariance of the four polynomial characterization for three dimensional pythagorean hodographs introduced by dietz et al 1993 under arbitrary spatial rotations is demonstrated. the proof relies on a factored quaternion representation for pythagorean hodographs in three dimensional euclidean space a particular instance of the ph representation map proposed by choi et al 2002 and the unit quaternion description of spatial rotations. this approach furnishes a remarkably simple derivation for the polynomials u t upsilon t p t q t that specify the canonical form of a rotated pythagorean hodograph in terms of the original polynomials u t upsilon t p t q t and the angle theta and axis n of the spatial rotation. the preservation of the canonical form of ph space curves under arbitrary spatial rotations is essential to their incorporation into computer aided design and manufacturing applications such as the contour machining of free form surfaces using a ball end mill and realtime ph curve cnc interpolators.
inspec,dev_152,linear tense logics of increasing sets. we provide an extension of the language of linear tense logic with future and past connectives f and p respectively by a modality that quantifies over the points of some set which is assumed to increase in the course of time. in this way we obtain a general framework for modelling growth qualitatively. we develop an appropriate logical system prove a corresponding completeness and decidability result and discuss the various kinds of flow of time in the new context. we also consider decreasing sets briefly.
inspec,dev_1520,uniform hyperbolic polynomial b spline curves. this paper presents a new kind of uniform splines called hyperbolic polynomial b splines generated over the space omega span sinh t cosh t t sup k 3  t sup k 3  t sup k 4   t 1 in which k is an arbitrary integer larger than or equal to 3. hyperbolic polynomial b splines share most of the properties of b splines in polynomial space. we give subdivision formulae for this new kind of curve and then prove that they have variation diminishing properties and the control polygons of the subdivisions converge. hyperbolic polynomial b splines can handle freeform curves as well as remarkable curves such as the hyperbola and the catenary. the generation of tensor product surfaces using these new splines is straightforward. examples of such tensor product surfaces the saddle surface the catenary cylinder and a certain kind of ruled surface are given.
inspec,dev_1521,optimal multi degree reduction of bezier curves with constraints of endpoints continuity. given a bezier curve of degree n the problem of optimal multi degree reduction degree reduction of more than one degree by a bezier curve of degree m m n 1 with constraints of endpoint continuity is investigated. with respect to l sub 2 norm this paper presents an approximate method mdr by l sub 2 that gives an explicit solution to deal with it. the method has good properties of endpoint interpolation continuity of any r s r s or 0 orders can be preserved at two endpoints respectively. the method in the paper performs multi degree reduction at one time and does not need stepwise computing. when applied to multi degree reduction with endpoint continuity of any order the mdr by l sub 2 obtains the best least squares approximation. comparison with another method of multi degree reduction mdr by l sub infinity  which achieves the nearly best uniform approximation with respect to l sub infinity norm is also given. the approximate effect of the mdr by l sub 2 is better than that of the mdr by l sub infinity. explicit approximate error analysis of the multi degree reduction methods is presented.
inspec,dev_1522,waltzing through port 80 web security. web services follow the trusting model of the internet but allow ever more powerful payloads to travel between businesses and consumers. before you leap online the author advises to scan the security concerns and the available fixes. he looks at how we define and store web services and incorporate them into business processes.
inspec,dev_1523,process specialization defining specialization for state diagrams. a precise definition of specialization and inheritance promises to be as useful in organizational process modeling as it is in object modeling. it would help us better understand maintain reuse and generate process models. however even though object oriented analysis and design methodologies take full advantage of the object specialization hierarchy the process specialization hierarchy is not supported in major process representations such as the state diagram data flow diagram and uml representations. partly underlying this lack of support is an implicit assumption that we can always specialize a process by treating it as just another object. we argue in this paper that this is not so straightforward as it might seem we argue that a process specific approach must be developed. we propose such an approach in the form of a set of transformations which when applied to a process description always result in specialization. we illustrate this approach by applying it to the state diagram representation and demonstrate that this approach to process specialization is not only theoretically possible but shows promise as a method for categorizing and analyzing processes. we point out apparent inconsistencies between our notion of process specialization and existing work on object specialization but show that these inconsistencies are superficial and that the definition we provide is compatible with the traditional notion of specialization.
inspec,dev_1524,organizational design information transfer and the acquisition of rent producing resources. within the resource based view of the firm a dynamic story has emerged in which the knowledge accumulated over the history of a firm and embedded in organizational routines and structures influences the firm s ability to recognize the value of new resources and capabilities. this paper explores the possibility of firms to select organizational designs that increase the likelihood that they will recognize and value rent producing resources and capabilities. a computational model is developed to study the tension between an organization s desire to explore its environment for new capabilities and the organization s need to exploit existing capabilities. support is provided for the proposition that integration both externally and internally is an important source of dynamic capability. the model provides greater insight into the tradeoffs between these two forms of integration and suggests when one form may be preferred over another. in particular evidence is provided that in uncertain environments the ability to explore possible alternatives is critical while in more certain environments the ability to transfer information internally is paramount.
inspec,dev_1525,dependence graphs dependence within and between groups. this paper applies the two party dependence theory castelfranchi cesta and miceli 1992 in y demazeau and e werner eds. decentralized ai 3 elsevier north holland to modelling multiagent and group dependence. these have theoretical potentialities for the study of emerging groups and collective structures and more generally for understanding social and organisational complexity and practical utility for both social organisational and agent systems purposes. in the paper the dependence theory is extended to describe multiagent links with a special reference to group and collective phenomena and is proposed as a framework for the study of emerging social structures such as groups and collectives. in order to do so we propose to extend the notion of dependence networks applied to a single agent to dependence graphs applied to an agency. in its present version the dependence theory is argued to provide a a theoretical instrument for the study of social complexity and b a computational system for managing the negotiation process in competitive contexts and for monitoring complexity in organisational and other cooperative contexts.
inspec,dev_1526,gk devs geometric and kinematic devs formalism for simulation modeling of 3 dimensional multi component systems. a combined discrete continuous simulation methodology based on the devs discrete event system specification formalism is presented in this paper that satisfies the simulation requirements of 3 dimensional and dynamic systems with multi components. we propose a geometric and kinematic devs gk devs formalism that is able to describe the geometric and kinematic structure of a system and its continuous state dynamics as well as the interaction among the multi components. to establish one model having dynamic behavior and a particular hierarchical structure the atomic and the coupled model of the conventional devs are merged into one model in the proposed formalism. for simulation of the continuous motion of 3 d components the sequential state set is partitioned into the discrete and the continuous state set and the rate of change function over the continuous state set is employed. although modified from the conventional devs formalism the gk devs formalism preserves a hierarchical modular modeling fashion and a coupling scheme. furthermore for the gk devs model simulation we propose an abstract simulation algorithm called a gk simulator in which data and control are separated and events are scheduled not globally but hierarchically so that an object oriented principle is satisfied. the proposed gk devs formalism and the gk simulator algorithm have been applied to the simulation of a flexible manufacturing system consisting of a 2 axis lathe a 3 axis milling machine and a vehicle mounted robot.
inspec,dev_1527,using devs formalism to operationalize elp models for diagnosis in sachem. this paper describes an original approach to discrete event control of continuous processes by means of expert knowledge. we present an application of this approach on the sachem diagnosis subsystem. the sachem system is a large scale knowledge based system that aims in helping a set of operators to control the dynamics of complex continuous systems e g blast furnaces. the proposed method is based on i the definition of a language facilitating the acquisition and representation of expert knowledge called elp expert language process ii the use of the devs formalism to make elp models operational iii algorithms for exploiting operational models.
inspec,dev_1528,devs simulation of distributed intrusion detection systems. an intrusion detection system ids attempts to identify unauthorized use misuse and abuse of computer and network systems. as intrusions become more sophisticated dealing with them moves beyond the scope of one ids. the need arises for systems to cooperate with one another to manage diverse attacks across networks. the feature of recent attacks is that the packet delivery is moderately slow and the attack sources and attack targets are distributed. these attacks are called stealthy attacks. to detect these attacks the deployment of distributed idss is needed. in such an environment the ability of an ids to share advanced information about these attacks is especially important. in this research the ids model exploits blacklist facts to detect the attacks that are based on either slow or highly distributed packets. to maintain the valid blacklist facts in the knowledge base of each ids the model should communicate with the other idss. when attack level goes beyond the interaction threshold id agents send interaction messages to id agents in other hosts. each agent model is developed as an interruptible atomic expert model in which the expert system is embedded as a model component.
inspec,dev_1529,quantized state systems a devs approach for continuous system simulation. a new class of dynamical systems quantized state systems or qss is introduced in this paper. qss are continuous time systems where the input trajectories are piecewise constant functions and the state variable trajectories being themselves piecewise linear functions are converted into piecewise constant functions via a quantization function equipped with hysteresis. it is shown that qss can be exactly represented and simulated by a discrete event model within the framework of the devs approach. further it is shown that qss can be used to approximate continuous systems thus allowing their discrete event simulation in opposition to the classical discrete time simulation. it is also shown that in an approximating qss some stability properties of the original system are conserved and the solutions of the qss go to the solutions of the original system when the quantization goes to zero.
inspec,dev_153,on the relationship between omega automata and temporal logic normal forms. we consider the relationship between omega automata and a specific logical formulation based on a normal form for temporal logic formulae. while this normal form was developed for use with execution and clausal resolution in temporal logics we show how it can represent syntactically omega automata in a high level way. technical proofs of the correctness of this representation are given.
inspec,dev_1530,uniform supersaturated design and its construction. supersaturated designs are factorial designs in which the number of main effects is greater than the number of experimental runs. in this paper a discrete discrepancy is proposed as a measure of uniformity for supersaturated designs and a lower bound of this discrepancy is obtained as a benchmark of design uniformity. a construction method for uniform supersaturated designs via resolvable balanced incomplete block designs is also presented along with the investigation of properties of the resulting designs. the construction method shows a strong link between these two different kinds of designs.
inspec,dev_1531,average optimization of the approximate solution of operator equations and its application. in this paper a definition of the optimization of operator equations in the average case setting is given. and the general result about the relevant optimization problem is obtained. this result is applied to the optimization of approximate solution of some classes of integral equations.
inspec,dev_1532,dedekind zeta functions and dedekind sums. in this paper we use dedekind zeta functions of two real quadratic number fields at 1 to denote dedekind sums of high rank. our formula is different from that of siegel s 1969. as an application we get a polynomial representation of zeta sub k 1 zeta sub k 1 1 45 26n sup 3  41n or 9 n identical to or 2 mod 5 where k q square root 5q prime q 4n sup 2  1 and the class number of quadratic number field k sub 2  q square root q is 1.
inspec,dev_1533,generic simulation approach for multi axis machining. part 2 model calibration and feed rate scheduling. for part 1 see ibid. vol 124 2002. this is the second part of a two part paper presenting a new methodology for analytically simulating multi axis machining of complex sculptured surfaces. the first section of this paper offers a detailed explanation of the model calibration procedure. a new methodology is presented for accurately determining the cutting force coefficients for multi axis machining. the force model presented in part 1 is reformulated so that the cutting force coefficients account for the effects of feed rate cutting speed and a complex cutting edge design. experimental results are presented for the calibration procedure. model verification tests were conducted with these cutting force coefficients. these tests demonstrate that the predicted forces are within 5 of experimentally measured forces. simulated results are also shown for predicting dynamic cutting forces and static dynamic tool deflection. the second section of the paper discusses how the modeling methodology can be applied for feed rate scheduling in an industrial application. a case study for process optimization of machining an airfoil like surface is used for demonstration. based on the predicted instantaneous chip load and or a specified force constraint the feed rate scheduling is utilized to increase the metal removal rate. the feed rate scheduling implementation results in a 30 reduction in machining time for the airfoil like surface.
inspec,dev_1534,generic simulation approach for multi axis machining. part 1 modeling methodology. this paper presents a new methodology for analytically simulating multi axis machining of complex sculptured surfaces. a generalized approach is developed for representing an arbitrary cutting edge design and the local surface topology of a complex sculptured surface. a nurbs curve is used to represent the cutting edge profile. this approach offers the advantages of representing any arbitrary cutting edge design in a generic way as well as providing standardized techniques for manipulating the location and orientation of the cutting edge. the local surface topology of the part is defined as those surfaces generated by previous tool paths in the vicinity of the current tool position. the local surface topology of the part is represented without using a computationally expensive cad system. a systematic prediction technique is then developed to determine the instantaneous tool part interaction during machining. the methodology employed here determines the cutting edge in cut segments by determining the intersection between the nurbs curve representation of the cutting edge and the defined local surface topology. these in cut segments are then utilized for predicting instantaneous chip load static and dynamic cutting forces and tool deflection. part 1 of this paper details the modeling methodology and demonstrates the capabilities of the simulation for machining a complex surface.
inspec,dev_1535,hot controllers. over the last few years the semiconductor industry has put much emphasis on ways to improve the accuracy of thermal mass flow controllers tmfcs. although issues involving tmfc mounting orientation and pressure effects have received much attention little has been done to address the effect of changes in ambient temperature or process gas temperature. scientists and engineers at qualiflow have succeeded to solve the problem using a temperature correction algorithm for digital tmfcs. using an in situ environmental temperature compensation technique we calculated correction factors for the temperature effect and obtained satisfactory results with both the traditional sensor and the new improved thin film sensors.
inspec,dev_1536,connection management for qos service on the web. the current web service model treats all requests equivalently both while being processed by servers and while being transmitted over the network. for some uses such as multiple priority schemes different levels of service are desirable. we propose application level tcp connection management mechanisms for web servers to provide two different levels of web service high and low service by setting different time outs for inactive tcp connections. we evaluated the performance of the mechanism under heavy and light loading conditions on the web server. our experiments show that though heavy traffic saturates the network high level class performance is improved by as much as 25 28. therefore this mechanism can effectively provide qos guaranteed services even in the absence of operating system and network supports.
inspec,dev_1537,technology on social issues of videoconferencing on the internet a survey. constant advances in audio video compression the development of the multicast protocol as well as fast improvement in computing devices e g higher speed larger memory have set forth the opportunity to have resource demanding videoconferencing vc sessions on the internet. multicast is supported by the multicast backbone mbone which is a special portion of the internet where this protocol is being deployed. mbone vc tools are steadily emerging and the user population is growing fast. vc is a fascinating application that has the potential to greatly impact the way we remotely communicate and work. yet the adoption of vc is not as fast as one could have predicted. hence it is important to examine the factors that affect a widespread adoption of vc. this paper examines the enabling technology and the social issues. it discusses the achievements and identifies the future challenges. it suggests an integration of many emerging multimedia tools into vc in order to enhance its versatility for more effectiveness.
inspec,dev_1538,a heuristic approach to resource locations in broadband networks. in broadband networks such as atm the importance of dynamic migration of data resources is increasing because of its potential to improve performance especially for transaction processing. in environments with migratory data resources it is necessary to have mechanisms to manage the locations of each data resource. in this paper we present an algorithm that makes use of system state information and heuristics to manage locations of data resources in a distributed network. in the proposed algorithm each site maintains information about state of other sites with respect to each data resource of the system and uses it to find 1 a subset of sites likely to have the requested data resource and 2 the site where the data resource is to be migrated from the current site. the proposed algorithm enhances its effectiveness by continuously updating system state information stored at each site. it focuses on reducing the overall average time delay needed by the transaction requests to locate and access the migratory data resources. we evaluated the performance of the proposed algorithm and also compared it with one of the existing location management algorithms by simulation studies under several system parameters such as the frequency of requests generation frequency of data resource migrations network topology and scale of network. the experimental results show the effectiveness of the proposed algorithm in all cases.
inspec,dev_1539,comments on some recent methods for the simultaneous determination of polynomial zeros. in this note we give some comments on the recent results concerning a simultaneous method of the fourth order for finding complex zeros in circular interval arithmetic. the main discussion is directed to a rediscovered iterative formula and its modification presented recently in sun and kosmol 2001. the presented comments include some critical parts of the papers petkovic trickovic herceg 1998 and sun and kosmol 2001 which treat the same subject.
inspec,dev_154,verifying concurrent systems with symbolic execution. current techniques for interactively proving temporal properties of concurrent systems translate transition systems into temporal formulas by introducing program counter variables. proofs are not intuitive because control flow is not explicitly considered. for sequential programs symbolic execution is a very intuitive interactive proof strategy. in this paper we adopt this technique for parallel programs. properties are formulated in interval temporal logic. an implementation in the interactive theorem prover kiv has shown that this technique offers a high degree of automation and allows simple local invariants.
inspec,dev_1540,adaptive thinning for bivariate scattered data. this paper studies adaptive thinning strategies for approximating a large set of scattered data by piecewise linear functions over triangulated subsets. our strategies depend on both the locations of the data points in the plane and the values of the sampled function at these points adaptive thinning. all our thinning strategies remove data points one by one so as to minimize an estimate of the error that results by the removal of a point from the current set of points this estimate is termed anticipated error. the thinning process generates subsets of most significant points such that the piecewise linear interpolants over the delaunay triangulations of these subsets approximate progressively the function values sampled at the original scattered points and such that the approximation errors are small relative to the number of points in the subsets. we design various methods for computing the anticipated error at reasonable cost and compare and test the performance of the methods. it is proved that for data sampled from a convex function with the strategy of convex triangulation the actual error is minimized by minimizing the best performing measure of anticipated error. it is also shown that for data sampled from certain quadratic polynomials adaptive thinning is equivalent to thinning which depends only on the locations of the data points nonadaptive thinning. based on our numerical tests and comparisons two practical adaptive thinning algorithms are proposed for thinning large data sets one which is more accurate and another which is faster.
inspec,dev_1541,the at89c51 52 flash memory programmers. when faced with a plethora of applications to design it s essential to have a versatile microcontroller in hand. the author describes the at89c51 52 microcontrollers. to get you started he ll describe his inexpensive microcontroller programmer.
inspec,dev_1542,the open source hcs project. despite the rumors the hcs ii project is not dead. in fact hcs has been licensed and is now an open source project. in this article the author brings us up to speed on the hcs ii project s past present and future. the hcs ii is an expandable standalone network based rs 485 intelligent node industrial oriented supervisory control sc system intended for demanding home control applications. the hcs incorporates direct and remote digital inputs and outputs direct and remote analog inputs and outputs real time or boolean decision event triggering x10 transmission and reception infrared remote control transmission and reception remote lcds and a master console. its program is compiled on a pc with the xpress compiler and then downloaded to the sc where it runs independently of the pc.
inspec,dev_1543,riscy business. part 1 risc projects by cornell students. the author looks at several projects that cornell university students entered in the atmel design 2001 contest. those covered include a vertical plotter bilines an electronic game a wireless internet pager cooking coach barbie s zip drive and a model train controller.
inspec,dev_1544,driving the nkk smartswitch 2. graphics and text. whether your message is one of workplace safety or world peace the long nights of brooding over ways to tell the world are over. part 1 described the basic interface to drive the smartswitch. part 2 adds the bells and whistles to allow both text and messages to be placed anywhere on the screen. it considers character generation graphic generation and the user interface.
inspec,dev_1545,pontryagin maximum principle of optimal control governed by fluid dynamic systems with two point boundary state constraint. we study the optimal control problem subject to the semilinear equation with a state constraint. we prove certain theorems and give examples of state constraints so that the maximum principle holds. the main difficulty of the problem is to make the sensitivity analysis of the state with respect to the control caused by the unboundedness and nonlinearity of an operator.
inspec,dev_1546,necessary conditions of optimality for impulsive systems on banach spaces. we present necessary conditions of optimality for optimal control problems arising in systems governed by impulsive evolution equations on banach spaces. basic notations and terminologies are first presented and necessary conditions of optimality are presented. special cases are discussed and we present an application to the classical linear quadratic regulator problem.
inspec,dev_1547,new projection type methods for monotone lcp with finite termination. in this paper we establish two new projection type methods for the solution of the monotone linear complementarity problem lcp. the methods are a combination of the extragradient method and the newton method in which the active set strategy is used and only one linear system of equations with lower dimension is solved at each iteration. it is shown that under the assumption of monotonicity these two methods are globally and linearly convergent. furthermore under a nondegeneracy condition they have a finite termination property. finally the methods are extended to solving the monotone affine variational inequality problem.
inspec,dev_1548,a second order characteristic finite element scheme for convection diffusion problems. a new characteristic finite element scheme is presented for convection diffusion problems. it is of second order accuracy in time increment symmetric and unconditionally stable. optimal error estimates are proved in the framework of l sup 2  theory. numerical results are presented for two examples which show the advantage of the scheme.
inspec,dev_1549,riccati based preconditioner for computing invariant subspaces of large matrices. this paper introduces and analyzes the convergence properties of a method that computes an approximation to the invariant subspace associated with a group of eigenvalues of a large not necessarily diagonalizable matrix. the method belongs to the family of projection type methods. at each step it refines the approximate invariant subspace using a linearized riccati s equation which turns out to be the block analogue of the correction used in the jacobi davidson method. the analysis conducted in this paper shows that the method converges at a rate quasi quadratic provided that the approximate invariant subspace is close to the exact one. the implementation of the method based on multigrid techniques is also discussed and numerical experiments are reported.
inspec,dev_155,fuzzy non homogeneous markov systems. in this paper the theory of fuzzy logic and fuzzy reasoning is combined with the theory of markov systems and the concept of a fuzzy non homogeneous markov system is introduced for the first time. this is an effort to deal with the uncertainty introduced in the estimation of the transition probabilities and the input probabilities in markov systems. the asymptotic behaviour of the fuzzy markov system and its asymptotic variability is considered and given in closed analytic form. moreover the asymptotically attainable structures of the system are estimated also in a closed analytic form under some realistic assumptions. the importance of this result lies in the fact that in most cases the traditional methods for estimating the probabilities can not be used due to lack of data and measurement errors. the introduction of fuzzy logic into markov systems represents a powerful tool for taking advantage of the symbolic knowledge that the experts of the systems possess.
inspec,dev_1550,on the convergence of the bermudez moreno algorithm with constant parameters. a bermudez and c moreno 1981 presented a duality numerical algorithm for solving variational inequalities of the second kind. the performance of this algorithm strongly depends on the choice of two constant parameters. assuming a further hypothesis of the inf sup type we present here a convergence theorem that improves on the one presented by a bermudez and c moreno. we prove that the convergence is linear and we give the expression of the asymptotic error constant and the explicit form of the optimal parameters as a function of some constants related to the variational inequality. finally we present some numerical examples that confirm the theoretical results.
inspec,dev_1551,the numerical solution of an evolution problem of second order in time on a closed smooth boundary. we consider an initial value problem for the second order differential equation with a dirichlet to neumann operator coefficient. for the numerical solution we carry out semi discretization by the laguerre transformation with respect to the time variable. then an infinite system of the stationary operator equations is obtained. by potential theory the operator equations are reduced to boundary integral equations of the second kind with logarithmic or hypersingular kernels. the full discretization is realized by nystrom s method which is based on the trigonometric quadrature rules. numerical tests confirm the ability of the method to solve these types of nonstationary problems.
inspec,dev_1552,stability of runge kutta methods for delay integro differential equations. we study stability of runge kutta rk methods for delay integro differential equations with a constant delay on the basis of the linear equation du dt lu t mu t tau k integral sub t tau  sup t u theta d theta where l m k are constant complex matrices. in particular we show that the same result as in the case k 0 koto 1994 holds for this test equation i e every a stable rk method preserves the delay independent stability of the exact solution whenever a step size of the form h tau m is used where m is a positive integer.
inspec,dev_1553,numerical solution of forward and backward problem for 2 d heat conduction equation. for a two dimensional heat conduction problem we consider its initial boundary value problem and the related inverse problem of determining the initial temperature distribution from transient temperature measurements. the conditional stability for this inverse problem and the error analysis for the tikhonov regularization are presented. an implicit inversion method which is based on the regularization technique and the successive over relaxation sor iteration process is established. due to the explicit difference scheme for a direct heat problem developed in this paper the inversion process is very efficient while the application of sor technique makes our inversion convergent rapidly. numerical results illustrating our method are also given.
inspec,dev_1554,differential calculus for p norms of complex valued vector functions with applications. for complex valued n dimensional vector functions t to s t supposed to be sufficiently smooth the differentiability properties of the mapping t to  s t  sub p at every point t t sub 0 epsilon r sub 0  sup   t epsilon r t or 0 are investigated where .  sub p is the usual vector norm in c sup n resp. r sup n  for p epsilon 1 o infinity. moreover formulae for the first three right derivatives d sub  sup k  s t  sub p  k 1 2 3 are determined. these formulae are applied to vibration problems by computing the best upper bounds on  s t  sub p in certain classes of bounds. these results can not be obtained by the methods used so far. the systematic use of the differential calculus for vector norms as done here for the first time could lead to major advances also in other branches of mathematics and other sciences.
inspec,dev_1555,a note on multi index polynomials of dickson type and their applications in quantum optics. we discuss the properties of a new family of multi index lucas type polynomials which are often encountered in problems of intracavity photon statistics. we develop an approach based on the integral representation method and show that this class of polynomials can be derived from recently introduced multi index hermite like polynomials.
inspec,dev_1556,regularity of some incomplete pal type interpolation problems. in this paper the regularity of nine pal type interpolation problems is proved. in the literature interpolation on the zeros of the pair w sub n  sup alpha z z alpha sup n  1 alpha z sup n  v sub n  sup alpha z z alpha sup n  1 alpha z sup n with 0 alpha 1 has been studied. here the nodes form a subset of these sets of zeros.
inspec,dev_1557,l sub p boundedness of c 1 means of orthonormal expansions for general exponential weights. let i be a finite or infinite interval and let w i to 0 infinity. assume that w sup 2 is a weight so that we may define orthonormal polynomials corresponding to w sup 2. for f r to r let s sub m f denote the mth partial sum of the orthonormal expansion of f with respect to these polynomials. we investigate boundedness in weighted l sub p spaces of the c 1 means 1 n sub m 1 sigma sup n s sub m f. the class of weights w sup 2 considered includes even and noneven exponential weights.
inspec,dev_1558,orthogonality of the jacobi polynomials with negative integer parameters. it is well known that the jacobi polynomials p sub n  sup alpha beta x are orthogonal with respect to a quasi definite linear functional whenever alpha beta and alpha beta 1 are not negative integer numbers. recently sobolev orthogonality for these polynomials has been obtained for alpha a negative integer and beta not a negative integer and also for the case alpha beta negative integer numbers. in this paper we give a sobolev orthogonality for the jacobi polynomials in the remainder cases.
inspec,dev_1559,a comparison theorem for the iterative method with the preconditioner i s sub max. a d gunawardena et al 1991 have reported the modified gauss seidel method with a preconditioner i s. in this article we propose to use a preconditioner i s sub max instead of i s. here s sub max is constructed by only the largest element at each row of the upper triangular part of a by using the lemma established by m neumann and r j plemmons 1987 we get the comparison theorem for the proposed method. simple numerical examples are also given.
inspec,dev_156,using extended logic programming for alarm correlation in cellular phone networks. alarm correlation is a necessity in large mobile phone networks where the alarm bursts resulting from severe failures would otherwise overload the network operators. we describe how to realize alarm correlation in cellular phone networks using extended logic programming. to this end we describe an algorithm and system solving the problem a model of a mobile phone network application and a detailed solution for a specific scenario.
inspec,dev_1560,determinantal solutions of solvable chaotic systems. it is shown that two solvable chaotic systems the arithmetic harmonic mean arm algorithm and the ulam von neumann uvn map have determinantal solutions. an additional formula for certain determinants and riccati difference equations play a key role in both cases. two infinite hierarchies of solvable chaotic systems are presented which have determinantal solutions.
inspec,dev_1561,self validating integration and approximation of piecewise analytic functions. let an analytic or a piecewise analytic function on a compact interval be given. we present algorithms that produce enclosures for the integral or the function itself. under certain conditions on the representation of the function this is done with the minimal order of numbers of operations. the integration algorithm is implemented and numerical comparisons to non validating integration software are presented.
inspec,dev_1562,solution of a class of two dimensional integral equations. the two dimensional integral equation 1 pi integral integral sub d phi r theta r sup 2 ds f r sub 0  theta sub 0 defined on a circular disk d r sub 0  or a 0 or theta sub 0  or 2 pi is considered in the present paper. here r in the kernel denotes the distance between two points p r theta and p sub 0 r sub 0  theta sub 0 in d and 0 alpha 2 or 2 alpha 4. based on some known results of bessel functions integral representations of the kernel are established for 0 alpha 2 and 2 alpha 4 respectively and employed to solve the corresponding two dimensional integral equation. the solutions of the weakly singular integral equation for 0 alpha 2 and of the hypersingular integral equation for 2 alpha 4 are obtained respectively.
inspec,dev_1563,a distance between elliptical distributions based in an embedding into the siegel group. this paper describes two different embeddings of the manifolds corresponding to many elliptical probability distributions with the informative geometry into the manifold of positive definite matrices with the siegel metric generalizing a result published previously elsewhere. these new general embeddings are applicable to a wide class of elliptical probability distributions in which the normal t student and cauchy are specific examples. a lower bound for the rao distance is obtained which is itself a distance and through these embeddings a number of statistical tests of hypothesis are derived.
inspec,dev_1564,asymptotic normality for the k sub phi  divergence goodness of fit tests. in this paper for a wide class of goodness of fit statistics based k sub phi  divergences the asymptotic normality is established under the assumption n m sub n to a in 0 infinity where n denotes sample size and m sub n the number of cells. this result is extended to contiguous alternatives to study asymptotic efficiency.
inspec,dev_1565,on lag windows connected with jacobi polynomials. lag windows whose corresponding spectral windows are jacobi polynomials or sums of jacobi polynomials are introduced. the bias and variance of their spectral density estimators are investigated and their window bandwidth and characteristic exponent are determined.
inspec,dev_1566,a numerical c sup 1  shadowing result for retarded functional differential equations. this paper gives a numerical c sup 1  shadowing between the exact solutions of a functional differential equation and its numerical approximations. the shadowing result is obtained by comparing exact solutions with numerical approximation which do not share the same initial value. behavior of stable manifolds of functional differential equations under numerics will follow from the shadowing result.
inspec,dev_1567,asymptotic expansions for the zeros of certain special functions. we derive asymptotic expansions for the zeros of the cosine integral ci x and the struve function h sub 0 x and extend the available formulae for the zeros of kelvin functions. numerical evidence is provided to illustrate the accuracy of the expansions.
inspec,dev_1568,natural language from artificial life. this article aims to show that linguistics in particular the study of the lexico syntactic aspects of language provides fertile ground for artificial life modeling. a survey of the models that have been developed over the last decade and a half is presented to demonstrate that alife techniques have a lot to offer an explanatory theory of language. it is argued that this is because much of the structure of language is determined by the interaction of three complex adaptive systems learning culture and biological evolution. computational simulation informed by theoretical linguistics is an appropriate response to the challenge of explaining real linguistic data in terms of the processes that underpin human language.
inspec,dev_1569,an interactive self replicator implemented in hardware. self replicating loops presented to date are essentially worlds unto themselves inaccessible to the observer once the replication process is launched. we present the design of an interactive self replicating loop of arbitrary size wherein the user can physically control the loop s replication and induce its destruction. after introducing the biowall a reconfigurable electronic wall for bio inspired applications we describe the design of our novel loop and delineate its hardware implementation in the wall.
inspec,dev_157,automatic extraction of eye and mouth fields from a face image using eigenfeatures and ensemble networks. this paper presents a novel algorithm for the extraction of the eye and mouth facial features fields from 2d gray level images. eigenfeatures are derived from the eigenvalues and eigenvectors of the binary edge data set constructed from eye and mouth fields. such eigenfeatures are ideal features for finely locating fields efficiently. the eigenfeatures are extracted from a set of the positive and negative training samples for facial features and are used to train a multilayer perceptron mlp whose output indicates the degree to which a particular image window contains the eyes or the mouth within itself. an ensemble network consisting of a multitude of independent mlps was used to enhance the generalization performance of a single mlp. it was experimentally verified that the proposed algorithm is robust against facial size and even slight variations of the pose.
inspec,dev_1570,self reproduction in three dimensional reversible cellular space. due to inevitable power dissipation it is said that nano scaled computing devices should perform their computing processes in a reversible manner. this will be a large problem in constructing three dimensional nano scaled functional objects. reversible cellular automata rca are used for modeling physical phenomena such as power dissipation by studying the dissipation of garbage signals. we construct a three dimensional self inspective self reproducing reversible cellular automaton by extending the two dimensional version sr sub 8. it can self reproduce various patterns in three dimensional reversible cellular space without dissipating garbage signals.
inspec,dev_1571,the simulated emergence of distributed environmental control in evolving microcosms. this work continues investigation into gaia theory lovelock the ages of gaia oxford university press 1995 from an artificial life perspective downing proceedings of the 7th international conference on artificial life p 90 99 mit press 2000 with the aim of assessing the general compatibility of emergent distributed environmental control with conventional natural selection. our earlier system guild downing and zvirinsky artificial life 5 p 291 318 1999 displayed emergent regulation of the chemical environment by a population of metabolizing agents but the chemical model underlying those results was trivial essentially admitting all possible reactions at a single energy cost. the new model metamic utilizes abstract chemistries that are both a constrained to a small set of legal reactions and b grounded in basic fundamental relationships between energy entropy and biomass synthesis breakdown. to explore the general phenomena of emergent homeostasis we generate 100 different chemistries and use each as the basis for several metamic runs as part of a gaia hunt. this search discovers 20 chemistries that support microbial populations capable of regulating a physical environmental factor within their growth optimal range despite the extra metabolic cost. case studies from the gaia hunt illustrate a few simple mechanisms by which real biota might exploit the underlying chemistry to achieve some control over their physical environment. although these results shed little light on the question of gaia on earth they support the possibility of emergent environmental control at the microcosmic level.
inspec,dev_1572,ant colony optimization and stochastic gradient descent. we study the relationship between the two techniques known as ant colony optimization aco and stochastic gradient descent. more precisely we show that some empirical aco algorithms approximate stochastic gradient descent in the space of pheromones and we propose an implementation of stochastic gradient descent that belongs to the family of aco algorithms. we then use this insight to explore the mutual contributions of the two techniques.
inspec,dev_1574,no go areas. content management. alex fry looks at how content management systems can be used to ensure website access for one important customer group the disabled.
inspec,dev_1578,records role in e business. records management standards are now playing a key role in e business strategy.
inspec,dev_158,neural and neuro fuzzy integration in a knowledge based system for air quality prediction. we propose a unified approach for integrating implicit and explicit knowledge in neurosymbolic systems as a combination of neural and neuro fuzzy modules. in the developed hybrid system a training data set is used for building neuro fuzzy modules and represents implicit domain knowledge. the explicit domain knowledge on the other hand is represented by fuzzy rules which are directly mapped into equivalent neural structures. the aim of this approach is to improve the abilities of modular neural structures which are based on incomplete learning data sets since the knowledge acquired from human experts is taken into account for adapting the general neural architecture. three methods to combine the explicit and implicit knowledge modules are proposed. the techniques used to extract fuzzy rules from neural implicit knowledge modules are described. these techniques improve the structure and the behavior of the entire system. the proposed methodology has been applied in the field of air quality prediction with very encouraging results. these experiments show that the method is worth further investigation.
inspec,dev_1583,cutting through the confusion workflow content management. information management vendors are rushing to re position themselves and put a portal spin on their products says itnet s graham urquhart. the result is confusion with a range of different definitions and claims clouding the true picture.
inspec,dev_1584,content all clear workflow content management. graeme muir of schlumbergersema cuts through the confusion between content document and records management.
inspec,dev_1588,contentment management. andersen s william yarker and richard young outline the route to a successful content management strategy.
inspec,dev_1589,view from the top workflow content management. international law firm linklaters has installed a global document and content management system that is accessible to clients and which has helped it move online.
inspec,dev_159,an intelligent system combining different resource bounded reasoning techniques. in this paper primes progressive reasoning and intelligent multiple methods system a new architecture for resource bounded reasoning that combines a form of progressive reasoning and the so called multiple methods approach is presented. each time critical reasoning unit is designed in such a way that it delivers an approximate result in time whenever an overload or a failure prevents the system from producing the most accurate result. indeed reasoning units use approximate processing based on two salient features. first an incremental processing unit constructs an approximate solution quickly and then refines it incrementally. second a multiple methods approach proposes different alternatives to solve the problem each of them being selected according to the available resources. in allowing several resource bounded reasoning paradigms to be combined we hope to extend their actual scope to cover more real world application domains.
inspec,dev_1590,holding on workflow content management. marc fresko of cornwell management consultants says think ahead when developing your electronic records management policy.
inspec,dev_1591,quadratic interpolation on spheres. riemannian quadratics are c sup 1 curves on riemannian manifolds obtained by performing the quadratic recursive decastlejeau algorithm in a riemannian setting. they are of interest for interpolation problems in riemannian manifolds such as trajectory planning for rigid body motion. some interpolation properties of riemannian quadratics are analysed when the ambient manifold is a sphere or projective space with the usual riemannian metrics.
inspec,dev_1592,hermite interpolation by rotation invariant spatial pythagorean hodograph curves. the interpolation of first order hermite data by spatial pythagorean hodograph curves that exhibit closure under arbitrary 3 dimensional rotations is addressed. the hodographs of such curves correspond to certain combinations of four polynomials given by dietz et al 1993 that admit compact descriptions in terms of quaternions an instance of the ph representation map proposed by choi et al 2002. the lowest order ph curves that interpolate arbitrary first order spatial hermite data are quintics. it is shown that with ph quintics the quaternion representation yields a reduction of the hermite interpolation problem to three simple quadratic equations in three quaternion unknowns. this system admits a closed form solution expressing all ph quintic interpolants to given spatial hermite data as a two parameter family. an integral shape measure is invoked to fix these two free parameters.
inspec,dev_1593,single and multi interval legendre tau methods in time for parabolic equations. in this paper we take the parabolic equation with periodic boundary conditions as a model to present a spectral method with the fourier approximation in spatial and single multi interval legendre petrov galerkin methods in time. for the single interval spectral method in time we obtain the optimal error estimate in l sup 2  norm. for the multi interval spectral method in time the l sup 2  optimal error estimate is valid in spatial. numerical results show the efficiency of the methods.
inspec,dev_1594,training multilayer perceptrons via minimization of sum of ridge functions. motivated by the problem of training multilayer perceptrons in neural networks we consider the problem of minimizing e x sigma sub i 1  sup n f sub i xi sub i. x where xi sub i in r sup s  1 or i or n and each f sub i xi sub i. x is a ridge function. we show that when n is small the problem of minimizing e can be treated as one of minimizing univariate functions and we use the gradient algorithms for minimizing e when n is moderately large. for a large n we present the online gradient algorithms and especially show the monotonicity and weak convergence of the algorithms.
inspec,dev_1595,convergence of finite element approximations and multilevel linearization for ginzburg landau model of d wave superconductors. in this paper we consider the finite element approximations of a recently proposed ginzburg landau type model for d wave superconductors. in contrast to the conventional ginzburg landau model the scalar complex valued order parameter is replaced by a multicomponent complex order parameter and the free energy is modified according to the d wave paring symmetry. convergence and optimal error estimates and some super convergent estimates for the derivatives are derived. furthermore we propose a multilevel linearization procedure to solve the nonlinear systems. it is proved that the optimal error estimates and super convergence for the derivatives are preserved by the multi level linearization algorithm.
inspec,dev_1596,wavelet collocation methods for a first kind boundary integral equation in acoustic scattering. in this paper we consider a wavelet algorithm for the piecewise constant collocation method applied to the boundary element solution of a first kind integral equation arising in acoustic scattering. the conventional stiffness matrix is transformed into the corresponding matrix with respect to wavelet bases and it is approximated by a compressed matrix. finally the stiffness matrix is multiplied by diagonal preconditioners such that the resulting matrix of the system of linear equations is well conditioned and sparse. using this matrix the boundary integral equation can be solved effectively.
inspec,dev_1597,application of heuristic methods for conformance test selection. in this paper we focus on the test selection problem. it is modeled after a real life problem that arises in telecommunication when one has to check the reliability of an application. we apply different metaheuristics namely reactive tabu search rts genetic algorithms ga and simulated annealing sa to solve the problem. we propose some modifications to the conventional schemes including an adaptive neighbourhood sampling in rts an adaptive variable mutation rate in ga and an adaptive variable neighbourhood structure in sa. the performance of the algorithms is evaluated in different models for existing protocols. computational results show that ga and sa can provide high quality solutions in acceptable time compared to the results of a commercial software which makes them applicable in practical test selection.
inspec,dev_1598,a decision support model for selecting product service benefit positionings. the art and science of successful product service positioning generally hinges on the firm s ability to select a set of attractively priced consumer benefits that are valued by the buyer distinctive in one or more respects believable deliverable and sustainable under actual or potential competitive abilities to imitate neutralize or overcome in the target markets that the firm selects. for many years the ubiquitous quadrant chart has been used to provide a simple graph of product service benefits usually called product service attributes described in terms of consumers perceptions of the importance of attributes to brand supplier choice and the performance of competing firms on these attributes. this paper describes a model that extends the quadrant chart concept to a decision support system that optimizes a firm s market share for a specified product service. in particular we describe a decision support model that utilizes relatively simple marketing research data on consumers judged benefit importances and supplier performances on these benefits to develop message components for specified target buyers. a case study is used to illustrate the model. the study deals with developing advertising message components for a relatively new entrant in the us air shipping market. we also discuss more briefly management reactions to application of the model to date and areas for further research and model extension.
inspec,dev_1599,evaluating the best main battle tank using fuzzy decision theory with linguistic criteria evaluation. in this paper experts opinions are described in linguistic terms which can be expressed in trapezoidal or triangular fuzzy numbers. to make the consensus of the experts consistent we utilize the fuzzy delphi method to adjust the fuzzy rating of every expert to achieve the consensus condition. for the aggregate of many experts opinions we take the operation of fuzzy numbers to get the mean of fuzzy rating x sub ij and the mean of weight w sub. j. in multi alternatives and multi attributes cases the fuzzy decision matrix x x sub ij  sub m n is constructed by means of the fuzzy rating x sub ij. then we can derive the aggregate fuzzy numbers by multiplying the fuzzy decision matrix with the corresponding fuzzy attribute weights. the final results become a problem of ranking fuzzy numbers. we also propose an easy procedure of using fuzzy numbers to rank aggregate fuzzy numbers a sub i. in this way we can obtain the best selection for evaluating the system. for practical application we propose an algorithm for evaluating the best main battle tank by fuzzy decision theory and comparing it with other methods.
inspec,dev_16,dual nature of mass multi agent systems. dual nature of mass multi agent systems mmas emerging as an internal discord of two spheres micro virtual consisting of agents and their internal phenomena and macro arising at the interface to the real world stems the necessity of a new approach to analysis design and utilisation of such systems. based on the concept of vr decomposition the problem of management of such systems is discussed. as a sub type that makes mmas closer to the application sphere an evolutionary multi agent system emas is proposed. emas combines features of mmas with advantages of an evolutionary model of computation. as an illustration of this consideration two particular emas are presented which allow us to obtain promising results in the fields of multiobjective optimisation and time series prediction and thus justify the approach.
inspec,dev_160,taming the paper tiger paperwork organization. generally acknowledged as a critical problem for many information professionals the massive flow of documents paper trails and information needs efficient and dependable approaches for processing and storing and finding items and information.
inspec,dev_1600,the development and evaluation of a fuzzy logic expert system for renal transplantation assignment is this a useful tool. allocating donor kidneys to patients is a complex multicriteria decision making problem which involves not only medical but also ethical and political issues. in this paper a fuzzy logic expert system approach was proposed as an innovative way to deal with the vagueness and complexity faced by medical doctors in kidney allocation decision making. a pilot fuzzy logic expert system for kidney allocation was developed and evaluated in comparison with two existing allocation algorithms a priority sorting system used by multiple organ retrieval and exchange more in canada and a point scoring systems used by united network for organ sharing unos in us. our simulated experiment based on real data indicated that the fuzzy logic system can represent the expert s thinking well in handling complex tradeoffs and overall the fuzzy logic derived recommendations were more acceptable to the expert than those from the more and unos algorithms.
inspec,dev_1601,solving the multiple competitive facilities location problem. in this paper we propose five heuristic procedures for the solution of the multiple competitive facilities location problem. a franchise of several facilities is to be located in a trade area where competing facilities already exist. the objective is to maximize the market share captured by the franchise as a whole. we perform extensive computational tests and conclude that a two step heuristic procedure combining simulated annealing and an ascent algorithm provides the best solutions.
inspec,dev_1602,an optimization approach to plan for reusable software components. it is well acknowledged in software engineering that there is a great potential for accomplishing significant productivity improvements through the implementation of a successful software reuse program. on the other hand such gains are attainable only by instituting detailed action plans at both the organizational and program level. given this need the paucity of research papers related to planning and in particular optimized planning is surprising. this research which is aimed at this gap brings out an application of optimization for the planning of reusable software components scs. we present a model that selects a set of scs that must be built in order to lower development and adaptation costs. we also provide implications to project management based on simulation an approach that has been adopted by other cost models in the software engineering literature. such a prescriptive model does not exist in the literature.
inspec,dev_1603,exploiting structure in adaptive dynamic programming algorithms for a stochastic batch service problem. the purpose of this paper is to illustrate the importance of using structural results in dynamic programming algorithms. we consider the problem of approximating optimal strategies for the batch service of customers at a service station. customers stochastically arrive at the station and wait to be served incurring a waiting cost and a service cost. service of customers is performed in groups of a fixed service capacity. we investigate the structure of cost functions and establish some theoretical results including monotonicity of the value functions. then we use our adaptive dynamic programming monotone algorithm that uses structure to preserve monotonicity of the estimates at each iterations to approximate the value functions. since the problem with homogeneous customers can be solved optimally we have a means of comparison to evaluate our heuristic. finally we compare our algorithm to classical forward dynamic programming methods.
inspec,dev_1604,improving supply chain performance by sharing advance demand information. in this paper we analyze how sharing advance demand information adi can improve supply chain performance. we consider two types of adi aggregated adi a adi and detailed adi d adi. with a adi customers share with manufacturers information about whether they will place an order for some product in the next time period but do not share information about which product they will order and which of several potential manufacturers will receive the order. with d adi customers additionally share information about which product they will order but which manufacturer will receive the order remains uncertain. we develop and solve mathematical models of supply chains where adi is shared. we derive exact expressions and closed form approximations for expected costs expected base stock levels and variations of the production quantities. we show that both the manufacturer and the customers benefit from sharing adi but that sharing adi increases the bullwhip effect. we also show that under certain conditions it is optimal to collect adi from either none or all of the customers. we study two supply chains in detail a supply chain with an arbitrary number of products that have identical demand rates and a supply chain with two products that have arbitrary demand rates. for these two supply chains we analyze how the values of a adi and d adi depend on the characteristics of the supply chain and on the quality of the shared information and we identify conditions under which sharing a adi and d adi can significantly reduce cost. our results can be used by decision makers to analyze the cost savings that can be achieved by sharing adi and help them to determine if sharing adi is beneficial for their supply chains.
inspec,dev_1605,a grasp heuristic for the mixed chinese postman problem. arc routing problems arps consist of finding a traversal on a graph satisfying some conditions related to the links of the graph. in the chinese postman problem cpp the aim is to find a minimum cost tour closed walk traversing all the links of the graph at least once. both the undirected cpp where all the links are edges that can be traversed in both ways and the directed cpp where all the links are arcs that must be traversed in a specified way are known to be polynomially solvable. however if we deal with a mixed graph having edges and arcs the problem turns out to be np hard. in this paper we present a heuristic algorithm for this problem the so called mixed cpp mcpp based on greedy randomized adaptive search procedure grasp techniques. the algorithm has been tested and compared with other known and recent methods from the literature on a wide collection of randomly generated instances with up to 200 nodes and 600 links producing encouraging computational results. as far as we know this is the best heuristic algorithm for the mcpp with respect to solution quality published up to now.
inspec,dev_1606,single machine earliness tardiness scheduling with resource dependent release dates. this paper deals with the single machine earliness and tardiness scheduling problem with a common due date and resource dependent release dates. it is assumed that the cost of resource consumption of a job is a non increasing linear function of the job release date and this function is common for all jobs. the objective is to find a schedule and job release dates that minimize the total resource consumption and earliness and tardiness penalties. it is shown that the problem is np hard in the ordinary sense even if the due date is unrestricted the number of jobs that can be scheduled before the due date is unrestricted. an exact dynamic programming dp algorithm for small and medium size problems is developed. a heuristic algorithm for large scale problems is also proposed and the results of a computational comparison between heuristic and optimal solutions are discussed.
inspec,dev_1607,a solvable queueing network model for railway networks and its validation and applications for the netherlands. the performance of new railway networks can not be measured or simulated as no detailed train schedules are available. railway infrastructure and capacities are to be determined long before the actual traffic is known. this paper therefore proposes a solvable queueing network model to compute performance measures of interest without requiring train schedules timetables. closed form expressions for mean delays are obtained. new network designs traffic scenarios and capacity expansions can so be evaluated. a comparison with real delay data for the netherlands supports the practical value of the model. a special dutch cargo line application is included.
inspec,dev_1608,a geometric process equivalent model for a multistate degenerative system. in this paper a monotone process model for a one component degenerative system with k 1 states k failure states and one working state is studied. we show that this model is equivalent to a geometric process gp model for a two state one component system such that both systems have the same long run average cost per unit time and the same optimal policy. furthermore an explicit expression for the determination of an optimal policy is derived.
inspec,dev_1609,modeling undesirable factors in efficiency evaluation. data envelopment analysis dea measures the relative efficiency of decision making units dmus with multiple performance factors which are grouped into outputs and inputs. once the efficient frontier is determined inefficient dmus can improve their performance to reach the efficient frontier by either increasing their current output levels or decreasing their current input levels. however both desirable good and undesirable bad factors may be present. for example if inefficiency exists in production processes where final products are manufactured with a production of wastes and pollutants the outputs of wastes and pollutants are undesirable and should be reduced to improve the performance. using the classification invariance property we show that the standard dea model can be used to improve the performance via increasing the desirable outputs and decreasing the undesirable outputs. the method can also be applied to situations when some inputs need to be increased to improve the performance. the linearity and convexity of dea are preserved through our proposal.
inspec,dev_161,electronic books reports of their death have been exaggerated. e books will survive but not in the consumer market at least not until reading devices become much cheaper and much better in quality which is not likely to happen soon. library journal s review of major events of the year 2001 noted that two requirements for the success of e books were development of a sustainable business model and development of better reading devices. the e book revolution has therefore become more of an evolution. we can look forward to further developments and advances in the future.
inspec,dev_1610,dynamic multi objective heating optimization. we develop a multicriteria approach to the problem of space heating under a time varying price of electricity. in our dynamic goal programming model the goals are ideal temperature intervals and the other criteria are the costs and energy consumption. we discuss the modelling requirements in multicriteria problems with a dynamic structure and present a new relaxation method combining the traditional epsilon constraint and goal programming gp methods. the multi objective heating optimization moho application in a spreadsheet environment with numerical examples is described.
inspec,dev_1611,data mining business intelligence for competitive advantage. organizations have lately realized that just processing transactions and or information faster and more efficiently no longer provides them with a competitive advantage vis a vis their competitors for achieving business excellence. information technology it tools that are oriented towards knowledge processing can provide the edge that organizations need to survive and thrive in the current era of fierce competition. enterprises are no longer satisfied with business information system s they require business intelligence system s. the increasing competitive pressures and the desire to leverage information technology techniques have led many organizations to explore the benefits of new emerging technology data warehousing and data mining. the paper discusses data warehouses and data mining tools and applications.
inspec,dev_1613,current waveform control of a high power factor rectifier circuit for harmonic suppression of voltage and current in a distribution system. this paper presents the input current waveform control of the rectifier circuit which realizes simultaneously the high input power factor and the harmonics suppression of the receiving end voltage and the source current under the distorted receiving end voltage. the proposed input current waveform includes the harmonic components which are in phase with the receiving end voltage harmonics. the control parameter in the proposed waveform is designed by examining the characteristics of both the harmonic suppression effect in the distribution system and the input power factor of the rectifier circuit. the effectiveness of the proposed current waveform has been confirmed experimentally.
inspec,dev_1614,a transmission line fault location system using the wavelet transform. this paper describes the locating system of line to ground faults on a power transmission line by using a wavelet transform. the possibility of the location with the surge generated by a fault has been theoretically proposed. in order to make the method practicable the authors realize very fast processors. they design the wavelet transform and location chips and construct a very fast fault location system by processing the measured data in parallel. this system is realized by a computer with three fpga processor boards on a pci bus. the processors are controlled by unix and the system has a graphical user interface with an x window system.
inspec,dev_1615,laguerre approximation of fractional systems. systems characterised by fractional power poles can be called fractional systems. here laguerre orthogonal polynomials are employed to approximate fractional systems by minimum phase reduced order rational transfer functions. both the time and the frequency domain analysis exhibit the accuracy of the approximation.
inspec,dev_1616,pitch post processing technique based on robust statistics. a novel pitch post processing technique based on robust statistics is proposed. performances in terms of pitch error rates and pitch contours show the superiority of the proposed method compared with the median filtering technique. further improvement is achieved through incorporating an uncertainty term in the robust statistics model.
inspec,dev_1617,adaptive array antenna based on radial basis function network as multiuser detection for wcdma. an adaptive array antenna is proposed based on the radial basis function rbf network as a multiuser detector for a wcdma system. the proposed system calculates the optimal combining weight coefficients using sample matrix inversion with a common correlation matrix algorithm and obtains the channel response vector using the rbf output signal.
inspec,dev_1618,optimal learning for patterns classification in rbf networks. the proposed modifying of the structure of the radial basis function rbf network by introducing the weight matrix to the input layer in contrast to the direct connection of the input to the hidden layer of a conventional rbf so that the training space in the rbf network is adaptively separated by the resultant decision boundaries and class regions is reported. the training of this weight matrix is carried out as for a single layer perceptron together with the clustering process. in this way the network is capable of dealing with complicated problems which have a high degree of interference in the training data and achieves a higher classification rate over the current classifiers using rbf.
inspec,dev_1619,rate allocation for video transmission over lossy correlated networks. a novel rate allocation algorithm for video transmission over lossy networks subject to bursty packet losses is presented. a gilbert elliot model is used at the encoder to drive the selection of coding parameters. experimental results using the h 26l test model show a significant performance improvement with respect to the assumption of independent packet losses.
inspec,dev_162,international news sites in english. web access to news sites all over the world allows us the opportunity to have an electronic news stand readily available and stocked with a variety of foreign to us news sites. a large number of currently available foreign sites are english language publications or english language versions of non north american sites. these sites are quite varied in terms of quality coverage and style. finding them can present a challenge. using them effectively requires critical thinking skills that are a part of media awareness or digital literacy.
inspec,dev_1620,rapid cauer filter design employing new filter model. the exact three dimensional 3d design of a coaxial cauer filter employing a new filter model a 3d field simulator and a circuit simulator is demonstrated. only a few iterations between the field simulator and the circuit simulator are necessary to meet a given specification.
inspec,dev_1621,current mode fully programmable piece wise linear block for neuro fuzzy applications. a new method to implement an arbitrary piece wise linear characteristic in current mode is presented. each of the breaking points and each slope is separately controllable. as an example a block that implements an n shaped piece wise linearity has been designed. the n shaped block operates in the subthreshold region and uses only ten transistors. these characteristics make it especially suitable for large arrays of neuro fuzzy systems where the number of transistors and power consumption per cell is an important concern. a prototype of this block has been fabricated in a 0 35 mu m cmos technology. the functionality and programmability of this circuit has been verified through experimental results.
inspec,dev_1622,error resilient intra refresh scheme for h 26l stream. recently much attention has been focused on video streaming through ip based networks. an error resilient rd intra macro block refresh scheme for h 26l internet video streaming is introduced. various channel simulations have proved that this scheme is more effective than those currently adopted in h 26l.
inspec,dev_1623,transmission of real time video over ip differentiated services. multimedia applications require high bandwidth and guaranteed quality of service qos. the current internet which provides best effort services can not meet the stringent qos requirements for delivering mpeg videos. it is proposed that mpeg frames are transported through various service models of diffserv. performance analysis and simulation results show that the proposed approach can not only guarantee qos but can also achieve high bandwidth utilisation.
inspec,dev_1624,genetic algorithm for input output selection in mimo systems based on controllability and observability indices. a time domain optimisation algorithm using a genetic algorithm in conjunction with a linear search scheme has been developed to find the smallest or near smallest subset of inputs and outputs to control a multi input multi output system. experimental results have shown that this proposed algorithm has a very fast convergence rate and high computation efficiency.
inspec,dev_1625,use of fuzzy weighted autocorrelation function for pitch extraction from noisy speech. an investigation is presented into the feasibility of incorporating a fuzzy weighting scheme into the calculation of an autocorrelation function for pitch extraction. simulation results reveal that the proposed method provides better robustness against background noise than the conventional approaches for extracting pitch period in a noisy environment.
inspec,dev_1626,modifier formula on mean square convergence of lms algorithm. in describing the mean square convergence of the lms algorithm the update formula based on independence assumption will bring explicit errors especially when step size is large. a modifier formula that describes the convergence well is proposed. simulations support the proposed formula in different conditions.
inspec,dev_1627,blind identification of non stationary ma systems. a new adaptive algorithm for blind identification of time varying ma channels is derived. this algorithm proposes the use of a novel system of equations derived by combining the third and fourth order statistics of the output signals of ma models. this overdetermined system of equations has the important property that it can be solved adaptively because of their symmetries via an overdetermined recursive instrumental variable type algorithm. this algorithm shows good behaviour in arbitrary noisy environments and good performance in tracking time varying systems.
inspec,dev_1628,quasi newton algorithm for adaptive minor component extraction. an adaptive quasi newton algorithm is first developed to extract a single minor component corresponding to the smallest eigenvalue of a stationary sample covariance matrix. a deflation technique instead of the commonly used inflation method is then applied to extract the higher order minor components. the algorithm enjoys the advantage of having a simpler computational complexity and a highly modular and parallel structure for efficient implementation. simulation results are given to demonstrate the effectiveness of the proposed algorithm for extracting multiple minor components adaptively.
inspec,dev_1629,robot trajectory control using neural networks. the use of a new type of neural network nn for controlling the trajectory of a robot is discussed. a control system is described which comprises an nn based controller and a fixed gain feedback controller. the nn based controller employs a modified recurrent nn the weights of which are obtained by training another nn to identify online the inverse dynamics of the robot. the work has confirmed the superiority of the proposed nn based control system in rejecting large disturbances.
inspec,dev_163,boolean operators and the naive end user moving to and. since so few end users make use of boolean searching it is obvious that any effective solution needs to take this reality into account. the most important aspect of a technical solution should be that it does not require any effort on the part of users. what is clearly needed is for search engine designers and programmers to take account of the information seeking behavior of internet users. users must be able to enter a series of words at random and have those words automatically treated as a carefully constructed boolean and search statement.
inspec,dev_1630,digital domain self calibration technique for video rate pipeline a d converters using gaussian white noise. a digital domain self calibration technique for video rate pipeline a d converters based on a gaussian white noise input signal is presented. the proposed algorithm is simple and efficient. a design example is shown to illustrate that the overall linearity of a pipeline adc can be highly improved using this technique.
inspec,dev_1631,recovering lost efficiency of exponentiation algorithms on smart cards. at the rsa cryptosystem implementation stage a major security concern is resistance against so called side channel attacks. solutions are known but they increase the overall complexity by a non negligible factor typically a protected rsa exponentiation is 133 slower. for the first time protected solutions are proposed that do not penalise the running time of an exponentiation.
inspec,dev_1632,one structure for fractional delay filter with small number of multipliers. a wide bandwidth high resolution fractional delay filter fdf structure with a small number of multipliers per output sample and a short coefficient computing time is presented. the proposal is based on the use of a frequency fdf design method up to only half of the nyquist frequency in a multirate structure.
inspec,dev_1633,48 gbit s inp dhbt ms dff with very low time jitter. a master slave d type flip flop ms dff fabricated in a self aligned inp dhbt technology is presented. the packaged circuit shows full rate clock operation at 48 gbit s. very low time jitter and good retiming capabilities are observed. layout aspects packaging and measurement issues are discussed in particular.
inspec,dev_1634,maple 8 keeps everyone happy. the author is impressed with the upgrade to the mathematics package maple 8 finding it genuinely useful to scientists and educators. the developments waterloo maple class as revolutionary include a student calculus package and maplets. the first provides a high level command set for calculus exploration and plotting removing the need to work with say plot primitives. the second is a package for hand coding custom graphical user interfaces guis using elements such as check boxes radio buttons slider bars and pull down menus. when called a maplet launches a runtime java environment that pops up a window analogous to a java applet to perform a programmed routine if required passing the result back to the maple worksheet.
inspec,dev_1635,simple but complex. flexpro 5 0 from weisang and co is one of those products which aim to serve an often ignored range of data users those who in flexpro s words are interested in documenting analysing and archiving data in the simplest way possible. the online help system is clearly designed to promote the product in this market segment with a very clear introduction from first principles and a hands on tutorial and the live project to which it was applied was selected with this in mind.
inspec,dev_1636,sparc ignites scholarly publishing. during the past several years initiatives which bring together librarians researchers university administrators and independent publishers have re invigorated the scholarly publishing marketplace. these initiatives take advantage of electronic technology and show great potential for restoring science to scientists. the author outlines sparc the scholarly publishing and academic resources coalition an initiative to make scientific journals more accessible.
inspec,dev_1637,what s best practice for open access. the business of publishing journals is in transition. nobody knows exactly how it will work in the future but everybody knows that the electronic publishing revolution will ensure it wo n t work as it does now. this knowledge has provoked a growing sense of nervous anticipation among those concerned some edgy and threatened by potential changes to their business others excited by the prospect of change and opportunity. the paper discusses the open publishing model for dissemination of research.
inspec,dev_1638,the chemical brotherhood. it has always been more difficult for chemistry to keep up in the internet age but a new language could herald a new era for the discipline. the paper discusses cml or chemical mark up language. the extensible mark up language provides a universal format for structured documents and data on the web and so offers a way for scientists and others to carry a wide range of information types across the net in a transparent way. all that is needed is an xml browser.
inspec,dev_1639,new hub gears up for algorithmic exchange. warwick university in the uk is on the up and up. sometimes considered a typical 1960s middle of the road redbrick institution not known for their distinction the 2001 uk research assessment exercise rae shows its research to be the fifth most highly rated in the country with outstanding standards in the sciences. this impressive performance has rightly given warwick a certain amount of muscle which it is flexing rather effectively aided by a snappy approach to making things happen that leaves some older institutions standing. the result is a brand new centre for scientific computing csc launched within a couple of years of its initial conception.
inspec,dev_164,plug ins for critical media literacy a collaborative program. information literacy is important in academic and other libraries. the paper looks at whether it would be more useful to librarians and to instructors as well as the students to deal with information literacy skill levels of students beginning their academic careers rather than checking them at the end. approaching the situation with an eye toward the broader scope of critical media literacy opens the discussion beyond a skills inventory to the broader range of intellectual activity.
inspec,dev_1640,integration is lims inspiration. for software manufacturers blessings come in the form of fast moving application areas. in the case of lims biotechnology is still in the driving seat inspiring developers to maintain consistently rapid and creative levels of innovation. current advancements are no exception. integration and linking initiatives are still popular and much of the activity appears to be coming from a very productive minority.
inspec,dev_1641,development through gaming. mainstream observers commonly underestimate the role of fringe activities in propelling science and technology. well known examples are how wars have fostered innovation in areas such as communications cryptography medicine and aerospace and how erotica has been a major factor in pioneering visual media from the first printed books to photography cinematography videotape or the latest online video streaming. the article aims to be a sampler of a less controversial but still often underrated symbiosis between scientific computing and computing for leisure and entertainment.
inspec,dev_1642,development and validation of user adaptive navigation and information retrieval tools for an intranet portal organizational memory information system. based on previous research and properties of organizational memory a conceptual model for navigation and retrieval functions in an intranet portal organizational memory information system was proposed and two human centred features memory structure map and history based tool were developed to support user s navigation and retrieval in a well known organizational memory. to test two hypotheses concerning the validity of the conceptual model and two human centred features an experiment was conducted with 30 subjects. testing of the two hypotheses indicated the following 1 the memory structure map s users showed 29 better performance in navigation and 2 the history based tool s users outperformed by 34 in identifying information. the results of the study suggest that a conceptual model and two human centred features could be used in a user adaptive interface design to improve user s performance in an intranet portal organizational memory information system.
inspec,dev_1643,effectiveness of user testing and heuristic evaluation as a function of performance classification. for different levels of user performance different types of information are processed and users will make different types of errors. based on the error s immediate cause and the information being processed usability problems can be classified into three categories. they are usability problems associated with skill based rule based and knowledge based levels of performance. in this paper a user interface for a web based software program was evaluated with two usability evaluation methods user testing and heuristic evaluation. the experiment discovered that the heuristic evaluation with human factor experts is more effective than user testing in identifying usability problems associated with skill based and rule based levels of performance. user testing is more effective than heuristic evaluation in finding usability problems associated with the knowledge based level of performance. the practical application of this research is also discussed in the paper.
inspec,dev_1644,an experimental evaluation of comprehensibility aspects of knowledge structures derived through induction techniques a case study of industrial fault diagnosis. machine induction has been extensively used in order to develop knowledge bases for decision support systems and predictive systems. the extent to which developers and domain experts can comprehend these knowledge structures and gain useful insights into the basis of decision making has become a challenging research issue. this article examines the knowledge structures generated by the c4 5 induction technique in a fault diagnostic task and proposes to use a model of human learning in order to guide the process of making comprehensive the results of machine induction. the model of learning is used to generate hierarchical representations of diagnostic knowledge by adjusting the level of abstraction and varying the goal structures between shallow and deep ones. comprehensibility is assessed in a global way in an experimental comparison where subjects are required to acquire the knowledge structures and transfer to new tasks. this method of addressing the issue of comprehensibility appears promising especially for machine induction techniques that are rather inflexible with regard to the number and sorts of interventions allowed to system developers.
inspec,dev_1645,effects of the transition to a client centred team organization in administrative surveying work. a new work organization was introduced in administrative surveying work in sweden during 1998. the new work organization implied a transition to a client centred team based organization and required a change in competence from specialist to generalist knowledge as well as a transition to a new information technology implying a greater integration within the company. the aim of this study was to follow the surveyors for two years from the start of the transition and investigate how perceived consequences of the transition job organizational factors well being and effectiveness measures changed between 1998 and 2000. the teamwork profile and qps nordic questionnaire were used. the 205 surveyors who participated in all three study phases constituted the study group. the result showed that surveyors who perceived that they were working as generalists rated the improvements in job and organizational factors significantly higher than those who perceived that they were not yet generalists. improvements were noted in 2000 in quality of service to clients time available to handle a case and effectiveness of teamwork in a transfer to a team based work organization group cohesion and continuous improvement practices for example learning by doing mentoring and guided delegation were important to improve the social effectiveness of group work.
inspec,dev_1646,the limits of shape constancy point to point mapping of perspective projections of flat figures. the present experiments investigate point to point mapping of perspective transformations of 2d outline figures under diverse viewing conditions binocular free viewing monocular perspective with 2d cues masked by an optic tunnel and stereoptic viewing through an optic tunnel. the first experiment involved upright figures and served to determine baseline point to point mapping accuracy which was found to be very good. three shapes were used square circle and irregularly round. the main experiment with slanted figures involved only two shapes square and irregularly shaped showed at several slant degrees. despite the accumulated evidence for shape constancy when the outline of perspective projections is considered metric perception of the inner structure of such projections was quite limited. systematic distortions were found especially with more extreme slants and attributed to the joint effect of several factors anchors 3d information and slant underestimation. contradictory flatness cues did not detract from performance while stereoptic information improved it.
inspec,dev_1647,examining children s reading performance and preference for different computer displayed text. this study investigated how common online text affects reading performance of elementary school age children by examining the actual and perceived readability of four computer displayed typefaces at 12 and 14 point sizes. twenty seven children ages 9 to 11 were asked to read eight children s passages and identify erroneous substituted words while reading. comic sans ms arial and times new roman typefaces regardless of size were found to be more readable as measured by a reading efficiency score than courier new. no differences in reading speed were found for any of the typeface combinations. in general the 14 point size and the examined sans serif typefaces were perceived as being the easiest to read fastest most attractive and most desirable for school related material. in addition participants significantly preferred comic sans ms and 14 point arial to 12 point courier. recommendations for appropriate typeface combinations for children reading on computers are discussed.
inspec,dev_1648,spatial solutions office furniture. take the stress out of the office by considering the design of furniture and staff needs before major buying decisions.
inspec,dev_1649,office essentials stationery suppliers. make purchasing stationery a relatively simple task through effective planning and management of stock and identifying the right supplier.
inspec,dev_165,monitoring the news online. the author looks at how we can focus on what we want finding small stories in vast oceans of news. there is no one tool that will scan every news resource available and give alerts on new available materials. every one has a slightly different focus. some are paid sources while many are free. if used wisely an excellent news monitoring system for a large number of topics can be set up for surprisingly little cost.
inspec,dev_1650,low to mid speed copiers buyer s guide. the low to mid speed copier market is being transformed by the almost universal adoption of digital solutions. the days of the analogue copier are numbered as the remaining vendors plan to withdraw from this sector by 2005. reflecting the growing market for digital vendors are reducing prices making a digital solution much more affordable. the battle for the copier market is intense and the popularity of the multifunctional device is going to transform the office equipment market. as total cost of ownership becomes increasingly important and as budgets are squeezed the most cost effective solutions are those that will survive this shake down.
inspec,dev_1651,h matrix approximation for the operator exponential with applications. we previously developed a data sparse and accurate approximation to parabolic solution operators in the case of a rather general elliptic part given by a strongly p positive operator. also a class of matrices h matrices has been analysed which are data sparse and allow an approximate matrix arithmetic with almost linear complexity. in particular the matrix vector matrix matrix product with such matrices as well as the computation of the inverse have linear logarithmic cost. in this paper we apply the h matrix techniques to approximate the exponent of an elliptic operator. starting with the dunford cauchy representation for the operator exponent we then discretise the integral by the exponentially convergent quadrature rule involving a short sum of resolvents. the latter are approximated by the h matrices. our algorithm inherits a two level parallelism with respect to both the computation of resolvents and the treatment of different time values. in the case of smooth data coefficients boundaries we prove the linear logarithmic complexity of the method.
inspec,dev_1652,convergence of a finite volume scheme for nonlinear degenerate parabolic equations. one approximates the entropy weak solution u of a nonlinear parabolic degenerate equation u sub t  div qf u delta phi u 0 by a piecewise constant function u sub d using a discretization d in space and time and a finite volume scheme. the convergence of u sub d to u is shown as the size of the space and time steps tend to zero. in a first step estimates on u sub d are used to prove the convergence up to a subsequence of u sub d to a measure valued entropy solution called here an entropy process solution. a result of uniqueness of the entropy process solution is proved yielding the strong convergence of u sub d to u. some numerical results on a model equation are shown.
inspec,dev_1653,the best circulant preconditioners for hermitian toeplitz systems ii. the multiple zero case. for pt i. see siam j numer. anal vol. 38 p 876 896. circulant type preconditioners have been proposed previously for ill conditioned hermitian toeplitz systems that are generated by nonnegative continuous functions with a zero of even order. the proposed circulant preconditioners can be constructed without requiring explicit knowledge of the generating functions. it was shown that the spectra of the preconditioned matrices are uniformly bounded except for a fixed number of outliers and that all eigenvalues are uniformly bounded away from zero. therefore the conjugate gradient method converges linearly when applied to solving the circulant preconditioned systems. previously it was claimed that this result can be extended to the case where the generating functions have multiple zeros. the main aim of this paper is to give a complete convergence proof of the method for this class of generating functions.
inspec,dev_1654,numerical validation of solutions of complementarity problems the nonlinear case. this paper proposes a validation method for solutions of nonlinear complementarity problems. the validation procedure performs a computational test. if the result of the test is positive then it is guaranteed that a given multi dimensional interval either includes a solution or excludes all solutions of the nonlinear complementarity problem.
inspec,dev_1655,an empirical investigation of the influences of the degree of interactivity on user outcomes in a multimedia environment. the study reported here investigates the influence of interactivity on the learning outcomes of users in a multimedia systems environment. drawing from past literature base and based on key tenets of three learning theories behaviorist cognitivist and constructivist the study first proposes a measurement scheme for interactivity and then hypothesizes that interactivity would influence the learning outcomes positively in terms of users learning achievement and attitude. three prototypes of a multimedia instructional training system to represent high low and noninteractive modes of use were developed and implemented and the hypothesized influences were investigated using a controlled laboratory research design. multiple analysis of variance manova results indicate that while interactivity does not necessarily enable enhanced gain in user learning it positively influences participants attitude. the study finds no support for hypothesized moderating effects of learning styles measured using kolb s learning style inventory scale on the relationship between interactivity and user outcomes. the results of this study have important implications for both education and corporations training efforts and investments. implications and future research directions are discussed.
inspec,dev_1656,impact of user satisfaction and trust on virtual team members. pressured by the growing need for fast response times mass customization and globalization many organizations are turning to flexible organizational forms such as virtual teams. virtual teams consist of cooperative relationships supported by information technology to overcome limitations of time and or location. virtual teams require their members to rely heavily on the use of information technology and trust in coworkers. this study investigates the impacts that the reliance on information technology operationalized in our study via the user satisfaction construct and trust have on the job satisfaction of virtual team members. the study findings reveal that both user satisfaction and trust are positively related to job satisfaction in virtual teams while system use was not found to play a significant role. these findings emphasize that organizations seeking the benefits of flexible it enabled virtual teams must consider both the level of trust among colleagues and the users satisfaction with the information technology on which virtual teams rely.
inspec,dev_1657,breaking the myths of rewards an exploratory study of attitudes about knowledge sharing. many ceo and managers understand the importance of knowledge sharing among their employees and are eager to introduce the knowledge management paradigm in their organizations. however little is known about the determinants of the individual s knowledge sharing behavior. the purpose of this study is to develop an understanding of the factors affecting the individual s knowledge sharing behavior in the organizational context. the research model includes various constructs based on social exchange theory self efficacy and theory of reasoned action. research results from the field survey of 467 employees of four large public organizations show that expected associations and contribution are the major determinants of the individual s attitude toward knowledge sharing. expected rewards believed by many to be the most important motivating factor for knowledge sharing are not significantly related to the attitude toward knowledge sharing. as expected positive attitude toward knowledge sharing is found to lead to positive intention to share knowledge and finally to actual knowledge sharing behaviors.
inspec,dev_1658,chaos theory as a framework for studying information systems. this paper introduces chaos theory as a means of studying information systems. it argues that chaos theory combined with new techniques for discovering patterns in complex quantitative and qualitative evidence offers a potentially more substantive approach to understand the nature of information systems in a variety of contexts. the paper introduces chaos theory concepts by way of an illustrative research design.
inspec,dev_1659,mobile commerce transforming the vision into reality. this editorial preface investigates current developments in mobile commerce m commerce and proposes an integrated architecture that supports business and consumer needs in an optimal way to successfully implement m commerce business processes. the key line of thought is based on the heuristic observation that customers will not want to receive m commerce offerings to their mobile telephones. as a result a pull as opposed to a push approach becomes a necessary requirement to conduct m commerce. in addition m commerce has to rely on local regional demographic and many other variables to be truly effective. both observations necessitate an m commerce architecture that allows the coherent integration of enterprise level systems as well as the aggregation of product and service offerings from many different and partially competing parties into a collaborative m commerce platform. the key software component within this integrated architecture is an event management engine to monitor detect store process and measure information about outside events that are relevant to all participants in m commerce.
inspec,dev_166,the semantic web differentiating between taxonomies and ontologies. there is a new vision of the www the semantic web that will dramatically improve web based services and products. it creates a setting where software agents perform everyday jobs for end users. deploying hierarchies metadata and structured vocabularies the semantic web expands basic internet functions.
inspec,dev_1660,a regularized conjugate gradient method for symmetric positive definite system of linear equations. a class of regularized conjugate gradient methods is presented for solving the large sparse system of linear equations of which the coefficient matrix is an ill conditioned symmetric positive definite matrix. the convergence properties of these methods are discussed in depth and the best possible choices of the parameters involved in the new methods are investigated in detail. numerical computations show that the new methods are more efficient and robust than both classical relaxation methods and classical conjugate direction methods.
inspec,dev_1661,the road to perpetual progress retail inventory management. with annual revenues increasing 17 0 to 20 0 consistently over the last three years and more than 2 500 new stores opened from 1998 through 2001 dollar general is on the fast track. however the road to riches could have easily become the road to ruin had the retailer not exerted control over its inventory management.
inspec,dev_1663,vsat technology aids growth. choosing to migrate to ip based applications also means deciding whether terrestrial technologies such as frame relay dsl or plain old telephone service pots can provide the scalability flexibility and high bandwidth required to support those applications and whether these technologies can do so affordably. each option has its tradeoffs. also in each case retailers with nationwide chains have to deal with multiple last mile service providers for service installation and network maintenance. because of this many retailers are selecting two way satellite networking technology frequently referred to as vsat as the technology of choice for always on nationwide high speed connectivity coupled with end to end network ownership and favorable economics. enterprises are adopting vsat platforms not only for emerging ip and web based applications but also for mission critical front office functions such as credit authorization and point of sale polling.
inspec,dev_1664,disappointment reigns retail it. cpfr remains at the forefront of cios minds but a number of barriers such as secretive corporate cultures and spotty data integrity stand between retail organizations and true supply chain collaboration. cios remain vexed at these obstacles as was evidenced at a roundtable discussion by retail and consumer goods it leaders at the retail systems 2002 conference held in chicago by the consultancy moonwatch media inc newton upper falls mass. other annoyances discussed by retail cios include poorly designed business processes and retail s poor image with the it talent emerging from school into the job market.
inspec,dev_1665,how airlines and airports recover from schedule perturbations a survey. the explosive growth in air traffic as well as the widespread adoption of operations research techniques in airline scheduling has given rise to tight flight schedules at major airports. an undesirable consequence of this is that a minor incident such as a delay in the arrival of a small number of flights can result in a chain reaction of events involving several flights and airports causing disruption throughout the system. this paper reviews recent literature in the area of recovery from schedule disruptions. first we review how disturbances at a given airport could be handled including the effects of runways and fixes. then we study the papers on recovery from airline schedule perturbations which involve adjustments in flight schedules aircraft and crew. the mathematical programming techniques used in ground holding are covered in some detail. we conclude the review with suggestions on how singular perturbation theory could play a role in analyzing disruptions to such highly sensitive schedules as those in the civil aviation industry.
inspec,dev_1666,airline base schedule optimisation by flight network annealing. a system for rigorous airline base schedule optimisation is described. the architecture of the system reflects the underlying problem structure. the architecture is hierarchical consisting of a master problem for logical aircraft schedule optimisation and a sub problem for schedule evaluation. the sub problem is made up of a number of component sub problems including connection generation passenger choice modelling passenger traffic allocation by simulation and revenue and cost determination. schedule optimisation is carried out by means of simulated annealing of flight networks. the operators for the simulated annealing process are feasibility preserving and form a complete set of operators.
inspec,dev_1667,combining constraint programming and linear programming on an example of bus driver scheduling. provides details of a successful application where the column generation algorithm was used to combine constraint programming and linear programming. in the past constraint programming and linear programming were considered to be two competing technologies that solved similar types of problems. both these technologies had their strengths and weaknesses. the paper shows that the two technologies can be combined together to extract the strengths of both these technologies. details of a real world application to optimize bus driver duties are given. this system was developed by ilog for a major software house in japan using ilog solver and ilog cplex constraint programming and linear programming c c  libraries.
inspec,dev_1668,elastic constraint branching the wedelin carmen lagrangian heuristic and integer programming for personnel scheduling. the wedelin algorithm is a lagrangian based heuristic that is being successfully used by carmen systems to solve large crew pairing problems within the airline industry. we extend the wedelin approach by developing an implementation for personnel scheduling problems also termed staff rostering problems that exploits the special structure of these problems. we also introduce elastic constraint branching with the twin aims of improving the performance of our new approach and making it more column generation friendly. numerical results show that our approach can outperform the commercial solver cplex on difficult commercial rostering problems.
inspec,dev_1669,supply chain optimisation in the paper industry. we describe the formulation and development of a supply chain optimisation model for fletcher challenge paper australasia fcpa. this model known as the paper industry value optimisation tool pivot is a large mixed integer program that finds an optimal allocation of supplier to mill product to paper machine and paper machine to customer while at the same time modelling many of the supply chain details and nuances which are peculiar to fcpa. pivot has assisted fcpa in solving a number of strategic and tactical decision problems and provided significant economic benefits for the company.
inspec,dev_167,business school research bridging the gap between producers and consumers. there has been a great deal of continuing discussion concerning the seemingly unbridgeable gap between so much of the research produced by business school professors and the needs of the business people who ideally would use it. here we examine this gap and suggest a model for bridging it. we sample four groups of people business school academics professors deans of business schools executive mba students recent graduates and senior business executives. each group rates 44 different potential properties of exemplary research. we analyze within group differences and more meaningfully between group differences. we then offer commentary on the results and use the results to develop the aforementioned suggestions for bridging the gap we find.
inspec,dev_1670,an integrated optimization model for train crew management. train crew management involves the development of a duty timetable for each of the drivers crew to cover a given train timetable in a rail transport organization. this duty timetable is spread over a certain period known as the roster planning horizon. train crew management may arise either from the planning stage when the total number of crew and crew distributions are to be determined or from the operating stage when the number of crew at each depot is known as input data. in this paper we are interested in train crew management in the planning stage. in the literature train crew management is decomposed into two stages crew scheduling and crew rostering which are solved sequentially. we propose an integrated optimization model to solve both crew scheduling and crew rostering. the model enables us to generate either cyclic rosters or non cyclic rosters. numerical experiments are carried out over data sets arising from a practical application.
inspec,dev_1671,cane railway scheduling via constraint logic programming labelling order and constraints in a real life application. in australia cane transport is the largest unit cost in the manufacturing of raw sugar making up around 35 of the total manufacturing costs. producing efficient schedules for the cane railways can result in significant cost savings. the paper presents a study using constraint logic programming clp to solve the cane transport scheduling problem. tailored heuristic labelling order and constraints strategies are proposed and encouraging results of application to several test problems and one real life case are presented. the preliminary results demonstrate that clp can be used as an effective tool for solving the cane transport scheduling problem with a potential decrease in development costs of the scheduling system. it can also be used as an efficient tool for rescheduling tasks which the existing cane transport scheduling system can not perform well.
inspec,dev_1672,two issues in setting call centre staffing levels. motivated by a problem facing the police communication centre in auckland new zealand we consider the setting of staffing levels in a call centre with priority customers. the choice of staffing level over any particular time period e g monday from 8 am 9 am relies on accurate arrival rate information. the usual method for identifying the arrival rate based on historical data can in some cases lead to considerable errors in performance estimates for a given staffing level. we explain why identify three potential causes of the difficulty and describe a method for detecting and addressing such a problem.
inspec,dev_1673,mission planning for regional surveillance. the regional surveillance problem discussed involves formulating a flight route for an aircraft to scan a given geographical region. aerial surveillance is conducted using a synthetic aperture radar device mounted on the aircraft to compose a complete high resolution image of the region. two models for determining an optimised flight route are described the first employing integer programming and the second genetic algorithms. a comparison of the solution optimality in terms of the total distance travelled and model efficiency of the two techniques in terms of their required cpu times is made in order to identify the conditions under which it is appropriate to apply each model.
inspec,dev_1674,a column generation approach to delivery planning over time with inhomogeneous service providers and service interval constraints. we consider a problem of delivery planning over multiple time periods. deliveries must be made to customers having nominated demand in each time period. demand must be met in each time period by use of some combination of inhomogeneous service providers. each service provider has a different delivery capacity different cost of delivery to each customer a different utilisation requirement and different rules governing the spread of deliveries in time. the problem is to plan deliveries so as to minimise overall costs subject to demand being met and service rules obeyed. a natural integer programming model was found to be intractable except on problems with loose demand constraints with gaps between best lower bound and best feasible solution of up to 35 1  with an average of 15 4 over the test data set. in all but the problem with loosest demand constraints cplex 6 5 applied to this formulation failed to find the optimal solution before running out of memory. however a column generation approach improved the lower bound by between 0 6 and 21 9  with an average of 9 9  and in all cases found the optimal solution at the root node without requiring branching.
inspec,dev_1675,an operations research approach to the problem of the sugar cane selection. selection for superior clones is the most important aspect of sugar cane improvement programs and is a long and expensive process. while studies have investigated different components of selection independently there has not been a whole system approach to improve the process. this study observes the problem as an integrated system where if one parameter changes the state of the whole system changes. a computer based stochastic simulation model that accurately represents the selection was developed. the paper describes the simulation model showing its accuracy as well as how a combination of dynamic programming and branch and bound can be applied to the model to optimise the selection system giving a new application of these techniques. the model can be directly applied to any region targeted by sugar cane breeding programs or to other clonally propagated crops.
inspec,dev_1676,an optimization based approach to the train operator scheduling problem at singapore mrt. singapore mass rapid transit smrt operates two train lines with 83 kilometers of track and 48 stations. a total of 77 trains are in operation during peak hours and 41 during off peak hours. we report on an optimization based approach to develop a computerized train operator scheduling system that has been implemented at smrt. the approach involves a bipartite matching algorithm for the generation of night duties and a tabu search algorithm for the generation of day duties. the system automates the train operator scheduling process at smrt and produces favorable schedules in comparison with the manual process. it is also able to handle the multiple objectives inherent in the crew scheduling system. while trying to minimize the system wide crew related costs the system is also able to address concern with respect to the number of split duties.
inspec,dev_1677,minimised geometric buchberger algorithm for integer programming. recently various algebraic integer programming ip solvers have been proposed based on the theory of grobner bases. the main difficulty of these solvers is the size of the grobner bases generated. in algorithms proposed so far large grobner bases are generated by either introducing additional variables or by considering the generic ip problem ip sub a c. some improvements have been proposed such as hosten and sturmfels method grin designed to avoid additional variables and thomas truncated grobner basis method which computes the reduced grobner basis for a specific ip problem ip sub a c b rather than its generalisation ipa c. in this paper we propose a new algebraic algorithm for solving ip problems. the new algorithm called minimised geometric buchberger algorithm combines hosten and sturmfels grin and thomas truncated grobner basis method to compute the fundamental segments of an ip problem ip sub a c directly in its original space and also the truncated grobner basis for a specific ip problem ip sub a c b. we have carried out experiments to compare this algorithm with others such as the geometric buchberger algorithm the truncated geometric buchberger algorithm and the algorithm in grin. these experiments show that the new algorithm offers significant performance improvement.
inspec,dev_1678,parallel interior point schemes for solving multistage convex programming. the predictor corrector interior point path following algorithm is promising in solving multistage convex programming problems. among many other general good features of this algorithm especially attractive is that the algorithm allows the possibility to parallelise the major computations. the dynamic structure of the multistage problems specifies a block tridiagonal system at each newton step of the algorithm. a wrap around permutation is then used to implement the parallel computation for this step.
inspec,dev_1679,project scheduling under time dependent costs a branch and bound algorithm. in a given project network execution of each activity in normal duration requires utilization of certain resources. if faster execution of an activity is desired then additional resources at extra cost would be required. given a project network the cost structure for each activity and a planning horizon the project compression problem is concerned with the determination of optimal schedule of performing each activity while satisfying given restrictions and minimizing the total cost of project execution. the paper considers the project compression problem with time dependent cost structure for each activity. the planning horizon is divided into several regular time intervals over which the cost structure of an activity may vary. but the cost structure of the activities remains the same within a time interval. the objective is to find an optimal project schedule minimizing the total project cost. we present a mathematical model for this problem develop some heuristics and an exact branch and bound algorithm. using simulated problems we provide an insight into the computational performances of heuristics and the branch and bound algorithm.
inspec,dev_168,nurturing clients trust to encourage engagement success during the customization of erp systems. customization is a crucial lengthy and costly aspect in the successful implementation of erp systems and has accordingly become a major specialty of many vendors and consulting companies. the study examines how such companies can increase their clients perception of engagement success through increased client trust that is brought about through responsive and dependable customization. survey data from erp customization clients show that as hypothesized clients trust influenced their perception of engagement success with the company. the data also show that clients trust in the customization company was increased when the company behaved in accordance with client expectations by being responsive and decreased when the company behaved in a manner that contradicted these expectations by not being dependable. responses to an open ended question addendum attached to the survey corroborated the importance of responsiveness and dependability. implications for customization companies and research on trust are discussed.
inspec,dev_1680,minimizing weighted number of early and tardy jobs with a common due window involving location penalty. studies a single machine scheduling problem to minimize the weighted number of early and tardy jobs with a common due window. there are n non preemptive and simultaneously available jobs. each job will incur an early tardy penalty if it is early tardy with respect to the common due window under a given schedule. the window size is a given parameter but the window location is a decision variable. the objective of the problem is to find a schedule that minimizes the weighted number of early and tardy jobs and the location penalty. we show that the problem is np complete in the ordinary sense and develop a dynamic programming based pseudo polynomial algorithm. we conduct computational experiments the results of which show that the performance of the dynamic algorithm is very good in terms of memory requirement and cpu time. we also provide polynomial time algorithms for two special cases.
inspec,dev_1681,one and two facility network design revisited. the one facility one commodity network design problem ofoc with nonnegative flow costs considers the problem of sending d units of flow from a source to a destination where arc capacity is purchased in batches of c units. the two facility problem tfoc is similar but capacity can be purchased either in batches of c units or one unit. flow costs are zero. these problems are known to be np hard. we describe an exact o n sup 3 3 sup n algorithm for these problems based on the repeated use of a bipartite matching algorithm. we also present a better lower bound of omega n sup 2k  for an earlier omega n sup 2k algorithm described in the literature where k d c and k  min k n 2 2. the matching algorithm is faster than this one for k or n 2 2. finally we provide another reformulation of the problem that is quasi integral. this property could be useful in designing a modified version of the simplex method to solve the problem using a sequence of pivots with integer extreme solutions referred to as the integral simplex method in the literature.
inspec,dev_1682,data mining efforts increase business productivity and efficiency. the use and acquisition of information is a key part of the way any business makes money. data mining technologies provide greater insight into how this information can be better used and more effectively acquired. steven kudyba an expert in the field of data mining technologies shares his expertise in an interview.
inspec,dev_1683,unlocking the potential of videoconferencing. i propose in this paper to show through a number of case studies that videoconferencing is user friendly cost effective time effective and life enhancing for people of all ages and abilities and that it requires only a creative and imaginative approach to unlock its potential. i believe that these benefits need not and should not be restricted to the education sector. my examples will range from simple storytelling through accessing international experts professional development and distance learning in a variety of forms to the use of videoconferencing for virtual meetings and planning sessions. in some cases extracts from the reactions and responses of the participants will be included to illustrate the impact of the medium.
inspec,dev_1684,e learning on the college campus a help or hindrance to students learning objectives a case study. if you know how to surf the world wide web have used email before and can learn how to send an email attachment then learning how to interact in an online course should not be difficult at all. in a way to find out i decided to offer two identical courses one of which would be offered online and the other the traditional way. i wanted to see how students would fare with identical material provided in each course. i wanted their anonymous feedback when the course was over.
inspec,dev_1685,use of web technologies in construction project management what are the critical success failure factors. a concept of how the world wide web www and its associated technologies can be used to manage construction projects has been recognized by practitioners in the construction industry for quite sometime. this concept is often referred to as a web based project management system wpms. it promises to enhance construction project documentation and control and to revolutionize the way construction project teams process and transmit project information. wpms is an electronic project management system conducted through the internet. the system provides a centralized commonly accessible reliable means of transmitting and storing project information. project information is stored on the server and a standard web browser is used as the gateway to exchange this information eliminating geographic and hardware platforms boundary.
inspec,dev_1686,internet infrastructure and the emerging information society an appraisal of the internet backbone industry. this paper examines the real constraints to the expansion of all encumbering and all pervasive information technology in our contemporary society. perhaps the u s internet infrastructure is the most appropriate to examine since it is u s technology that has led the world into the internet age. in this context this paper reviews the state of the u s internet backbone that will lead us into information society of the future by facilitating massive data transmission.
inspec,dev_1687,cleared for take off hummingbird enterprise. a recent gartner report identifies hummingbird in the first wave of vendors as an early example of convergence in the smart enterprise suite market. we spoke to hummingbird s marketing director for northern europe.
inspec,dev_1688,connecting the business without busting the budget. the multi channel content delivery model mccd might be a new concept to you but it is already beginning to replace traditional methods of business communications print and content delivery argues darren atkinson cto formscape.
inspec,dev_169,mrp in a job shop environment using a resource constrained project scheduling model. one of the most difficult tasks in a job shop manufacturing environment is to balance schedule and capacity in an ongoing basis. mrp systems are commonly used for scheduling although their inability to deal with capacity constraints adequately is a severe drawback. in this study we show that material requirements planning can be done more effectively in a job shop environment using a resource constrained project scheduling model. the proposed model augments mrp models by incorporating capacity constraints and using variable lead time lengths. the efficacy of this approach is tested on mrp systems by comparing the inventory carrying costs and resource allocation of the solutions obtained by the proposed model to those obtained by using a traditional mrp model. in general it is concluded that the proposed model provides improved schedules with considerable reductions in inventory carrying costs.
inspec,dev_1692,passing the image test imaging accreditation. accredited imaging qualifications hot on the heels of microsoft cisco and others are taking off in the usa. dave tyler looks at the cdia qualification that looks likely to become the exam of choice for the dm industry.
inspec,dev_1693,healthy wealthy and wise. health sector document management. nhs spending will rise from pounds 65 4 bn in 2002 to pounds 87 2 bn in 2006 and by 2008 spending will total pounds 105 6 bn. david tyler looks at how the health sector is already beginning to exploit it and particularly document management to improve service and cut costs.
inspec,dev_1694,product development using a 3d computer model to optimize the stability of the rocket tm powered wheelchair. a three dimensional 3d lumped parameter model of a powered wheelchair was created to aid the development of the rocket prototype wheelchair and to help explore the effect of innovative design features on its stability. the model was developed using simulation software specifically working model 3d. the accuracy of the model was determined by comparing both its static stability angles and dynamic behavior as it passed down a 4 8 cm 1 9 road curb at a heading of 45 degrees with the performance of the actual wheelchair. the model s predictions of the static stability angles in the forward rearward and lateral directions were within 9 3 7 1 and 3 8 of the measured values respectively. the average absolute error in the predicted position of the wheelchair as it moved down the curb was 2 2 cm m 0 9 per 3 3 traveled. the accuracy was limited by the inability to model soft bodies the inherent difficulties in modeling a statically indeterminate system and the computing time. nevertheless it was found to be useful in investigating the effect of eight design alterations on the lateral stability of the wheelchair. stability was quantified by determining the static lateral stability angles and the maximum height of a road curb over which the wheelchair could successfully drive on a diagonal heading. the model predicted that the stability was more dependent on the configuration of the suspension system than on the dimensions and weight distribution of the wheelchair. furthermore for the situations and design alterations studied predicted improvements in static stability were not correlated with improvements in dynamic stability.
inspec,dev_1695,medical image computing at the institute of mathematics and computer science in medicine university hospital hamburg eppendorf. the author reviews the history of medical image computing at his institute summarizes the achievements sketches some of the difficulties encountered and draws conclusions that might be of interest especially to people new to the field. the origin and history section provides a chronology of this work emphasizing the milestones reached during the past three decades. in accordance with the author s group s focus on imaging the paper is accompanied by many pictures some of which he thinks are of historical value.
inspec,dev_1696,comments on frequency decomposition and computing of ultrasound medical images with wavelet packets. in this paper errors and discrepancies in the subject paper cincotti et al 2002 are highlighted. a comment concerning the axial resolution associated to the adopted processing procedure is also reported.
inspec,dev_1697,exact frequency domain reconstruction for thermoacoustic tomography. ii. cylindrical geometry. for pt. i see ibid vol. 21 no 7 p 823 8 2002. microwave induced thermoacoustic tomography tat in a cylindrical configuration is developed to image biological tissue. thermoacoustic signals are acquired by scanning a flat ultrasonic transducer. using a new expansion of a spherical wave in cylindrical coordinates we apply the fourier and hankel transforms to tat and obtain an exact frequency domain reconstruction method. the effect of discrete spatial sampling on image quality is analyzed. an aliasing proof reconstruction method is proposed. numerical and experimental results are included.
inspec,dev_1698,exact frequency domain reconstruction for thermoacoustic tomography. i planar geometry. we report an exact and fast fourier domain reconstruction algorithm for thermoacoustic tomography in a planar configuration assuming thermal confinement and constant acoustic speed. the effects of the finite size of the detector and the finite length of the excitation pulse are explicitly included in the reconstruction algorithm. the algorithm is numerically and experimentally verified. we also demonstrate that the blurring caused by the finite size of the detector surface is the primary limiting factor on the resolution and that it can be compensated for by deconvolution.
inspec,dev_1699,time domain reconstruction for thermoacoustic tomography in a spherical geometry. reconstruction based microwave induced thermoacoustic tomography in a spherical configuration is presented. thermoacoustic waves from biological tissue samples excited by microwave pulses are measured by a wide band unfocused ultrasonic transducer which is set on a spherical surface enclosing the sample. sufficient data are acquired from different directions to reconstruct the microwave absorption distribution. an exact reconstruction solution is derived and approximated to a modified backprojection algorithm. experiments demonstrate that the reconstructed images agree well with the original samples. the spatial resolution of the system reaches 0 5 mm.
inspec,dev_17,fault diagnosis and fault tolerant control of linear stochastic systems with unknown inputs. this paper presents an integrated robust fault detection and isolation fdi and fault tolerant control ftc scheme for a fault in actuators or sensors of linear stochastic systems subjected to unknown inputs disturbances. as usual in this kind of works it is assumed that single fault occurs at a time and the fault treated is of random bias type. the fdi module is constructed using banks of robust two stage kalman filters which simultaneously estimate the state and the fault bias and generate residual sets decoupled from unknown disturbances. all elements of residual sets are evaluated by using a hypothesis statistical test and the fault is declared according to the prepared decision logic. the ftc module is activated based on the fault indicator and additive compensation signal is computed using the fault bias estimate and combined to the nominal control law for compensating the fault s effect on the system. simulation results for the simplified longitudinal flight control system with parameter variations process and measurement noises demonstrate the effectiveness of the approach proposed.
inspec,dev_170,the impact of the product mix on the value of flexibility. product mix flexibility is one of the major types of manufacturing flexibility referring to the ability to produce a broad range of products or variants with presumed low changeover costs. the value of such a capability is important to establish for an industrial firm in order to ensure that the flexibility provided will be at the right level and used profitably rather than in excess of market requirements and consequently costly. we use option pricing theory to analyse the impact of various product mix issues on the value of flexibility. the real options model we use incorporates multiple products capacity constraints as well as set up costs. the issues treated here include the number of products demand variability correlation between products and the relative demand distribution within the product mix. thus we are interested in the nature of the input data to analyse its effect on the value of flexibility. we also check the impact at different capacity levels. the results suggest that the value of flexibility i increases with an increasing number of products ii decreases with increasing volatility of product demand iii decreases the more positively correlated the demand is and iv reduces for marginal capacity with increasing levels of capacity. of these the impact of positively correlated demand seems to be a major issue. however the joint impact of the number of products and demand correlation showed some non intuitive results.
inspec,dev_1700,computation of unmeasured third generation vct views from measured views. we compute unmeasured cone beam projections from projections measured by a third generation helical volumetric computed tomography system by solving a characteristic problem for an ultrahyperbolic differential equation john 1938. by working in the fourier domain we convert the second order pde into a family of first order ordinary differential equations. a simple first order integration is used to solve the odes.
inspec,dev_1701,estimation of 3 d left ventricular deformation from medical images using biomechanical models. the quantitative estimation of regional cardiac deformation from three dimensional 3 d image sequences has important clinical implications for the assessment of viability in the heart wall. we present here a generic methodology for estimating soft tissue deformation which integrates image derived information with biomechanical models and apply it to the problem of cardiac deformation estimation. the method is image modality independent. the images are segmented interactively and then initial correspondence is established using a shape tracking approach. a dense motion field is then estimated using a transversely isotropic linear elastic model which accounts for the muscle fiber directions in the left ventricle. the dense motion field is in turn used to calculate the deformation of the heart wall in terms of strain in cardiac specific directions. the strains obtained using this approach in open chest dogs before and after coronary occlusion exhibit a high correlation with strains produced in the same animals using implanted markers. further they show good agreement with previously published results in the literature. this proposed method provides quantitative regional 3 d estimates of heart deformation.
inspec,dev_1702,reconstruction of time varying 3 d left ventricular shape from multiview x ray cineangiocardiograms. this paper reports on the clinical application of a system for recovering the time varying three dimensional 3 d left ventricular lv shape from multiview x ray cineangiocardiograms. considering that x ray cineangiocardiography is still commonly employed in clinical cardiology and computational costs for 3 d recovery and visualization are rapidly decreasing it is meaningful to develop a clinically applicable system for 3 d lv shape recovery from x ray cineangiocardiograms. the system is based on a previously reported closed surface method of shape recovery from two dimensional occluding contours with multiple views. to apply the method to real lv cineangiocardiograms user interactive systems were implemented for preprocessing including detection of lv contours calibration of the imaging geometry and setting of the lv model coordinate system. the results for three real lv angiographic image sequences are presented two with fixed multiple views using supplementary angiography and one with rotating views. 3 d reconstructions utilizing different numbers of views were compared and evaluated in terms of contours manually traced by an experienced radiologist. the performance of the preprocesses was also evaluated and the effects of variations in user specified parameters on the final 3 d reconstruction results were shown to be sufficiently small. these experimental results demonstrate the potential usefulness of combining multiple views for 3 d recovery from real lv cineangiocardiograms.
inspec,dev_1703,statistical analysis of nonlinearly reconstructed near infrared tomographic images. ii. experimental interpretation. for pt. i see ibid vol. 21 no 7 p 755 63 2002. image error analysis of a diffuse near infrared tomography nir system has been carried out on simulated data using a statistical approach described in pt. i of this paper pogue et al 2002. the methodology is used here with experimental data acquired on phantoms with a prototype imaging system intended for characterizing breast tissue. results show that imaging performance is not limited by random measurement error but rather by calibration issues. the image error over the entire field of view is generally not minimized when an accurate homogeneous estimate of the phantom properties is available however local image error over a target region of interest roi is reduced. the image reconstruction process which includes a levenberg marquardt style regularization provides good minimization of the objective function yet its reduction is not always correlated with an overall image error decrease. minimization of the bias in an roi which contains localized changes in the optical properties can be achieved through five to nine iterations of the algorithm. precalibration of the algorithm through statistical evaluation of phantom studies may provide a better measure of the image accuracy than that implied by minimization of the standard objective function.
inspec,dev_1704,statistical analysis of nonlinearly reconstructed near infrared tomographic images. i theory and simulations. near infrared nir diffuse tomography is an emerging method for imaging the interior of tissues to quantify concentrations of hemoglobin and exogenous chromophores noninvasively in vivo. it often exploits an optical diffusion model based image reconstruction algorithm to estimate spatial property values from measurements of the light flux at the surface of the tissue. in this study mean squared error mse over the image is used to evaluate methods for regularizing the ill posed inverse image reconstruction problem in nir tomography. estimates of image bias and image standard deviation were calculated based upon 100 repeated reconstructions of a test image with randomly distributed noise added to the light flux measurements. it was observed that the bias error dominates at high regularization parameter values while variance dominates as the algorithm is allowed to approach the optimal solution. this optimum does not necessarily correspond to the minimum projection error solution but typically requires further iteration with a decreasing regularization parameter to reach the lowest image error. increasing measurement noise causes a need to constrain the minimum regularization parameter to higher values in order to achieve a minimum in the overall image mse.
inspec,dev_1705,the use of visual search for knowledge gathering in image decision support. this paper presents a new method of knowledge gathering for decision support in image understanding based on information extracted from the dynamics of saccadic eye movements. the framework involves the construction of a generic image feature extraction library from which the feature extractors that are most relevant to the visual assessment by domain experts are determined automatically through factor analysis. the dynamics of the visual search are analyzed by using the markov model for providing training information to novices on how and where to look for image features. the validity of the framework has been evaluated in a clinical scenario whereby the pulmonary vascular distribution on computed tomography images was assessed by experienced radiologists as a potential indicator of heart failure. the performance of the system has been demonstrated by training four novices to follow the visual assessment behavior of two experienced observers. in all cases the accuracy of the students improved from near random decision making 33 to accuracies ranging from 50 to 68.
inspec,dev_1706,quantitative analysis of reconstructed 3 d coronary arterial tree and intracoronary devices. traditional quantitative coronary angiography is performed on two dimensional 2 d projection views. these views are chosen by the angiographer to minimize vessel overlap and foreshortening. with 2 d projection views that are acquired in this nonstandardized fashion however there is no way to know or estimate how much error occurs in the qca process. furthermore coronary arteries possess a curvilinear shape and undergo a cyclical deformation due to their attachment to the myocardium. therefore it is necessary to obtain three dimensional 3 d information to best describe and quantify the dynamic curvilinear nature of the human coronary artery. using a patient specific 3 d coronary reconstruction algorithm and routine angiographic images a new technique is proposed to describe 1 the curvilinear nature of 3 d coronary arteries and intracoronary devices 2 the magnitude of the arterial deformation caused by intracoronary devices and due to heart motion and 3 optimal view s with respect to the desired pathway for delivering intracoronary devices.
inspec,dev_1707,tactical airborne reconnaissance goes dual band and beyond. multispectral imaging technologies are satisfying the need for a persistent look at the battlefield. we highlight the need to persistently monitor a battlefield to determine exactly who and what is there. for example infrared imaging can be used to expose the fuel status of an aircraft on the runway. a daytime visible spectrum image of the same aircraft would offer information about external details such as the plane s markings and paint scheme. a dual band camera enables precision image registration by fusion and frequently yields more information than is possible by evaluating the images separately.
inspec,dev_1708,a study of hospitality and tourism information technology education and industrial applications. the purpose of this study was to examine the subject relevance of information technology it in hospitality and tourism management programs with skills deployed in the workplace. this study aimed at investigating graduates transition from education to employment and to determine how well they appear to be equipped to meet the needs of the hospitality and tourism industry. one hundred and seventeen graduates responded to a mail survey. these graduates rated the importance of it skills in the workplace the level of it teaching in hotel and tourism management programs and the self competence level in it. this study concluded that a gap exists between the it skills required at work and those acquired at university.
inspec,dev_1709,development of computer mediated teaching resources for tourism distance education the university of otago model. this article presents a qualitative account of the development of computer mediated tourism distance learning resources. a distance learning model was developed at the centre for tourism university of otago new zealand in 1998 1999. the article reviews the development of this internet based learning resource explaining the design and development of programme links providing study information for students and paper links course material and learning features. the design of course material is reviewed with emphasis given to consistency of presentation between papers. the template for course material is described and illustrated and the article concludes with an overview of important design considerations.
inspec,dev_171,education training and development policies and practices in medium sized companies in the uk do they really influence firm performance. this paper sets out to examine the relationship between training and firm performance in middle sized uk companies. it recognises that there is evidence that high performance work practices appear to be associated with better performance in large us companies but argues that this relationship is less likely to be present in middle sized companies. the paper s key contribution is to justify the wider concept of education training and development etd as applicable to such companies. it then finds that clusters of some etd variables do appear to be associated with better middle sized company performance.
inspec,dev_1710,vonna hbp a multimedia learning package on hotel budget planning. in this paper a new learning package vonna hbp which provides an interactive and online environment for novices to study and practice hotel budget planning is introduced. its design philosophy will be discussed thoughtfully with special focus on how to make use of the multimedia and internet. according to literatures learning packages are faced to be more effective in delivering teaching material. researchers indicate that students using a self paced learning package score higher than in a traditional classroom setting. moreover the learning package provides different scenarios for students to explore themselves in a practical environment and is more cost effective and systematic than lectures. currently most learning packages in hotel education are not implemented using multimedia with internet access. our paper describes a new learning package that fills the gaps. vonna hbp requires participants to investigate operational budgets on various areas such as sales levels payroll inventory level promotion strategies and facilities planning etc. eventually the students novices are required to practice their skills in a comprehensive case about a hypothetical hotel. they need to solve managerial problems by a combination of budgetary planning on human resources staff training programmes facilities maintenance and replacement or promotion schemes. analytical tools are available for students novices to judge an appropriate decision in handling constrained resources.
inspec,dev_1711,developing a cd rom as a teaching and learning tool in food and beverage management a case study in hospitality education. food and beverage management is the traditional core of hospitality education but in its laboratory manifestation has come under increasing pressure in recent years. it is an area that arguably presents the greatest challenges in adaptation to contemporary learning technologies but at the same time stands to benefit most from the potential of the web. this paper addresses the design and development of a cd rom learning resource for food and beverage. it is a learning resource which is designed to integrate with rather than to replace existing conventional classroom and laboratory learning methods and thus compensate for the decline in the resource base faced in food and beverage education in recent years. the paper includes illustrative material drawn from the cd rom which demonstrates its use in teaching and learning.
inspec,dev_1712,eliminating counterevidence with applications to accountable certificate management. this paper presents a method to increase the accountability of certificate management by making it intractable for the certification authority ca to create contradictory statements about the validity of a certificate. the core of the method is a new primitive undeniable attester that allows someone to commit to some set s of bitstrings by publishing a short digest of s and to give attestations for any x that it is or is not a member of s. such an attestation can be verified by obtaining in an authenticated way the published digest and applying a verification algorithm to the triple of the bitstring the attestation and the digest. the most important feature of this primitive is the intractability of creating two contradictory proofs for the same candidate element x and digest. we give an efficient construction for undeniable attesters based on authenticated search trees. we show that the construction also applies to sets of more structured elements. we also show that undeniable attesters exist iff collision resistant hash functions exist.
inspec,dev_1713,a uniform framework for regulating service access and information release on the web. the widespread use of internet based services is increasing the amount of information such as user profiles that clients are required to disclose. this information demand is necessary for regulating access to services and functionally convenient e g to support service customization but it has raised privacy related concerns which if not addressed may affect the users disposition to use network services. at the same time servers need to regulate service access without disclosing entirely the details of their access control policy. there is therefore a pressing need for privacy aware techniques to regulate access to services open to the network. we propose an approach for regulating service access and information disclosure on the web. the approach consists of a uniform formal framework to formulate and reason about both service access and information disclosure constraints. it also provides a means for parties to communicate their requirements while ensuring that no private information be disclosed and that the communicated requirements are correct with respect to the constraints.
inspec,dev_1714,hordes a multicast based protocol for anonymity. with widespread acceptance of the internet as a public medium for communication and information retrieval there has been rising concern that the personal privacy of users can be eroded by cooperating network entities. a technical solution to maintaining privacy is to provide anonymity. we present a protocol for initiator anonymity called hordes which uses forwarding mechanisms similar to those used in previous protocols for sending data but is the first protocol to make use of multicast routing to anonymously receive data. we show this results in shorter transmission latencies and requires less work of the protocol participants in terms of the messages processed. we also present a comparison of the security and anonymity of hordes with previous protocols using the first quantitative definition of anonymity and unlinkability. our analysis shows that hordes provides anonymity in a degree similar to that of crowds and onion routing but also that hordes has numerous performance advantages.
inspec,dev_1715,information processing and computing systems at thermal power stations in china. the development and commissioning of information processing and computing systems ipcss at four power units each of 500 mw capacity at the thermal power stations tszisyan and imin in china are considered. the functional structure and the characteristics of the functions of the ipcss are presented as is information on the technology of development and experience in adjustments. ways of using the experience gained in creating a comprehensive functional firmware system are shown.
inspec,dev_1716,the vibration reliability of poppet and contoured actuator valves. the problem of selecting the shape of the actuator valve the final control valve itself is discussed the solution to this problem will permit appreciable dynamic loads to be eliminated from the moving elements of the steam distribution system of steam turbines under all operating conditions.
inspec,dev_1717,responding to market trends with predictive segmentation health care. technology and technological advances have always been a part of healthcare but often it s advances in treatment machinery and materials that get the attention. however technology gains also occur behind the scenes in operations. one of the less glamorous but powerful technological advances available today is predictive segmentation a phrase that means a new way to assess and view individuals in the market based on their health status and health needs. sophisticated databases data mining neural networks and statistical capabilities have enabled the development of predictive segmentation techniques. these predictive models for healthcare can identify who is likely to need certain services and who is likely to become ill. they are a significant departure from various geographical and attitudinal segmentation methods that healthcare strategists have used in the past to gain a better understanding of their customers.
inspec,dev_1719,the ups as network management tool. uninterrupted power supplies ups or battery backup systems once provided a relatively limited although important function continual battery support to connected equipment in the event of a power failure. however yesterday s battery in a box has evolved into a sophisticated network power management tool that can monitor and actively correct many of the problems that might plague a healthy network. this new breed of ups system provides such features as automatic voltage regulation generous runtimes and unattended system shutdown and now also monitors and automatically restarts critical services and operating systems if they lock up or otherwise fail.
inspec,dev_172,a vmebus interface for multi detector trigger and control system. muse multiplicity selector is the trigger and control system of chimera a 4 pi charged particle detector. initialization of muse can be performed via vmebus. this paper describes the design of vmebus interface and functional module in muse and briefly discusses an application of muse.
inspec,dev_1721,dueling platforms healthcare network servers. many large hospitals and healthcare systems have grown accustomed to the reliability of mainframe architecture although tighter operating budgets coupled with advances in client server technology have led to more office and clinical applications being moved off mainframes. but evanston northwestern healthcare was n t ready to get rid of its ibm os 390 mainframe just yet. while a number of new clinical applications are being installed on two brand new ibm servers evanston northwestern healthcare will retain its favored hospital billing system and let it reside on the organization s mainframe as it has since 1982.
inspec,dev_1723,positive productivity better billing health care. workflow software provides the right communication solution for hospital specialists and delivers an unexpected financial boost too.
inspec,dev_1724,a winning combination wireless health care. three years ago the institute of medicine iom reported that medical errors result in at least 44 000 deaths each year more than deaths from highway accidents breast cancer or aids. that report and others which placed serious errors as high as 98 000 annually served as a wake up call for healthcare providers such as the caregroup healthcare system inc a boston area healthcare network that is the second largest integrated delivery system in the northeastern united states. with annual revenues of 1 2 b caregroup provides primary care and specialty services to more than 1 000 000 patients. caregroup combined wireless technology with the web to create a provider order entry poe system designed to reduce the frequency of costly medical mistakes. the poe infrastructure includes intersystems corporation s cache database dell computer c600 laptops and cisco systems aironet 350 wireless networks.
inspec,dev_1725,cutting the cord wireless health care. more and more healthcare executives are electing to cut the cord to their existing computer systems by implementing mobile technology. the allure of information anywhere anytime is intoxicating demonstrated by the cell phones and personal digital assistants pdas that adorn today s professionals. the utility and convenience of these devices is undeniable. but what is the best strategy for implementing a mobile solution within a healthcare enterprise be it large or small and under what circumstances. what types of healthcare workers benefit most from mobile technology. and how state of the art is security for wireless applications and devices. these are the questions that healthcare executives are asking and should be asking as they evaluate mobile solutions.
inspec,dev_1726,two layer model for the formation of states of the hidden markov chains. procedures for the formation of states of the hidden markov models are described. formant amplitudes and frequencies are used as state features. the training strategy is presented that allows one to calculate the parameters of conditional probabilities of the generation of a given formant set by a given hidden state with the help of the maximum likelihood method.
inspec,dev_1727,linguistic knowledge and new technologies. modern language studies are characterized by a variety of forms ways and methods of their development. in this connection it is necessary to specify the problem of the development of their internal differentiation and classification which lead to the formation of specific areas knowledge. an example of such an area is speechology a field of science belonging to fundamental theoretical and applied linguistics.
inspec,dev_1728,a characterization of generalized pareto distributions by progressive censoring schemes and goodness of fit tests. in this paper we generalize a characterization property of generalized pareto distributions which is known for ordinary order statistics to arbitrary schemes of progressive type ii censored order statistics. various goodness of fit tests for generalized pareto distributions based on progressively censored data statistics are discussed.
inspec,dev_1729,maintaining e commerce. e commerce over the web has created a relatively new type of information system. so it is hardly surprising that little attention has been given to the maintenance of such systems and even less to attempting to develop them with future maintenance in mind. but there are various ways e commerce systems can be developed to reduce future maintenance.
inspec,dev_173,stock market trading rule discovery using technical charting heuristics. in this case study in knowledge engineering and data mining we implement a recognizer for two variations of the bull flag technical charting heuristic and use this recognizer to discover trading rules on the nyse composite index. out of sample results indicate that these rules are effective.
inspec,dev_1730,meeting of minds. technical specialists need to think about their role in it projects and how they communicate with end users and other participants to ensure they contribute fully as team members. it is especially important to communicate and document trade offs that may have to be made including the rationale behind them so that if requirements change the impact and decisions can be readily communicated to the stakeholders.
inspec,dev_1731,hit the road jack. going freelance offers the potential of higher earnings variety and independence but also removes the benefits of permanent employment and can mean long distance travel and periods out of work. the author looks at the benefits and drawbacks and how to get started as an it contractor.
inspec,dev_1732,community spirit. it companies that contribute volunteers resources or funding to charities and local groups not only make a real difference to their communities but also add value to their businesses. so says a new coalition of it industry bodies formed to raise awareness of the options for community involvement promote the business case and publicise examples of best practice. the bcs intellect formed from the merger of the computing services and software association and the federation of the electronics industry and the worshipful company of information technologists plan to run advisory seminars and provide guidelines on how companies of all sizes can transform their local communities using their specialist it skills and resources while reaping business benefits.
inspec,dev_1733,computing grid unlocks research. under the uk government s spending review in 2000 the office of science and technology was allocated pounds 98m to establish a three year e science research and development programme. the programme has a bold vision to change the dynamic of the way science is undertaken. the term e science was introduced by john taylor director general of research councils in the office of science and technology. he saw many areas of science becoming increasingly reliant on new ways of collaborative multidisciplinary interorganisation working. e science is intended to capture these new modes of working. there are two major components to the programme the science and the infrastructure to support that science. the infrastructure is generally referred to as the grid. the choice of name resonates with the idea of a future in which computing resources and storage as well as expensive scientific facilities and software can be accessed on demand like electricity. open source prototypes of the middleware are available and under development as part of the e science programme and other international efforts.
inspec,dev_1734,going electronic auditing. a study group examines the issues auditors face in gathering electronic information as evidence and its impact on the audit.
inspec,dev_1735,mid market accounting systems. welcome to our fourth annual survey of accounting systems and enterprise resource planning erp systems. last september we concentrated on financial and distribution systems for medium sized businesses mid market and included 22 products in our charts. this year we extended the products to include manufacturing and added 34 products to the list.
inspec,dev_1736,wired right accounting. from business intelligence to wireless networking to service providers here is what you need to know to keep up to speed with a changing landscape.
inspec,dev_1737,the road to recovery disaster planning. september 11 stripped us of our innocence forcing corporations to recognize that disaster planning is a business necessity.
inspec,dev_1738,nurture the geek in you accounting on the internet. when chartered accountants focus on it it s not simply because we think technology is neat. we keep on top of tech trends and issues because it helps us do our jobs well. we need to know how to best manage and implement the wealth of technology systems within out client base or employer as well as to determine on an ongoing basis how evolving technologies might affect business strategies threats and opportunities. one way to stay current with technology is by monitoring the online drumbeat. imagine the internet as an endless conversation of millions of chattering voices each focusing on a multitude of topics and issues. it s not surprising that a great deal of the information relates to technology itself and if you learn how to tune in to the drumbeat you can keep yourself informed.
inspec,dev_1739,application of normal possibility decision rule to silence. the paper presents the way of combining two decision problems concerning a single or a common dimension so that an effective fuzzy decision rule can be obtained. normality of the possibility distribution is assumed leading to possibility of fusing the respective functions related to the two decision problems and their characteristics decisions states of nature utility functions etc. the approach proposed can be applied in cases when the statement of the problem requires making of more refined distinctions rather than considering simply a bi criterion or bi utility two decision problem.
inspec,dev_174,the biogenes system for knowledge based bioprocess control. the application of knowledge based control systems in the area of biotechnological processes has become increasingly popular over the past decade. this paper outlines the structure of the advanced knowledge based part of the biogenes copyright control system for the control of bioprocesses such as the fed batch saccharomyces cerevisiae cultivation. first a brief overview of all the tasks implemented in the knowledge based level including process data classification qualitative process state identification and supervisory process control is given. the procedures performing the on line identification of metabolic states and supervisory process control setpoint calculation and control strategy selection are described in more detail. finally the performance of the system is discussed using results obtained from a number of experimental cultivation runs in a laboratory unit.
inspec,dev_1740,verification of ideological classifications a statistical approach. the paper presents a statistical method of verifying ideological classifications of votes. parliamentary votes preclassified by an expert on a chosen subset are verified at an assumed significance level by seeking the most likely match with the actual vote results. classifications that do not meet the requirements defined are rejected. the results obtained can be applied in the ideological dimensioning algorithms enabling ideological identification of dimensions obtained.
inspec,dev_1741,the top cycle and uncovered solutions for weak tournaments. we study axiomatic properties of the top cycle and uncovered solutions for weak tournaments. subsequently we establish its connection with the rational choice theory.
inspec,dev_1742,a sufficient condition for optimality in nondifferentiable invex programming. a sufficient optimality condition is established for a nonlinear programming problem without differentiability assumption on the data wherein clarke s 1975 generalized gradient is used to define invexity.
inspec,dev_1743,adaptive stabilization of undamped flexible structures. in the paper non identifier based adaptive stabilization of undamped flexible structures is considered in the case of collocated input and output operators. the systems have poles and zeros on the imaginary axis. in the case where velocity feedback is available the adaptive stabilizer is constructed by an adaptive pd controller proportional plus derivative controller. in the case where only position feedback is available the adaptive stabilizer is constructed by an adaptive p controller for the augmented system which consists of the controlled system and a parallel compensator. numerical examples are given to illustrate the effectiveness of the proposed controllers.
inspec,dev_1744,convergence of toland s critical points for sequences of dc functions and application to the resolution of semilinear elliptic problems. we prove that if a sequence f sub n  sub n of dc functions difference of two convex functions converges to a dc function f in some appropriate way and if u sub n is a critical point of f sub n  in the sense described by toland 1978 1979 and is such that u sub n  sub n converges to u then u is a critical point of f still in toland s sense. we also build a new algorithm which searches for this critical point u and then apply it in order to compute the solution of a semilinear elliptic equation.
inspec,dev_1745,approximate relaxed descent method for optimal control problems. we consider an optimal control problem for systems governed by ordinary differential equations with control constraints. since no convexity assumptions are made on the data the problem is reformulated in relaxed form. the relaxed state equation is discretized by the implicit trapezoidal scheme and the relaxed controls are approximated by piecewise constant relaxed controls. we then propose a combined descent and discretization method that generates sequences of discrete relaxed controls and progressively refines the discretization. since here the adjoint of the discrete state equation is not defined we use at each iteration an approximate derivative of the cost functional defined by discretizing the continuous adjoint equation and the integral involved by appropriate trapezoidal schemes. it is proved that accumulation points of sequences constructed by this method satisfy the strong relaxed necessary conditions for optimality for the continuous problem. finally the computed relaxed controls can be easily approximated by piecewise constant classical controls.
inspec,dev_1746,the exact solution of coupled thermoelectroelastic behavior of piezoelectric laminates. exact solutions for static analysis of thermoelectroelastic laminated plates are presented. in this analysis a new concise procedure for the analytical solution of composite laminated plates with piezoelectric layers is developed. a simple eigenvalue formula in real number form is directly developed from the basic coupled piezoelectric differential equations and the difficulty of treating imaginary eigenvalues is avoided. the solution is defined in the trigonometric series and can be applied to thin and thick plates. numerical studies are conducted on a five layer piezoelectric plate and the complexity of stresses and deformations under combined loading is illustrated. the results could be used as a benchmark for assessing any numerical solution by approximate approaches such as the finite element method while also providing useful physical insight into the behavior of piezoelectric plates in a thermal environment.
inspec,dev_1747,on a general constitutive description for the inelastic and failure behavior of fibrous laminates. ii. laminate theory and applications. for pt. i see ibid pp 1159 76. the two papers report systematically a constitutive description for the inelastic and strength behavior of laminated composites reinforced with various fiber preforms. the constitutive relationship is established micromechanically through layer by layer analysis. namely only the properties of the constituent fiber and matrix materials of the composites are required as input data. in the previous part lamina theory was presented. three fundamental quantities of the laminae i e the internal stresses generated in the constituent fiber and matrix materials and the instantaneous compliance matrix with different fiber preform including woven braided and knitted fabric reinforcements were explicitly obtained by virtue of the bridging micromechanics model. in this paper the laminate stress analysis is shown. the purpose of this analysis is to determine the load shared by each lamina in the laminate so that the lamina theory can be applied. incorporation of the constitutive equations into an fem software package is illustrated. a number of application examples are given to demonstrate the efficiency of the constitutive theory. the predictions made include failure envelopes of multidirectional laminates subjected to biaxial in plane loads thermomechanical cycling stress strain curves of a titanium metal matrix composite laminate s n curves of multilayer knitted fabric reinforced laminates under tensile fatigue and bending load deflection plots and ultimate bending strengths of laminated braided fabric reinforced beams subjected to lateral loads.
inspec,dev_1748,on a general constitutive description for the inelastic and failure behavior of fibrous laminates. i lamina theory. it is well known that a structural design with isotropic materials can only be accomplished based on a stress failure criterion. this is however generally not true with laminated composites. only when the laminate is subjected to an in plane load can the ultimate failure of the laminate correspond to its last ply failure and hence a stress failure criterion may be sufficient to detect the maximum load that can be sustained by the laminate. even in such a case the load shared by each lamina in the laminate can not be correctly determined if the lamina instantaneous stiffness matrix is inaccurately provided since the lamina is always statically indeterminate in the laminate. if however the laminate is subjected to a lateral load its ultimate failure occurs before last ply failure and use of the stress failure criterion is no longer sufficient an additional critical deflection or curvature condition must also be employed. this necessitates development of an efficient constitutive relationship for laminated composites in order that the laminate strains deflections up to ultimate failure can be accurately calculated. a general constitutive description for the thermomechanical response of a fibrous laminate up to ultimate failure with applications to various fibrous laminates is presented in the two papers. the constitutive relationship is obtained by combining classical lamination theory with a recently developed bridging micromechanics model through a layer by layer analysis. this paper focuses on lamina analysis.
inspec,dev_1749,advanced aerostatic stability analysis of cable stayed bridges using finite element method. based on the concept of limit point instability an advanced nonlinear finite element method that can be used to analyze the aerostatic stability of cable stayed bridges is proposed. both geometric nonlinearity and three components of wind loads are considered in this method. the example bridge is the second santou bay cable stayed bridge with a main span length of 518 m built in china. aerostatic stability of the example bridge is investigated using linear and proposed methods. the effect of pitch moment coefficient on the aerostatic stability of the bridge has been studied. the results show that the aerostatic instability analyses of cable stayed bridges based on the linear method considerably overestimate the wind resisting capacity of cable stayed bridges. the proposed method is highly accurate and efficient. pitch moment coefficient has a major effect on the aerostatic stability of cable stayed bridges. finally the aerostatic failure mechanism of cable stayed bridges is explained by tracing the aerostatic instability path.
inspec,dev_175,diagnostic expert system using non monotonic reasoning. the objective of this work is to develop an expert system for cucumber disorder diagnosis using non monotonic reasoning to handle the situation when the system can not reach a conclusion. one reason for this situation is when the information is incomplete. another reason is when the domain knowledge itself is incomplete. another reason is when the information is inconsistent. this method maintains the truth of the system in case of changing a piece of information. the proposed method uses two types of non monotonic reasoning namely default reasoning and reasoning in the presence of inconsistent information to achieve its goal.
inspec,dev_1750,a dynamic method for weighted linear least squares problems. a new method for solving the weighted linear least squares problems with full rank is proposed. based on the theory of liapunov s stability the method associates a dynamic system with a weighted linear least squares problem whose solution we are interested in and integrates the former numerically by an a stable numerical method. the numerical tests suggest that the new method is more than comparative with current conventional techniques based on the normal equations.
inspec,dev_1751,an adaptive time step procedure for a parabolic problem with blow up. in this paper we introduce and analyze a fully discrete approximation for a parabolic problem with a nonlinear boundary condition which implies that the solutions blow up in finite time. we use standard linear elements with mass lumping for the space variable. for the time discretization we write the problem in an equivalent form which is obtained by introducing an appropriate time re scaling and then we use explicit runge kutta methods for this equivalent problem. in order to motivate our procedure we present it first in the case of a simple ordinary differential equation and show how the blow up time is approximated in this case. we obtain necessary and sufficient conditions for the blowup of the numerical solution and prove that the numerical blow up time converges to the continuous one. we also study for the explicit euler approximation the localization of blow up points for the numerical scheme.
inspec,dev_1752,non nested multi level solvers for finite element discretisations of mixed problems. we consider a general framework for analysing the convergence of multi grid solvers applied to finite element discretisations of mixed problems both of conforming and nonconforming type. as a basic new feature. our approach allows to use different finite element discretisations on each level of the multi grid hierarchy. thus in our multi level approach accurate higher order finite element discretisations can be combined with fast multi level solvers based on lower order nonconforming finite element discretisations. this leads to the design of efficient multi level solvers for higher order finite element discretisations.
inspec,dev_1753,risk theory with a nonlinear dividend barrier. in the framework of classical risk theory we investigate a surplus process in the presence of a nonlinear dividend barrier and derive equations for two characteristics of such a process the probability of survival and the expected sum of discounted dividend payments. number theoretic solution techniques are developed for approximating these quantities and numerical illustrations are given for exponential claim sizes and a parabolic dividend barrier.
inspec,dev_1754,coordination crisis management. communications during a crisis both internal and external set the tone during response and carry a message through recovery. the authors describe how to set up a system for information coordination to make sure the right people get the right message and the organization stays in control.
inspec,dev_1755,theta functions with harmonic coefficients over number fields. we investigate theta functions attached to quadratic forms over a number field k. we establish a functional equation by regarding the theta functions as specializations of symplectic theta functions. by applying a differential operator to the functional equation we show how theta functions with harmonic coefficients over k behave under modular transformations.
inspec,dev_1756,on the diophantine equation x sup 2  q sup 2k 1  y sup n. in this paper it has been proved that if q is an odd prime q not 7 mod 8 n is an odd integer or 5 n is not a multiple of 3 and h n 1 where h is the class number of the filed q square root q then the diophantine equation x sup 2  q sup 2k 1  y sup n has exactly two families of solutions q n k x y.
inspec,dev_1757,even unimodular gaussian lattices of rank 12. we classify even unimodular gaussian lattices of rank 12 that is even unimodular integral lattices of rank 12 over the ring of gaussian integers. this is equivalent to the classification of the automorphisms tau with tau sup 2  1 in the automorphism groups of all the niemeier lattices which are even unimodular real integral lattices of rank 24. there are 28 even unimodular gaussian lattices of rank 12 up to equivalence.
inspec,dev_1758,hilbert modular threefolds of arithmetic genus one. d weisser 1981 proved that there are exactly four galois cubic number fields with hilbert modular threefolds of arithmetic genus one. in this paper we extend weisser s work to cover all cubic number fields. our main result is that there are exactly 33 fields with hilbert modular threefolds of arithmetic genus one. these fields are enumerated explicitly.
inspec,dev_1759,on the p adic birch swinnerton dyer conjecture for non semistable reduction. in this paper we examine the iwasawa theory of elliptic curves e with additive reduction at an odd prime p by extending perrin riou s theory to certain nonsemistable representations we are able to convert kato s zeta elements into p adic l functions. this allows us to deduce the cotorsion of the selmer group over the cyclotomic z sub p  extension of q and thus prove an inequality in the p adic birch and swinnerton dyer conjecture at primes p whose square divides the conductor of e.
inspec,dev_176,knowledge model reuse therapy decision through specialisation of a generic decision model. we present the definition of the therapy decision task and its associated heuristic multi attribute hm solving method in the form of a kads style specification. the goal of the therapy decision task is to identify the ideal therapy for a given patient in accordance with a set of objectives of a diverse nature constituting a global therapy evaluation framework in which considerations such as patient preferences and quality of life results are integrated. we give a high level overview of this task as a specialisation of the generic decision task and additional decomposition methods for the subtasks involved. these subtasks possess some reflective capabilities for reasoning about self models particularly the learning subtask which incrementally corrects and refines the model used to assess the effects of the therapies. this work illustrates the process of reuse in the framework of ai software development methodologies such as kads commonkads in order to obtain new more specialised but still generic components for the analysis libraries developed in this context. in order to maximise reuse benefits where possible the therapy decision task and hm method have been defined in terms of regular components from the earlier mentioned libraries. to emphasise the importance of using a rigorous approach to the modelling of domain and method ontologies we make extensive use of the semi formal object oriented analysis notation uml together with its associated constraint language ocl to illustrate the ontology of the decision method and the corresponding specific one of the therapy decision domain the latter being a refinement via inheritance of the former.
inspec,dev_1760,dihedral congruence primes and class fields of real quadratic fields. we show that for a real quadratic field f the dihedral congruence primes with respect to f for cusp forms of weight k and quadratic nebentypus are essentially the primes dividing expressions of the form epsilon sub  sup k 1  or 1 where epsilon sub  is a totally positive fundamental unit of f. this extends work of hida. our results allow us to identify a family of ray class fields of f which are generated by torsion points on modular abelian varieties.
inspec,dev_1761,superconvergence of discontinuous galerkin method for nonstationary hyperbolic equation. for the first order nonstationary hyperbolic equation taking the piecewise linear discontinuous galerkin solver we prove that under the uniform rectangular partition such a discontinuous solver after postprocessing can have two and half approximative order which is half order higher than the optimal estimate by p lesaint and p raviart 1974 under the rectangular partition.
inspec,dev_1762,laguerre pseudospectral method for nonlinear partial differential equations. the laguerre gauss radau interpolation is investigated. some approximation results are obtained. as an example the laguerre pseudospectral scheme is constructed for the bbm equation. the stability and the convergence of proposed scheme are proved. the numerical results show the high accuracy of this approach.
inspec,dev_1763,numerical studies of 2d free surface waves with fixed bottom. the motion of surface waves under the effect of bottom is a very interesting and challenging phenomenon in the nature. we use boundary integral method to compute and analyze this problem. in the linear analysis the linearized equations have bounded error increase under some compatible conditions. this contributes to the cancellation of instable kelvin helmholtz terms. under the effect of bottom the existence of equations is hard to determine but given some limitations it proves true. these limitations are that the swing of interfaces should be small enough and the distance between surface and bottom should be large enough. in order to maintain the stability of computation some compatible relationship must be satisfied. in the numerical examples the simulation of standing waves and breaking waves are calculated. and in the case of shallow bottom we found that the behavior of waves are rather singular.
inspec,dev_1764,two scale curved element method for elliptic problems with small periodic coefficients. this paper is concerned with the second order elliptic problems with small periodic coefficients on a bounded domain with a curved boundary. a two scale curved element method which couples linear elements and isoparametric elements is proposed. the error estimate is obtained over the given smooth domain. furthermore an additive schwarz method is provided for the isoparametric element method.
inspec,dev_1765,on bandlimited scaling function. this paper discusses band limited scaling function especially the single interval band case and three interval band cases. their relationship to oversampling property and weakly translation invariance are also studied. at the end we propose an open problem.
inspec,dev_1766,a note on vector cascade algorithm. the focus of this paper is on the relationship between accuracy of multivariate refinable vector and vector cascade algorithm. we show that if the vector cascade algorithm 1 5 with isotropic dilation converges to a vector valued function with regularity then the initial function must satisfy the strang fix conditions.
inspec,dev_1767,bivariate fractal interpolation functions on rectangular domains. non tensor product bivariate fractal interpolation functions defined on gridded rectangular domains are constructed. linear spaces consisting of these functions are introduced. the relevant lagrange interpolation problem is discussed. a negative result about the existence of affine fractal interpolation functions defined on such domains is obtained.
inspec,dev_1768,isogenous of the elliptic curves over the rationals. an elliptic curve is a pair e o where e is a smooth projective curve of genus 1 and o is a point of e called the point at infinity. every elliptic curve can be given by a weierstrass equation e y sup 2  a sub 1 xy a sub 3 y x sup 3  a sub 2 x sup 2  a sub 4 x a sub 6. let q be the set of rationals. e is said to be defined over q if the coefficients a sub i  i 1 2 3 4 6 are rationals and o is defined over q let e q be an elliptic curve and let e q sub tors be the torsion group of points of e defined over q. the theorem of mazur asserts that e q sub tors is one of the following 15 groups e q sub tors z mz z mz z 2mz m  1 2  10 12 m 1 2 3 4. we say that an elliptic curve e  q is isogenous to the elliptic curve e if there is an isogeny i e a morphism phi e to e such that phi o o where o is the point at infinity. we give an explicit model of all elliptic curves for which e q sub tors is in the form z mz where m 9 10 12 or z 2z z 2mz where m 4 according to mazur s theorem. moreover for every family of such elliptic curves we give an explicit model of all their isogenous curves with cyclic kernels consisting of rational points.
inspec,dev_1769,transformation rules and strategies for functional logic programs. this paper abstracts the contents of a phd dissertation entitled transformation rules and strategies for functional logic programs which has been recently defended. these techniques are based on fold unfold transformations and they can be used to optimize integrated functional logic programs for a wide class of applications. experimental results show that typical examples in the field of artificial intelligence are successfully enhanced by our transformation system synth. the thesis presents the first approach of these methods for declarative languages that integrate the best features from functional and logic programming.
inspec,dev_177,turning telecommunications call details to churn prediction a data mining approach. as deregulation new technologies and new competitors open up the mobile telecommunications industry churn prediction and management has become of great concern to mobile service providers. a mobile service provider wishing to retain its subscribers needs to be able to predict which of them may be at risk of changing services and will make those subscribers the focus of customer retention efforts. in response to the limitations of existing churn prediction systems and the unavailability of customer demographics in the mobile telecommunications provider investigated we propose design and experimentally evaluate a churn prediction technique that predicts churning from subscriber contractual information and call pattern changes extracted from call details. this proposed technique is capable of identifying potential churners at the contract level for a specific prediction time period. in addition the proposed technique incorporates the multi classifier class combiner approach to address the challenge of a highly skewed class distribution between churners and non churners. the empirical evaluation results suggest that the proposed call behavior based churn prediction technique exhibits satisfactory predictive effectiveness when more recent call details are employed for the churn prediction model construction. furthermore the proposed technique is able to demonstrate satisfactory or reasonable predictive power within the one month interval between model construction and churn prediction. using a previous demographics based churn prediction system as a reference the lift factors attained by our proposed technique appear largely satisfactory.
inspec,dev_1770,new developments in inductive learning. any intelligent system whether natural or artificial must have three characteristics knowledge reasoning and learning. artificial intelligence ai studies these three aspects in artificial systems. briefly we could say that knowledge refers to the system s world model and reasoning to the manipulation of this knowledge. learning is slightly more complex the system interacts with the world and as a consequence it builds onto and modifies its knowledge. this process of self building and self modifying is known as learning. this thesis is set within the field of artificial intelligence and focuses on learning. more specifically it deals with the inductive learning of decision trees.
inspec,dev_1771,quadratic gauss sums over finite commutative rings. this article explicitly determines the quadratic gauss sum over finite commutative rings.
inspec,dev_1772,the effects of technology on midcareer librarians. this article investigates technology competency requirements in the library profession. using the position advertisements in american libraries in five year increments over a twenty year period 1970 1990 the article examines and evaluates the advertised qualifications of positions and attempts to see if midcareer librarians especially those who have achieved their degree prior to the change in mls curriculum that currently emphasizes technology are effective librarians in the present and future job market.
inspec,dev_1773,happily ever after plateauing as a means for long term career satisfaction. little did i know when i attended judith bardwick s presentation on plateauing at the ala annual convention in 1988 that it would turn out to be one of the most valuable sessions i would attend at any library conference since it has enabled me to understand the phenomenon of plateauing and to use the strategies she suggested to rejuvenate my career and personal life continually. key concepts and solutions from her book and from other literature on plateauing are summarized and examples given as to how i incorporated them into my life.
inspec,dev_1774,a work journal librarianship. keeping a work journal can be useful in exploring one s thoughts and feelings about work challenges and work decisions. it can help bring about greater fulfillment in one s work life by facilitating self renewal change the search for new meaning and job satisfaction. one example of a work journal which i kept in 1998 is considered. it touches on several issues of potential interest to midlife career librarians including the challenge of technology returning to work at midlife after raising a family further education professional writing and job exchange.
inspec,dev_1775,are we there yet. facing the never ending speed and change of technology in midlife. this essay is a personal reflection on entering librarianship in middle age at a time when the profession like society in general is experiencing rapidly accelerating change. much of this change is due to the increased use of computers and information technologies in the library setting. these aids in the production collection storage retrieval and dissemination of the collective information knowledge and sometimes wisdom of the past and the contemporary world can exhilarate or burden depending on one s worldview the organization and the flexibility of the workplace. this writer finds herself working in a library where everyone is expected continually to explore and use new ways of working and providing library service to a campus and a wider community. no time is spent in reflecting on what was but all efforts are to anticipate and prepare for what will be.
inspec,dev_1776,job rotation in an academic library damned if you do and damned if you do n t. this article considers job rotation the systematic movement of employees from one job to another as one of the many tools within the organizational development tool kit. there is a brief consideration of useful print and internet literature on the subject as well as a discussion of the pros and cons of job rotation. the application of job rotation methods in ryerson university library a small academic library concludes the article in order to illustrate process and insights through example.
inspec,dev_1777,midlife career choices how are they different from other career choices. it was 1963 when candy start began working in libraries. libraries seemed to be a refuge from change a dependable environment devoted primarily to preservation. she was mistaken. technological changes in every decade of her experience have affected how and where she used her mls. far from a static refuge libraries have proven to be spaceships loaded with precious cargo hurtling into the unknown. the historian in the author says that perhaps libraries have always been like this. this paper looks at a midlife decision point and the choice that this librarian made to move from a point of lessening productivity and interest to one of increasing challenge and contribution. it is a personal narrative of midlife experience from one librarian s point of view. since writing this article candy s career has followed more changes. after selling the wings tm system she has taken her experiences and vision to another library vendor gaylord information systems where she serves as a senior product strategist.
inspec,dev_1778,helin pilot mentoring scheme. the health care libraries unit coordinates facilitates and promotes continuing personal development for all staff in the health libraries and information network helin of the oxford deanery uk. it supports the development of a culture of lifelong learning and recognizes that cpd should help deliver organizational objectives as well as enabling all staff to expand and fulfill their potential. a major emphasis for 2000 was to investigate ways of improving support for individual learning within the workplace. the group identified a need to build on existing informal support networks in order to provide additional learning opportunities and decided to investigate the feasibility of piloting a mentoring scheme. the objectives of the pilot were to increase understanding and knowledge of mentoring as a tool for cpd to investigate existing mentoring schemes and their applicability for helin to develop a pilot mentoring scheme for helin incorporating a program for accreditation of mentors and to evaluate the scheme and disseminate the results. in order to identify current practice in this area a literature review was carried out and colleagues with an interest in or existing knowledge of mentoring schemes were contacted where possible. in the absence of clearly defined appraisal tools all abstracts were read and articles that met the following criteria were obtained and distributed to the group for review.
inspec,dev_1779,maybe it s not too late to join the circus books for midlife career management. midcareer librarians looking for career management help on the bookshelf face thousands of choices. this article reviews thirteen popular career self help books. the reviewed books cover various aspects of career management and provide information on which might be best suited for particular goals including career change career tune up and personal and professional self evaluation. the comments reflect issues of interest to midcareer professionals.
inspec,dev_178,a parallelized indexing method for large scale case based reasoning. case based reasoning cbr is a problem solving methodology commonly seen in artificial intelligence. it can correctly take advantage of the situations and methods in former cases to find out suitable solutions for new problems. cbr must accurately retrieve similar prior cases for getting a good performance. in the past many researchers proposed useful technologies to handle this problem. however the performance of retrieving similar cases may be greatly influenced by the number of cases. in this paper the performance issue of large scale cbr is discussed and a parallelized indexing architecture is then proposed for efficiently retrieving similar cases in large scale cbr. several algorithms for implementing the proposed architecture are also described. some experiments are made and the results show the efficiency of the proposed method.
inspec,dev_1780,migrating to public librarianship depart on time to ensure a smooth flight. career change can be a difficult time consuming and anxiety laden process for anyone contemplating this important decision. the challenges faced by librarians considering the move from academic to public librarianship can be equally and significantly demanding. to most outsiders at least on the surface it may appear to be a quick and easy transition to make but some professional librarians recognize the distinct differences between these areas of librarianship. although the ubiquitous nature of technology has brought the various work responsibilities of academic and public librarians closer together during the last decade there remain key differences in job related duties and the work environments. these dissimilarities pose meaningful hurdles to leap for academic librarians wishing to migrate to the public sector. the paper considers the variations between academic and public librarianship.
inspec,dev_1781,making it to the major leagues career movement between library and archival professions and from small college to large university libraries. issues of career movement and change are examined between library and archival fields and from small colleges to large universities. issues examined include professional education and training initial career planning and placement continuing education scouting and mentoring job market conditions work experience and personal skills professional involvement and professional association self interest. this examination leads to five observations 1. it is easier in terms of career transitions for a librarian to become an archivist than it is for an archivist to become a librarian 2. the progression from a small college venue to a large research university is very manageable with the proper planning and experience 3. at least three of the career elements professional education career planning and professional association self interest in their best moments provide a foundation that enables a future consideration of change between institutional types and professional areas and in their worst moments conspire against the midcareer professional in terms of change 4. the elements of scouting continuing education work experience and professional involvement offer the greatest assistance in career transitions 5. the job market is the wildcard that either stymies or stimulates occupational development.
inspec,dev_1782,exploring the sabbatical or other leave as a means of energizing a career. this article challenges librarians to create leaves that will not only inspire professional growth but also renewal. it presents a framework for developing a successful leave incorporating useful advice from librarians at concordia university montreal. as food for thought the article offers examples of specific options meant to encourage professionals to explore their own creative ideas. finally a central theme of this article is that a midlife leave provides one with the perfect opportunity to take stock of oneself in order to define future career directions. midlife is a time when rebel forces feisty protestors from within often insist on being heard. it is a time in other words when professionals often long to break loose from the stress to do far more in less time barner 1994. escaping from current job constraints into a world of creative endeavor when well executed is a superb means of invigorating a career stuck in gear and discovering a fresh perspective from which to view one s profession. to ignite renewal midcareer is the perfect time to grant one s imagination free reign.
inspec,dev_1783,becoming a chief librarian an analysis of transition stages in academic library leadership. the author explores how the four part model of transition cycles identified by nicholson and west 1988 applies to becoming a chief librarian of an academic library. the four stages preparation encounter adjustment and stabilization are considered from the micro  mezzo  and macrolevels of the organization as well as for their psychological and social impact on the new job incumbent. an instrument for assessment of transitional success which could be administered in the adjustment or stabilization stage is considered.
inspec,dev_1784,cyberethics bibliography 2002 a select list of recent works. included in the 2002 annual bibliography update is a select list of recent books and conference proceedings that have been published since 2000. also included is a select list of special issues of journals and periodicals that were recently published. for additional lists of recently published books and articles see ibid. june 2000 june 2001.
inspec,dev_1785,the effect of a male oriented computer gaming culture on careers in the computer industry. if careers in the computer industry were viewed it would be evident that there is a conspicuous gender gap between the number of male and female employees. the same gap can be observed at the college level where males are dominating females as to those who pursue and obtain a degree in computer science. the question that this research paper intends to show is why are males so dominant when it comes to computer related matters. the author has traced this question back to the computer game. computer games are a fun medium and provide the means for an individual to become computer literate through the engagement of spatial learning and cognitive processing abilities. since such games are marketed almost exclusively to males females have a distinct disadvantage. males are more computer literate through the playing of computer games and are provided with an easy lead in to more advanced utilization of computers such as programming. females tend to be turned off due to the male stereotypes and marketing associated with games and thus begins the gender gap.
inspec,dev_1786,a humane tool for aiding computer science advisors computer science students and parents. over the past few years the computer science department faculty at baylor has observed that some students who perform adequately during the freshman and sophomore years have substantial difficulty during the junior and senior years of study. baylor university is an institution committed to being caring of its students. the objective for this study grew out of these two realities. there are three objectives of this research. one objective is to identify students no later than the sophomore year who are less likely to succeed as computer science majors. a second objective is to accomplish this identification by using data from seniors majoring in computer science. a third objective is to begin to use this information at the end of their sophomore year when meeting with a computer science faculty advisor. a regression study is conducted on the data from all students classified as seniors majoring in computer science in may 2001 showing grades in six freshman and sophomore courses and showing grades for at least five junior or senior level computer science courses. these students and their course performance data constituted the study sample.
inspec,dev_1787,the theory of information reversal. the end of the industrial age coincides with the advent of the information society as the next model of social and economic organization which brings about significant changes in the way modern man conceives work and the social environment. the functional basis of the new model is pivoted upon the effort to formulate the theory on the violent reversal of the basic relationship between man and information and isolate it as one of the components for the creation of the new electronic reality. the objective of the theory of reversal is to effectively contribute to the formulation of a new definition consideration in regards to the concept of the emerging information society. in order to empirically apply the theory of reversal we examine a case study based on the example of the digital library.
inspec,dev_1788,resolving web user on the fly. identity authentication systems and procedures are rapidly becoming central issues in the practice and study of information systems development and security. requirements for web transaction security wts include strong authentication of a user non repudiation and encryption of all traffic. in this paper we present an effective mechanism involving two different channels which addresses the prime concerns involved in the security of electronic commerce transactions ect viz. user authentication and non repudiation. although the product is primarily targeted to provide a fillip to transactions carried out over the web this product can also be effectively used for non internet transactions that are carried out where user authentication is required.
inspec,dev_1789,dousing terrorist funding mission possible. banks. the government is tightening its grip on terrorist money flows. but as the banking industry continues to expand its patriot act compliance activities it is with the realization that a great deal of work remains to be done before the american financial system can become truly airtight. identification instruments especially drivers licenses represent a significant weak spot.
inspec,dev_179,document based workflow modeling a case based reasoning approach. a workflow model is useful for business process analysis. a well built workflow can help a company streamline its internal processes by reducing overhead. the results of workflow modeling need to be managed as information assets in a systematic fashion. reusing these results is likely to enhance the quality of the modeling. therefore this paper proposes a document based workflow modeling mechanism which employs a case based reasoning cbr technique for the effective reuse of design outputs. a repository is proposed to support this cbr process. a real life case is illustrated to demonstrate the usefulness of our approach.
inspec,dev_1790,copyright of electronic publishing. with the spreading of the internet and the wide use of computers electronic publishing is becoming an indispensable measure to gain knowledge and skills. meanwhile copyright is facing much more infringement than ever in this electronic environment. so it is a key factor to effectively protect copyright of electronic publishing to foster the new publication fields. the paper analyzes the importance of copyright the main causes for copyright infringement in electronic publishing and presents viewpoints on the definition and application of fair use of a copyrighted work and thinking of some means to combat breach of copyright.
inspec,dev_1791,the pedagogy of on line learning a report from the university of the highlands and islands millennium institute. authoritative sources concerned with computer aided learning resource based learning and on line learning and teaching are generally agreed that in addition to subject matter expertise and technical support the quality of the learning materials and the learning experiences of students are critically dependent on the application of pedagogically sound theories of learning and teaching and principles of course design. the university of the highlands and islands project uhimi is developing on line learning on a large scale. these developments have been accompanied by a comprehensive programme of staff development. a major emphasis of the programme is concerned with ensuring that course developers and tutors are pedagogically aware. this paper reviews i what is meant by on line learning in the uhimi context ii the theories of learning and teaching and principles of course design that inform the staff development programme and iii a review of progress to date.
inspec,dev_1792,database technology in digital libraries. database technology advancements have provided many opportunities for libraries. these advancements can bring the world closer together through information accessibility. digital library projects have been established worldwide to ultimately fulfil the needs of end users through more efficiency and convenience. resource sharing will continue to be the trend for libraries. changes often create issues which need to be addressed. issues relating to database technology and digital libraries are reviewed. some of the major challenges in digital libraries and managerial issues are identified as well.
inspec,dev_1793,the paradigm of viral communication. the iiw institute of information management www iiw de is dealing with commercial applications of digital technologies such as the internet digital printing and many more. a study which has been carried out by the institute identifies viral messages as a new paradigm of communication mostly found in the area of direct marketing and who wonders mainly within the usa. viral messages underlie certain principles 1 prospects and customers of the idea are offered a technology platform providing a possibility to send a message to a majority of persons 2 there is an emotional or pecuniary incentive to participate. ideally niches of needs and market vacua are filled with funny ideas 3 also the recipients are facing emotional or pecuniary incentives to contact a majority of further recipients this induces a snowball effect and the message is spread virally and 4 the customer is activated as an ambassador of the piece of information for instance promoting a product or a company. it is evident that there has been a long lasting history of what we call word of mouth ever since however bundles of digital technologies empower the viral communication paradigm.
inspec,dev_1794,well posed anisotropic diffusion for image denoising. a nonlinear iterative smoothing filter based on a second order partial differential equation is introduced. it smooths out the image according to an anisotropic diffusion process. the approach is based on a smooth approximation of the total variation tv functional which overcomes the non differentiability of the tv functional at the origin. in particular the authors perform linear smoothing over smooth areas but selective smoothing over candidate edges. by relating the smoothing parameter to the time step they arrive at a cfl condition which guarantees the causality of the discrete scheme. this allows the adoption of higher time discretisation steps while ensuring the absence of artefacts deriving from the non smooth behaviour of the tv functional at the origin. in particular it is shown that the proposed approach avoids the typical staircase effects in smooth areas which occur in the standard time marching tv scheme.
inspec,dev_1795,new voice over internet protocol technique with hierarchical data security protection. the authors propose a voice over internet protocol voip technique with a new hierarchical data security protection hdsp scheme. the proposed hdsp scheme can maintain the voice quality degraded from packet loss and preserve high data security. it performs both the data inter leaving on the inter frame of voice for achieving better error recovery of voices suffering from continuous packet loss and the data encryption on the intra frame of voice for achieving high data security which are controlled by a random bit string sequence generated from a chaotic system. to demonstrate the performance of the proposed hdsp scheme we have successfully verified and analysed the proposed approach through software simulation and statistical measures on several test voices.
inspec,dev_1796,taylor series based two dimensional digital differentiators. a new type of taylor series based 2 d finite difference approximation is presented and it is shown that the coefficients of these approximations are not unique. explicit formulas are presented for one of the possible sets of coefficients for an arbitrary order by extending the previously presented 1 d approximations. these coefficients are implemented as maximally linear 2 d fir digital differentiators and their formulas are modified to narrow the inaccuracy regions on the resultant frequency responses close to the nyquist frequencies.
inspec,dev_1797,use of periodic and monotonic activation functions in multilayer feedforward neural networks trained by extended kalman filter algorithm. the authors investigate the convergence and pruning performance of multilayer feedforward neural networks with different types of neuronal activation functions in solving various problems. three types of activation functions are adopted in the network namely the traditional sigmoid function the sinusoidal function and a periodic function that can be considered as a combination of the first two functions. to speed up the learning as well as to reduce the network size the extended kalman filter ekf algorithm conjunct with a pruning method is used to train the network. the corresponding networks are applied to solve five typical problems namely 4 point xor logic function parity generation handwritten digit recognition piecewise linear function approximation and sunspot series prediction. simulation results show that periodic activation functions perform better than monotonic ones in solving multicluster classification problems. moreover the combined periodic activation function is found to possess the fast convergence and multicluster classification capabilities of the sinusoidal activation function while keeping the robustness property of the sigmoid function required in the modelling of unknown systems.
inspec,dev_1798,robustness evaluation of a minimal rbf neural network for nonlinear data storage channel equalisation. the authors present a performance robustness evaluation of the recently developed minimal resource allocation network mran for equalisation in highly nonlinear magnetic recording channels in disc storage systems. unlike communication systems equalisation of signals in these channels is a difficult problem as they are corrupted by data dependent noise and highly nonlinear distortions. nair and moon 1997 have proposed a maximum signal to distortion ratio msdr equaliser for data storage channels which uses a specially designed neural network where all the parameters of the neural network are determined theoretically based on the exact knowledge of the channel model parameters. in the present paper the performance of the msdr equaliser is compared with that of the mran equaliser using a magnetic recording channel model under conditions that include variations in partial erasure jitter width and noise power as well as model mismatch. results from the study indicate that the less complex mran equaliser gives consistently better performance robustness than the msdr equaliser in terms of signal to distortion ratios sdrs.
inspec,dev_1799,steady state mean square error analysis of the cross correlation and constant modulus algorithm in a mimo convolutive system. the cross correlation and constant modulus algorithm cc cma has been proven to be an effective approach in the problem of joint blind equalisation and source separation in a multi input and multi output system. in the paper the steady state mean square error performance of cc cma in a noise free environment is studied and a new expression is derived based on the energy preservation approach of mai and sayed 2000. simulation studies are undertaken to support the analysis.
inspec,dev_18,differential and integral calculus on discrete time series data. it has been found that discontinuity plays a crucial role in natural evolutions lin 1998. in this presentation we will generalize the idea of integration and differentiation we developed in calculus to the study of time series in the hope that the problem of outliers and discontinuities can be resolved more successfully than simply deleting the outliers and avoiding discontinuities from the overall data analysis. in general appearances of outliers tend to mean existence of discontinuities explosive growth or decline in the evolution. at the same time our approach can be employed to partially overcome the problem of not having enough data values in any available time series. at the end we will look at some real life problems of prediction in order to see the power of this new approach.
inspec,dev_180,problems with my pda. tom berry has lost his pda and now he has an even better understanding of the risks and benefits of working on the move.
inspec,dev_1800,multi output regression using a locally regularised orthogonal least squares algorithm. the paper considers data modelling using multi output regression models. a locally regularised orthogonal least squares lrols algorithm is proposed for constructing sparse multi output regression models that generalise well. by associating each regressor in the regression model with an individual regularisation parameter the ability of the multi output orthogonal least squares ols model selection to produce a parsimonious model with a good generalisation performance is greatly enhanced.
inspec,dev_1801,least load dispatching algorithm for parallel web server nodes. a least load dispatching algorithm for distributing requests to parallel web server nodes is described. in this algorithm the load offered to a node by a request is estimated based on the expected transfer time of the corresponding reply through the internet. this loading information is then used by the algorithm to identify the least load node of the web site. by using this algorithm each request will always be sent for service at the earliest possible time. performance comparison using nasa and clarknet access logs between the proposed algorithm and commonly used dispatching algorithms is performed. the results show that the proposed algorithm gives 10 higher throughput than that of the commonly used random and round robin dispatching algorithms.
inspec,dev_1802,novel tcp congestion control scheme and its performance evaluation. a novel self tuning proportional and derivative st pd control based tcp congestion control scheme is proposed. the new scheme approaches the congestion control problem from a control theoretical perspective and overcomes several important limitations associated with existing tcp congestion control schemes which are heuristic based. in the proposed scheme a pd controller is employed to keep the buffer occupancy of the bottleneck node on the connection path at an ideal operating level and it adjusts the tcp window accordingly. the control gains of the pd controller are tuned online by a fuzzy logic controller based on the perceived bandwidth delay product of the tcp connection. this scheme gives st pd tcp several advantages over current tcp implementations. these include rapid response to bandwidth variations insensitivity to buffer sizes and significant improvement of tcp throughput over lossy links by decoupling congestion control and error control functions of tcp.
inspec,dev_1803,linear complexity of polyphase power residue sequences. the well known family of binary legendre or quadratic residue sequences can be generalised to the multiple valued case by employing a polyphase representation. these p phase sequences with p prime also have prime length l and can be constructed from the index sequence of length l or equivalently from the cosets of pth power residues and non residues modulo l. the linear complexity of these polyphase sequences is derived and shown to fall into four classes depending on the value assigned to b sub 0  the initial digit of the sequence and on whether p belongs to the set of pth power residues or not. the characteristic polynomials of the linear feedback shift registers that generate these sequences are also derived.
inspec,dev_1804,module placement with boundary constraints using b  trees. the module placement problem is to determine the co ordinates of logic modules in a chip such that no two modules overlap and some cost e g silicon area interconnection length etc is optimised. to shorten connections between inputs and outputs and or make related modules adjacent it is desired to place some modules along the specific boundaries of a chip. to deal with such boundary constraints we explore the feasibility conditions of a b  tree with boundary constraints and develop a simulated annealing based algorithm using b  trees. unlike most previous work the proposed algorithm guarantees a feasible b  tree with boundary constraints for each perturbation. experimental results show that the algorithm can obtain a smaller silicon area than the most recent work based on sequence pairs.
inspec,dev_1805,exact analytical model for the aep of control signals. an exact analytical model for the aliasing error probability aep in the signature analysis of control signals using a modified signature analyser is presented. the signature analyser used comprises a general structure two input compacting module ticm which simplifies the motherboard vlsi design by providing a flexible geometry which could be easily integrated with neighbouring structures. the use of the modified data probe eliminates the ambiguity introduced by the high impedance state and at the same time retains the same signature of the binary stream. the model specifies algebraically the effects of the ticm architecture the test pattern length and the control stream error probabilities. it is proved that the hardware criterion used for calculating the aep for the internal and external exclusive or two input shift registers is not valid for the general case and a new criterion is provided. the results obtained are augmented by two special cases a case study and associated simulation.
inspec,dev_1806,fast and efficient algorithm for the multiplierless realisation of linear dsp transforms. a fast algorithm having a pseudopolynomial run time and memory requirement in the worst case is developed to generate multiplierless architectures at all wordlengths for constant multiplications in linear dsp transforms. it is also re emphasised that indefinitely reducing operators for multiplierless architectures is not sufficient to reduce the final chip area. for a major reduction techniques like resource folding must be used. simple techniques for improving the results are also presented.
inspec,dev_1807,regional flux target with minimum energy. an extension of a gradient controllability problem to the case where the target subregion is a part of the boundary of a parabolic system domain is discussed. a definition and some properties adapted to this case are presented. the focus is on the characterisation of the control achieving a regional boundary gradient target with minimum energy. an approach is developed that leads to a numerical algorithm for the computation of optimal control. numerical illustrations show the efficiency of the approach and lead to conjectures.
inspec,dev_1808,nonlinearities in narx polynomial models representation and estimation. it is shown how nonlinearities are mapped in narx polynomial models. general expressions are derived for the gain and eigenvalue functions in terms of the regressors and coefficients of narx models. such relationships are useful in grey box identification problems. the results are illustrated using simulated and real data.
inspec,dev_1809,approach to adaptive neural net based h sub infinity control design. an approach is investigated for the adaptive neural net based h sub infinity control design of a class of nonlinear uncertain systems. in the proposed framework two multilayer feedforward neural networks are constructed as an alternative to approximate the nonlinear system. the neural networks are piecewisely interpolated to generate a linear differential inclusion model by which a linear state feedback h sub infinity control law can be applied. an adaptive weight adjustment mechanism for the multilayer feedforward neural networks is developed to ensure h sub infinity regulation performance. it is shown that finding the control gain matrices can be transformed into a standard linear matrix inequality problem and solved via a developed recurrent neural network.
inspec,dev_181,electromagnetics computations using the mpi parallel implementation of the steepest descent fast multipole method sdfmm. the computational solution of large scale linear systems of equations necessitates the use of fast algorithms but is also greatly enhanced by employing parallelization techniques. the objective of this work is to demonstrate the speedup achieved by the mpi message passing interface parallel implementation of the steepest descent fast multipole method sdfmm. although this algorithm has already been optimized to take advantage of the structure of the physics of scattering problems there is still the opportunity to speed up the calculation by dividing tasks into components using multiple processors and solve them in parallel. the sdfmm has three bottlenecks ordered as 1 filling the sparse impedance matrix associated with the near field method of moments interactions mom 2 the matrix vector multiplications associated with this sparse matrix and 3 the far field interactions associated with the fast multipole method. the parallel implementation task is accomplished using a thirty one node intel pentium beowulf cluster and is also validated on a 4 processor alpha workstation. the beowulf cluster consists of thirty one nodes of 350 mhz intel pentium iis with 256 mb of ram and one node of a 4 450 mhz intel pentium ii xeon shared memory processor with 2 gb of ram with all nodes connected to a 100 basetx ethernet network. the alpha workstation has a maximum of four 667 mhz processors. our numerical results show significant linear speedup in filling the sparse impedance matrix. using the 32 processors on the beowulf cluster lead to a 7 2 overall speedup while a 2 5 overall speedup is gained using the 4 processors on the alpha workstation.
inspec,dev_1810,input output based pole placement controller for a class of time delay systems. a controller structure valid for siso plants involving both internal and external point delays is presented. the control signal is based only on the input and output plant signals. the controller allows finite or infinite spectrum assignment. the most important feature of the proposed controller is that it only involves the use of a class of point delayed signals. thus the controller synthesis involves less computational cost than former methods. since the plant control input is generated by filtering the input and output plant signals this controller structure is potentially applicable to the adaptive case of unknown plant parameters.
inspec,dev_1811,adaptive tracking controller design for robotic systems using gaussian wavelet networks. an adaptive tracking control design for robotic systems using gaussian wavelet networks is proposed. a gaussian wavelet network with accurate approximation capability is employed to approximate the unknown dynamics of robotic systems by using an adaptive learning algorithm that can learn the parameters of the dilation and translation of gaussian wavelet functions. depending on the finite number of wavelet basis functions which result in inevitable approximation errors a robust control law is provided to guarantee the stability of the closed loop robotic system that can be proved by lyapunov theory. finally the effectiveness of the gaussian wavelet network based control approach is illustrated through comparative simulations on a six link robot manipulator.
inspec,dev_1812,computing the frequency response of systems affinely depending on uncertain parameters. the computation of the frequency response of systems depending affinely on uncertain parameters can be reduced to that of all its one dimensional edge plants while the image of such an edge plant at a fixed frequency is an arc or a line segment in the complex plane. based on this conclusion four computational formulas of the maximal and minimal maxi mini magnitudes and phases of an edge plant at a fixed frequency are given. the formulas besides sharing a simpler form of expression concretely display how the extrema of the frequency response of the edge plant relate to the typical characteristics of the arc and line segment such as the centre radius and tangent points of the arc the distance from the origin to the line segment etc. the direct application of the results is to compute the bode  nichols and nyquist plot collections of the systems which are needed in robustness analysis and design.
inspec,dev_1813,lmi approach to digital redesign of linear time invariant systems. a simple design methodology for the digital redesign of static state feedback controllers by using linear matrix inequalities is presented. the proposed method provides close matching of the states between the original continuous time system and those of the digitally redesigned system with a guaranteed stability. specifically the digital redesign problem is reformulated as linear matrix inequalities lmis and solved by a numerical optimisation technique. the main feature of the proposed method is that the closed loop stability of the digitally redesigned system is explicitly guaranteed within the design procedure using the lmi based approach. a numerical example of the position control of a simple crane system is presented.
inspec,dev_1814,control of integral processes with dead time. 2. quantitative analysis. for part 1 see ibid p 285 90 2002. several different control schemes for integral processes with dead time resulted in the same disturbance response. it has already been shown that such a response is subideal. hence it is necessary to quantitatively analyse the achievable specifications and the robust stability regions. the control parameter can be quantitatively determined with a compromise between the disturbance response and the robustness. four specifications normalised maximum dynamic error maximum decay rate normalised control action bound and approximate recovery time are used to characterise the step disturbance response. it is shown that any attempt to obtain a normalised dynamic error less than tau sub m is impossible and a sufficient condition on the relative gain uncertainty bound is square root 3 2.
inspec,dev_1815,control of integral processes with dead time. 1. disturbance observer based 2 dof control scheme. a disturbance observer based control scheme a version of 2 dof internal model control which is very effective in controlling integral processes with dead time is presented. the controller can be designed to reject ramp disturbances as well as step disturbances and even arbitrary disturbances. when the plant model is available only two parameters are left to tune. one is the time constant of the set point response and the other is the time constant of the disturbance response. the latter is tuned according to the compromise between disturbance response and robustness. this control scheme has a simple clear easy to design easy to implement structure and good performance. it is compared to the best results so far using some simulation examples.
inspec,dev_1816,hamiltonian modelling and nonlinear disturbance attenuation control of tcsc for improving power system stability. to tackle the obstacle of applying passivity based control pbc to power systems an affine non linear system widely existing in power systems is formulated as a standard hamiltonian system using a pre feedback method. the port controlled hamiltonian with dissipation pchd model of a thyristor controlled serial compensator tcsc is then established corresponding with a revised hamiltonian function. furthermore employing the modified hamiltonian function directly as the storage function a non linear adaptive l sub 2 gain control method is proposed to solve the problem of l sub 2 gain disturbance attenuation for this hamiltonian system with parametric perturbations. finally simulation results are presented to verify the validity of the proposed controller.
inspec,dev_1817,nonlinear adaptive control via sliding mode state and perturbation observer. the paper presents a nonlinear adaptive controller nac for single input single output feedback linearisable nonlinear systems. a sliding mode state and perturbation observer is designed to estimate the system states and perturbation which includes the combined effect of system nonlinearities uncertainties and external disturbances. the nac design does not require the details of the nonlinear system model and full system states. it possesses an adaptation capability to deal with system parameter uncertainties unmodelled system dynamics and external disturbances. the convergence of the observer and the stability analysis of the controller observer system are given. the proposed control scheme is applied for control of a synchronous generator in comparison with a state feedback linearising controller flc. simulation study is carried out based on a single generator infinite bus power system to show the performance of the controller observer system.
inspec,dev_1818,sliding mode control scheme for a class of continuous chemical reactors. the synthesis of a robust control law for regulation control of a class of relative degree one nonlinear systems is presented. the control design is based on a sliding mode uncertainty estimator developed under a framework of algebraic differential concepts. the closed loop stability for the underlying closed loop system is achieved via averaging techniques. robustness of the proposed control scheme is proved in the face of noise measurements model uncertainties and sustained disturbances. the performance of the proposed control law is illustrated with numerical simulations comparing the proposed controller with a well tuned pi controller.
inspec,dev_1819,structural interpretation of matched pole zero discretisation. deals with matched pole zero discretisation which has been used in practice for hand calculations in the digital redesign of continuous time systems but available only in the transfer function form. since this form is inconvenient for characterising the time domain properties of sampled data loops and for computerising the design of such systems a state space formulation is developed. under the new interpretation the matched pole zero model is shown to be structurally identical to a hold equivalent discrete time model where the generalised hold takes integral part thus unifying the most widely used discretisation approaches. an algorithm for obtaining the generalised hold function is presented. the hold equivalent structure of the matched pole zero model clarifies several discrete time system properties such as controllability and observability and their preservation or loss with a matched pole zero discretisation. with the proposed formulation the matched pole zero hold equivalent and mapping models can now all be constructed with a single schematic model.
inspec,dev_182,phase transition for parking blocks brownian excursion and coalescence. in this paper we consider hashing with linear probing for a hashing table with m places n items n m and l m n empty places. for a noncomputer science minded reader we shall use the metaphore of n cars parking on m places each car c sub i chooses a place p sub i at random and if p sub i is occupied c sub i tries successively p sub i 1 p sub i 2 until it finds an empty place. pittel 42 proves that when l m goes to some positive limit beta 1 the size b sub 1  sup m l of the largest block of consecutive cars satisfies 2 beta 1 log beta b sub 1  sup m l  2 log m 3 log log m xi sub m  where xi sub m converges weakly to an extreme value distribution. in this paper we examine at which level for n a phase transition occurs between b sub 1  sup m l  o m and m b sub 1  sup m l  o m. the intermediate case reveals an interesting behavior of sizes of blocks related to the standard additive coalescent in the same way as the sizes of connected components of the random graph are related to the multiplicative coalescent.
inspec,dev_1820,fast accurate and stable simulation of power electronic systems using virtual resistors and capacitors. simulation of power electronic circuits remains a problem due to the high level of stiffness brought about by the modelling of switches as biresistors i e very low turn on resistance and very high turn off resistance. the merits and drawbacks of two modelling methods that address this problem are discussed. a modelling solution for ensuring numerically stable accurate and fast simulation of power electronic systems is proposed. the solution enables easy connectivity between power electronic elements in the simulation model. it involves the modelling of virtual capacitance at switching nodes to soften voltage discontinuity due to the switch current suddenly going to zero. undesirable ringing effects that may arise due to the interaction between the virtual capacitance and circuit inductance are eliminated by modelling virtual damping resistors in parallel to inductors that are adjacent to switching elements. a midpoint configuration method is also introduced for modelling shunt capacitors. a dc traction system is simulated using this modelling strategy and the results are included. simulation results obtained using this modelling strategy are validated by comparison with the established mesh analysis technique of modelling. the simulation performance is also compared with the power system blockset commercial software.
inspec,dev_1821,performance design and control of a series parallel cl sup 2  type resonant dc dc converter. the three element resonant network has various topological alternatives one of which a prospective compound topology is investigated in detail. the converter uses one capacitor c and two inductors l sup 2  to form a compound type cl sup 2 network. various advantages and limitations of the converter are detailed and a new design procedure for such converters is also introduced. the converter may be controlled by varying the switching frequency or by pulse width modulation. an experimental prototype has been produced and an excellent performance in the lagging power factor mode has been confirmed.
inspec,dev_1822,single phase half bridge converter topology for power quality compensation. a high power factor half bridge rectifier with neutral point switch clamped scheme is proposed. three power switches are employed in the proposed rectifier. two pwm control schemes are used to draw a sinusoidal line current with low current distortion. the control signals of the power switches are derived from the dc link voltage balance compensator line current controller and dc link voltage regulator. the hysteresis current control scheme is employed to track the line current command. the proposed control scheme and the circuit configuration can be applied to the active power filter to eliminate the harmonic currents and compensate the reactive power generated from the nonlinear load. analytical and experimental results are included to illustrate the validity and effectiveness of the proposed control scheme.
inspec,dev_1823,single phase shunt active power filter with harmonic detection. an advanced active power filter for the compensation of instantaneous harmonic current components in nonlinear current loads is presented. a signal processing technique using an adaptive neural network algorithm is applied for the detection of harmonic components generated by nonlinear current loads and it can efficiently determine the instantaneous harmonic components in real time. the validity of this active filtering processing system to compensate current harmonics is substantiated by simulation results.
inspec,dev_1824,parallel operation of capacity limited three phase four wire active power filters. three phase four wire active power filters apfs are presented that can be paralleled to enlarge the system capacity and reliability. the apf employs the pwm four leg voltage source inverter. a decoupling control approach for the leg connected to the neutral line is proposed such that the switching of all legs has no interaction. functions of the proposed apf include compensation of reactive power harmonic current unbalanced power and zero sequence current of the load. the objective is to achieve unity power factor balanced line current and zero neutral line current. compensation of all components is capacity limited co operating with the cascaded load current sensing scheme. multiple apfs can be paralleled to share the load power without requiring any control interconnection. in addition to providing the theoretic bases and detailed design of the apfs two 6 kva apfs are implemented. the effectiveness of the proposed method is validated with experimental results.
inspec,dev_1825,fuzzy logic controlled shunt active power filter for power quality improvement. the simulation and experimental study of a fuzzy logic controlled three phase shunt active power filter to improve power quality by compensating harmonics and reactive power required by a nonlinear load is presented. the advantage of fuzzy control is that it is based on a linguistic description and does not require a mathematical model of the system. the fuzzy control scheme is realised on an inexpensive dedicated micro controller intel 8031 based system. the compensation process is based on sensing line currents only an approach different from conventional methods which require harmonics or reactive volt ampere requirement of the load. the performance of the fuzzy logic controller is compared with a conventional pi controller. the dynamic behavior of the fuzzy controller is found to be better than the conventional pi controller. pwm pattern generation is based on carrierless hysteresis based current control to obtain the switching signals. various simulation and experimental results are presented under steady state and transient conditions.
inspec,dev_1826,modeling shape and topology of low resolution density maps of biological macromolecules. we develop an efficient way of representing the geometry and topology of volumetric datasets of biological structures from medium to low resolution aiming at storing and querying them in a database framework. we make use of a new vector quantization algorithm to select the points within the macromolecule that best approximate the probability density function of the original volume data. connectivity among points is obtained with the use of the alpha shapes theory. this novel data representation has a number of interesting characteristics such as 1 it allows us to automatically segment and quantify a number of important structural features from low resolution maps such as cavities and channels opening the possibility of querying large collections of maps on the basis of these quantitative structural features 2 it provides a compact representation in terms of size 3 it contains a subset of three dimensional points that optimally quantify the densities of medium resolution data and 4 a general model of the geometry and topology of the macromolecule as opposite to a spatially unrelated bunch of voxels is easily obtained by the use of the alpha shapes theory.
inspec,dev_1827,gossip is synteny incomplete gossip and the syntenic distance between genomes. the syntenic distance between two genomes is given by the minimum number of fusions fissions and translocations required to transform one into the other ignoring the order of genes within chromosomes. computing this distance is np hard. in the present work we give a tight connection between syntenic distance and the incomplete gossip problem a novel generalization of the classical gossip problem. in this problem there are n gossipers each with a unique piece of initial information they communicate by phone calls in which the two participants exchange all their information. the goal is to minimize the total number of phone calls necessary to inform each gossiper of his set of relevant gossip which he desires to learn. as an application of the connection between syntenic distance and incomplete gossip we derive an o 2 sup o n log n algorithm to exactly compute the syntenic distance between two genomes with at most n chromosomes each. our algorithm requires o n sup 2 2 sup o d log d time when this distance is d improving the o n sup 2 2 o d  sup 2 running time of the best previous exact algorithm.
inspec,dev_1828,exploiting structure in quantified formulas. we study the computational problem find the value of the quantified formula obtained by quantifying the variables in a sum of terms. the sum can be based on any commutative monoid the quantifiers need only satisfy two simple conditions and the variables can have any finite domain. this problem is a generalization of the problem given a sum of products of terms find the value of the sum studied by r e stearns and h b hunt iii 1996. a data structure called a structure tree is defined which displays information about subproblems that can be solved independently during the process of evaluating the formula. some formulas have good structure trees which enable certain generic algorithms to evaluate the formulas in significantly less time than by brute force evaluation. by generic algorithm  we mean an algorithm constructed from uninterpreted function symbols quantifier symbols and monoid operations. the algebraic nature of the model facilitates a formal treatment of local reductions based on the local replacement of terms. such local reductions preserve formula structure in the sense that structure trees with nice properties transform into structure trees with similar properties. these local reductions can also be used to transform hierarchical specified problems with useful structure into hierarchically specified problems having similar structure.
inspec,dev_1829,improved approximation of max cut on graphs of bounded degree. let alpha approximately 0 87856 denote the best approximation ratio currently known for the max cut problem on general graphs. we consider a semidefinite relaxation of the max cut problem round it using the random hyperplane rounding technique of m x goemans and d p williamson 1995 and then add a local improvement step. we show that for graphs of degree at most delta our algorithm achieves an approximation ratio of at least alpha epsilon where epsilon 0 is a constant that depends only on delta.. using computer assisted analysis we show that for graphs of maximal degree 3 our algorithm obtains an approximation ratio of at least 0 921 and for 3 regular graphs the approximation ratio is at least 0 924. we note that for the semidefinite relaxation of max cut used by goemans and williamson the integrality gap is at least 1 0 885 even for 2 regular graphs.
inspec,dev_183,asymptotic analysis of 3 2 1 shell sort. we analyze the 3 2 1 shell sort algorithm under the usual random permutation model.
inspec,dev_1830,approximation of pathwidth of outerplanar graphs. there exists a polynomial time algorithm to compute the pathwidth of outerplanar graphs but the large exponent makes this algorithm impractical. in this paper we give an algorithm that given a biconnected outerplanar graph g finds a path decomposition of g of pathwidth at most twice the pathwidth of g plus one. to obtain the result several relations between the pathwidth of a biconnected outerplanar graph and its dual are established.
inspec,dev_1831,fast broadcasting and gossiping in radio networks. we establish an o n log sup 2 n upper bound on the time for deterministic distributed broadcasting in multi hop radio networks with unknown topology. this nearly matches the known lower bound of omega n log n. the fastest previously known algorithm for this problem works in time o n sup 3 2. using our broadcasting algorithm we develop an o n sup 3 2 log sup 2 n algorithm for gossiping in the same network model.
inspec,dev_1832,a linear time algorithm for recognizing regular boolean functions. a positive or monotone boolean function is regular if its variables are naturally ordered left to fight by decreasing strength so that shifting the nonzero component of any true vector to the left always yields another true vector. this paper considers the problem of recognizing whether a positive function f is regular where f is given by min t f the set of all minimal true vectors of f. we propose a simple linear time i e o n min t f  time algorithm for it. this improves upon the previous algorithm by j s provan and m o ball 1988 which requires o n sup 2  min t f time. as a corollary we also present an o n n  min t f  time algorithm for the recognition problem of 2 monotonic functions.
inspec,dev_1833,british standard 7666 as a framework for geocoding land and property information the uk. the article examines the role of british standard 7666 in the development of a national framework for geocoding land and property information in the united kingdom. the author assesses how local authorities and other agencies concerned with property and address datasets are coping with the introduction of british standard 7666 and examines the prospects and limitations of this development. british standard 7666 has four parts comprising specifications for street gazetteer land and property gazetteer addresses and public rights of way. the organisation coordinating the introduction of british standard 7666 improvement and development agency idea is also overseeing the development and maintenance of a national land and property gazetteer nlpg based on british standard 7666. the introduction of the new addressing standard has mainly been prompted by britain s effort to set up a national cadastral service to replace the obsolescent property registration system currently in place.
inspec,dev_1834,a formal model of correctness in a cadastre. a key issue for cadastral systems is the maintenance of their correctness. correctness is defined to be the proper correspondence between the valid legal situation and the content of the cadastre. this correspondence is generally difficult to achieve since the cadastre is not a complete representation of all aspects influencing the legal situation in reality. the goal of the paper is to develop a formal model comprising representations of the cadastre and of reality that allows the simulation and investigation of cases where this correspondence is potentially violated. for this purpose the model consists of two parts the first part represents the valid legal situation and the second part represents the cadastre. this makes it feasible to mark the differences between reality and the cadastre. the marking together with the two parts of the model facilitate the discussion of issues in real world cadastral systems where incorrectness occurs. in order to develop a formal model the paper uses the transfer of ownership of a parcel between two persons as minimal case study. the foundation for the formalization is a modern version of the situation calculus. the focus moves from the analysis of the cadastre to the preparation of a conceptual and a formalized model and the implementation of a prototype.
inspec,dev_1835,establishing an urban digital cadastre analytical reconstruction of parcel boundaries. a new method for generating a spatially accurate legally supportive and operationally efficient cadastral database of the urban cadastral reality is described. the definition and compilation of an accurate cadastral database achieving a standard deviation smaller than 0 1 m is based on an analytical reconstruction of cadastral boundaries rather than on the conventional field reconstruction process. the new method is based on gps control points and traverse networks for providing the framework the old field books for defining the links between the various original ground features and a geometrical and cadastral adjustment process as the conceptual basis. a pilot project that was carried out in order to examine and evaluate the new method is described.
inspec,dev_1836,parcel boundary identification with computer assisted boundary overlay process for taiwan. the study investigates the design of a process for parcel boundary identification with cadastral map overlay using the principle of least squares. the objective of this research is to provide an objective tool for boundary identification survey. the proposed process includes an adjustment model a weighting scheme and other related operations. a numerical example is included.
inspec,dev_1837,a review of methodologies used in research on cadastral development. world wide much attention has been given to cadastral development. as a consequence of experiences made during recent decades several authors have stated the need for research in the domain of cadastre and proposed methodologies to be used. the paper contributes to the acceptance of research methodologies needed for cadastral development and thereby enhances theory in the cadastral domain. the paper reviews nine publications on cadastre and identifies the methodologies used. the review focuses on the institutional social political and economic aspects of cadastral development rather than on the technical aspects. the main conclusion is that the methodologies used are largely those of the social sciences. that agrees with the notion that cadastre relates as much to people and institutions as it relates to land and that cadastral systems are shaped by social political and economic conditions as well as technology. since the geodetic survey profession has been the keeper of the cadastre geodetic surveyors will have to deal ever more with social science matters a fact that universities will have to consider.
inspec,dev_1838,anticipating the further development of cadastral systems. although the paper recognises the merits of the evolution of cadastral systems towards an increased capability over time it promotes a radical introduction or overhaul of existing cadastral systems. it encourages the development of a capability to cope with some key drivers of major change. these have been identified as globalisation the advent of fully automated cadastral environments improved decentralised methods of governance and greatly improved service delivery of future cadastral systems to a wide range of users. the paper promotes the registration of title supported by government guarantee as an effective means for rapidly introducing cadastral systems to facilitate globally competitive land markets in developing countries. in developing automated environments for cadastral systems the need to completely re engineer and redesign cadastral systems to meet basic cadastral principles and responsiveness to individual user needs is promoted. in this environment highly decentralised cadastral operations and administration combined with light regulatory control are advocated as a future governance strategy. with regard to the level of services to users an emphasis on recognising and serving the future needs of users is seen as essential. international and national professional and user organisations involved in land administration are seen as an important vehicle for developing strategies and providing evaluation to guide the over arching development of cadastral systems around the world.
inspec,dev_1839,the dynamic aspect of land administration an often forgotten component in system design. although the establishment of a land administration system is enough of a challenge as it is the task of keeping the system up to date with developments in society is even more challenging. initial adjudication and cadastral mapping basically record land tenure as it exists at a given moment i e the static situation. the paper aims to analyse the developments that might occur in a society with respect to tenure value and use of land. these developments constitute a dynamic component of land administration. as land administration systems have to serve society on a long term basis and normally have a long term return on investment the author recommends taking into account both the static and dynamic component when designing land administration systems.
inspec,dev_184,on the expected value of the minimum assignment. the minimum k assignment of an m n matrix x is the minimum sum of k entries of x no two of which belong to the same row or column. coppersmith and sorkin conjectured that if x is generated by choosing each entry independently from the exponential distribution with mean 1 then the expected value of its minimum k assignment is given by an explicit formula which has been proven only in a few cases. in this paper we describe our efforts to prove the coppersmith sorkin conjecture by considering the more general situation where the entries x sub ij of x are chosen independently from different distributions. in particular we require that x sub ij be chosen from the exponential distribution with mean 1 r sub i c sub j. we conjecture an explicit formula for the expected value of the minimum k assignment of such x and give evidence for this formula.
inspec,dev_1840,too much middleware. the movement from client server computing to multi tier computing has created a potpourri of so called middleware systems including application servers workflow products eai systems etl systems and federated data systems. we argue that the explosion in middleware has created a myriad of poorly integrated systems with overlapping functionality. the world would be well served by considerable consolidation and we present some of the ways this might happen. some of the points covered in the article have been previously explored by p bernstein 1996.
inspec,dev_1841,the xml typechecking problem. when an xml document conforms to a given type e g a dtd or an xml schema type it is called a valid document. checking if a given xml document is valid is called the validation problem and is typically performed by a parser hence validating parser more precisely it is performed right after parsing by the same program module. in practice however xml documents are often generated dynamically by some program checking whether all xml documents generated by the program are valid wrt a given type is called the typechecking problem. while a validation analyzes an xml document a type checker analyzes a program and the problem s difficulty is a function of the language in which that program is expressed. the xml typechecking problem has been investigated recently and the xquery working group adopted some of these techniques for typechecking xquery. all these techniques however have limitations which need to be understood and further explored and investigated. we define the xml typechecking problem and present current approaches to typechecking discussing their limitations.
inspec,dev_1842,the role of b2b engines in b2b integration architectures. semantic b2b integration architectures must enable enterprises to communicate standards based b2b events like purchase orders with any potential trading partner. this requires not only back end application integration capabilities to integrate with e g enterprise resource planning erp systems as the company internal source and destination of b2b events but also a capability to implement every necessary b2b protocol like electronic data interchange edi rosettanet as well as more generic capabilities like web services ws. this paper shows the placement and functionality of b2b engines in semantic b2b integration architectures that implement a generic framework for modeling and executing any b2b protocol. a detailed discussion shows how a b2b engine can provide the necessary abstractions to implement any standard based b2b protocol or any trading partner specific specialization.
inspec,dev_1843,supply chain infrastructures system integration and information sharing. the need for supply chain integration sci methodologies has been increasing as a consequence of the globalization of production and sales and the advancement of enabling information technologies. in this paper we describe our experience with implementing and modeling scis. we present the integration architecture and the software components of our prototype implementation. we then discuss a variety of information sharing methodologies. then within the framework of a multi echelon supply chain process model spanning multiple organizations we summarize research on the benefits of intraorganizational knowledge sharing and we discuss performance scalability.
inspec,dev_1844,a multi agent system infrastructure for software component marketplace an ontological perspective. in this paper we introduce a multi agent system architecture and an implemented prototype for a software component marketplace. we emphasize the ontological perspective by discussing ontology modeling for the component marketplace uml extensions for ontology modeling and the idea of ontology transfer which makes the multi agent system adapt itself to dynamically changing ontologies.
inspec,dev_1845,business data management for business to business electronic commerce. business to business electronic commerce b2b ec opens up new possibilities for trade. for example new business partners from around the globe can be found their offers can be compared even complex negotiations can be conducted electronically and a contract can be drawn up and fulfilled via an electronic marketplace. however sophisticated data management is required to provide such facilities. in this paper the results of a multi national project on creating a business to business electronic marketplace for small and medium sized enterprises are presented. tools for information discovery protocol based negotiations and monitored contract enactment are provided and based on a business data repository. the repository integrates heterogeneous business data with business communication. specific problems such as multilingual nature data ownership and traceability of contracts and related negotiations are addressed and it is shown that the present approach provides efficient business data management for b2b ec.
inspec,dev_1846,semantic b2b integration issues in ontology based approaches. solving queries to support e commerce transactions can involve retrieving and integrating information from multiple information resources. often users do n t care which resources are used to answer their query. in such situations the ideal solution would be to hide from the user the details of the resources involved in solving a particular query. an example would be providing seamless access to a set of heterogeneous electronic product catalogues. there are many problems that must be addressed before such a solution can be provided. in this paper we discuss a number of these problems indicate how we have addressed these and go on to describe the proof of concept demonstration system we have developed.
inspec,dev_1847,conceptual modeling and specification generation for b2b business processes based on ebxml. in order to support dynamic setup of business processes among independent organizations a formal standard schema for describing the business processes is basically required. the ebxml framework provides such a specification schema called bpss business process specification schema which is available in two standalone representations a uml version and an xml version. the former however is not intended for the direct creation of business process specifications but for defining specification elements and their relationships required for creating an ebxml compliant business process specification. for this reason it is very important to support conceptual modeling that is well organized and directly matched with major modeling concepts. this paper deals with how to represent and manage b2b business processes using uml compliant diagrams. the major challenge is to organize uml diagrams in a natural way that is well suited to the business process meta model and then to transform the diagrams into an xml version. this paper demonstrates the usefulness of conceptually modeling business processes by prototyping a business process editor tool called ebdesigner.
inspec,dev_1848,contracting in the days of ebusiness. putting electronic business on a sound foundation model theoretically as well as technologically is a central challenge for research as well as commercial development. this paper concentrates on the discovery and negotiation phase of concluding an agreement based on a contract. we present a methodology for moving seamlessly from a many to many relationship in the discovery phase to a one to one relationship in the contract negotiation phase. making the content of contracts persistent is achieved by reconstructing contract templates by means of mereologic logic of the whole part relation. possibly nested sub structures of the contract template are taken as a basis for negotiation in a dialogical way. for the negotiation itself the contract templates are extended by implications logical and sequences topical.
inspec,dev_1849,an active functionality service for e business applications. service based architectures are a powerful approach to meet the fast evolution of business rules and the corresponding software. an active functionality service that detects events and involves the appropriate business rules is a critical component of such a service based middleware architecture. in this paper we present an active functionality service that is capable of detecting events in heterogeneous environments it uses an integral ontology based approach for the semantic interpretation of heterogeneous events and data and provides notifications through a publish subscribe notification mechanism. the power of this approach is illustrated with the help of an auction application and through the personalization of car and driver portals in internet enabled vehicles.
inspec,dev_185,property testers for dense constraint satisfaction programs on finite domains. many np hard languages can be decided in subexponential time if the definition of decide is relaxed only slightly. rubinfeld and sudan introduced the notion of property testers probabilistic algorithms that can decide with high probability if a function has a certain property or if it is far from any function having this property. goldreich goldwasser and ron constructed property testers with constant query complexity for dense instances of a large class of graph problems. since many graph problems can be viewed as special cases of the constraint satisfaction problem on boolean domains it is natural to try to construct property testers for more general cases of the constraint satisfaction problem. in this paper we give explicit constructions of property testers using a constant number of queries for dense instances of constraint satisfaction problems where the constraints have constant arity and the variables assume values in some domain of finite size.
inspec,dev_1850,the n tier hub technology. during 2001 the enterprise engineering laboratory at george mason university was contracted by the boeing company to develop an ehub capability for aerospace suppliers in taiwan. in a laboratory environment the core technology was designed developed and tested and now a large first tier aerospace supplier in taiwan is commercializing the technology. the project objective was to provide layered network and application services for transporting xml based business transaction flows across multi tier heterogeneous data processing environments. this paper documents the business scenario the ehub application and the network transport mechanisms that were used to build the n tier hub. in contrast to most ehubs this solution takes the point of view of suppliers pushing data in accordance with supplier requirements hence enhancing the probability of supplier adoption. the unique contribution of this project is the development of an ehub that meets the needs of small and medium enterprises smes and first tier suppliers.
inspec,dev_1851,supporting global user profiles through trusted authorities. personalization generally refers to making a web site more responsive to the unique and individual needs of each user. we argue that for personalization to work effectively detailed and interoperable user profiles should be globally available for authorized sites and these profiles should dynamically reflect changes in user interests. creating user profiles from user click stream data seems to be an effective way of generating detailed and dynamic user profiles. however a user profile generated in this way is available only on the computer where the user accesses his browser and is inaccessible when the same user works on a different computer. on the other hand integration of the internet with telecommunication networks has made it possible for the users to connect to the web with a variety of mobile devices as well as desktops. this requires that user profiles should be available to any desktop or mobile device on the internet that users choose to work with. in this paper we address these problems through the concept of trusted authority. a user agent at the client side that captures the user click stream dynamically generates a navigational history log file in extensible markup language xml. this log file is then used to produce user profiles in a resource description framework rdf. a user s right to privacy is provided through the platform for privacy preferences p3p standard. user profiles are uploaded to the trusted authority and served next time the user connects to the web.
inspec,dev_1852,the design and performance evaluation of alternative xml storage strategies. this paper studies five strategies for storing xml documents including one that leaves documents in the file system three that use a relational database system and one that uses an object manager. we implement and evaluate each approach using a number of xquery queries. a number of interesting insights are gained from these experiments and a summary of the advantages and disadvantages of the approaches is presented.
inspec,dev_1853,cherylann silberer all about process accounting technologist. silberer s company complete is making a specialty of workflow process analysis.
inspec,dev_1854,software technology looking for quality accountants. software technology wants to turn 23 years of reselling experience in the legal business into an asset in the accounting market.
inspec,dev_1855,distribution software roi is king. middle market accounting software vendors are taking to the open road by way of souped up distribution suites that can track product as it wends its way from warehouse floor to customer site. integration provides efficiencies and cost savings.
inspec,dev_1856,tax forms cd or not cd. the move from cd to the web looks unstoppable. besides counting how many thousands of electronic tax forms they offer vendors are rapidly moving those documents to the web.
inspec,dev_1858,account aggregation shaping up portfolios. cpa providers of financial planning services are providing clients with a unified view of their investments.
inspec,dev_1859,practice management goes remote accounting. there s a lot of life in accounting practice management software a valuable category that has been subject to much change in the last few years. web based time tracking grows in popularity. looks at cch prosystem fx practice cms open solutions 6 creative solutions practice time matters cpasoftware visual practice management and abak.
inspec,dev_186,the diameter of a long range percolation graph. we consider the following long range percolation model an undirected graph with the node set 0 1  n sup d  has edges x y selected with probability approximately beta  x y  sup s if  x y  1 and with probability 1 if  x y  1 for some parameters beta s 0. this model was introduced by who obtained bounds on the diameter of this graph for the one dimensional case d 1 and for various values of s but left cases s 1 2 open. we show that with high probability the diameter of this graph is theta log n log log n when s d and for some constants 0 eta sub 1  eta sub 2  1 it is at most n sup eta 2 when s 2d and is at least n sup eta 1 when d 1 s 2 beta 1 or when s 2d. we also provide a simple proof that the diameter is at most log sup o 1 n with high probability when d s 2d established previously in benjamini and berger 2001.
inspec,dev_1860,the art of the cross sell accounting software. with the market for accounting software nearing saturation vendors are training resellers in the subtleties of the cross sell. the rewards can be great. the key is knowing when to focus and when to partner.
inspec,dev_1861,technology in distance education a global perspective to alternative delivery mechanisms. technology is providing a positive impact on delivery mechanisms employed in distance education at the university level. some institutions are incorporating distance education as a way to extend the classroom. other institutions are investigating new delivery mechanisms which support a revised perspective on education. these latter institutions are revising their processes for interacting with students and taking a more learner centered approach to the delivery of education. this article discusses the impact of technology on the delivery mechanisms employed in distance education. a framework is proposed here which presents a description of alternative modes of generic delivery mechanisms. it is suggested that those institutions which adopt a delivery mechanism employing an asynchronous mode can gain the most benefit from technology. this approach seems to represent the only truly innovative use of technology in distance education. the approach creates a student oriented environment while maintaining high levels of interaction both of which are factors that contribute to student satisfaction with their overall educational experience.
inspec,dev_1862,global comparison of stages of growth based on critical success factors. with increasing globalization of business the management of it in international organizations is faced with the complex task of dealing with the difference between local and international it needs. this study evaluates and compares the level of it maturity and the critical success factors csfs in selected geographic regions namely norway australia new zealand north america europe asia pacific and india. the results show that significant differences in the it management needs in these geographic regions exist and that the it management operating in these regions must balance the multiple critical success factors for achieving an optimal local global mix for business success.
inspec,dev_1863,information systems project failure a comparative study of two countries. many organizations regardless of size engage in at least one and often many information system projects each year. many of these projects consume massive amounts of resources and may cost as little as a few thousand dollars to ten and even hundreds of millions of dollars. needless to say the investment of time and resources into these ventures are of significant concern to chief information officers cios executives staff members project managers and others in leadership positions. this paper describes the results of a survey performed between australia and the united states regarding factors leading to is project failure. the findings suggest that among other things end user involvement and executive management leadership are key indicators influencing is project failure.
inspec,dev_1864,cultural differences in developers perceptions of information systems success factors japan vs the united states. the study examined the perceptions of information systems is developers from japan and the united states regarding the strategies that are considered most important for successful implementation of an is. the results of principal component analysis revealed that the is strategies could be reduced to five components 1 characteristics of the team members 2 characteristics of the project leader 3 management user input 4 proper technology and 5 communication. the results indicated that there was a significant difference in the perceptions of japanese and us developers with respect to the importance of the five components. japanese developers perceived the project leader as the most crucial component for determining the success of an is project. team member characteristics was viewed as the least important by japanese developers. on the other hand developers from the us viewed communications as the most critical component. project leader characteristics were perceived to be the least important by us developers. the results were discussed in terms of cultural differences.
inspec,dev_1865,towards the globalisation of the is it function. the is it function has recently emerged from the peripheral aspects of the finance department to the centre of critical organisational change. there is an increasing dependency on its activities as systems extend beyond supporting the internal efficiency of the organisation to augmenting global performance. the growth of wide and local networks has resulted in communication possibilities that were not possible a few years ago. e commerce challenges the achievements of the is it function and is very prominent in the globalisation of modern organisations. the complexity and diversity of electronic exchange is also well documented hackney et al 2000. this has a number of impacts on the development and implementation of is it solutions for organisations involved in international trade. it is a conjecture that the is it function is critically important for the alignment of the business to meet the demands of global competition through building internal marketing strategies and creating knowledge based communities. there is clear evidence that is it can lead to improved business performance and potentially for sustained competitive advantage. this is obviously true through the advent of new and emerging technologies such as the internet.
inspec,dev_1866,tracking with sensor failures. studies the reliability with sensor failures of the asymptotic tracking problem for linear time invariant systems using the factorization approach. the plant is two output and the compensator is two degree of freedom. necessary and sufficient conditions are presented for the general problem and a simple solution is given for problems with stable plants.
inspec,dev_1867,optimization based design of fixed order controllers for command following. for discrete time scalar systems we propose an approach for designing feedback controllers of fixed order to minimize an upper bound on the peak magnitude of the tracking error to a given command input. the work makes use of linear programming to design over a class of closed loop systems proposed for the rejection of non zero initial conditions and bounded disturbances. we incorporate performance robustness in the form of a guaranteed upper bound on the peak magnitude of the tracking error under plant coprime factor uncertainty.
inspec,dev_1868,estimation of an n l n hammerstein wiener model. estimation of a single input single output block oriented model is studied. the model consists of a linear block embedded between two static nonlinear gains. hence it is called an n l n hammerstein wiener model. first the model structure is motivated and the disturbance model is discussed. the paper then concentrates on parameter estimation. a relaxation iteration scheme is proposed by making use of a model structure in which the error is bilinear in parameters. this leads to a simple algorithm which minimizes the original loss function. the convergence and consistency of the algorithm are studied. in order to reduce the variance error the obtained linear model is further reduced using frequency weighted model reduction. a simulation study is used to illustrate the method.
inspec,dev_1869,stability and l sub 2 gain properties of lpv systems. stability and l sub 2 gain properties of linear parameter varying systems are obtained under assumed bounds on either the maximum or average value of the parameter rate.
inspec,dev_187,control of a thrust vectored flying wing a receding horizon lpv approach. this paper deals with the application of receding horizon methods to hover and forward flight models of an experimental tethered flying wing developed at caltech. the dynamics of the system are representative of a vertical landing and take off aircraft such as a harrier around hover or a thrust vectored aircraft such as f18 harv or x 31 in forward flight. the adopted control methodology is a hybrid of receding horizon techniques and control lyapunov function clf based ideas. first a clf is generated using quasi lpv methods and then by using the clf as the terminal cost in the receding horizon optimization stability is guaranteed. the main advantage of this approach is that stability can be guaranteed without imposing constraints in the on line optimization allowing the problem to be solved in a more efficient manner. models of the experimental set up are obtained for the hover and forward flight modes. numerical simulations for different time horizons are presented to illustrate the effectiveness of the discussed methods. specifically it is shown that a mere upper bound on the cost to go is not an appropriate choice for a terminal cost when the horizon length is short. simulation results are presented using experimentally verified model parameters.
inspec,dev_1870,robust control of nonlinear systems with parametric uncertainty. probabilistic robustness analysis and synthesis for nonlinear systems with uncertain parameters are presented. monte carlo simulation is used to estimate the likelihood of system instability and violation of performance requirements subject to variations of the probabilistic system parameters. stochastic robust control synthesis searches the controller design parameter space to minimize a cost that is a function of the probabilities that design criteria will not be satisfied. the robust control design approach is illustrated by a simple nonlinear example. a modified feedback linearization control is chosen as controller structure and the design parameters are searched by a genetic algorithm to achieve the tradeoff between stability and performance robustness.
inspec,dev_1871,strong and weak points of the muscadet theorem prover examples from casc jc. muscadet is a knowledge based theorem prover based on natural deduction. it has participated in cade automated theorem proving system competitions. the results show its complementarity with regard to resolution based provers. this paper presents some of its crucial methods and gives some examples of muscadet proofs from the last competition casc jc in ijcar 2001.
inspec,dev_1872,tptp casc and the development of a semantically guided theorem prover. the first order theorem prover scott has been through a series of versions over some ten years. the successive provers while retaining the same underlying technology have used radically different algorithms and shown wide differences of behaviour. the development process has depended heavily on experiments with problems from the tptp library and has been sharpened by participation in casc each year since 1997. we outline some of the difficulties inherent in designing and refining a theorem prover as complex as scott and explain our experimental methodology. while scott is not one of the systems which have been highly optimised for casc it does help to illustrate the influence of both casc and the tptp library on contemporary theorem proving research.
inspec,dev_1873,a phytography of waldmeister. the architecture of the waldmeister prover for unit equational deduction is based on a strict separation of active and passive facts. after an inspection of the system s proof procedure the representation of each of the central data structures is outlined namely indexing for the active facts compression for the passive facts successor sets for the hypotheses and minimal recording of inference steps for the proof object. in order to cope with large search spaces specialized redundancy criteria are employed and the empirically gained control knowledge is integrated to ease the use of the system. the paper concludes with a quantitative comparison of the waldmeister versions over the years and a view of the future prospects.
inspec,dev_1874,e a brainiac theorem prover. we describe the superposition based theorem prover e e is a sound and complete prover for clausal first order logic with equality. important properties of the prover include strong redundancy elimination criteria the discount loop proof procedure a very flexible interface for specifying search control heuristics and an efficient inference engine. we also discuss the strengths and weaknesses of the system.
inspec,dev_1875,the design and implementation of vampire. we describe vampire a high performance theorem prover for first order logic. as our description is mostly targeted to the developers of such systems and specialists in automated reasoning it focuses on the design of the system and some key implementation features. we also analyze the performance of the prover at casc jc.
inspec,dev_1876,the development of casc automated theorem proving. researchers who make theoretical advances also need some way to demonstrate that an advance really does have general overall positive consequences for system performance. for this it is necessary to evaluate the system on a set of problems that is sufficiently large and diverse to be somehow representative of the intended application area as a whole. it is only a small step from system evaluation to a communal system competition. the cade atp system competition casc has been run annually since 1996. any competition is difficult to design and organize in the first instance and to then run over the years. in order to obtain the full benefits of a competition a thoroughly organized event with an unambiguous and motivated design is necessary. for some issues relevant to the casc design inevitable constraints have emerged. for other issues there have been several choices and decisions have had to be made. this paper describes the evolution of casc paying particular attention to its design design changes and organization.
inspec,dev_1877,strong completeness of lattice valued logic. this paper shows strong completeness of the system l for lattice valued logic given by s titani 1999 in which she formulates a lattice valued set theory by introducing the logical implication which represents the order relation on the lattice. syntax and semantics concerned are described and strong completeness is proved.
inspec,dev_1878,max and min limiters. if a contained in omega n or 2 and the function max x sub 1   x sub n intersection a is partial recursive it is easily seen that a is recursive. in this paper we weaken this hypothesis in various ways and similarly for min in place of max and investigate what effect this has on the complexity of a. we discover a sharp contrast between retraceable and co retraceable sets and we characterize sets which are the union of a recursive set and a co r e retraceable set. most of our proofs are noneffective. several open questions are raised.
inspec,dev_1879,on the distribution of lachlan nonsplitting bases. we say that a computably enumerable c e degree b is a lachlan nonsplitting base lnb if there is a computably enumerable degree a such that a b and for any c e degrees w v or a if a or wvvv b then either a or wv b or a or vv b. in this paper we investigate the relationship between bounding and nonbounding of lachlan nonsplitting bases and the high low hierarchy. we prove that there is a non low sub 2 c e degree which bounds no lachlan nonsplitting base.
inspec,dev_188,sampled data implementation of a gain scheduled controller. a continuous time gain scheduled controller must be transformed to a corresponding discrete time controller for sampled data implementation. we show that certain linearization properties of a continuous time gain scheduled controller are inherited by its sampled data implementation. we also show that a similar relationship exists for multi rate gain scheduled controllers arising in flight control applications.
inspec,dev_1880,simulation and transient testing of numerical relays. a hybrid and practical solution for relay evaluation is presented. two main issues are taken into account power system simulation and relay simulation both of which consist of different stages. system simulation is carried out by means of emtp and is complemented by additional features such as filtering for location and determination of fault parameters that allow comparing simulated and actual fault records to improve and guarantee a correct system simulation. relay simulation includes filtering algorithms all the relaying units and the decision logic. playing simulated or real faults over the actual relay and comparing simulated and real responses can check for correct relay simulation.
inspec,dev_1881,stabilization of positive systems with first integrals. positive systems possessing first integrals are considered. these systems frequently occur in applications. the paper is devoted to two stabilization problems. the first is concerned with the design of feedbacks to stabilize a given level set. secondly it is shown that the same feedback allows us to globally stabilize an equilibrium point if it is asymptotically stable with respect to initial conditions in its level set. two examples are provided and the results are compared with those in the literature.
inspec,dev_1882,bandwidth vs gains design of h sub infinity tracking controllers for current fed induction motors. describes a systematic procedure for designing speed and rotor flux norm tracking h sub infinity. controllers with unknown load torque disturbances for current fed induction motors. a new effective design tool is developed to allow selection of the control gains so as to adjust the disturbances rejection capability of the controllers in the face of the bandwidth requirements of the closed loop system. application of the proposed design procedure is demonstrated in a case study and the results of numerical simulations illustrate the satisfactory performance achievable even in presence of rotor resistance uncertainty.
inspec,dev_1883,analysis of exclusively kinetic two link underactuated mechanical systems. analysis of exclusively kinetic two link underactuated mechanical systems is undertaken. it is first shown that such systems are not full state feedback linearizable around any equilibrium point. also the equilibrium points for which the system is small time locally controllable stlc is at most a one dimensional submanifold. a concept less restrictive than stlc termed the small time local output controllability stloc is introduced the satisfaction of which guarantees that a chosen configuration output can be controlled at its desired value. it is shown that the class of systems considered is stloc if the inertial coupling between the input and output is nonzero. also in such a case the system is nonminimum phase. an example section illustrates all the results presented.
inspec,dev_1884,observer based strict positive real spr feedback control system design. presents theory for stability analysis and design for a class of observer based feedback control systems. relaxation of the controllability and observability conditions imposed in the yakubovich kalman popov lemma can be made for a class of nonlinear systems described by a linear time invariant system with a feedback connected cone bounded nonlinear element. it is shown how a circle criterion approach can be used to design an observer based state feedback control which yields a closed loop system with specified robustness characteristics. the approach is relevant for design with preservation of stability when a cone bounded nonlinearity is introduced in the feedback loop. important applications are to be found in nonlinear control with high robustness requirements.
inspec,dev_1885,analysis of nonlinear time delay systems using modules over non commutative rings. the theory of non commutative rings is introduced to provide a basis for the study of nonlinear control systems with time delays. the left ore ring of non commutative polynomials defined over the field of a meromorphic function is suggested as the framework for such a study. this approach is then generalized to a broader class of nonlinear systems with delays that are called generalized roesser systems. finally the theory is applied to analyze nonlinear time delay systems. a weak observability is defined and characterized generalizing the well known linear result. properties of closed submodules are then developed to obtain a result on the accessibility of such systems.
inspec,dev_1886,non asymptotic confidence ellipsoids for the least squares estimate. we consider the finite sample properties of least squares system identification and derive non asymptotic confidence ellipsoids for the estimate. the shape of the confidence ellipsoids is similar to the shape of the ellipsoids derived using asymptotic theory but unlike asymptotic theory they are valid for a finite number of data points. the probability that the estimate belongs to a certain ellipsoid has a natural dependence on the volume of the ellipsoid the data generating mechanism the model order and the number of data points available.
inspec,dev_1887,doubly invariant equilibria of linear discrete time games. the notion of doubly invariant di equilibrium is introduced. the concept extends controlled and robustly controlled invariance notions to the context of two person dynamic games. each player tries to keep the state in a region of state space independently of the actions of the rival player. the paper gives existence conditions criteria and algorithms for the determination of di equilibria of linear dynamic games in discrete time. two examples illustrate the results. the first one is in the area of fault tolerant controller synthesis. the second is an application to macroeconomics.
inspec,dev_1888,l sub 2 model reduction and variance reduction. we examine certain variance properties of model reduction. the focus is on l sub 2 model reduction but some general results are also presented. these general results can be used to analyze various other model reduction schemes. the models we study are finite impulse response fir and output error oe models. we compare the variance of two estimated models. the first one is estimated directly from data and the other one is computed by reducing a high order model by l sub 2 model reduction. in the fir case we show that it is never better to estimate the model directly from data compared to estimating it via l sub 2 model reduction of a high order fir model. for oe models we show that the reduced model has the same variance as the directly estimated one if the reduced model class used contains the true system.
inspec,dev_1889,sliding mode dynamics in continuous feedback control for distributed discrete event scheduling. a continuous feedback control approach for real time scheduling of discrete events is presented motivated by the need for control theoretic techniques to analyze and design such systems in distributed manufacturing applications. these continuous feedback control systems exhibit highly nonlinear and discontinuous dynamics. specifically when the production demand in the manufacturing system exceeds the available resource capacity then the control system chatters and exhibits sliding modes. this sliding mode behavior is advantageously used in the scheduling application by allowing the system to visit different schedules within an infinitesimal region near the sliding surface. in the paper an analytical model is developed to characterize the sliding mode dynamics. this model is then used to design controllers in the sliding mode domain to improve the effectiveness of the control system to search for schedules with good performance. computational results indicate that the continuous feedback control approach can provide near optimal schedules and that it is computationally efficient compared to existing scheduling techniques.
inspec,dev_189,identification of linear parameter varying models. we consider identification of a certain class of discrete time nonlinear systems known as linear parameter varying system. we assume that inputs outputs and the scheduling parameters are directly measured and a form of the functional dependence of the system coefficients on the parameters is known. we show how this identification problem can be reduced to a linear regression and provide compact formulae for the corresponding least mean square and recursive least squares algorithms. we derive conditions on persistency of excitation in terms of the inputs and scheduling parameter trajectories when the functional dependence is of polynomial type. these conditions have a natural polynomial interpolation interpretation and do not require the scheduling parameter trajectories to vary slowly. this method is illustrated with a simulation example using two different parameter trajectories.
inspec,dev_1890,robustness of trajectories with finite time extent. the problem of estimating perturbation bounds of finite trajectories is considered. the trajectory is assumed to be generated by a linear system with uncertainty characterized in terms of integral quadratic constraints. it is shown that such perturbation bounds can be obtained as the solution to a nonconvex quadratic optimization problem which can be addressed using lagrange relaxation. the result can be used in robustness analysis of hybrid systems and switched dynamical systems.
inspec,dev_1891,on trajectory and force tracking control of constrained mobile manipulators with parameter uncertainty. studies the trajectory and force tracking control problem of mobile manipulators subject to holonomic and nonholonomic constraints with unknown inertia parameters. adaptive controllers are proposed based on a suitable reduced dynamic model the defined reference signals and the mixed tracking errors. the proposed controllers not only ensure the entire state of the system to asymptotically converge to the desired trajectory but also ensure the constraint force to asymptotically converge to the desired force. a detailed numerical example is presented to illustrate the developed methods.
inspec,dev_1892,closed loop persistent identification of linear systems with unmodeled dynamics and stochastic disturbances. the essential issues of time complexity and probing signal selection are studied for persistent identification of linear time invariant systems in a closed loop setting. by establishing both upper and lower bounds on identification accuracy as functions of the length of observation size of unmodeled dynamics and stochastic disturbances we demonstrate the inherent impact of unmodeled dynamics on identification accuracy reduction of time complexity by stochastic averaging on disturbances and probing capability of full rank periodic signals for closed loop persistent identification. these findings indicate that the mixed formulation in which deterministic uncertainty of system dynamics is blended with random disturbances is beneficial to reduction of identification complexity.
inspec,dev_1893,closed loop model set validation under a stochastic framework. deals with probabilistic model set validation. it is assumed that the dynamics of a multi input multi output mimo plant is described by a model set with unstructured uncertainties and identification experiments are performed in closed loop. a necessary and sufficient condition has been derived for the consistency of the model set with both the stabilizing controller and closed loop frequency domain experimental data fded. in this condition only the euclidean norm of a complex vector is involved and this complex vector depends linearly on both the disturbances and the measurement errors. based on this condition an analytic formula has been derived for the sample unfalsified probability sup of the model set. some of the asymptotic statistical properties of the sup have also been briefly discussed. a numerical example is included to illustrate the efficiency of the suggested method in model set quality evaluation.
inspec,dev_1894,switching controller design via convex polyhedral lyapunov functions. we propose a systematic switching control design method for a class of nonlinear discrete time hybrid systems. the novelty of the adopted approach is in the fact that unlike conventional control the control burden is shifted to a logical level thus creating the need for the development of new analysis design methods.
inspec,dev_1895,an algorithm combining neural networks with fundamental parameters. an algorithm combining neural networks with the fundamental parameters equations nnfp is proposed for making corrections for non linear matrix effects in x ray fluorescence analysis. in the algorithm neural networks were applied to relate the concentrations of components to both the measured intensities and the relative theoretical intensities calculated by the fundamental parameter equations. the nnfp algorithm is compared with the classical theoretical correction models including the fundamental parameters approach the lachance traill model a hyperbolic function model and the cola algorithm. for an alloy system with 15 measured elements in most cases the prediction errors of the nnfp algorithm are lower than those of the fundamental parameters approach the lachance traill model the hyperbolic function model and the cola algorithm separately. if there are the serious matrix effects such as matrix effects among cr fe and ni the nnfp algorithm generally decreased predictive errors as compared with the classical models except for the case of cr by the fundamental parameters approach. the main reason why the nnfp algorithm has generally a better predictive ability than the classical theoretical correction models might be that neural networks can better calibrate the non linear matrix effects in a complex multivariate system.
inspec,dev_1896,the dynamics of a railway freight wagon wheelset with dry friction damping. we investigate the dynamics of a simple model of a wheelset that supports one end of a railway freight wagon by springs with linear characteristics and dry friction dampers. the wagon runs on an ideal straight and level track with constant speed. the lateral dynamics in dependence on the speed is examined. we have included stick slip and hysteresis in our model of the dry friction and assume that coulomb s law holds during the slip phase. it is found that the action of dry friction completely changes the bifurcation diagram and that the longitudinal component of the dry friction damping forces destabilizes the wagon.
inspec,dev_1897,user appropriate tyre modelling for vehicle dynamics in standard and limit situations. when modelling vehicles for the vehicle dynamic simulation special attention must be paid to the modelling of tyre forces and torques according to their dominant influence on the results. this task is not only about sufficiently exact representation of the effective forces but also about user friendly and practical relevant applicability especially when the experimental tyre input data is incomplete or missing. this text firstly describes the basics of the vehicle dynamic tyre model conceived to be a physically based semi empirical model for application in connection with multi body systems mbs. on the basis of tyres for a passenger car and a heavy truck the simulated steady state tyre characteristics are shown together and compared with the underlying experimental values. the possibility to link the tyre model tmeasy to any mbs program is described as far as it supports the standard tyre interface. as an example the simulated and experimental data of a heavy truck doing a standardized driving manoeuvre are compared.
inspec,dev_1898,design of a stroke dependent damper for the front axle suspension of a truck using multibody system dynamics and numerical optimization. a stroke dependent damper is designed for the front axle suspension of a truck. the damper supplies extra damping for inward deflections rising above 4 cm. in this way the damper should reduce extreme suspension deflections without deteriorating the comfort of the truck. but the question is which stroke dependent damping curve yields the best compromise between suspension deflection working space and comfort. therefore an optimization problem is defined to minimize the maximum inward suspension deflection subject to constraints on the chassis acceleration for three typical road undulations. the optimization problem is solved using sequential linear programming slp and multibody dynamics simulation software. several optimization runs have been carried out for a small two degree of freedom vehicle model and a large full scale model of the truck semi trailer combination. the results show that the stroke dependent damping can reduce large deflections at incidental road disturbances but that the optimum stroke dependent damping curve is related to the acceleration bound. by means of vehicle model simulation and numerical optimization we have been able to quantify this trade off between suspension deflection working space and truck comfort.
inspec,dev_1899,human face detection in visual scenes using neural networks. this paper presents a neural network based face detection system. our objective is to design a system that can detect human faces in visual scenes at high searching speed and accuracy. we used a neural network with a simple structure but trained using face and non face samples preprocessed by several methods position normalization histogram equalization etc to attain high accuracy then pruned the size of the neural network so that it could run faster and reduced the total search area of a target visual scene using the skin color detector. skin color detection assumes that faces reside only in skin color regions. the system design is made up of two parts the face detecting system that detects the faces and the searching speed improving system. speed improvement is achieved by reducing the face locator network size using the structural learning with knowledge and by reducing the face search area using the skin color detection system. faster training of the neural networks was also achieved using variable step sizes.
inspec,dev_19,decentralized adaptive output feedback stabilization for a class of interconnected systems with unknown bound of uncertainties. the problem of adaptive decentralized stabilization for a class of linear time invarying large scale systems with nonlinear interconnectivity and uncertainties is discussed. the bounds of uncertainties are assumed to be unknown. for such uncertain dynamic systems an adaptive decentralized controller is presented. the resulting closed loop systems are asymptotically stable in theory. moreover an adaptive decentralized control scheme is given. the scheme ensures the closed loop systems exponentially practically stable and can be used in practical engineering. finally simulations show that the control scheme is effective.
inspec,dev_190,on the design of gain scheduled trajectory tracking controllers auv application. a new methodology is proposed for the design of trajectory tracking controllers for autonomous vehicles. the design technique builds on gain scheduling control theory. an application is made to the design of a trajectory tracking controller for a prototype autonomous underwater vehicle auv. the effectiveness and advantages of the new control laws derived are illustrated in simulation using a full set of non linear equations of motion of the vehicle.
inspec,dev_1900,robust l sub 2 disturbance attenuation for nonlinear systems with input dynamical uncertainty. deals with the problem of robust l sub 2 disturbance attenuation for nonlinear systems with input dynamical uncertainty. the input dynamical uncertainty is restricted to be minimum phase and relative degree zero. a sufficient condition. is given such that the nonlinear system satisfies the l sub 2 gain performance and input to state stable property. using this condition a design approach is given for a smooth state feedback control law that solves the robust l sub 2 disturbance attenuation problem and the approach is extended to a more general case where the nominal system has higher relative degree. finally a numerical example is given to demonstrate the proposed approach.
inspec,dev_1901,fc  functional tools for object oriented tasks. fc  is a library for programming functionally in c. compared to other c functional programming libraries fc  is distinguished by its powerful type system which allows the manipulation of parametrically polymorphic functions e g passing them as arguments to other functions and returning them as results. in this paper we show how fc  can be used in common object oriented programming tasks. we demonstrate fc  implementations of several common design patterns adapter builder command and more. compared to conventional c implementations of these patterns our implementations are either simpler in that fewer classes dependencies are needed more efficient or more type safe thanks to parametric polymorphism and type inference.
inspec,dev_1902,engineering plug in software components to support collaborative work. many software applications require co operative work support including collaborative editing group awareness versioning messaging and automated notification and co ordination agents. most approaches hard code such facilities into applications with fixed functionality and limited ability to reuse groupware implementations. we describe our recent work in seamlessly adding such capabilities to component based applications via a set of collaborative work supporting plug in software components. we describe a variety of applications of this technique along with descriptions of the novel architecture user interface adaptation and implementation techniques for the collaborative work supporting components that we have developed. we report on our experiences to date with this method of supporting collaborative work enhancement of component based systems and discuss the advantages of our approach over conventional techniques.
inspec,dev_1903,the bliss programming language a history. the bliss programming language was invented by william a wulf and others at carnegie mellon university in 1969 originally for the dec pdp 10. bliss 10 caught the interest of ronald f brender of dec digital equipment corporation. after several years of collaboration including the creation of bliss 11 for the pdp 11 bliss was adopted as dec s implementation language for use on its new line of vax computers in 1975. dec developed a completely new generation of blisss for the vax pdp 10 and pdp 11 which became widely used at dec during the 1970s and 1980s. with the creation of the alpha architecture in the early 1990s bliss was extended again in both 32 and 64 bit flavors. bliss support for the intel ia 32 architecture was introduced in 1995 and ia 64 support is now in progress. bliss has a number of unusual characteristics it is typeless requires use of an explicit contents of operator written as a period or dot  takes an algorithmic approach to data structure definition has no goto is an expression language and has an unusually rich compile time language. this paper reviews the evolution and use of bliss over its three decade lifetime. emphasis is on how the language evolved to facilitate portable programming while retaining its initial highly machine specific character. finally the success of its characteristics are assessed.
inspec,dev_1904,component support in plt scheme. plt scheme drscheme and mzscheme supports the component object model com standard with two pieces of software. the first piece is mzcom a com class that makes a scheme evaluator available to com clients. with mzcom programmers can embed scheme code in programs written in mainstream languages such as c or visual basic. some applications can also be used as mzcom clients. the other piece of component support software is mysterx which makes com classes available to plt scheme programs. when needed mysterx uses a programmable web browser to display com objects. we describe the technical issues encountered in building these two systems and sketch some applications.
inspec,dev_1905,tool and process improvements from mfc control system technology. a new approach to mfc calibration links the physical parameters of nitrogen to the physical characteristics of various process gases. this precludes the conventional need for surrogate gases. what results is a physics based tuning algorithm and enhanced digital control system that enables rearranging and gas change of digital mfcs. the end result should be better process control through more accurate gas flow. the new method also decreases the number of mfc spare parts required to back up a fab.
inspec,dev_1906,integrated process control using an in situ sensor for etch. the migration to tighter geometries and more complex process sequence integration schemes requires having the ability to compensate for upstream deviations from target specifications. doing so ensures that downstream process sequences operate on work in progress that is well within control. because point of use visibility of work in progress quality has become of paramount concern in the industry s drive to reduce scrap and improve yield controlling trench depth has assumed greater importance. an integrated interferometric based rate monitor for etch to depth and spacer etch applications has been developed for controlling this parameter. this article demonstrates that the integrated rate monitor using polarization and digital signal processing enhances control etch to depth processes and can also be implemented as a predictive endpoint in a wafer manufacturing environment for dual damascene trench etch and spacer etch applications.
inspec,dev_1907,multiple comparison methods for means. multiple comparison methods mcms are used to investigate differences between pairs of population means or more generally between subsets of population means using sample data. although several such methods are commonly available in statistical software packages users may be poorly informed about the appropriate method s to use and or the correct way to interpret the results. this paper classifies the mcms and presents the important methods for each class. both simulated and real data are used to compare the methods and emphasis is placed on a correct application and interpretation. we include suggestions for choosing the best method. mathematica programs developed by the authors are used to compare mcms. by taking the advantage of mathematica s notebook structure all interested student can use these programs to explore the subject more deeply.
inspec,dev_1908,explicit solutions for transcendental equations. a simple method to formulate an explicit expression for the roots of any analytic transcendental function is presented. the method is based on cauchy s integral theorem and uses only basic concepts of complex integration. a convenient method for numerically evaluating the exact expression is presented. the application of both the formulation and evaluation of the exact expression is illustrated for several classical root finding problems.
inspec,dev_1909,breast mr imaging with high spectral and spatial resolutions preliminary experience. the authors evaluated magnetic resonance mr imaging with high spectral and spatial resolutions hssr of water and fat in breasts of healthy volunteers n 6 and women with suspicious lesions n 6. fat suppression edge delineation and image texture were improved on mr images derived from hssr data compared with those on conventional mr images. hssr mr imaging data acquired before and after contrast medium injection showed spectrally inhomogeneous changes in the water resonances in small voxels that were not detectable with conventional mr imaging.
inspec,dev_191,linear parameter varying control and its application to a turbofan engine. this paper describes application of parameter dependent control design methods to a turbofan engine. parameter dependent systems are linear systems whose state space descriptions are known functions of time varying parameters. the time variation of each of the parameters is not known in advance but is assumed to be measurable in real time. three linear parameter varying lpv approaches to control design are discussed. the first method is based on linear fractional transformations which relies on the small gain theorem for bounds on performance and robustness. the other methods make use of either a single sqlf or parameter dependent pdqlf quadratic lyapunov function to bound the achievable level of performance. the latter two techniques are used to synthesize controllers for a high performance turbofan engine. a lpv model of the turbofan engine is constructed from jacobian linearizations at fixed power codes for control design. the control problem is formulated as a model matching problem in the h sub infinity and lpv framework. the objective is decoupled command response of the closed loop system to pressure and rotor speed requests. the performance of linear h sub infinity point designs are compared with the sqlf and pdqlf controllers. nonlinear simulations indicate that the controller synthesized using the sqlf approach is slightly more conservative than the pdqlf controller. nonlinear simulations with the sqlf and pdqlf controllers show very robust designs that achieve all desired performance objectives.
inspec,dev_1910,breast cancer effectiveness of computer aided diagnosis observer study with independent database of mammograms. evaluates the effectiveness of a computerized classification method as an aid to radiologists reviewing clinical mammograms for which the diagnoses were unknown to both the radiologists and the computer. six mammographers and six community radiologists participated in an observer study. these 12 radiologists interpreted with and without the computer aid 110 cases that were unknown to both the 12 radiologist observers and the trained computer classification scheme. the radiologists performances in differentiating between benign and malignant masses without and with the computer aid were evaluated with receiver operating characteristic roc analysis. two tailed p values were calculated for the student t test to indicate the statistical significance of the differences in performances with and without the computer aid. when the computer aid was used the average performance of the 12 radiologists improved as indicated by an increase in the area under the roc curve a sub z from 0 93 to 0 96 p 001 by an increase in partial area under the roc curve sub 0 9 0a  sub z from 0 56 to 0 72 p 001 and by an increase in sensitivity from 94 to 98 p 022. no statistically significant difference in specificity was found between readings with and those without computer aid delta 0 014 p 46 95 cl 0 054 0 026 where delta is difference in specificity. when we analyzed results from the mammographers and community radiologists as separate groups a larger improvement was demonstrated for the community radiologists. computer aided diagnosis can potentially help radiologists improve their diagnostic accuracy in the task of differentiating between benign and malignant masses seen on mammograms.
inspec,dev_1911,pulmonary perfusion patterns and pulmonary arterial pressure. uses artificial intelligence methods to determine whether quantitative parameters describing the perfusion image can be synthesized to make a reasonable estimate of the pulmonary arterial pa pressure measured at angiography. radionuclide perfusion images were obtained in 120 patients with normal chest radiographs who also underwent angiographic pa pressure measurement within 3 days of the radionuclide study. an artificial neural network ann was constructed from several image parameters describing statistical and boundary characteristics of the perfusion images. with use of a leave one out cross validation technique this method was used to predict the pa systolic pressure in cases on which the ann had not been trained. a pearson correlation coefficient was determined between the predicted and measured pa systolic pressures. ann predictions correlated with measured pulmonary systolic pressures r 0 846 p 001. the accuracy of the predictions was not influenced by the presence of pulmonary embolism. none of the 51 patients with predicted pa pressures of less than 29 mm hg had pulmonary hypertension at angiography. all 13 patients with predicted pa pressures greater than 48 mm hg had pulmonary hypertension at angiography. meaningful information regarding pa pressure can be derived from noninvasive radionuclide perfusion scanning. the use of image analysis in concert with artificial intelligence methods helps to reveal physiologic information not readily apparent at visual image inspection.
inspec,dev_1912,a novel preterm respiratory mechanics active simulator to test the performances of neonatal pulmonary ventilators. a patient active simulator is proposed which is capable of reproducing values of the parameters of pulmonary mechanics of healthy newborns and preterm pathological infants. the implemented prototype is able to a let the operator choose the respiratory pattern times of apnea episodes of cough sobs etc b continuously regulate and control the parameters characterizing the pulmonary system and finally c reproduce the attempt of breathing of a preterm infant. taking into account both the limitation due to the chosen application field and the preliminary autocalibration phase automatically carried out by the proposed device accuracy and reliability on the order of 1 is estimated. the previously indicated value has to be considered satisfactory in light of the field of application and the small values of the simulated parameters. finally the achieved metrological characteristics allow the described neonatal simulator to be adopted as a reference device to test performances of neonatal ventilators and more specifically to measure the time elapsed between the occurrence of a potentially dangerous condition to the patient and the activation of the corresponding alarm of the tested ventilator.
inspec,dev_1913,a six degree of freedom precision motion stage. this article presents the design and performance evaluation of a six degree of freedom piezoelectrically actuated fine motion stage that will be used for three dimensional error compensation of a long range translation mechanism. development of a single element piezoelectric linear displacement actuator capable of translations of 1 67 mu m with 900 v potential across the electrodes and under a 27 4 n axial load and 0 5 mm lateral distortion is presented. finite element methods have been developed and used to evaluate resonant frequencies of the stage platform and the complete assembly with and without a platform payload. in general an error of approximately 10 0 between the finite element results and the experimentally measured values were observed. the complete fine motion stage provided approximately or 0 93 mu m of translation and or 38 0 mu rad of rotation in all three planes of motion using an excitation range of 1000 v. an impulse response indicating a fundamental mode resonance at 162 hz was measured with a 0 650 kg payload rigidly mounted to the top of the stage.
inspec,dev_1914,vacuum compatible vibration isolation stack for an interferometric gravitational wave detector tama300. interferometric gravitational wave detectors require a large degree of vibration isolation. for this purpose a multilayer stack constructed of rubber and metal blocks is suitable because it provides isolation in all degrees of freedom at once. in tama300 a 300 m interferometer in japan long term dimensional stability and compatibility with an ultrahigh vacuum environment of about 10 sup 6 pa are also required. to keep the interferometer at its operating point despite ground strain and thermal drift of the isolation system a thermal actuator was introduced. to prevent the high outgassing rate of the rubber from spoiling the vacuum the rubber blocks were enclosed by gas tight bellows. using these techniques we have successfully developed a three layer stack which has a vibration isolation ratio of more than 10 sup 3 at 300 hz with control of drift and enough vacuum compatibility.
inspec,dev_1915,multichannel scaler for general statistical analysis of dynamic light scattering. a four channel scaler for counting applications has been designed and built using a standard high transfer rate parallel computer interface bus parallel data card. the counter section is based on standard complex programmable logic device integrated circuits. with a 200 mhz pentium based host pc a sustained counting and data transfer with channel widths as short as 200 ns for a single channel is realized. the use of the multichannel scaler is demonstrated in dynamic light scattering experiments. the recorded traces are analyzed with wavelet and other statistical techniques to obtain transient changes in the properties of the scattered light.
inspec,dev_1916,changes in the entropy and the tsallis difference information during spontaneous decay and self organization of nonextensive systems. a theoretical information description of self organization processes during stimulated transitions between stationary states of open nonextensive systems is presented. s sub q  and i sub q  theorems on changes of the entropy and tsallis difference information measures in the process of evolution in the space of control parameters are proved. the entropy and the tsallis difference information are derived and their new extreme properties are discussed.
inspec,dev_1917,design and modeling of an interval based abr flow control protocol. a novel flow control protocol is presented for availability bit rate abr service in asynchronous transfer mode atm networks. this scheme features periodic explicit rate feedback that enables precise allocation of link bandwidth and buffer space on a hop by hop basis to guarantee maximum throughput minimum cell loss and high resource efficiency. with the inclusion of resource management cell synchronization and consolidation algorithms this protocol is capable of controlling point to multipoint abr services within a unified framework. the authors illustrate the modeling of single abr connection the interaction between multiple abr connections and the constraints applicable to flow control decisions. a loss free flow control mechanism is presented for high speed abr connections using a fluid traffic model. supporting algorithms and atm signaling procedures are specified in company with linear system modeling numerical analysis and simulation results which demonstrate its performance and cost benefits in high speed backbone networking scenarios.
inspec,dev_1918,negotiating the semantics of agent communication languages. this article presents a formal framework and outlines a method that autonomous agents can use to negotiate the semantics of their communication language at run time. such an ability is needed in open multi agent systems so that agents can ensure they understand the implications of the utterances that are being made and so that they can tailor the meaning of the primitives to best fit their prevailing circumstances. to this end the semantic space framework provides a systematic means of classifying the primitives along multiple relevant dimensions. this classification can then be used by the agents to structure their negotiation or semantic fixing process so that they converge to the mutually agreeable semantics that are necessary for coherent social interactions.
inspec,dev_1919,toward a formalism for conversation protocols using joint intention theory. conversation protocols are used to achieve certain goals or to bring about certain states in the world. therefore one may identify the landmarks or the states that must be brought about during the goal directed execution of a protocol. accordingly the landmarks characterized by propositions that are true in the state represented by that landmark are the most important aspect of a protocol. families of conversation protocols can be expressed formally as partially ordered landmarks after the landmarks necessary to achieve a goal have been identified. concrete protocols represented as joint action expressions can then be derived from the partially ordered landmarks and executed directly by joint intention interpreters. this approach of applying joint intention theory to protocols also supports flexibility in the actions used to get to landmarks shortcutting protocol execution automatic exception handling and correctness criterion for protocols and protocol compositions.
inspec,dev_192,new jersey african american women writers and their publications a study of identification from written and oral sources. this study examines the use of written sources and personal interviews and informal conversations with individuals from new jersey s religious political and educational community to identify african american women writers in new jersey and their intellectual output. the focus on recognizing the community as an oral repository of history and then tapping these oral sources for collection development and acquisition purposes is supported by empirical and qualitative evidence. findings indicate that written sources are so limited that information professionals must rely on oral sources to uncover local writers and their publications.
inspec,dev_1920,to commit or not to commit modeling agent conversations for action. conversations are sequences of messages exchanged among interacting agents. for conversations to be meaningful agents ought to follow commonly known specifications limiting the types of messages that can be exchanged at any point in the conversation. these specifications are usually implemented using conversation policies which are rules of inference or conversation protocols which are predefined conversation templates. in this article we present a semantic model for specifying conversations using conversation policies. this model is based on the principles that the negotiation and uptake of shared social commitments entail the adoption of obligations to action which indicate the actions that agents have agreed to perform. in the same way obligations are retracted based on the negotiation to discharge their corresponding shared social commitments. based on these principles conversations are specified as interaction specifications that model the ideal sequencing of agent participations negotiating the execution of actions in a joint activity. these specifications not only specify the adoption and discharge of shared commitments and obligations during an activity but also indicate the commitments and obligations that are required as preconditions or that outlive a joint activity as postconditions. we model the contract net protocol as an example of the specification of conversations in a joint activity.
inspec,dev_1921,an acl for a dynamic system of agents. in this article we present the design of an acl for a dynamic system of agents. the acl includes a set of conversation performatives extended with operations to register create and terminate agents. the main design goal at the agent level is to provide only knowledge level primitives that are well integrated with the dynamic nature of the system. this goal has been achieved by defining an anonymous interaction protocol which enables agents to request and supply knowledge without considering symbol level issues concerning management of agent names routing and agent reachability. this anonymous interaction protocol exploits a distributed facilitator schema which is hidden at the agent level and provides mechanisms for registering capabilities of agents and delivering requests according to the competence of agents. we present a formal specification of the acl and of the underlying architecture exploiting an algebra of actors and illustrate it with the help of a graphical notation. this approach provides the basis for discussing dynamic primitives in acl and for studying properties of dynamic multi agent systems for example concerning the behavior of agents and the correctness of their conversation policies.
inspec,dev_1922,trends in agent communication language. agent technology is an exciting and important new way to create complex software systems. agents blend many of the traditional properties of ai programs knowledge level reasoning flexibility proactiveness goal directedness and so forth with insights gained from distributed software engineering machine learning negotiation and teamwork theory and the social sciences. an important part of the agent approach is the principle that agents like humans can function more effectively in groups that are characterized by cooperation and division of labor. agent programs are designed to autonomously collaborate with each other in order to satisfy both their internal goals and the shared external demands generated by virtue of their participation in agent societies. this type of collaboration depends on a sophisticated system of inter agent communication. the assumption that inter agent communication is best handled through the explicit use of an agent communication language acl underlies each of the articles in this special issue. in this introductory article we will supply a brief background and introduction to the main topics in agent communication.
inspec,dev_1923,predictive control of a high temperature short time pasteurisation process. modifications on the dynamic matrix control dmc algorithm are presented to deal with transfer functions with varying parameters in order to control a high temperature short time pasteurisation process. to control processes with first order with pure time delay models whose parameters present an exogenous variable dependence a new method of free response calculation using multiple model information is developed. two methods to cope with those nonlinear models that allow a generalised hammerstein model description are proposed. the proposed methods have been tested both in simulation and in real cases in comparison with pid and dmc classic controllers showing important improvements on reference tracking and disturbance rejection.
inspec,dev_1924,existence theorems for nonconvex problems of variational calculus. a solution to a variational calculus problem is studied under the conditions of integrant convexity. the existence theorem is proved. as an example a function is given which satisfies all the conditions of the theorem but is not convex.
inspec,dev_1925,on the accuracy of polynomial interpolation in hilbert space with disturbed nodal values of the operator. the interpolation accuracy of polynomial operators in a hilbert space with a measure is estimated when nodal values of these operators are given approximately.
inspec,dev_1926,simulation of ecological and economical structural type functions. an optimization approach to the simulation of ecological and economical structural type functions is proposed. a methodology for construction of such functions is created in an explicit analytical form.
inspec,dev_1927,optimal strategies for a semi markovian inventory system. control for a semi markovian inventory system is considered. under general assumptions on system functioning conditions for existence of an optimal nonrandomized markovian strategy are found. it is shown that under some additional assumptions on storing conditions for the inventory the optimal strategy has a threshold s s frame.
inspec,dev_1928,solution of a euclidean combinatorial optimization problem by the dynamic programming method. a class of euclidean combinatorial optimization problems is selected that can be solved by the dynamic programming method. the problem of allocation of servicing enterprises is solved as an example.
inspec,dev_1929,optimal time of switching between portfolios of securities. optimal time of switching between several portfolios of securities are found for the purpose of profit maximization. two methods of their determination are considered. the cases with three and n portfolios are studied in detail.
inspec,train_100,separate accounts go mainstream investment. new entrants are shaking up the separate account industry by supplying web based platforms that give advisers the tools to pick independent money managers.
inspec,train_1000,does classicism explain universality. arguments against a pure classical component of mind. one of the hallmarks of human cognition is the capacity to generalize over arbitrary constituents. marcus cognition 66 p 153 cognitive psychology 37 p 243 1998 argued that this capacity called universal generalization universality is not supported by connectionist models. instead universality is best explained by classical symbol systems with connectionism as its implementation. here it is argued that universality is also a problem for classicism in that the syntax sensitive rules that are supposed to provide causal explanations of mental processes are either too strict precluding possible generalizations or too lax providing no information as to the appropriate alternative. consequently universality is not explained by a classical theory.
inspec,train_1001,a conflict between language and atomistic information. fred dretske and jerry fodor are responsible for popularizing three well known theses in contemporary philosophy of mind the thesis of information based semantics ibs the thesis of content atomism atomism and the thesis of the language of thought lot. lot concerns the semantically relevant structure of representations involved in cognitive states such as beliefs and desires. it maintains that all such representations must have syntactic structures mirroring the structure of their contents. ibs is a thesis about the nature of the relations that connect cognitive representations and their parts to their contents semantic relations. it holds that these relations supervene solely on relations of the kind that support information content perhaps with some help from logical principles of combination. atomism is a thesis about the nature of the content of simple symbols. it holds that each substantive simple symbol possesses its content independently of all other symbols in the representational system. i argue that dretske s and fodor s theories are false and that their falsehood results from a conflict ibs and atomism on the one hand and lot on the other.
inspec,train_1002,selective representing and world making. we discuss the thesis of selective representing the idea that the contents of the mental representations had by organisms are highly constrained by the biological niches within which the organisms evolved. while such a thesis has been defended by several authors elsewhere our primary concern here is to take up the issue of the compatibility of selective representing and realism. we hope to show three things. first that the notion of selective representing is fully consistent with the realist idea of a mind independent world. second that not only are these two consistent but that the latter the realist conception of a mind independent world provides the most powerful perspective from which to motivate and understand the differing perceptual and cognitive profiles themselves. third that the genuine and important sense in which organism and environment may together constitute an integrated system of scientific interest poses no additional threat to the realist conception.
inspec,train_1003,lob s theorem as a limitation on mechanism. we argue that lob s theorem implies a limitation on mechanism. specifically we argue via an application of a generalized version of lob s theorem that any particular device known by an observer to be mechanical can not be used as an epistemic authority of a particular type by that observer either the belief set of such an authority is not mechanizable or if it is there is no identifiable formal system of which the observer can know or truly believe it to be the theorem set. this gives we believe an important and hitherto unnoticed connection between mechanism and the use of authorities by human like epistemic agents.
inspec,train_1004,games machines play. individual rationality or doing what is best for oneself is a standard model used to explain and predict human behavior and von neumann morgenstern game theory is the classical mathematical formalization of this theory in multiple agent settings. individual rationality however is an inadequate model for the synthesis of artificial social systems where cooperation is essential since it does not permit the accommodation of group interests other than as aggregations of individual interests. satisficing game theory is based upon a well defined notion of being good enough and does accommodate group as well as individual interests through the use of conditional preference relationships whereby a decision maker is able to adjust its preferences as a function of the preferences and not just the options of others. this new theory is offered as an alternative paradigm to construct artificial societies that are capable of complex behavior that goes beyond exclusive self interest.
inspec,train_1005,the average case identifiability and controllability of large scale systems. needs for increased product quality reduced pollution and reduced energy and material consumption are driving enhanced process integration. this increases the number of manipulated and measured variables required by the control system to achieve its objectives. this paper addresses the question of whether processes tend to become increasingly more difficult to identify and control as the process dimension increases. tools and results of multivariable statistics are used to show that under a variety of assumed distributions on the elements square processes of higher dimension tend to be more difficult to identify and control whereas the expected controllability and identifiability of nonsquare processes depends on the relative numbers of measured and manipulated variables. these results suggest that the procedure of simplifying the control problem so that only a square process is considered is a poor practice for large scale systems.
inspec,train_1006,robust model order reduction of complex biological processes. this paper addresses robust model order reduction of a high dimensional nonlinear partial differential equation pde model of a complex biological process. based on a nonlinear distributed parameter model of the same process which was validated against experimental data of an existing pilot scale biological nutrient removal bnr activated sludge plant we developed a state space model with 154 state variables. a general algorithm for robustly reducing the nonlinear pde model is presented and based on an investigation of five state of the art model order reduction techniques we are able to reduce the original model to a model with only 30 states without incurring pronounced modelling errors. the singular perturbation approximation balanced truncating technique is found to give the lowest modelling errors in low frequency ranges and hence is deemed most suitable for controller design and other real time applications.
inspec,train_1007,conditions for decentralized integral controllability. the term decentralized integral controllability dic pertains to the existence of stable decentralized controllers with integral action that have closed loop properties such as stable independent detuning. it is especially useful to select control structures systematically at the early stage of control system design because the only information needed for dic is the steady state process gain matrix. here a necessary and sufficient condition conjectured in the literature is proved. the real structured singular value which can exploit realness of the controller gain is used to describe computable conditions for dic. the primary usage of dic is to eliminate unworkable pairings. for this two other simple necessary conditions are proposed. examples are given to illustrate the effectiveness of the proposed conditions for dic.
inspec,train_1008,quadratic programming algorithms for large scale model predictive control. quadratic programming qp methods are an important element in the application of model predictive control mpc. as larger and more challenging mpc applications are considered more attention needs to be focused on the construction and tailoring of efficient qp algorithms. in this study we tailor and apply a new qp method called qpschur to large mpc applications such as cross directional control problems in paper machines. written in c qpschur is an object oriented implementation of a novel dual space schur complement algorithm. we compare this approach to three widely applied qp algorithms and show that qpschur is significantly more efficient up to two orders of magnitude than the other algorithms. in addition detailed simulations are considered that demonstrate the importance of the flexible object oriented construction of qpschur along with additional features for constraint handling warm starts and partial solution.
inspec,train_1009,robust output feedback model predictive control using off line linear matrix inequalities. a fundamental question about model predictive control mpc is its robustness to model uncertainty. in this paper we present a robust constrained output feedback mpc algorithm that can stabilize plants with both polytopic uncertainty and norm bound uncertainty. the design procedure involves off line design of a robust constrained state feedback mpc law and a state estimator using linear matrix inequalities lmis. since we employ an off line approach for the controller design which gives a sequence of explicit control laws we are able to analyze the robust stabilizability of the combined control laws and estimator and by adjusting the design parameters guarantee robust stability of the closed loop system in the presence of constraints. the algorithm is illustrated with two examples.
inspec,train_1010,robust self tuning pid controller for nonlinear systems. in this paper we propose a robust self tuning pid controller suitable for nonlinear systems. the control system employs a preload relay p_relay in series with a pid controller. the p_relay ensures a high gain to yield a robust performance. however it also incurs a chattering phenomenon. in this paper instead of viewing the chattering as an undesirable yet inevitable feature we use it as a naturally occurring signal for tuning and re tuning the pid controller as the operating regime digresses. no other explicit input signal is required. once the pid controller is tuned for a particular operating point the relay may be disabled and chattering ceases correspondingly. however it is invoked when there is a change in setpoint to another operating regime. in this way the approach is also applicable to time varying systems as the pid tuning can be continuous based on the latest set of chattering characteristics. analysis is provided on the stability properties of the control scheme. simulation results for the level control of fluid in a spherical tank using the scheme are also presented.
inspec,train_1011,a self organizing context based approach to the tracking of multiple robot trajectories. we have combined competitive and hebbian learning in a neural network designed to learn and recall complex spatiotemporal sequences. in such sequences a particular item may occur more than once or the sequence may share states with another sequence. processing of repeated shared states is a hard problem that occurs very often in the domain of robotics. the proposed model consists of two groups of synaptic weights competitive interlayer and hebbian intralayer connections which are responsible for encoding respectively the spatial and temporal features of the input sequence. three additional mechanisms allow the network to deal with shared states context units neurons disabled from learning and redundancy used to encode sequence states. the network operates by determining the current and the next state of the learned sequences. the model is simulated over various sets of robot trajectories in order to evaluate its storage and retrieval abilities its sequence sampling effects its robustness to noise and its tolerance to fault.
inspec,train_1012,evolving receptive field controllers for mobile robots. the use of evolutionary methods to generate controllers for real world autonomous agents has attracted attention. most of the pertinent research has employed genetic algorithms or variations thereof. research has applied an alternative evolutionary method evolution strategies to the generation of simple braitenberg vehicles. this application accelerates the development of such controllers by more than an order of magnitude a few hours compared to more than two days. motivated by this useful speedup the paper investigates the evolution of more complex architectures receptive field controllers that can employ nonlinear interactions and therefore can yield more complex behavior. it is interesting to note that the evolution strategy yields the same efficacy in terms of function evaluations even though the second class of controllers requires up to 10 times more parameters than the simple braitenberg architecture. in addition to the speedup there is an important theoretical reason for preferring an evolution strategy over a genetic algorithm for this problem namely the presence of epistasis.
inspec,train_1013,a scalable intelligent takeoff controller for a simulated running jointed leg. running with jointed legs poses a difficult control problem in robotics. neural controllers are attractive because they allow the robot to adapt to changing environmental conditions. however scalability is an issue with many neural controllers. the paper describes the development of a scalable neurofuzzy controller for the takeoff phase of the running stride. scalability is achieved by selecting a controller whose size does not grow with the dimensionality of the problem. empirical results show that with proper design the takeoff controller scales from a leg with a single movable link to one with three movable links without a corresponding growth in size and without a loss of accuracy.
inspec,train_1014,modelling of complete robot dynamics based on a multi dimensional rbf like neural architecture. a neural network based identification approach of manipulator dynamics is presented. for a structured modelling rbf like static neural networks are used in order to represent and adapt all model parameters with their non linear dependences on the joint positions. the neural architecture is hierarchically organised to reach optimal adjustment to structural a priori knowledge about the identification problem. the model structure is substantially simplified by general system analysis independent of robot type. but also a lot of specific features of the utilised experimental robot are taken into account. a fixed grid based neuron placement together with application of b spline polynomial basis functions is utilised favourably for a very effective recursive implementation of the neural architecture. thus an online identification of a dynamic model is submitted for a complete 6 joint industrial robot.
inspec,train_1015,scalable techniques from nonparametric statistics for real time robot learning. locally weighted learning lwl is a class of techniques from nonparametric statistics that provides useful representations and training algorithms for learning about complex phenomena during autonomous adaptive control of robotic systems. the paper introduces several lwl algorithms that have been tested successfully in real time learning of complex robot tasks. we discuss two major classes of lwl memory based lwl and purely incremental lwl that does not need to remember any data explicitly. in contrast to the traditional belief that lwl methods can not work well in high dimensional spaces we provide new algorithms that have been tested on up to 90 dimensional learning problems. the applicability of our lwl algorithms is demonstrated in various robot learning examples including the learning of devil sticking pole balancing by a humanoid robot arm and inverse dynamics learning for a seven and a 30 degree of freedom robot. in all these examples the application of our statistical neural networks techniques allowed either faster or more accurate acquisition of motor control than classical control engineering.
inspec,train_1016,a scalable model of cerebellar adaptive timing and sequencing the recurrent slide and latch rsl model. from the dawn of modern neural network theory the mammalian cerebellum has been a favored object of mathematical modeling studies. early studies focused on the fanout convergence thresholding and learned weighting of perceptual motor signals within the cerebellar cortex. this led to the still viable idea that the granule cell stage in the cerebellar cortex performs a sparse expansive recoding of the time varying input vector. this recoding reveals and emphasizes combinations in a distributed representation that serves as a basis for the learned state dependent control actions engendered by cerebellar outputs to movement related centers. to make optimal use of available signals the cerebellum must be able to sift the evolving state representation for the most reliable predictors of the need for control actions and to use those predictors even if they appear only transiently and well in advance of the optimal time for initiating the control action. the paper proposes a modification to prior population models for cerebellar adaptive timing and sequencing. since it replaces a population with a single element the proposed rsl model is in one sense maximally efficient and therefore optimal from the perspective of scalability.
inspec,train_1017,searching a scalable approach to cerebellar based control. decades of research into the structure and function of the cerebellum have led to a clear understanding of many of its cells as well as how learning might take place. furthermore there are many theories on what signals the cerebellum operates on and how it works in concert with other parts of the nervous system. nevertheless the application of computational cerebellar models to the control of robot dynamics remains in its infant state. to date few applications have been realized. the currently emerging family of light weight robots poses a new challenge to robot control due to their complex dynamics traditional methods depending on a full analysis of the dynamics of the system are no longer applicable since the joints influence each other dynamics during movement. can artificial cerebellar models compete here.
inspec,train_1018,fabrication of polymeric microlens of hemispherical shape using micromolding. polymeric microlenses play an important role in reducing the size weight and cost of optical data storage and optical communication systems. we fabricate polymeric microlenses using the microcompression molding process. the design and fabrication procedures for mold insertion is simplified using silicon instead of metal. pmma powder is used as the molding material. governed by process parameters such as temperature and pressure histories the micromolding process is controlled to minimize various defects that develop during the molding process. the radius of curvature and magnification ratio of fabricated microlens are measured as 150 mu m and over 3 0 respectively.
inspec,train_1019,optical setup and analysis of disk type photopolymer high density holographic storage. a relatively simple scheme for disk type photopolymer high density holographic storage based on angular and spatial multiplexing is described. the effects of the optical setup on the recording capacity and density are studied. calculations and analysis show that this scheme is more effective than a scheme based on the spatioangular multiplexing for disk type photopolymer high density holographic storage which has a limited medium thickness. also an optimal beam recording angle exists to achieve maximum recording capacity and density.
inspec,train_102,harmless delays in cohen grossberg neural networks. without assuming monotonicity and differentiability of the activation functions and any symmetry of interconnections we establish some sufficient conditions for the globally asymptotic stability of a unique equilibrium for the cohen grossberg 1983 neural network with multiple delays. lyapunov functionals and functions combined with the razumikhin technique are employed. the criteria are all independent of the magnitudes of the delays and thus the delays under these conditions are harmless.
inspec,train_1020,supersampling multiframe blind deconvolution resolution enhancement of adaptive optics compensated imagery of low earth orbit satellites. we describe a postprocessing methodology for reconstructing undersampled image sequences with randomly varying blur that can provide image enhancement beyond the sampling resolution of the sensor. this method is demonstrated on simulated imagery and on adaptive optics ao compensated imagery taken by the starfire optical range 3 5 m telescope that has been artificially undersampled. also shown are the results of multiframe blind deconvolution of some of the highest quality optical imagery of low earth orbit satellites collected with a ground based telescope to date. the algorithm used is a generalization of multiframe blind deconvolution techniques that include a representation of spatial sampling by the focal plane array elements based on a forward stochastic model. this generalization enables the random shifts and shape of the ao compensated point spread function psf to be used to partially eliminate the aliasing effects associated with sub nyquist sampling of the image by the focal plane array. the method could be used to reduce resolution loss that occurs when imaging in wide field of view fov modes.
inspec,train_1021,error probability analysis of mil std 1773 optical fiber data buses. we have analyzed the error probabilities of mil std 1773 optical fiber data buses with three modulation schemes namely original manchester ii bi phase coding ptmbc and embc bsf. using these derived expressions of error probabilities we can also compare the receiver sensitivities of such optical fiber data buses.
inspec,train_1022,bad pixel identification by means of principal components analysis. bad pixels are defined as those pixels showing a temporal evolution of the signal different from the rest of the pixels of a given array. principal component analysis helps us to understand the definition of a statistical distance associated with each pixels and using this distance it is possible to identify those pixels labeled as bad pixels. the spatiality of a pixel is also calculated. an assumption about the normality of the distribution of the distances of the pixels is revised. although the influence on the robustness of the identification algorithm is negligible the definition of a parameter related with this nonnormality helps to identify those principal components and eigenimages responsible for the departure from a multinormal distribution. the method for identifying the bad pixels is successfully applied to a set of frames obtained from a ccd visible and a focal plane array fpa ir camera.
inspec,train_1023,simple nonlinear dual window operator for edge detection. we propose a nonlinear edge detection technique based on a two concentric circular window operator. we perform a preliminary selection of edge candidates using a standard gradient and use the dual window operator to reveal edges as zero crossing points of a simple difference function depending only on the minimum and maximum values in the two windows. comparisons with other well established techniques are reported in terms of visual appearance and computational efficiency. they show that detected edges are surely comparable with canny s and laplacian of gaussian algorithms with a noteworthy reduction in terms of computational load.
inspec,train_1024,rational systems exhibit moderate risk aversion with respect to gambles on variable resolution compression. in an embedded wavelet scheme for progressive transmission a tree structure naturally defines the spatial relationship on the hierarchical pyramid. transform coefficients over each tree correspond to a unique local spatial region of the original image and they can be coded bit plane by bit plane through successive approximation quantization. after receiving the approximate value of some coefficients the decoder can obtain a reconstructed image. we show a rational system for progressive transmission that in absence of a priori knowledge about regions of interest chooses at any truncation time among alternative trees for further transmission in such a way as to avoid certain forms of behavioral inconsistency. we prove that some rational transmission systems might exhibit aversion to risk involving gambles on tree dependent quality of encoding while others favor taking such risks. based on an acceptable predictor for visual distinctness from digital imagery we demonstrate that without any outside knowledge risk prone systems as well as those with strong risk aversion appear in capable of attaining the quality of reconstructions that can be achieved with moderate risk averse behavior.
inspec,train_1025,watermarking techniques for electronic delivery of remote sensing images. earth observation missions have recently attracted a growing interest mainly due to the large number of possible applications capable of exploiting remotely sensed data and images. along with the increase of market potential the need arises for the protection of the image products. such a need is a very crucial one because the internet and other public private networks have become preferred means of data exchange. a critical issue arising when dealing with digital image distribution is copyright protection. such a problem has been largely addressed by resorting to watermarking technology. a question that obviously arises is whether the requirements imposed by remote sensing imagery are compatible with existing watermarking techniques. on the basis of these motivations the contribution of this work is twofold assessment of the requirements imposed by remote sensing applications on watermark based copyright protection and modification of two well established digital watermarking techniques to meet such constraints. more specifically the concept of near lossless watermarking is introduced and two possible algorithms matching such a requirement are presented. experimental results are shown to measure the impact of watermark introduction on a typical remote sensing application i e unsupervised image classification.
inspec,train_1026,use of spot images as a tool for coastal zone management and monitoring of environmental impacts in the coastal zone. modern techniques such as remote sensing have been one of the main factors leading toward the achievement of serious plans regarding coastal management. a multitemporal analysis of land use in certain areas of the colombian caribbean coast is described. it mainly focuses on environmental impacts caused by anthropogenic activities such as deforestation of mangroves due to shrimp farming. selection of sensitive areas percentage of destroyed mangroves possible endangered areas etc are some of the results of this analysis. recommendations for a coastal management plan in the area have also resulted from this analysis. some other consequences of the deforestation of mangroves in the coastal zone and the construction of shrimp ponds are also analyzed such as the increase of erosion problems in these areas and water pollution among others. the increase of erosion in these areas has also changed part of their morphology which has been studied by the analysis of spot images in previous years. a serious concern exists about the future of these areas. for this reason new techniques like satellite images spot have been applied with good results leading to more effective control and coastal management in the area. the use of spot images to study changes of the land use of the area is a useful technique to determine patterns of human activities and suggest solutions for severe problems in these areas.
inspec,train_1027,extracting straight road structure in urban environments using ikonos satellite imagery. we discuss a fully automatic technique for extracting roads in urban environments. the method has its bases in a vegetation mask derived from multispectral ikonos data and in texture derived from panchromatic ikonos data. these two techniques together are used to distinguish road pixels. we then move from individual pixels to an object based representation that allows reasoning on a higher level. recognition of individual segments and intersections and the relationships among them are used to determine underlying road structure and to then logically hypothesize the existence of additional road network components. we show results on an image of san diego california. the object based processing component may be adapted to utilize other basis techniques as well and could be used to build a road network in any scene having a straight line structured topology.
inspec,train_1028,novel approach to super resolution pits readout. we proposed a novel method to realize the readout of super resolution pits by using a super resolution reflective film to replace the reflective layer of the conventional rom. at the same time by using sb as the super resolution reflective layer and sin as a dielectric layer the super resolution pits with diameters of 380 nm were read out by a setup whose laser wavelength is 632 8 nm and numerical aperture is 0 40. in addition the influence of the sb thin film thickness on the readout signal was investigated the results showed that the optimum sb thin film thickness is 28 to 30 nm and the maximum cnr is 38 to 40 db.
inspec,train_1029,effect of insulation layer on transcribability and birefringence distribution in optical disk substrate. as the need for information storage media with high storage density increases digital video disks dvds with smaller recording marks and thinner optical disk substrates than those of conventional dvds are being required. therefore improving the replication quality of land groove or pit structure and reducing the birefringence distribution are emerging as important criteria in the fabrication of high density optical disk substrates. we control the transcribability and distribution of birefringence by inserting an insulation layer under the stamper during injection compression molding of dvd ram substrates. the effects of the insulation layer on the geometrical and optical properties such as transcribability and birefringence distribution are examined experimentally. the inserted insulation layer is found to be very effective in improving the quality of replication and leveling out the first peak of the gapwise birefringence distribution near the mold wall and reducing the average birefringence value because the insulation layer retarded the growth of the solidified layer.
inspec,train_1030,comparison of automated digital elevation model extraction results using along track aster and across track spot stereo images. a digital elevation model dem can be extracted automatically from stereo satellite images. during the past decade the most common satellite data used to extract dem was the across track spot. recently the addition of along track aster data which can be downloaded freely provides another attractive alternative to extract dem data. this work compares the automated dem extraction results using an aster stereo pair and a spot stereo pair over an area of hilly mountains in drum mountain utah when compared to a usgs 7 5 min dem standard product. the result shows that spot produces better dem results in terms of accuracy and details if the radiometric variations between the images taken on subsequent satellite revolutions are small. otherwise the aster stereo pair is a better choice because of simultaneous along track acquisition during a single pass. compared to the usgs 7 5 min dem the aster and the spot extracted dems have a standard deviation of 11 6 and 4 6 m respectively.
inspec,train_1031,noise constrained hyperspectral data compression. storage and transmission requirements for hyperspectral data sets are significant. to reduce hardware costs well designed compression techniques are needed to preserve information content while maximizing compression ratios. lossless compression techniques maintain data integrity but yield small compression ratios. we present a slightly lossy compression algorithm that uses the noise statistics of the data to preserve information content while maximizing compression ratios. the adaptive principal components analysis apca algorithm uses noise statistics to determine the number of significant principal components and selects only those that are required to represent each pixel to within the noise level. we demonstrate the effectiveness of these methods with airborne visible infrared spectrometer aviris hyperspectral digital imagery collection experiment hydice hyperspectral mapper hymap and hyperion datasets.
inspec,train_1032,satellite image collection optimization. imaging satellite systems represent a high capital cost. optimizing the collection of images is critical for both satisfying customer orders and building a sustainable satellite operations business. we describe the functions of an operational multivariable time dynamic optimization system that maximizes the daily collection of satellite images. a graphical user interface allows the operator to quickly see the results of what if adjustments to an image collection plan. used for both long range planning and daily collection scheduling of space imaging s ikonos satellite the satellite control and tasking sct software allows collection commands to be altered up to 10 min before upload to the satellite.
inspec,train_1033,optical two step modified signed digit addition based on binary logic gates. a new modified signed digit msd addition algorithm based on binary logic gates is proposed for parallel computing. it is shown that by encoding each of the input msd digits and flag digits into a pair of binary bits the number of addition steps can be reduced to two. the flag digit is introduced to characterize the next low order pair nlop of the input digits in order to suppress carry propagation. the rules for two step addition of binary coded msd bcmsd numbers are formulated that can be implemented using optical shadow casting logic system.
inspec,train_1034,vibration control of the rotating flexible shaft multi flexible disk system with the eddy current damper. in this paper the rotating flexible timoshenko shaft flexible disk coupling system is formulated by applying the assumed mode method into the kinetic and strain energies and the virtual work done by the eddy current damper. from lagrange s equations the resulting discretized equations of motion can be simplified as a bilinear system bls. introducing the control laws including the quadratic nonlinear and optimal feedback control laws into the bls it is found that the eddy current damper can be used to suppress flexible and shear vibrations simultaneously and the system is globally asymptotically stable. numerical results are provided to validate the theoretical analysis.
inspec,train_1035,h sub 2 optimization of the three element type dynamic vibration absorbers. the dynamic vibration absorber dva is a passive vibration control device which is attached to a vibrating body called a primary system subjected to exciting force or motion. in this paper we will discuss an optimization problem of the three element type dva on the basis of the h sub 2 optimization criterion. the objective of the h sub 2 optimization is to reduce the total vibration energy of the system for overall frequencies the total area under the power spectrum response curve is minimized in this criterion. if the system is subjected to random excitation instead of sinusoidal excitation then the h sub 2 optimization is probably more desirable than the popular h sub infinity optimization. in the past decade there has been increasing interest in the three element type dva. however most previous studies on this type of dva were based on the h sub infinity optimization design and no one has been able to find the algebraic solution as of yet. we found a closed form exact solution for a special case where the primary system has no damping. furthermore the general case solution including the damped primary system is presented in the form of a numerical solution. the optimum parameters obtained here are compared to those of the conventional voigt type dva. they are also compared to other optimum parameters based on the h sub infinity criterion.
inspec,train_1036,nonlinear control of a shape memory alloy actuated manipulator. this paper presents a nonlinear robust control algorithm for accurate positioning of a single degree of freedom rotary manipulator actuated by shape memory alloy sma. a model for an sma actuated manipulator is presented. the model includes nonlinear dynamics of the manipulator a constitutive model of shape memory alloy and electrical and heat transfer behavior of sma wire. this model is used for open and closed loop motion simulations of the manipulator. experiments are presented that show results similar to both closed and open loop simulation results. due to modeling uncertainty and nonlinear behavior of the system classic control methods such as proportional integral derivative control are not able to present fast and accurate performance. hence a nonlinear robust control algorithm is presented based on variable structure control. this algorithm is a control gain switching technique based on the weighted average of position and velocity feedbacks. this method has been designed through simulation and tested experimentally. results show fast accurate and robust performance of the control system. computer simulation and experimental results for different stabilization and tracking situations are also presented.
inspec,train_1037,a stochastic averaging approach for feedback control design of nonlinear systems under random excitations. this paper presents a method for designing and quantifying the performance of feedback stochastic controls for nonlinear systems. the design makes use of the method of stochastic averaging to reduce the dimension of the state space and to derive the ito stochastic differential equation for the response amplitude process. the moment equation of the amplitude process closed by the rayleigh approximation is used as a means to characterize the transient performance of the feedback control. the steady state and transient response of the amplitude process are used as the design criteria for choosing the feedback control gains. numerical examples are studied to demonstrate the performance of the control.
inspec,train_1038,the analysis and control of longitudinal vibrations from wave viewpoint. the analysis and control of longitudinal vibrations in a rod from feedback wave viewpoint are synthesized. both collocated and noncollocated feedback wave control strategies are explored. the control design is based on the local properties of wave transmission and reflection in the vicinity of the control force applied area hence there is no complex closed form solution involved. the controller is designed to achieve various goals such as absorbing the incoming vibration energy creating a vibration free zone and eliminating standing waves in the structure. the findings appear to be very useful in practice due to the simplicity in the implementation of the controllers.
inspec,train_1039,design of an adaptive vibration absorber to reduce electrical transformer structural vibration. this paper considers the design of a vibration absorber to reduce structural vibration at multiple frequencies with an enlarged bandwidth control at these target frequencies. while the basic absorber is a passive device a control system has been added to facilitate tuning effectively giving the combination of a passive and active device which leads to far greater stability and robustness. experimental results demonstrating the effectiveness of the absorber are also described.
inspec,train_1040,crone control principles and extension to time variant plants with asymptotically constant coefficients. the principles of crone control a frequency domain robust control design methodology based on fractional differentiation are presented. continuous time variant plants with asymptotically constant coefficients are analysed in the frequency domain through their representation using time variant frequency responses. a stability theorem for feedback systems including time variant plants with asymptotically constant coefficients is proposed. finally crone control is extended to robust control of these plants.
inspec,train_1041,fractional differentiation in passive vibration control. from a single degree of freedom model used to illustrate the concept of vibration isolation a method to transform the design for a suspension into a design for a robust controller is presented. fractional differentiation is used to model the viscoelastic behaviour of the suspension. the use of fractional differentiation not only permits optimisation of just four suspension parameters showing the compactness of the fractional derivative operator but also leads to robustness of the suspension s performance to uncertainty of the sprung mass. as an example an engine suspension is studied.
inspec,train_1042,chaotic phenomena and fractional order dynamics in the trajectory control of redundant manipulators. redundant manipulators have some advantages when compared with classical arms because they allow the trajectory optimization both on the free space and on the presence of obstacles and the resolution of singularities. for this type of arms the proposed kinematic control algorithms adopt generalized inverse matrices but in general the corresponding trajectory planning schemes show important limitations. motivated by these problems this paper studies the chaos revealed by the pseudoinverse based trajectory planning algorithms using the theory of fractional calculus.
inspec,train_1043,fractional motion control application to an xy cutting table. in path tracking design the dynamic of actuators must be taken into account in order to reduce overshoots appearing for small displacements. a new approach to path tracking using fractional differentiation is proposed with its application on a xy cutting table. it permits the generation of optimal movement reference input leading to a minimum path completion time taking into account both maximum velocity acceleration and torque and the bandwidth of the closed loop system. fractional differentiation is used here through a davidson cole filter. a methodology aiming at improving the accuracy especially on checkpoints is presented. the reference input obtained is compared with spline function. both are applied to an xy cutting table model and actuator outputs compared.
inspec,train_1044,analogue realizations of fractional order controllers. an approach to the design of analogue circuits implementing fractional order controllers is presented. the suggested approach is based on the use of continued fraction expansions in the case of negative coefficients in a continued fraction expansion the use of negative impedance converters is proposed. several possible methods for obtaining suitable rational approximations and continued fraction expansions are discussed. an example of realization of a fractional order i sup lambda controller is presented and illustrated by obtained measurements. the suggested approach can be used for the control of very fast processes where the use of digital controllers is difficult or impossible.
inspec,train_1045,using fractional order adjustment rules and fractional order reference models in model reference adaptive control. this paper investigates the use of fractional order calculus foc in conventional model reference adaptive control mrac systems. two modifications to the conventional mrac are presented i e the use of fractional order parameter adjustment rule and the employment of fractional order reference model. through examples benefits from the use of foc are illustrated together with some remarks for further research.
inspec,train_1046,a suggestion of fractional order controller for flexible spacecraft attitude control. a controller design method for flexible spacecraft attitude control is proposed. the system is first described by a partial differential equation with internal damping. then the frequency response is analyzed and the three basic characteristics of the flexible system namely average function lower bound and upper bound are defined. on this basis a fractional order controller is proposed which functions as phase stabilization control for lower frequency and smoothly enters to amplitude stabilization at higher frequency by proper amplitude attenuation. it is shown that the equivalent damping ratio increases in proportion to the square of frequency.
inspec,train_1047,dynamics and control of initialized fractional order systems. due to the importance of historical effects in fractional order systems this paper presents a general fractional order system and control theory that includes the time varying initialization response. previous studies have not properly accounted for these historical effects. the initialization response along with the forced response for fractional order systems is determined. the scalar fractional order impulse response is determined and is a generalization of the exponential function. stability properties of fractional order systems are presented in the complex w plane which is a transformation of the s plane. time responses are discussed with respect to pole positions in the complex w plane and frequency response behavior is included. a fractional order vector space representation which is a generalization of the state space concept is presented including the initialization response. control methods for vector representations of initialized fractional order systems are shown. finally the fractional order differintegral is generalized to continuous order distributions which have the possibility of including all fractional orders in a transfer function.
inspec,train_1048,parallel and distributed haskells. parallel and distributed languages specify computations on multiple processors and have a computation language to describe the algorithm i e what to compute and a coordination language to describe how to organise the computations across the processors. haskell has been used as the computation language for a wide variety of parallel and distributed languages and this paper is a comprehensive survey of implemented languages. it outlines parallel and distributed language concepts and classifies haskell extensions using them. similar example programs are used to illustrate and contrast the coordination languages and the comparison is facilitated by the common computation language. a lazy language is not an obvious choice for parallel or distributed computation and we address the question of why haskell is a common functional computation language.
inspec,train_1049,a typed representation for html and xml documents in haskell. we define a family of embedded domain specific languages for generating html and xml documents. each language is implemented as a combinator library in haskell. the generated html xml documents are guaranteed to be well formed. in addition each library can guarantee that the generated documents are valid xml documents to a certain extent for html only a weaker guarantee is possible. on top of the libraries haskell serves as a meta language to define parameterized documents to map structured documents to html xml to define conditional content or to define entire web sites. the combinator libraries support element transforming style a programming style that allows programs to have a visual appearance similar to html xml documents without modifying the syntax of haskell.
inspec,train_105,greenberger horne zeilinger paradoxes for many qubits. we construct greenberger horne zeilinger ghz contradictions for three or more parties sharing an entangled state the dimension of each subsystem being an even integer d. the simplest example that goes beyond the standard ghz paradox three qubits involves five ququats d 4. we then examine the criteria that a ghz paradox must satisfy in order to be genuinely m partite and d dimensional.
inspec,train_1050,secrets of the glasgow haskell compiler inliner. higher order languages such as haskell encourage the programmer to build abstractions by composing functions. a good compiler must inline many of these calls to recover an efficiently executable program. in principle inlining is dead simple just replace the call of a function by an instance of its body. but any compiler writer will tell you that inlining is a black art full of delicate compromises that work together to give good performance without unnecessary code bloat. the purpose of this paper is therefore to articulate the key lessons we learned from a full scale production inliner the one used in the glasgow haskell compiler. we focus mainly on the algorithmic aspects but we also provide some indicative measurements to substantiate the importance of various aspects of the inliner.
inspec,train_1051,faking it simulating dependent types in haskell. dependent types reflect the fact that validity of data is often a relative notion by allowing prior data to affect the types of subsequent data. not only does this make for a precise type system but also a highly generic one both the type and the program for each instance of a family of operations can be computed from the data which codes for that instance. recent experimental extensions to the haskell type class mechanism give us strong tools to relativize types to other types. we may simulate some aspects of dependent typing by making counterfeit type level copies of data with type constructors simulating data constructors and type classes simulating datatypes. this paper gives examples of the technique and discusses its potential.
inspec,train_1052,developing a high performance web server in concurrent haskell. server applications and in particular network based server applications place a unique combination of demands on a programming language lightweight concurrency high i o throughput and fault tolerance are all important. this paper describes a prototype web server written in concurrent haskell with extensions and presents two useful results firstly a conforming server could be written with minimal effort leading to an implementation in less than 1500 lines of code and secondly the naive implementation produced reasonable performance. furthermore making minor modifications to a few time critical components improved performance to a level acceptable for anything but the most heavily loaded web servers.
inspec,train_1053,a static semantics for haskell. this paper gives a static semantics for haskell 98 a non strict purely functional programming language. the semantics formally specifies nearly all the details of the haskell 98 type system including the resolution of overloading kind inference including defaulting and polymorphic recursion the only major omission being a proper treatment of ambiguous overloading and its resolution. overloading is translated into explicit dictionary passing as in all current implementations of haskell. the target language of this translation is a variant of the girard reynolds polymorphic lambda calculus featuring higher order polymorphism. and explicit type abstraction and application in the term language. translated programs can thus still be type checked although the implicit version of this system is impredicative. a surprising result of this formalization effort is that the monomorphism restriction when rendered in a system of inference rules compromises the principal type property.
inspec,train_1054,choice preferences without inferences subconscious priming of risk attitudes. we present a procedure for subconscious priming of risk attitudes. in experiment 1 we were reliably able to induce risk seeking or risk averse preferences across a range of decision scenarios using this priming procedure. in experiment 2 we showed that these priming effects can be reversed by drawing participants attention to the priming event. our results support claims that the formation of risk preferences can be based on preconscious processing as for example postulated by the affective primacy hypothesis rather than rely on deliberative mental operations as posited by several current models of judgment and decision making.
inspec,train_1055,a re examination of probability matching and rational choice. in a typical probability learning task participants are presented with a repeated choice between two response alternatives one of which has a higher payoff probability than the other. rational choice theory requires that participants should eventually allocate all their responses to the high payoff alternative but previous research has found that people fail to maximize their payoffs. instead it is commonly observed that people match their response probabilities to the payoff probabilities. we report three experiments on this choice anomaly using a simple probability learning task in which participants were provided with i large financial incentives ii meaningful and regular feedback and iii extensive training. in each experiment large proportions of participants adopted the optimal response strategy and all three of the factors mentioned above contributed to this. the results are supportive of rational choice theory.
inspec,train_1056,eliminating recency with self review the case of auditors  going concern judgments. this paper examines the use of self review to debias recency. recency is found in the going concern judgments of staff auditors but is successfully eliminated by the auditor s use of a simple self review technique that would be extremely easy to implement in audit practice. auditors who self review are also less inclined to make audit report choices that are inconsistent with their going concern judgments. these results are important because the judgments of staff auditors often determine the type and extent of documentation in audit workpapers and serve as preliminary inputs for senior auditors judgments and choices. if staff auditors judgments are affected by recency the impact of this bias may be impounded in the ultimate judgments and choices of senior auditors. since biased judgments can expose auditors to significant costs involving extended audit procedures legal liability and diminished reputation simple debiasing techniques that reduce this exposure are valuable. the paper also explores some future research needs and other important issues concerning judgment debiasing in applied professional settings.
inspec,train_1057,acceptance of a price discount the role of the semantic relatedness between purchases and the comparative price format. two studies are reported where people are asked to accept or not a price reduction on a target product. in the high low relative saving version the regular price of the target product is low high. in both versions the absolute value of the price reduction is the same as well as the total of regular prices of planned purchases. as first reported by tversky and kahneman 1981 findings show that the majority of people accept the price discount in the high relative saving version whereas the minority do it in the low one. in study 1 findings show that the previous preference reversal disappears when planned purchases are strongly related. also a previously unreported preference reversal is found. the majority of people accept the price discount when the products are weakly related whereas the minority accept when the products are strongly related. in study 2 findings show that the classic preference reversal disappears as a function of the comparative price format. also another previously unreported preference reversal is found. when the offered price reduction relates to a low priced product people are more inclined to accept it with a control than a minimal comparative price format. findings reported in studies 1 and 2 are interpreted in terms of mental accounting shifts.
inspec,train_1058,bigger is better the influence of physical size on aesthetic preference judgments. the hypothesis that the physical size of an object can influence aesthetic preferences was investigated. in a series of four experiments participants were presented with pairs of abstract stimuli and asked to indicate which member of each pair they preferred. a preference for larger stimuli was found on the majority of trials using various types of stimuli stimuli of various sizes and with both adult and 3 year old participants. this preference pattern was disrupted only when participants had both stimuli that provided a readily accessible alternative source of preference evoking information and sufficient attentional resources to make their preference judgments.
inspec,train_1059,mustering motivation to enact decisions how decision process characteristics influence goal realization. decision scientists tend to focus mainly on decision antecedents studying how people make decisions. action psychologists in contrast study post decision issues investigating how decisions once formed are maintained protected and enacted. through the research presented here we seek to bridge these two disciplines proposing that the process by which decisions are reached motivates subsequent pursuit and benefits eventual realization. we identify three characteristics of the decision process dp as having motivation mustering potential dp effort investment dp importance and dp confidence. through two field studies tracking participants decision processes pursuit and realization we find that after controlling for the influence of the motivational mechanisms of goal intention and implementation intention the three decision process characteristics significantly influence the successful enactment of the chosen decision directly. the theoretical and practical implications of these findings are considered and future research opportunities are identified.
inspec,train_106,quantum zeno subspaces. the quantum zeno effect is recast in terms of an adiabatic theorem when the measurement is described as the dynamical coupling to another quantum system that plays the role of apparatus. a few significant examples are proposed and their practical relevance discussed. we also focus on decoherence free subspaces.
inspec,train_1060,variety identification of wheat using mass spectrometry with neural networks and the influence of mass spectra processing prior to neural network analysis. the performance of matrix assisted laser desorption ionisation time of flight mass spectrometry with neural networks in wheat variety classification is further evaluated. two principal issues were studied a the number of varieties that could be classified correctly and b various means of preprocessing mass spectrometric data. the number of wheat varieties tested was increased from 10 to 30. the main pre processing method investigated was based on gaussian smoothing of the spectra but other methods based on normalisation procedures and multiplicative scatter correction of data were also used. with the final method it was possible to classify 30 wheat varieties with 87 correctly classified mass spectra and a correlation coefficient of 0 90.
inspec,train_1061,abacus efi and anti virus. the extensible firmware interface efi standard emerged as a logical step to provide flexibility and extensibility to boot sequence processes enabling the complete abstraction of a system s bios interface from the system s hardware. in doing so this provided the means of standardizing a boot up sequence extending device drivers and boot time applications portability to non pc at based architectures including embedded systems like internet appliances tv internet set top boxes and 64 bit itanium platforms.
inspec,train_1062,fidelity of quantum teleportation through noisy channels. we investigate quantum teleportation through noisy quantum channels by solving analytically and numerically a master equation in the lindblad form. we calculate the fidelity as a function of decoherence rates and angles of a state to be teleported. it is found that the average fidelity and the range of states to be accurately teleported depend on types of noises acting on quantum channels. if the quantum channels are subject to isotropic noise the average fidelity decays to 1 2 which is smaller than the best possible value of 2 3 obtained only by the classical communication. on the other hand if the noisy quantum channel is modeled by a single lindblad operator the average fidelity is always greater than 2 3.
inspec,train_1063,operations that do not disturb partially known quantum states. consider a situation in which a quantum system is secretly prepared in a state chosen from the known set of states. we present a principle that gives a definite distinction between the operations that preserve the states of the system and those that disturb the states. the principle is derived by alternately applying a fundamental property of classical signals and a fundamental property of quantum ones. the principle can be cast into a simple form by using a decomposition of the relevant hilbert space which is uniquely determined by the set of possible states. the decomposition implies the classification of the degrees of freedom of the system into three parts depending on how they store the information on the initially chosen state one storing it classically one storing it nonclassically and the other one storing no information. then the principle states that the nonclassical part is inaccessible and the classical part is read only if we are to preserve the state of the system. from this principle many types of no cloning no broadcasting and no imprinting conditions can easily be derived in general forms including mixed states. it also gives a unified view on how various schemes of quantum cryptography work. the principle helps one to derive optimum amount of resources bits qubits and ebits required in data compression or in quantum teleportation of mixed state ensembles.
inspec,train_1064,quantum controlled measurement device for quantum state discrimination. we propose a programmable quantum device that is able to perform a specific generalized measurement from a certain set of measurements depending on a quantum state of a program register. in particular we study a situation when the programmable measurement device serves for the unambiguous discrimination between nonorthogonal states. the particular pair of states that can be unambiguously discriminated is specified by the state of a program qubit. the probability of successful discrimination is not optimal for all admissible pairs. however for some subsets it can be very close to the optimal value.
inspec,train_1065,quantum universal variable length source coding. we construct an optimal quantum universal variable length code that achieves the admissible minimum rate i e our code is used for any probability distribution of quantum states. its probability of exceeding the admissible minimum rate exponentially goes to 0. our code is optimal in the sense of its exponent. in addition its average error asymptotically tends to 0.
inspec,train_1066,application of artificial intelligence to search ground state geometry of clusters. we introduce a global optimization procedure the neural assisted genetic algorithm naga. it combines the power of an artificial neural network ann with the versatility of the genetic algorithm. this method is suitable to solve optimization problems that depend on some kind of heuristics to limit the search space. if a reasonable amount of data is available the ann can understand the problem and provide the genetic algorithm with a selected population of elements that will speed up the search for the optimum solution. we tested the method in a search for the ground state geometry of silicon clusters. we trained the ann with information about the geometry and energetics of small silicon clusters. next the ann learned how to restrict the configurational space for larger silicon clusters. for si sub 10 and si sub 20  we noticed that the naga is at least three times faster than the pure genetic algorithm. as the size of the cluster increases it is expected that the gain in terms of time will increase as well.
inspec,train_1067,quantum information processing by nuclear magnetic resonance experimental implementation of half adder and subtractor operations using an oriented spin 7 2 system. the advantages of using quantum systems for performing many computational tasks have already been established. several quantum algorithms have been developed which exploit the inherent property of quantum systems such as superposition of states and entanglement for efficiently performing certain tasks. the experimental implementation has been achieved on many quantum systems of which nuclear magnetic resonance has shown the largest progress in terms of number of qubits. this paper describes the use of a spin 7 2 as a three qubit system and experimentally implements the half adder and subtractor operations. the required qubits are realized by partially orienting sup 133 cs nuclei in a liquid crystalline medium yielding a quadrupolar split well resolved septet. another feature of this paper is the proposal that labeling of quantum states of system can be suitably chosen to increase the efficiency of a computational task.
inspec,train_1068,quantum phase gate for photonic qubits using only beam splitters and postselection. we show that a beam splitter of reflectivity one third can be used to realize a quantum phase gate operation if only the outputs conserving the number of photons on each side are postselected.
inspec,train_1069,entangling atoms in bad cavities. we propose a method to produce entangled spin squeezed states of a large number of atoms inside an optical cavity. by illuminating the atoms with bichromatic light the coupling to the cavity induces pairwise exchange of excitations which entangles the atoms. unlike most proposals for entangling atoms by cavity qed our proposal does not require the strong coupling regime g sup 2  kappa gamma 1 where g is the atom cavity coupling strength kappa is the cavity decay rate and gamma is the decay rate of the atoms. in this work the important parameter is ng sup 2  kappa gamma where n is the number of atoms and our proposal permits the production of entanglement in bad cavities as long as they contain a large number of atoms.
inspec,train_107,deterministic single photon source for distributed quantum networking. a sequence of single photons is emitted on demand from a single three level atom strongly coupled to a high finesse optical cavity. the photons are generated by an adiabatically driven stimulated raman transition between two atomic ground states with the vacuum field of the cavity stimulating one branch of the transition and laser pulses deterministically driving the other branch. this process is unitary and therefore intrinsically reversible which is essential for quantum communication and networking and the photons should be appropriate for all optical quantum information processing.
inspec,train_1070,universal simulation of hamiltonian dynamics for quantum systems with finite dimensional state spaces. what interactions are sufficient to simulate arbitrary quantum dynamics in a composite quantum system. dodd et al phys. rev a 65 040301 r 2002 provided a partial solution to this problem in the form of an efficient algorithm to simulate any desired two body hamiltonian evolution using any fixed two body entangling n qubit hamiltonian and local unitaries. we extend this result to the case where the component systems are qudits that is have d dimensions. as a consequence we explain how universal quantum computation can be performed with any fixed two body entangling n qudit hamiltonian and local unitaries.
inspec,train_1071,dense coding in entangled states. we consider the dense coding of entangled qubits shared between two parties alice and bob. the efficiency of classical information gain through quantum entangled qubits is also considered for the case of pairwise entangled qubits and maximally entangled qubits. we conclude that using the pairwise entangled qubits can be more efficient when two parties communicate whereas using the maximally entangled qubits can be more efficient when the n parties communicate.
inspec,train_1072,quantum state information retrieval in a rydberg atom data register. we analyze a quantum search protocol to retrieve phase information from a rydberg atom data register using a subpicosecond half cycle electric field pulse. calculations show that the half cycle pulse can perform the phase retrieval only within a range of peak field values. by varying the phases of the constituent orbitals of the rydberg wave packet register we demonstrate coherent control of the phase retrieval process. by specially programming the phases of the orbitals comprising the initial wave packet we show that it is possible to use the search method as a way to synthesize single energy eigenstates.
inspec,train_1073,quantum retrodiction in open systems. quantum retrodiction involves finding the probabilities for various preparation events given a measurement event. this theory has been studied for some time but mainly as an interesting concept associated with time asymmetry in quantum mechanics. recent interest in quantum communications and cryptography however has provided retrodiction with a potential practical application. for this purpose quantum retrodiction in open systems should be more relevant than in closed systems isolated from the environment. in this paper we study retrodiction in open systems and develop a general master equation for the backward time evolution of the measured state which can be used for calculating preparation probabilities. we solve the master equation by way of example for the driven two level atom coupled to the electromagnetic field.
inspec,train_1074,inhibiting decoherence via ancilla processes. general conditions are derived for preventing the decoherence of a single two state quantum system qubit in a thermal bath. the employed auxiliary systems required for this purpose are merely assumed to be weak for the general condition while various examples such as extra qubits and extra classical fields are studied for applications in quantum information processing. the general condition is confirmed by well known approaches toward inhibiting decoherence. an approach to decoherence free quantum memories and quantum operations is presented by placing the qubit into the center of a sphere with extra qubits on its surface.
inspec,train_1075,numerical simulation of information recovery in quantum computers. decoherence is the main problem to be solved before quantum computers can be built. to control decoherence it is possible to use error correction methods but these methods are themselves noisy quantum computation processes. in this work we study the ability of steane s and shor s fault tolerant recovering methods as well as a modification of steane s ancilla network to correct errors in qubits. we test a way to measure correctly ancilla s fidelity for these methods and state the possibility of carrying out an effective error correction through a noisy quantum channel even using noisy error correction methods.
inspec,train_1076,delayed choice entanglement swapping with vacuum one photon quantum states. we report the experimental realization of a recently discovered quantum information protocol by peres implying an apparent nonlocal quantum mechanical retrodiction effect. the demonstration is carried out by a quantum optical method by which each singlet entangled state is physically implemented by a two dimensional subspace of fock states of a mode of the electromagnetic field specifically the space spanned by the vacuum and the one photon state along lines suggested recently by e knill et al nature london 409 46 2001 and by m duan et al ibid. 414 413 2001.
inspec,train_1077,quantum learning and universal quantum matching machine. suppose that three kinds of quantum systems are given in some unknown states f  sup x n  g sub 1  sup x k  and g sub 2  sup x k  and we want to decide which template state g sub 1  or g sub 2  each representing the feature of the pattern class c sub 1 or c sub 2  respectively is closest to the input feature state f. this is an extension of the pattern matching problem into the quantum domain. assuming that these states are known a priori to belong to a certain parametric family of pure qubit systems we derive two kinds of matching strategies. the first one is a semiclassical strategy that is obtained by the natural extension of conventional matching strategies and consists of a two stage procedure identification estimation of the unknown template states to design the classifier learning process to train the classifier and classification of the input system into the appropriate pattern class based on the estimated results. the other is a fully quantum strategy without any intermediate measurement which we might call as the universal quantum matching machine. we present the bayes optimal solutions for both strategies in the case of k 1 showing that there certainly exists a fully quantum matching procedure that is strictly superior to the straightforward semiclassical extension of the conventional matching strategy based on the learning process.
inspec,train_1078,action aggregation and defuzzification in mamdani type fuzzy systems. discusses the issues of action aggregation and defuzzification in mamdani type fuzzy systems. the paper highlights the shortcomings of defuzzification techniques associated with the customary interpretation of the sentence connective and by means of the set union operation. these include loss of smoothness of the output characteristic and inaccurate mapping of the fuzzy response. the most appropriate procedure for aggregating the outputs of different fuzzy rules and converting them into crisp signals is then suggested. the advantages in terms of increased transparency and mapping accuracy of the fuzzy response are demonstrated.
inspec,train_1079,a novel robot hand with embedded shape memory alloy actuators. describes the development of an active robot hand which allows smooth and lifelike motions for anthropomorphic grasping and fine manipulations. an active robot finger 10 mm in outer diameter with a shape memory alloy sma wire actuator embedded in the finger with a constant distance from the geometric centre of the finger was designed and fabricated. the practical specifications of the sma wire and the flexible rod were determined on the basis of a series of formulae. the active finger consists of two bending parts the sma actuators and a connecting part. the mechanical properties of the bending part are investigated. the control system on the basis of resistance feedback is also presented. finally a robot hand with three fingers was designed and the grasping experiment was carried out to demonstrate its performance.
inspec,train_108,exploiting randomness in quantum information processing. we consider how randomness can be made to play a useful role in quantum information processing in particular for decoherence control and the implementation of quantum algorithms. for a two level system in which the decoherence channel is non dissipative we show that decoherence suppression is possible if memory is present in the channel. random switching between two potentially harmful noise sources can then provide a source of stochastic control. such random switching can also be used in an advantageous way for the implementation of quantum algorithms.
inspec,train_1080,car caravan snaking. 2 active caravan braking. for part 1 see ibid p 707 22. founded on the review and results of part 1 part 2 contains a description of the virtual design of an active braking system for caravans or other types of trailer to suppress snaking vibrations while being simple from a practical viewpoint. the design process and the design itself are explained. the performance is examined by simulations and it is concluded that the system is effective robust and realizable with modest and available components.
inspec,train_1081,stability of w methods with applications to operator splitting and to geometric theory. we analyze the stability properties of w methods applied to the parabolic initial value problem u  au bu. we work in an abstract banach space setting assuming that a is the generator of an analytic semigroup and that b is relatively bounded with respect to a. since w methods treat the term with a implicitly whereas the term involving b is discretized in an explicit way they can be regarded as splitting methods. as an application of our stability results convergence for nonsmooth initial data is shown. moreover the layout of a geometric theory for discretizations of semilinear parabolic problems u  au f u is presented.
inspec,train_1082,numerical approximation of nonlinear bvps by means of bvms. boundary value methods bvms would seem to be suitable candidates for the solution of nonlinear boundary value problems bvps. they have been successfully used for solving linear bvps together with a mesh selection strategy based on the conditioning of the linear systems. our aim is to extend this approach so as to use them for the numerical approximation of nonlinear problems. for this reason we consider the quasi linearization technique that is an application of the newton method to the nonlinear differential equation. consequently each iteration requires the solution of a linear bvp. in order to guarantee the convergence to the solution of the continuous nonlinear problem it is necessary to determine how accurately the linear bvps must be solved. for this goal suitable stopping criteria on the residual and on the error for each linear bvp are given. numerical experiments on stiff problems give rather satisfactory results showing that the experimental code called tom that uses a class of bvms and the quasi linearization technique may be competitive with well known solvers for bvps.
inspec,train_1083,differential algebraic systems anew. it is proposed to figure out the leading term in differential algebraic systems more precisely. low index linear systems with those properly stated leading terms are considered in detail. in particular it is asked whether a numerical integration method applied to the original system reaches the inherent regular ode without conservation i e whether the discretization and the decoupling commute in some sense. in general one can not expect this commutativity so that additional difficulties like strong stepsize restrictions may arise. moreover abstract differential algebraic equations in infinite dimensional hilbert spaces are introduced and the index notion is generalized to those equations. in particular partial differential algebraic equations are considered in this abstract formulation.
inspec,train_1084,on quasi linear pdaes with convection applications indices numerical solution. for a class of partial differential algebraic equations pdaes of quasi linear type which include nonlinear terms of convection type a possibility to determine a time and spatial index is considered. as a typical example we investigate an application from plasma physics. especially we discuss the numerical solution of initial boundary value problems by means of a corresponding finite difference splitting procedure which is a modification of a well known fractional step method coupled with a matrix factorization. the convergence of the numerical solution towards the exact solution of the corresponding initial boundary value problem is investigated. some results of a numerical solution of the plasma pdae are given.
inspec,train_1085,a variable stepsize variable order multistep method for the integration of perturbed linear problems. g scheifele 1971 wrote the solution of a perturbed oscillator as an expansion in terms of a new set of functions which extends the monomials in the taylor series of the solution. recently p martin and j m ferrandiz 1997 constructed a multistep code based on the scheifele technique and it was generalized by d j lopez and p martin 1998 for perturbed linear problems. however the remarked codes are constant steplength methods and efficient integrators must be able to change the steplength. in this paper we extend the ideas of f t krogh 1974 from adams methods to the algorithm proposed by lopez and martin and we show the advantages of the new code in perturbed problems.
inspec,train_1086,some recent advances in validated methods for ivps for odes. compared to standard numerical methods for initial value problems ivps for ordinary differential equations odes validated methods often called interval methods for ivps for odes have two important advantages if they return a solution to a problem then 1 the problem is guaranteed to have a unique solution and 2 an enclosure of the true solution is produced. we present a brief overview of interval taylor series its methods for ivps for odes and discuss some recent advances in the theory of validated methods for ivps for odes. in particular we discuss an interval hermite obreschkoff iho scheme for computing rigorous bounds on the solution of an ivp for an ode the stability of its and iho methods and a new perspective on the wrapping effect where we interpret the problem of reducing the wrapping effect as one of finding a more stable scheme for advancing the solution.
inspec,train_1087,implementation of dimsims for stiff differential systems. some issues related to the implementation of diagonally implicit multistage integration methods for stiff differential systems are discussed. they include reliable estimation of the local discretization error construction of continuous interpolants solution of nonlinear systems of equations by simplified newton iterations choice of initial stepsize and order and step and order changing strategy. numerical results are presented which indicate that an experimental matlab code based on type 2 methods of order one two and three outperforms ode15s code from matlab ode suite on problems whose jacobian has eigenvalues which are close to the imaginary axis.
inspec,train_1088,parallel implicit predictor corrector methods. the performance of parallel codes for the solution of initial value problems is usually strongly sensitive to the dimension of the continuous problem. this is due to the overhead related to the exchange of information among the processors and motivates the problem of minimizing the amount of communications. according to this principle we define the so called parallel implicit predictor corrector methods and in this class we derive a stable l stable and numerically zero stable formulas. the latter property refers to the zero stability condition of a given formula when roundoff errors are introduced in its coefficients due to their representation in finite precision arithmetic. some numerical experiment show the potentiality of this approach.
inspec,train_1089,accuracy and stability of splitting with stabilizing corrections. this paper contains a convergence analysis for the method of stabilizing corrections which is an internally consistent splitting scheme for initial boundary value problems. to obtain more accuracy and a better treatment of explicit terms several extensions are regarded and analyzed. the relevance of the theoretical results is tested for convection diffusion reaction equations.
inspec,train_109,an entanglement measure based on the capacity of dense coding. an asymptotic entanglement measure for any bipartite states is derived in the light of the dense coding capacity optimized with respect to local quantum operations and classical communications. general properties and some examples with explicit forms of this entanglement measure are investigated.
inspec,train_1090,on the contractivity of implicit explicit linear multistep methods. this paper is concerned with the class of implicit explicit linear multistep methods for the numerical solution of initial value problems for ordinary differential equations which are composed of stiff and nonstiff parts. we study the contractivity of such methods with regard to linear autonomous systems of ordinary differential equations and a scaled euclidean norm. in addition we derive a strong stability result based on the stability regions of these methods.
inspec,train_1091,car caravan snaking. 1. the influence of pintle pin friction. a brief review of knowledge of car caravan snaking is carried out. against the background described a fairly detailed mathematical model of a contemporary car trailer system is constructed and a baseline set of parameter values is given. in reduced form the model is shown to give results in accordance with literature. the properties of the baseline combination are explored using both linear and non linear versions of the model. the influences of damping at the pintle joint and of several other design parameters on the stability of the linear system in the neighbourhood of the critical snaking speed are calculated and discussed. coulomb friction damping at the pintle pin is then included and simulations are used to indicate the consequent amplitude dependent behaviour. the friction damping especially when its level has to be chosen by the user is shown to give dangerous characteristics despite having some capacity for stabilization of the snaking motions. it is concluded that pintle pin friction damping does not represent a satisfactory solution to the snaking problem. the paper sets the scene for the development of an improved solution.
inspec,train_1092,ride quality evaluation of an actively controlled stretcher for an ambulance. this study considers the subjective evaluation of ride quality during ambulance transportation using an actively controlled stretcher acs. the ride quality of a conventional stretcher and an assistant driver s seat is also compared. braking during ambulance transportation generates negative foot to head acceleration in patients and causes blood pressure to rise in the patient s head. the acs absorbs the foot to head acceleration by changing the angle of the stretcher thus reducing the blood pressure variation. however the ride quality of the acs should be investigated further because the movement of the acs may cause motion sickness and nausea. experiments of ambulance transportation including rapid acceleration and deceleration are performed to evaluate the effect of differences in posture of the transported subject on the ride quality the semantic differential method and factor analysis are used in the investigations. subjects are transported using a conventional stretcher with head forward a conventional stretcher with head backward the acs and an assistant driver s seat for comparison with transportation using a stretcher. experimental results show that the acs gives the most comfortable transportation when using a stretcher. moreover the reduction of the negative foot to head acceleration at frequencies below 0 2 hz and the small variation of the foot to head acceleration result in more comfortable transportation. conventional transportation with the head forward causes the worst transportation although the characteristics of the vibration of the conventional stretcher seem to be superior to that of the acs.
inspec,train_1093,a fuzzy logic approach to accommodate thermal stress and improve the start up phase in combined cycle power plants. use of combined cycle power generation plant has increased dramatically over the last decade. a supervisory control approach based on a dynamic model is developed which makes use of proportional integral derivative pid fuzzy logic and fuzzy pid schemes. the aim is to minimize the steam turbine plant start up time without violating maximum thermal stress limits. an existing start up schedule provides the benchmark by which the performance of candidate controllers is assessed. improvements regarding possible reduced start up times and satisfaction of maximum thermal stress restrictions have been realized using the proposed control scheme.
inspec,train_1094,efficient allocation of knowledge in distributed business structures. accelerated business processes demand new concepts and realizations of information systems and knowledge databases. this paper presents the concept of the collaborative information space cis which supplies the necessary tools to transform individual knowledge into collective useful information. the creation of information objects in the cis allows an efficient allocation of information in all business process steps at any time. furthermore the specific availability of heterogeneous distributed data is realized by a web based user interface which enables effective search by a multidimensionally hierarchical composition.
inspec,train_1095,development of a real time monitoring system. this paper describes a pattern recognition pr technique which uses learning vector quantization lvq. this method is adapted for practical application to solve problems in the area of condition monitoring and fault diagnosis where a number of fault signatures are involved. in these situations the aim is health monitoring including identification of deterioration of the healthy condition and identification of causes of the failure in real time. for this reason a fault database is developed which contains the collected information about various states of operation of the system in the form of pattern vectors. the task of the real time monitoring system is to correlate patterns of unknown faults with the known fault signatures in the fault database. this will determine cause of failure and degree of deterioration of the system under test. the problem of fault diagnosis may involve a large number of patterns and large sampling time which affects the learning stage of neural networks. the study here also aims to find a fast learning model of neural networks for instances when a high number of patterns and numerous processing elements are involved. it begins searching for an appropriate solution. the study is extended to the enforcement learning models and considers lvq as a network emerged from the competitive learning model through enforcement training. finally tests show an accuracy of 92 3 per cent in the fault diagnostic capability of the technique.
inspec,train_1096,evaluating alternative manufacturing control strategies using a benchmark system. this paper describes an investigation of the effects of dynamic job routing and job sequencing decisions on the performance of a distributed control system and its adaptability against disturbances. this experimental work was carried out to compare the performance of alternative control strategies in various manufacturing environments and to investigate the relationship between the control and controlled systems. the experimental test bed presented in this paper consists of an agent based control system implemented in c and a discrete event simulation model. using this test bed various control strategies were tested on a benchmark manufacturing system by varying production volumes to model the production system with looser tighter schedules and disturbance frequencies. it was found that hybrid strategies that combine reactive agent mechanisms and allocation strategies such as the contract net with appropriate job sequencing heuristics provide the best performance particularly when job congestion increases on a shop floor.
inspec,train_1097,a study on an automatic seam tracking system by using an electromagnetic sensor for sheet metal arc welding of butt joints. many sensors such as the vision sensor and the laser displacement sensor have been developed to automate the arc welding process. however these sensors have some problems due to the effects of arc light fumes and spatter. an electromagnetic sensor which utilizes the generation of an eddy current was developed for detecting the weld line of a butt joint in which the root gap size was zero. an automatic seam tracking system designed for sheet metal arc welding was constructed with a sensor. through experiments it was revealed that the system had an excellent seam tracking accuracy of the order of or 0 2 mm.
inspec,train_1098,instability phenomena in the gas metal arc welding self regulation process. arc instability is a very important determinant of weld quality. the instability behaviour of the gas metal arc welding gmaw process is characterized by strong oscillations in arc length and current. in the paper a model of the gmaw process is developed using an exact arc voltage characteristic. this model is used to study stability of the self regulation process and to develop a simulation program that helps to understand the transient or dynamic nature of the gmaw process and relationships among current electrode extension and contact tube work distance. the process is shown to exhibit instabilities at both long electrode extension and normal extension. results obtained from simulation runs of the model were also experimentally confirmed by the present author as reported in this study. in order to explain the concept of the instability phenomena the metal transfer mode and the arc voltage current characteristic were examined. based on this examination the conclusion of this study is that their combined effects lead to the oscillations in arc current and length.
inspec,train_1099,webcad a computer aided design tool constrained with explicit design for manufacturability rules for computer numerical control milling. a key element in the overall efficiency of a manufacturing enterprise is the compatibility between the features that have been created in a newly designed part and the capabilities of the downstream manufacturing processes. with this in mind a process aware computer aided design cad system called webcad has been developed. the system restricts the freedom of the designer in such a way that the designed parts can be manufactured on a three axis computer numerical control milling machine. this paper discusses the vision of webcad and explains the rationale for its development in comparison with commercial cad cam computer aided design manufacture systems. the paper then goes on to describe the implementation issues that enforce the manufacturability rules. finally certain design tools are described that aid a user during the design process. some examples are given of the parts designed and manufactured with webcad.
inspec,train_11,does social capital determine innovation. to what extent. this paper deals with two questions does social capital determine innovation in manufacturing firms. if it is the case to what extent. to deal with these questions we review the literature on innovation in order to see how social capital came to be added to the other forms of capital as an explanatory variable of innovation. in doing so we have been led to follow the dominating view of the literature on social capital and innovation which claims that social capital can not be captured through a single indicator but that it actually takes many different forms that must be accounted for. therefore to the traditional explanatory variables of innovation we have added five forms of structural social capital business network assets information network assets research network assets participation assets and relational assets and one form of cognitive social capital reciprocal trust. in a context where empirical investigations regarding the relations between social capital and innovation are still scanty this paper makes contributions to the advancement of knowledge in providing new evidence regarding the impact and the extent of social capital on innovation at the two decisionmaking stages considered in this study.
inspec,train_110,a switching synchronization scheme for a class of chaotic systems. in this letter we propose an observer based synchronization scheme for a class of chaotic systems. this class of systems are given by piecewise linear dynamics. by using some properties of such systems we give a procedure to construct the gain of the observer. we prove various stability results and comment on the robustness of the proposed scheme. we also present some simulation results.
inspec,train_1100,evaluation of existing and new feature recognition algorithms. 2. experimental results. for pt 1 see ibid p 839 851. this is the second of two papers investigating the performance of general purpose feature detection techniques. the first paper describes the development of a methodology to synthesize possible general feature detection face sets. six algorithms resulting from the synthesis have been designed and implemented on a sun workstation in c using acis as the geometric modelling system. in this paper extensive tests and comparative analysis are conducted on the feature detection algorithms using carefully selected components from the public domain mostly from the national design repository. the results show that the new and enhanced algorithms identify face sets that previously published algorithms can not detect. the tests also show that each algorithm can detect among other types a certain type of feature that is unique to it. hence most of the algorithms discussed in this paper would have to be combined to obtain complete coverage.
inspec,train_1101,evaluation of existing and new feature recognition algorithms. 1. theory and implementation. this is the first of two papers evaluating the performance of general purpose feature detection techniques for geometric models. in this paper six different methods are described to identify sets of faces that bound depression and protrusion faces. each algorithm has been implemented and tested on eight components from the national design repository. the algorithms studied include previously published general purpose feature detection algorithms such as the single face inner loop and concavity techniques. others are improvements to existing algorithms such as extensions of the two dimensional convex hull method to handle curved faces as well as protrusions. lastly new algorithms based on the three dimensional convex hull minimum concave visible and multiple face inner loop face sets are described.
inspec,train_1102,design and implementation of a reusable and extensible hl7 encoding decoding framework. the health level seven hl7 an international standard for electronic data exchange in all health care environments enables disparate computer applications to exchange key sets of clinical and administrative information. above all it defines the standard hl7 message formats prescribed by the standard encoding rules. in this paper we propose a flexible reusable and extensible hl7 encoding and decoding framework using a message object model mom and message definition repository mdr. the mom provides an abstract hl7 message form represented by a group of objects and their relationships. it reflects logical relationships among the standard hl7 message elements such as segments fields and components while enforcing the key structural constraints imposed by the standard. since the mom completely eliminates the dependency of the hl7 encoder and decoder on platform specific data formats it makes it possible to build the encoder and decoder as reusable standalone software components enabling the interconnection of arbitrary heterogeneous hospital information systems his with little effort. moreover the mdr an external database of key definitions for hl7 messages helps make the encoder and decoder as resilient as possible to future modifications of the standard hl7 message formats. it is also used by the encoder and decoder to perform a well formedness check for their respective inputs i e hl7 message objects expressed in the mom and encoded hl7 message strings. although we implemented a prototype version of the encoder and decoder using java they can be easily packaged and delivered as standalone components using the standard component frameworks.
inspec,train_1103,new age computing autonomic computing. autonomic computing ac sometimes called self managed computing is the name chosen by ibm to describe the company s new initiative aimed at making computing more reliable and problem free. it is a response to a growing realization that the problem today with computers is not that they need more speed or have too little memory but that they crash all too often. this article reviews current initiatives being carried out in the ac field by the it industry followed by key challenges which require to be addressed in its development and implementation.
inspec,train_1104,a 3 stage pipelined architecture for multi view images decoder. in this paper we proposed the architecture of the decoder which implements the multi view images decoding algorithm. the study of the hardware structure of the multi view image processing has not been accomplished. the proposed multi view images decoder operates in a three stage pipelined manner and extracts the depth of the pixels of the decoded image every clock. the multi view images decoder consists of three modules node selector which transfers the value of the nodes repeatedly and depth extractor which extracts the depth of each pixel from the four values of the nodes and affine transformer which generates the projecting position on the image plane from the values of the pixels and the specified viewpoint. the proposed architecture is designed and simulated by the max plusii design tool and the operating frequency is 30 mhz. the image can be constructed in a real time by the decoder with the proposed architecture.
inspec,train_1105,fuzzy business halden reactor project. the halden reactor project has developed two systems to investigate how signal validation and thermal performance monitoring techniques can be improved. peano is an online calibration monitoring system that makes use of artificial intelligence techniques. the system has been tested in cooperation with epri and edan engineering using real data from a us pwr plant. these tests showed that peano could reliably assess the performance of the process instrumentation at different plant conditions. real cases of zero and span drifts were successfully detected by the system. tempo is a system for thermal performance monitoring and optimisation which relies on plant wide first principle models. the system has been installed on a swedish bwr plant. results obtained show an overall rms deviation from measured values of a few tenths of a percent and giving goodness of fits in the order of 95. the high accuracy demonstrated is a good basis for detecting possible faults and efficiency losses in steam turbine cycles.
inspec,train_1106,virtual projects at halden reactor project. the halden man machine systems mms programme for 2002 is intended to address issues related to human factors control room design computer based support system areas and system safety and reliability. the halden mms programme is intended to address extensive experimental work in the human factors control room design and computer based support system areas. the work is based on experiments and demonstrations carried out in the experimental facility hammlab. pilot versions of several operator aids are adopted and integrated to the hammlab simulators and demonstrated in a full dynamic setting. the halden virtual reality laboratory has recently become an integral and important part of the programme.
inspec,train_1107,a knowledge navigation system for dimensional metrology. geometric dimensioning and tolerancing gd t is a method to specify the dimensions and form of a part so that it will meet its design intent. gd t is difficult to master for two main reasons. first it is based on complex 3d geometric entities and relationships. second the geometry is associated with a large diverse knowledge base of dimensional metrology with many interconnections. this paper describes an approach to create a dimensional metrology knowledge base that is organized around a set of key concepts and to represent those concepts as virtual objects that can be navigated with interactive computer visualization techniques to access the associated knowledge. the approach can enable several applications. first is the application to convey the definition and meaning of gd t over a broad range of tolerance types. second is the application to provide a visualization of dimensional metrology knowledge within a control hierarchy of the inspection process. third is the application to show the coverage of interoperability standards to enable industry to make decisions on standards development and harmonization efforts. a prototype system has been implemented to demonstrate the principles involved in the approach.
inspec,train_1108,the visible cement data set. with advances in x ray microtomography it is now possible to obtain three dimensional representations of a material s microstructure with a voxel size of less than one micrometer. the visible cement data set represents a collection of 3 d data sets obtained using the european synchrotron radiation facility in grenoble france in september 2000. most of the images obtained are for hydrating portland cement pastes with a few data sets representing hydrating plaster of paris and a common building brick. all of these data sets are being made available on the visible cement data set website at http visiblecement nist gov. the website includes the raw 3 d datafiles a description of the material imaged for each data set example two dimensional images and visualizations for each data set and a collection of c language computer programs that will be of use in processing and analyzing the 3 d microstructural images. this paper provides the details of the experiments performed at the esrf the analysis procedures utilized in obtaining the data set files and a few representative example images for each of the three materials investigated.
inspec,train_1109,the existence condition of gamma acyclic database schemes with mvds constraints. it is very important to use database technology for a large scale system such as erp and mis. a good database design may improve the performance of the system. some research shows that a gamma acyclic database scheme has many good properties e g each connected join expression is monotonous which helps to improve query performance of the database system. thus what conditions are needed to generate a gamma acyclic database scheme for a given relational scheme. in this paper the sufficient and necessary condition of the existence of gamma acyclic join lossless and dependencies preserved database schemes meeting 4nf is given.
inspec,train_111,modification for synchronization of rossler and chen chaotic systems. active control is an effective method for making two identical rossler and chen systems be synchronized. however this method works only for a certain class of chaotic systems with known parameters both in drive systems and response systems. modification based on lyapunov stability theory is proposed in order to overcome this limitation. an adaptive synchronization controller which can make the states of two identical rossler and chen systems globally asymptotically synchronized in the presence of system s unknown constant parameters is derived. especially when some unknown parameters are positive we can make the controller more simple besides the controller is independent of those positive uncertain parameters. at last when the condition that arbitrary unknown parameters in two systems are identical constants is cancelled we demonstrate that it is possible to synchronize two chaotic systems. all results are proved using a well known lyapunov stability theorem. numerical simulations are given to validate the proposed synchronization approach.
inspec,train_1110,a hybrid model for smoke simulation. a smoke simulation approach based on the integration of traditional particle systems and density functions is presented in this paper. by attaching a density function to each particle as its attribute the diffusion of smoke can be described by the variation of particles density functions along with the effect on airflow by controlling particles movement and fragmentation. in addition a continuous density field for realistic rendering can be generated quickly through the look up tables of particle s density functions. compared with traditional particle systems this approach can describe smoke diffusion and provide a continuous density field for realistic rendering with much less computation. a quick rendering scheme is also presented in this paper as a useful preview tool for tuning appropriate parameters in the smoke model.
inspec,train_1111,the contiguity in r m. an r e degree c is contiguous if deg sub wtt a deg sub wtt b for any r e sets a b in c. in this paper we generalize the notation of contiguity to the structure r m the upper semilattice of the r e degree set r modulo the cappable r e degree set m. an element c in r m is contiguous if deg sub wtt a deg sub wtt b for any r e sets a b such that deg sub t a deg sub t b in c. it is proved in this paper that every nonzero element in r m is not contiguous i e for every element c in r m if c not o then there exist at least two r e sets a b such that deg sub t a deg sub t b in c and deg sub wtt a not deg sub wtt b.
inspec,train_1112,blending parametric patches with subdivision surfaces. in this paper the problem of blending parametric surfaces using subdivision patches is discussed. a new approach named removing boundary is presented to generate piecewise smooth subdivision surfaces through discarding the outmost quadrilaterals of the open meshes derived by each subdivision step. then the approach is employed both to blend parametric bicubic b spline surfaces and to fill n sided holes. it is easy to produce piecewise smooth subdivision surfaces with both convex and concave corners on the boundary and limit surfaces are guaranteed to be c sup 2 continuous on the boundaries except for a few singular points by the removing boundary approach. thus the blending method is very efficient and the blending surface generated is of good effect.
inspec,train_1113,word spotting based on a posterior measure of keyword confidence. in this paper an approach of keyword confidence estimation is developed that well combines acoustic layer scores and syllable based statistical language model lm scores. an a posteriori ap confidence measure and its forward backward calculating algorithm are deduced. a zero false alarm zfa assumption is proposed for evaluating relative confidence measures by word spotting task. in a word spotting experiment with a vocabulary of 240 keywords the keyword accuracy under the ap measure is above 94  which well approaches its theoretical upper limit. in addition a syllable lattice hidden markov model slhmm is formulated and a unified view of confidence estimation word spotting optimal path search and n best syllable re scoring is presented. the proposed ap measure can be easily applied to various speech recognition systems as well.
inspec,train_1114,a new algebraic modelling approach to distributed problem solving in mas. this paper is devoted to a new algebraic modelling approach to distributed problem solving in multi agent systems mas which is featured by a unified framework for describing and treating social behaviors social dynamics and social intelligence. a conceptual architecture of algebraic modelling is presented. the algebraic modelling of typical social behaviors social situation and social dynamics is discussed in the context of distributed problem solving in mas. the comparison and simulation on distributed task allocations and resource assignments in mas show more advantages of the algebraic approach than other conventional methods.
inspec,train_1115,four point wavelets and their applications. multiresolution analysis mra and wavelets provide useful and efficient tools for representing functions at multiple levels of details. wavelet representations have been used in a broad range of applications including image compression physical simulation and numerical analysis. in this paper the authors construct a new class of wavelets called four point wavelets based on an interpolatory four point subdivision scheme. they are of local support symmetric and stable. the analysis and synthesis algorithms have linear time complexity. depending on different weight parameters w the scaling functions and wavelets generated by the four point subdivision scheme are of different degrees of smoothness. therefore the user can select better wavelets relevant to the practice among the classes of wavelets. the authors apply the four point wavelets in signal compression. the results show that the four point wavelets behave much better than b spline wavelets in many situations.
inspec,train_1116,an interlingua based chinese english mt system. chinese english machine translation is a significant and challenging problem in information processing. the paper presents an interlingua based chinese english natural language translation system icent. it introduces the realization mechanism of chinese language analysis which contains syntactic parsing and semantic analyzing and gives the design of interlingua in details. experimental results and system evaluation are given. the result is satisfying.
inspec,train_1117,an attack finding algorithm for security protocols. this paper proposes an automatic attack construction algorithm in order to find potential attacks on security protocols. it is based on a dynamic strand space model which enhances the original strand space model by introducing active nodes on strands so as to characterize the dynamic procedure of protocol execution. with exact causal dependency relations between messages considered in the model this algorithm can avoid state space explosion caused by asynchronous composition. in order to get a finite state space a new method called strand added on demand is exploited which extends a bundle in an incremental manner without requiring explicit configuration of protocol execution parameters. a finer granularity model of term structure is also introduced in which subterms are divided into check subterms and data subterms. moreover data subterms can be further classified based on the compatible data subterm relation to obtain automatically the finite set of valid acceptable terms for an honest principal. in this algorithm terms core is designed to represent the intruder s knowledge compactly and forward search technology is used to simulate attack patterns easily. using this algorithm a new attack on the dolve yao protocol can be found which is even more harmful because the secret is revealed before the session terminates.
inspec,train_1118,run time data flow analysis. parallelizing compilers have made great progress in recent years. however there still remains a gap between the current ability of parallelizing compilers and their final goals. in order to achieve the maximum parallelism run time techniques were used in parallelizing compilers during last few years. first this paper presents a basic run time privatization method. the definition of run time dead code is given and its side effect is discussed. to eliminate the imprecision caused by the run time dead code backward data flow information must be used. proteus test which can use backward information in run time is then presented to exploit more dynamic parallelism. also a variation of proteus test the advanced proteus test is offered to achieve partial parallelism. proteus test was implemented on the parallelizing compiler aft. in the end of this paper the program fpppp f of spec95fp benchmark is taken as an example to show the effectiveness of proteus test.
inspec,train_1119,a component based software configuration management model and its supporting system. software configuration management scm is an important key technology in software development. component based software development cbsd is an emerging paradigm in software development. however to apply cbsd effectively in real world practice supporting scm in cbsd needs to be further investigated. in this paper the objects that need to be managed in cbsd is analyzed and a component based scm model is presented. in this model components as the integral logical constituents in a system are managed as the basic configuration items in scm and the relationships between among components are defined and maintained. based on this model a configuration management system is implemented.
inspec,train_112,revisiting hardy s paradox counterfactual statements real measurements entanglement and weak values. hardy s 1992 paradox is revisited. usually the paradox is dismissed on grounds of counterfactuality i e because the paradoxical effects appear only when one considers results of experiments which do not actually take place. we suggest a new set of measurements in connection with hardy s scheme and show that when they are actually performed they yield strange and surprising outcomes. more generally we claim that counterfactual paradoxes point to a deeper structure inherent to quantum mechanics.
inspec,train_1120,an effective feedback control mechanism for diffserv architecture. as a scalable qos quality of service architecture diffserv differentiated service mainly consists of two components traffic conditioning at the edge of the diffserv domain and simple packet forwarding inside the diffserv domain. diffserv has many advantages such as flexibility scalability and simplicity. but when providing af assured forwarding services diffserv has some problems such as unfairness among aggregated flows or among micro flows belonging to an aggregated flow. in this paper a feedback mechanism for af aggregated flows is proposed to solve this problem. simulation results show that this mechanism does improve the performance of diffserv. first it can improve the fairness among aggregated flows and make diffserv more friendly toward tcp transmission control protocol flows. second it can decrease the buffer requirements at the congested router and thus obtain lower delay and packet loss rate. third it also keeps almost the same link utility as in normal diffserv. finally it is simple and easy to be implemented.
inspec,train_1121,optimal bandwidth utilization of all optical ring with a converter of degree 4. in many models of all optical routing a set of communication paths in a network is given and a wavelength is to be assigned to each path so that paths sharing an edge receive different wavelengths. the goal is to assign as few wavelengths as possible in order to use the optical bandwidth efficiently. if a node of a network contains a wavelength converter any path that passes through this node may change its wavelength. having converters at some of the nodes can reduce the number of wavelengths required for routing. this paper presents a wavelength converter with degree 4 and gives a routing algorithm which shows that any routing with load l can be realized with l wavelengths when a node of an all optical ring hosts such a wavelength converter. it is also proved that 4 is the minimum degree of the converter to reach the full utilization of the available wavelengths if only one node of an all optical ring hosts a converter.
inspec,train_1122,hybrid broadcast for the video on demand service. multicast offers an efficient means of distributing video contents programs to multiple clients by batching their requests and then having them share a server s video stream. batching customers requests is either client initiated or server initiated. most advanced client initiated video multicasts are implemented by patching. periodic broadcast a typical server initiated approach can be entirety based or segment based. this paper focuses on the performance of the vod service for popular videos. first we analyze the limitation of conventional patching when the customer request rate is high. then by combining the advantages of each of the two broadcast schemes we propose a hybrid broadcast scheme for popular videos which not only lowers the service latency but also improves clients interactivity by using an active buffering technique. this is shown to be a good compromise for both lowering service latency and improving the vcr like interactivity.
inspec,train_1123,a transactional asynchronous replication scheme for mobile database systems. in mobile database systems mobility of users has a significant impact on data replication. as a result the various replica control protocols that exist today in traditional distributed and multidatabase environments are no longer suitable. to solve this problem a new mobile database replication scheme the transaction level result set propagation tlrsp model is put forward in this paper. the conflict detection and resolution strategy based on tlrsp is discussed in detail and the implementation algorithm is proposed. in order to compare the performance of the tlrsp model with that of other mobile replication schemes we have developed a detailed simulation model. experimental results show that the tlrsp model provides an efficient support for replicated mobile database systems by reducing reprocessing overhead and maintaining database consistency.
inspec,train_1124,data extraction from the web based on pre defined schema. with the development of the internet the world wide web has become an invaluable information source for most organizations. however most documents available from the web are in html form which is originally designed for document formatting with little consideration of its contents. effectively extracting data from such documents remains a nontrivial task. in this paper we present a schema guided approach to extracting data from html pages. under the approach the user defines a schema specifying what to be extracted and provides sample mappings between the schema and the html page. the system will induce the mapping rules and generate a wrapper that takes the html page as input and produces the required data in the form of xml conforming to the user defined schema. a prototype system implementing the approach has been developed. the preliminary experiments indicate that the proposed semi automatic approach is not only easy to use but also able to produce a wrapper that extracts required data from inputted pages with high accuracy.
inspec,train_1125,structure of weakly invertible semi input memory finite automata with delay 1. semi input memory finite automata a kind of finite automata introduced by the first author of this paper for studying error propagation are a generalization of input memory finite automata by appending an autonomous finite automaton component. in this paper we give a characterization of the structure of weakly invertible semi input memory finite automata with delay 1 in which the state graph of each autonomous finite automaton is a cycle. from a result on mutual invertibility of finite automata obtained by the authors recently it leads to a characterization of the structure of feedforward inverse finite automata with delay 1.
inspec,train_1126,a note on an axiomatization of the core of market games. as shown by peleg 1993 the core of market games is characterized by nonemptiness individual rationality superadditivity the weak reduced game property the converse reduced game property and weak symmetry. it was not known whether weak symmetry was logically independent. with the help of a certain transitive 4 person tu game it is shown that weak symmetry is redundant in this result. hence the core on market games is axiomatized by the remaining five properties if the universe of players contains at least four members.
inspec,train_1127,repeated games with lack of information on one side the dual differential approach. we introduce the dual differential game of a repeated game with lack of information on one side as the natural continuous time version of the dual game introduced by de meyer 1996. a traditional way to study the value of differential games is through discrete time approximations. here we follow the opposite approach we identify the limit value of a repeated game in discrete time as the value of a differential game. namely we use the recursive structure for the finitely repeated version of the dual game to construct a differential game for which the upper values of the uniform discretization satisfy precisely the same property. the value of the dual differential game exists and is the unique viscosity solution of a first order derivative equation with a limit condition. we identify the solution by translating viscosity properties in the primal.
inspec,train_1128,the semi algebraic theory of stochastic games. the asymptotic behavior of the min max value of a finite state zero sum discounted stochastic game as the discount rate approaches 0 has been studied in the past using the theory of real closed fields. we use the theory of semi algebraic sets and mappings to prove some asymptotic properties of the min max value which hold uniformly for all stochastic games in which the number of states and players actions are predetermined to some fixed values. as a corollary we prove a uniform polynomial convergence rate of the value of the n stage game to the value of the nondiscount game over a bounded set of payoffs.
inspec,train_1129,computing stationary nash equilibria of undiscounted single controller stochastic games. given a two person nonzero sum stochastic game where the second player controls the transitions we formulate a linear complementarity problem lcp q m whose solution gives a nash equilibrium pair of stationary strategies under the limiting average payoff criterion. the matrix m constructed is of the copositive class so that lemke s algorithm will process it. we will also do the same for a special class of n person stochastic games called polymatrix stochastic games.
inspec,train_113,quantum limit on computational time and speed. we investigate if physical laws can impose limits on computational time and speed of a quantum computer built from elementary particles. we show that the product of the speed and the running time of a quantum computer is limited by the type of fundamental interactions present inside the system. this will help us to decide as to what type of interaction should be allowed in building quantum computers in achieving the desired speed.
inspec,train_1130,node capacitated ring routing. we consider the node capacitated routing problem in an undirected ring network along with its fractional relaxation the node capacitated multicommodity flow problem. for the feasibility problem farkas lemma provides a characterization for general undirected graphs asserting roughly that there exists such a flow if and only if the so called distance inequality holds for every choice of distance functions arising from nonnegative node weights. for rings this straightforward result will be improved in two ways. we prove that independent of the integrality of node capacities it suffices to require the distance inequality only for distances arising from 0 1 2 valued node weights a requirement that will be called the double cut condition. moreover for integer valued node capacities the double cut condition implies the existence of a half integral multicommodity flow. in this case there is even an integer valued multicommodity flow that violates each node capacity by at most one. our approach gives rise to a combinatorial strongly polynomial algorithm to compute either a violating double cut or a node capacitated multicommodity flow. a relation of the problem to its edge capacitated counterpart will also be explained.
inspec,train_1131,a min max theorem on feedback vertex sets. we establish a necessary and sufficient condition for the linear system x hx or e x or 0 associated with a bipartite tournament to be totally dual integral where h is the cycle vertex incidence matrix and e is the all one vector. the consequence is a min max relation on packing and covering cycles together with strongly polynomial time algorithms for the feedback vertex set problem and the cycle packing problem on the corresponding bipartite tournaments. in addition we show that the feedback vertex set problem on general bipartite tournaments is np complete and approximable within 3 5 based on the min max theorem.
inspec,train_1132,semidefinite programming vs lp relaxations for polynomial programming. we consider the global minimization of a multivariate polynomial on a semi algebraic set omega defined with polynomial inequalities. we then compare two hierarchies of relaxations namely lp relaxations based on products of the original constraints in the spirit of the rlt procedure of sherali and adams 1990 and recent semidefinite programming sdp relaxations introduced by the author. the comparison is analyzed in light of recent results in real algebraic geometry on various representations of polynomials positive on a compact semi algebraic set.
inspec,train_1133,an analytic center cutting plane method for semidefinite feasibility problems. semidefinite feasibility problems arise in many areas of operations research. the abstract form of these problems can be described as finding a point in a nonempty bounded convex body gamma in the cone of symmetric positive semidefinite matrices. assume that gamma is defined by an oracle which for any given m m symmetric positive semidefinite matrix gamma either confirms that y epsilon gamma or returns a cut i e a symmetric matrix a such that gamma is in the half space y a. y or a. y. we study an analytic center cutting plane algorithm for this problem. at each iteration the algorithm computes an approximate analytic center of a working set defined by the cutting plane system generated in the previous iterations. if this approximate analytic center is a solution then the algorithm terminates otherwise the new cutting plane returned by the oracle is added into the system. as the number of iterations increases the working set shrinks and the algorithm eventually finds a solution to the problem. all iterates generated by the algorithm are positive definite matrices. the algorithm has a worst case complexity of o m sup 3  epsilon sup 2 on the total number of cuts to be used where epsilon is the maximum radius of a ball contained by gamma.
inspec,train_1134,relationship between strong monotonicity property p sub 2  property and the gus property in semidefinite linear complementarity problems. in a recent paper on semidefinite linear complementarity problems gowda and song 2000 introduced and studied the p property p sub 2  property gus property and strong monotonicity property for linear transformation l s sup n to s sup n  where s sup n is the space of all symmetric and real n n matrices. in an attempt to characterize the p sub 2  property they raised the following two questions i does the strong monotonicity imply the p sub 2  property. ii does the gus property imply the p sub 2  property. in this paper we show that the strong monotonicity property implies the p sub 2  property for any linear transformation and describe an equivalence between these two properties for lyapunov and other transformations. we show by means of an example that the gus property need not imply the p sub 2  property even for lyapunov transformations.
inspec,train_1135,a combinatorial graph based solution method for a class of continuous time optimal control problems. the paper addresses a class of continuous time optimal control problems whose solutions are typically characterized by both bang bang and singular control regimes. analytical study and numerical computation of such solutions are very difficult and far from complete when only techniques from control theory are used. this paper solves optimal control problems by reducing them to the combinatorial search for the shortest path in a specially constructed graph. since the nodes of the graph are weighted in a sequence dependent manner we extend the classical shortest path algorithm to our case. the proposed solution method is currently limited to single state problems with multiple control functions. a production planning problem and a train operation problem are optimally solved to illustrate the method.
inspec,train_1136,q learning for risk sensitive control. we propose for risk sensitive control of finite markov chains a counterpart of the popular q learning algorithm for classical markov decision processes. the algorithm is shown to converge with probability one to the desired solution. the proof technique is an adaptation of the o d e approach for the analysis of stochastic approximation algorithms with most of the work involved used for the analysis of the specific o d e s that arise.
inspec,train_1137,on deciding stability of constrained homogeneous random walks and queueing systems. we investigate stability of scheduling policies in queueing systems. to this day no algorithmic characterization exists for checking stability of a given policy in a given queueing system. in this paper we introduce a certain generalized priority policy and prove that the stability of this policy is algorithmically undecidable. we also prove that stability of a homogeneous random walk in l sub  sup d is undecidable. finally we show that the problem of computing a fluid limit of a queueing system or of a constrained homogeneous random walk is undecidable. to the best of our knowledge these are the first undecidability results in the area of stability of queueing systems and random walks in l sub  sup d. we conjecture that stability of common policies like first in first out and priority policy is also an undecidable problem.
inspec,train_1138,approximating martingales for variance reduction in markov process simulation. knowledge of either analytical or numerical approximations should enable more efficient simulation estimators to be constructed. this principle seems intuitively plausible and certainly attractive yet no completely satisfactory general methodology has been developed to exploit it. the authors present a new approach for obtaining variance reduction in markov process simulation that is applicable to a vast array of different performance measures. the approach relies on the construction of a martingale that is then used as an internal control variate.
inspec,train_1139,development and evaluation of a case based reasoning classifier for prediction of breast biopsy outcome with bi rads sup tm lexicon. approximately 70 85 of breast biopsies are performed on benign lesions. to reduce this high number of biopsies performed on benign lesions a case based reasoning cbr classifier was developed to predict biopsy results from bi rads sup tm findings. we used 1433 931 benign biopsy proven mammographic cases. cbr similarity was defined using either the hamming or euclidean distance measure over case features. ten features represented each case calcification distribution calcification morphology calcification number mass margin mass shape mass density mass size associated findings special cases and age. performance was evaluated using round robin sampling receiver operating characteristic roc analysis and bootstrap. to determine the most influential features for the cbr an exhaustive feature search was performed over all possible feature combinations 1022 and similarity thresholds. influential features were defined as the most frequently occurring features in the feature subsets with the highest partial roc areas sub 0 90 auc. for cbr with hamming distance the most influential features were found to be mass margin calcification morphology age calcification distribution calcification number and mass shape resulting in an sub 0 90 auc of 0 33. at 95 sensitivity the hamming cbr would spare from biopsy 34 of the benign lesions. at 98 sensitivity the hamming cbr would spare 27 benign lesions. for the cbr with euclidean distance the most influential feature subset consisted of mass margin calcification morphology age mass density and associated findings resulting in sub 0 90 auc of 0 37. at 95 sensitivity the euclidean cbr would spare from biopsy 41 benign lesions. at 98 sensitivity the euclidean cbr would spare 27 benign lesions. the profile of cases spared by both distance measures at 98 sensitivity indicates that the cbr is a potentially useful diagnostic tool for the classification of mammographic lesions by recommending short term follow up for likely benign lesions that is in agreement with final biopsy results and mammographer s intuition.
inspec,train_114,cooperative three and four player quantum games. a cooperative multi player quantum game played by 3 and 4 players has been studied. a quantum superposed operator is introduced in this work which solves the non zero sum difficulty in previous treatments. the role of quantum entanglement of the initial state is discussed in detail.
inspec,train_1140,computer aided classification of masses in ultrasonic mammography. frequency compounding was recently investigated for computer aided classification of masses in ultrasonic b mode images as benign or malignant. the classification was performed using the normalized parameters of the nakagami distribution at a single region of interest at the site of the mass. a combination of normalized nakagami parameters from two different images of a mass was undertaken to improve the performance of classification. receiver operating characteristic roc analysis showed that such an approach resulted in an area of 0 83 under the roc curve. the aim of the work described in this paper is to see whether a feature describing the characteristic of the boundary can be extracted and combined with the nakagami parameter to further improve the performance of classification. the combination of the features has been performed using a weighted summation. results indicate a 10 improvement in specificity at a sensitivity of 96 after combining the information at the site and at the boundary. moreover the technique requires minimal clinical intervention and has a performance that reaches that of the trained radiologist. it is hence suggested that this technique may be utilized in practice to characterize breast masses.
inspec,train_1141,reproducibility of mammary gland structure during repeat setups in a supine position. purpose in breast conserving therapy complete excision of the tumor with an acceptable cosmetic outcome depends on accurate localization in terms of both the position of the lesion and its extent. we hypothesize that preoperative contrast enhanced magnetic resonance mr imaging of the patient in a supine position may be used for accurate tumor localization and marking of its extent immediately prior to surgery. our aims in this study are to assess the reproducibility of mammary gland structure during repeat setups in a supine position to evaluate the effect of a breast immobilization device and to derive reproducibility margins that take internal tissue shifts into account occurring between repeat setups. materials methods the reproducibility of mammary gland structure during repeat setups in a supine position is estimated by quantification of tissue shifts in the breasts of healthy volunteers between repeat mr setups. for each volunteer fiducials are identified and registered with their counter locations in corresponding mr volumes. the difference in position denotes the shift of breast tissue. the dependence on breast volume and the part of the breast as well as the effect of a breast immobilization cast are studied. results the tissue shifts are small with a mean standard deviation on the order of 1 5 mm being slightly larger in large breasts v 1000 cm sup 3  and in the posterior part toward the pectoral muscle of both small and large breasts. the application of a breast immobilization cast reduces the tissue shifts in large breasts. a reproducibility margin on the order of 5 mm will take the internal tissue shifts into account that occur between repeat setups. conclusion the results demonstrate a high reproducibility of mammary gland structure during repeat setups in a supine position.
inspec,train_1142,fast and accurate leaf verification for dynamic multileaf collimation using an electronic portal imaging device. a prerequisite for accurate dose delivery of imrt profiles produced with dynamic multileaf collimation dmlc is highly accurate leaf positioning. in our institution leaf verification for dmlc was initially done with film and ionization chamber. to overcome the limitations of these methods a fast accurate and two dimensional method for daily leaf verification using our ccd camera based electronic portal imaging device epid has been developed. this method is based on a flat field produced with a 0 5 cm wide sliding gap for each leaf pair. deviations in gap widths are detected as deviations in gray scale value profiles derived from the epid images and not by directly assessing leaf positions in the images. dedicated software was developed to reduce the noise level in the low signal images produced with the narrow gaps. the accuracy of this quality assurance procedure was tested by introducing known leaf position errors. it was shown that errors in leaf gap as small as 0 01 0 02 cm could be detected which is certainly adequate to guarantee accurate dose delivery of dmlc treatments even for strongly modulated beam profiles. using this method it was demonstrated that both short and long term reproducibility in leaf positioning were within 0 01 cm 1 sigma for all gantry angles and that the effect of gravity was negligible.
inspec,train_1143,a three source model for the calculation of head scatter factors. accurate determination of the head scatter factor s sub c is an important issue especially for intensity modulated radiation therapy where the segmented fields are often very irregular and much less than the collimator jaw settings. in this work we report an s sub c calculation algorithm for symmetric asymmetric and irregular open fields shaped by the tertiary collimator a multileaf collimator or blocks at different source to chamber distance. the algorithm was based on a three source model in which the photon radiation to the point of calculation was treated as if it originated from three effective sources one source for the primary photons from the target and two extra focal photon sources for the scattered photons from the primary collimator and the flattening filter respectively. the field mapping method proposed by kim et al phys. med. biol. 43 1593 1604 1998 was extended to two extra focal source planes and the scatter contributions were integrated over the projected areas determined by the detector s eye view in the three source planes considering the source intensity distributions. the algorithm was implemented using microsoft visual c c  in the ms windows environment. the only input data required were head scatter factors for symmetric square fields which are normally acquired during machine commissioning. a large number of different fields were used to evaluate the algorithm and the results were compared with measurements. we found that most of the calculated s sub c s agreed with the measured values to within 0 4. the algorithm can also be easily applied to deal with irregular fields shaped by a multileaf collimator that replaces the upper or lower collimator jaws.
inspec,train_1144,simultaneous iterative reconstruction of emission and attenuation images in positron emission tomography from emission data only. for quantitative image reconstruction in positron emission tomography attenuation correction is mandatory. in case that no data are available for the calculation of the attenuation correction factors one can try to determine them from the emission data alone. however it is not clear if the information content is sufficient to yield an adequate attenuation correction together with a satisfactory activity distribution. therefore we determined the log likelihood distribution for a thorax phantom depending on the choice of attenuation and activity pixel values to measure the crosstalk between both. in addition an iterative image reconstruction one dimensional newton type algorithm with a maximum likelihood estimator which simultaneously reconstructs the images of the activity distribution and the attenuation coefficients is used to demonstrate the problems and possibilities of such a reconstruction. as result we show that for a change of the log likelihood in the range of statistical noise the associated change in the activity value of a structure is between 6 and 263. in addition we show that it is not possible to choose the best maximum on the basis of the log likelihood when a regularization is used because the coupling between different structures mediated by the smoothing regularization prevents an adequate solution due to crosstalk. we conclude that taking into account the attenuation information in the emission data improves the performance of image reconstruction with respect to the bias of the activities however the reconstruction still is not quantitative.
inspec,train_1145,mammogram synthesis using a 3d simulation. ii. evaluation of synthetic mammogram texture. we have evaluated a method for synthesizing mammograms by comparing the texture of clinical and synthetic mammograms. the synthesis algorithm is based upon simulations of breast tissue and the mammographic imaging process. mammogram texture was synthesized by projections of simulated adipose tissue compartments. it was hypothesized that the synthetic and clinical texture have similar properties assuming that the mammogram texture reflects the 3d tissue distribution. the size of the projected compartments was computed by mathematical morphology. the texture energy and fractal dimension were also computed and analyzed in terms of the distribution of texture features within four different tissue regions in clinical and synthetic mammograms. comparison of the cumulative distributions of the mean features computed from 95 mammograms showed that the synthetic images simulate the mean features of the texture of clinical mammograms. correlation of clinical and synthetic texture feature histograms averaged over all images showed that the synthetic images can simulate the range of features seen over a large group of mammograms. the best agreement with clinical texture was achieved for simulated compartments with radii of 4 13 3 mm in predominantly adipose tissue regions and radii of 2 7 5 33 and 1 3 2 7 mm in retroareolar and dense fibroglandular tissue regions respectively.
inspec,train_1146,mammogram synthesis using a 3d simulation. i breast tissue model and image acquisition simulation. a method is proposed for generating synthetic mammograms based upon simulations of breast tissue and the mammographic imaging process. a computer breast model has been designed with a realistic distribution of large and medium scale tissue structures. parameters controlling the size and placement of simulated structures adipose compartments and ducts provide a method for consistently modeling images of the same simulated breast with modified position or acquisition parameters. the mammographic imaging process is simulated using a compression model and a model of the x ray image acquisition process. the compression model estimates breast deformation using tissue elasticity parameters found in the literature and clinical force values. the synthetic mammograms were generated by a mammogram acquisition model using a monoenergetic parallel beam approximation applied to the synthetically compressed breast phantom.
inspec,train_1147,angular disparity in etact scintimammography. emission tuned aperture computed tomography etact has been previously shown to have the potential for the detection of small tumors 1 cm in scintimammography. however the optimal approach to the application of etact in the clinic has yet to be determined. therefore we sought to determine the effect of the angular disparity between the etact projections on image quality through the use of a computer simulation. a small spherical tumor of variable size 5 7 5 or 10 mm was placed at the center of a hemispherical breast 15 cm diameter. the tumor to nontumor ratio was either 5 1 or 10 1. the detector was modeled to be a gamma camera fitted with a 4 mm diam pinhole collimator. the pinhole to detector and the pinhole to tumor distances were 25 and 15 cm respectively. a ray tracing technique was used to generate three sets of projections 10 degrees 15 degrees and 20 degrees angular disparity. these data were blurred to a resolution consistent with the 4 mm pinhole. the tact reconstruction method was used to reconstruct these three image sets. the tumor contrast and the axial spatial resolution was measured. smaller angular disparity led to an improvement in image contrast but at a cost of degraded axial spatial resolution. the improvement in contrast is due to a slight improvement in the in plane spatial resolution. since improved contrast should lead to better tumor detectability smaller angular disparity should be used. however the difference in contrast between 10 degrees and 15 degrees was very slight and therefore a reasonable clinical choice for angular disparity is 15 degrees.
inspec,train_1148,benchmarking of the dose planning method dpm monte carlo code using electron beams from a racetrack microtron. a comprehensive set of measurements and calculations has been conducted to investigate the accuracy of the dose planning method dpm monte carlo code for dose calculations from 10 and 50 mev scanned electron beams produced from a racetrack microtron. central axis depth dose measurements and a series of profile scans at various depths were acquired in a water phantom using a scanditronix type rk ion chamber. source spatial distributions for the monte carlo calculations were reconstructed from in air ion chamber measurements carried out across the two dimensional beam profile at 100 cm downstream from the source. the in air spatial distributions were found to have full width at half maximum of 4 7 and 1 3 cm at 100 cm from the source for the 10 and 50 mev beams respectively. energy spectra for the 10 and 50 mev beams were determined by simulating the components of the microtron treatment head using the code mcnp4b. dpm calculations are on average within or 2 agreement with measurement for all depth dose and profile comparisons conducted in this study. the accuracy of the dpm code illustrated in this work suggests that dpm may be used as a valuable tool for electron beam dose calculations.
inspec,train_1149,deterministic calculations of photon spectra for clinical accelerator targets. a method is proposed to compute photon energy spectra produced in clinical electron accelerator targets based on the deterministic solution of the boltzmann equation for coupled electron photon transport in one dimensional 1 d slab geometry. it is shown that the deterministic method gives similar results as monte carlo calculations over the angular range of interest for therapy applications. relative energy spectra computed by deterministic and 3 d monte carlo methods respectively are compared for several realistic target materials and different electron beams and are found to give similar photon energy distributions and mean energies. the deterministic calculations typically require 1 2 mins of execution time on a sun workstation compared to 2 36 h for the monte carlo runs.
inspec,train_115,non optimal universal quantum deleting machine. we verify the non existence of some standard universal quantum deleting machine. then a non optimal universal quantum deleting machine is constructed and we emphasize the difficulty for improving its fidelity. in a way our results complement the universal quantum cloning machine established by buzek and hillery 1996 and manifest some of their distinctions.
inspec,train_1150,effect of multileaf collimator leaf width on physical dose distributions in the treatment of cns and head and neck neoplasms with intensity modulated radiation therapy. the purpose of this work is to examine physical radiation dose differences between two multileaf collimator mlc leaf widths 5 and 10 mm in the treatment of cns and head and neck neoplasms with intensity modulated radiation therapy imrt. three clinical patients with cns tumors were planned with two different mlc leaf sizes 5 and 10 mm representing varian 120 and varian 80 millennium multileaf collimators respectively. two sets of imrt treatment plans were developed. the goal of the first set was radiation dose conformality in three dimensions. the goal for the second set was organ avoidance of a nearby critical structure while maintaining adequate coverage of the target volume. treatment planning utilized the cadplan helios system varian medical systems milpitas ca for dynamic mlc treatment delivery. all beam parameters and optimization cost function parameters were identical for the 5 and 10 mm plans. for all cases the number of beams gantry positions and table positions were taken from clinically treated three dimensional conformal radiotherapy plans. conformality was measured by the ratio of the planning isodose volume to the target volume. organ avoidance was measured by the volume of the critical structure receiving greater than 90 of the prescription dose v sub 90. for three patients with squamous cell carcinoma of the head and neck t2 t4 n0 n2c m0 5 and 10 mm leaf widths were compared for parotid preservation utilizing nine coplanar equally spaced beams delivering a simultaneous integrated boost. because modest differences in physical dose to the parotid were detected a ntcp model based upon the clinical parameters of eisbruch et al was then used for comparisons. the conformality improved in all three cns cases for the 5 mm plans compared to the 10 mm plans. for the organ avoidance plans v sub 90 also improved in two of the three cases when the 5 mm leaf width was utilized for imrt treatment delivery. in the third case both the 5 and 10 mm plans were able to spare the critical structure with none of the structure receiving more than 90 of the prescription dose but in the moderate dose range less dose was delivered to the critical structure with the 5 mm plan. for the head and neck cases both the 5 and 10 2 5 mm beamlets dmlc sliding window techniques spared the contralateral parotid gland while maintaining target volume coverage. the mean parotid dose was modestly lower with the smaller beamlet size 21 04 gy vs 22 36 gy. the resulting average ntcp values were 13 72 for 10 mm dmlc and 8 24 for 5 mm dmlc. in conclusion five mm leaf width results in an improvement in physical dose distribution over 10 mm leaf width that may be clinically relevant in some cases. these differences may be most pronounced for single fraction radiosurgery or in cases where the tolerance of the sensitive organ is less than or close to the target volume prescription.
inspec,train_1151,a method for geometrical verification of dynamic intensity modulated radiotherapy using a scanning electronic portal imaging device. in order to guarantee the safe delivery of dynamic intensity modulated radiotherapy imrt verification of the leaf trajectories during the treatment is necessary. our aim in this study is to develop a method for on line verification of leaf trajectories using an electronic portal imaging device with scanning read out independent of the multileaf collimator. examples of such scanning imagers are electronic portal imaging devices epids based on liquid filled ionization chambers and those based on amorphous silicon. portal images were acquired continuously with a liquid filled ionization chamber epid during the delivery together with the signal of treatment progress that is generated by the accelerator. for each portal image the prescribed leaf and diaphragm positions were computed from the dynamic prescription and the progress information. motion distortion effects of the leaves are corrected based on the treatment progress that is recorded for each image row. the aperture formed by the prescribed leaves and diaphragms is used as the reference field edge while the actual field edge is found using a maximum gradient edge detector. the errors in leaf and diaphragm position are found from the deviations between the reference field edge and the detected field edge. earlier measurements of the dynamic epid response show that the accuracy of the detected field edge is better than 1 mm. to ensure that the verification is independent of inaccuracies in the acquired progress signal the signal was checked with diode measurements beforehand. the method was tested on three different dynamic prescriptions. using the described method we correctly reproduced the distorted field edges. verifying a single portal image took 0 1 s on an 866 mhz personal computer. two flaws in the control system of our experimental dynamic multileaf collimator were correctly revealed with our method. first the errors in leaf position increase with leaf speed indicating a delay of approximately 0 8 s in the control system. second the accuracy of the leaves and diaphragms depends on the direction of motion. in conclusion the described verification method is suitable for detailed verification of leaf trajectories during dynamic imrt.
inspec,train_1152,incorporating multi leaf collimator leaf sequencing into iterative imrt optimization. intensity modulated radiation therapy imrt treatment planning typically considers beam optimization and beam delivery as separate tasks. following optimization a multi leaf collimator mlc or other beam delivery device is used to generate fluence patterns for patient treatment delivery. due to limitations and characteristics of the mlc the deliverable intensity distributions often differ from those produced by the optimizer leading to differences between the delivered and the optimized doses. objective function parameters are then adjusted empirically and the plan is reoptimized to achieve a desired deliverable dose distribution. the resulting plan though usually acceptable may not be the best achievable. a method has been developed to incorporate the mlc restrictions into the optimization process. our in house imrt system has been modified to include the calculation of the deliverable intensity into the optimizer. in this process prior to dose calculation the mlc leaf sequencer is used to convert intensities to dynamic mlc sequences from which the deliverable intensities are then determined. all other optimization steps remain the same. to evaluate the effectiveness of deliverable based optimization 17 patient cases have been studied. compared with standard optimization plus conversion to deliverable beams deliverable based optimization results show improved isodose coverage and a reduced dose to critical structures. deliverable based optimization results are close to the original nondeliverable optimization results suggesting that imrt can overcome the mlc limitations by adjusting individual beamlets. the use of deliverable based optimization may reduce the need for empirical adjustment of objective function parameters and reoptimization of a plan to achieve desired results.
inspec,train_1153,direct aperture optimization a turnkey solution for step and shoot imrt. imrt treatment plans for step and shoot delivery have traditionally been produced through the optimization of intensity distributions or maps for each beam angle. the optimization step is followed by the application of a leaf sequencing algorithm that translates each intensity map into a set of deliverable aperture shapes. in this article we introduce an automated planning system in which we bypass the traditional intensity optimization and instead directly optimize the shapes and the weights of the apertures. we call this approach direct aperture optimization. this technique allows the user to specify the maximum number of apertures per beam direction and hence provides significant control over the complexity of the treatment delivery. this is possible because the machine dependent delivery constraints imposed by the mlc are enforced within the aperture optimization algorithm rather than in a separate leaf sequencing step. the leaf settings and the aperture intensities are optimized simultaneously using a simulated annealing algorithm. we have tested direct aperture optimization on a variety of patient cases using the egs4 beam monte carlo package for our dose calculation engine. the results demonstrate that direct aperture optimization can produce highly conformal step and shoot treatment plans using only three to five apertures per beam direction. as compared with traditional optimization strategies our studies demonstrate that direct aperture optimization can result in a significant reduction in both the number of beam segments and the number of monitor units. direct aperture optimization therefore produces highly efficient treatment deliveries that maintain the full dosimetric benefits of imrt.
inspec,train_1154,the effect of voxel size on the accuracy of dose volume histograms of prostate sup 125 i seed implants. cumulative dose volume histograms dvh are crucial in evaluating the quality of radioactive seed prostate implants. when calculating dvhs the choice of voxel size is a compromise between computational speed larger voxels and accuracy smaller voxels. we quantified the effect of voxel size on the accuracy of dvhs using an in house computer program. the program was validated by comparison with a hand calculated dvh for a single 0 4 u iodine 125 model 6711 seed. we used the program to find the voxel size required to obtain accurate dvhs of five iodine 125 prostate implant patients at our institution. one millimeter cubes were sufficient to obtain dvhs that are accurate within 5 up to 200 of the prescription dose. for the five patient plans we obtained good agreement with the variseed version 6 7 varian usa treatment planning software s dvh algorithm by using voxels with a sup inf dimension equal to the spacing between successive transverse seed implant planes 5 mm. the volume that receives at least 200 of the target dose v sub 200  calculated by variseed was 30 to 43 larger than that calculated by our program with small voxels. the single seed dvh calculated by variseed fell below the hand calculation by up to 50 at low doses 30 gy and above it by over 50 at high doses 250 gy.
inspec,train_1155,a leaf sequencing algorithm to enlarge treatment field length in imrt. with mlc based imrt the maximum usable field size is often smaller than the maximum field size for conventional treatments. this is due to the constraints of the overtravel distances of mlc leaves and or jaws. using a new leaf sequencing algorithm the usable imrt field length perpendicular to the mlc motion can be mostly made equal to the full length of the mlc field without violating the upper jaw overtravel limit. for any given intensity pattern a criterion was proposed to assess whether an intensity pattern can be delivered without violation of the jaw position constraints. if the criterion is met the new algorithm will consider the jaw position constraints during the segmentation for the step and shoot delivery method. the strategy employed by the algorithm is to connect the intensity elements outside the jaw overtravel limits with those inside the jaw overtravel limits. several methods were used to establish these connections during segmentation by modifying a previously published algorithm areal algorithm including changing the intensity level alternating the leaf sequencing direction or limiting the segment field size. the algorithm was tested with 1000 random intensity patterns with dimensions of 21 27 cm sup 2  800 intensity patterns with higher intensity outside the jaw overtravel limit and three different types of clinical treatment plans that were undeliverable using a segmentation method from a commercial treatment planning system. the new algorithm achieved a success rate of 100 with these test patterns. for the 1000 random patterns the new algorithm yields a similar average number of segments of 36 9 or 2 9 in comparison to 36 6 or 1 3 when using the areal algorithm. for the 800 patterns with higher intensities outside the jaw overtravel limits the new algorithm results in an increase of 25 in the average number of segments compared to the areal algorithm. however the areal algorithm fails to create deliverable segments for 90 of these patterns. using a single isocenter the new algorithm provides a solution to extend the usable imrt field length from 21 to 27 cm for imrt on a commercial linear accelerator using the step and shoot delivery method.
inspec,train_1156,favorable noise uniformity properties of fourier based interpolation and reconstruction approaches in single slice helical computed tomography. volumes reconstructed by standard methods from single slice helical computed tomography ct data have been shown to have noise levels that are highly nonuniform relative to those in conventional ct. these noise nonuniformities can affect low contrast object detectability and have also been identified as the cause of the zebra artifacts that plague maximum intensity projection mip images of such volumes. while these spatially variant noise levels have their root in the peculiarities of the helical scan geometry there is also a strong dependence on the interpolation and reconstruction algorithms employed. in this paper we seek to develop image reconstruction strategies that eliminate or reduce at its source the nonuniformity of noise levels in helical ct relative to that in conventional ct. we pursue two approaches independently and in concert. we argue and verify that fourier based longitudinal interpolation approaches lead to more uniform noise ratios than do the standard 360li and 180li approaches. we also demonstrate that a fourier based fan to parallel rebinning algorithm used as an alternative to fanbeam filtered backprojection for slice reconstruction also leads to more uniform noise ratios even when making use of the 180li and 360li interpolation approaches.
inspec,train_1157,portal dose image prediction for dosimetric treatment verification in radiotherapy. ii. an algorithm for wedged beams. a method is presented for calculation of a two dimensional function t sub wedge x y describing the transmission of a wedged photon beam through a patient. this in an extension of the method that we have published for open nonwedged fields med. phys. 25 830 840 1998. transmission functions for open fields are being used in our clinic for prediction of portal dose images pdi i e a dose distribution behind the patient in a plane normal to the beam axis which are compared with pdis measured with an electronic portal imaging device epid. the calculations are based on the planning ct scan of the patient and on the irradiation geometry as determined in the treatment planning process. input data for the developed algorithm for wedged beams are derived from the already available measured input data set for transmission prediction in open beams which is extended with only a limited set of measurements in the wedged beam. the method has been tested for a pdi plane at 160 cm from the focus in agreement with the applied focus to detector distance of our fluoroscopic epids. for low and high energy photon beams 6 and 23 mv good agreement 1 has been found between calculated and measured transmissions for a slab and a thorax phantom.
inspec,train_1158,from powder to perfect parts. gkn sinter metals has increased productivity and quality by automating the powder metal lines that produce its transmission parts.
inspec,train_1159,sigma admissible families over linear orders. admissible sets of the form hyp m where m is a recursively saturated system are treated. we provide descriptions of subsets m which are sigma sub  sets in hyp m and of families of subsets m which form sigma regular families in hyp m in terms of the concept of being fundamental couched in the article. fundamental subsets and families are characterized for models of dense linear orderings.
inspec,train_116,frontier between separability and quantum entanglement in a many spin system. we discuss the critical point x sub c separating the quantum entangled and separable states in two series of n spins s in the simple mixed state characterized by the matrix operator rho x phi  phi 1 x d sup n i sub d n where x in 0 1 d 2s 1 i sub d n is the d sup n  d sup n unity matrix and phi is a special entangled state. the cases x 0 and x 1 correspond respectively to fully random spins and to a fully entangled state. in the first of these series we consider special states phi invariant under charge conjugation that generalizes the n 2 spin s 1 2 einstein podolsky rosen state and in the second one we consider generalizations of the werner 1989 density matrices. the evaluation of the critical point x sub c was done through bounds coming from the partial transposition method of peres 1996 and the conditional nonextensive entropy criterion. our results suggest the conjecture that whenever the bounds coming from both methods coincide the result of x sub c is the exact one. the results we present are relevant for the discussion of quantum computing teleportation and cryptography.
inspec,train_1160,monoids all polygons over which are omega stable proof of the mustafin poizat conjecture. a monoid s is called an omega stabilizer superstabilizer or stabilizer if every s polygon has an omega stable superstable or stable theory. it is proved that every omega stabilizer is a regular monoid. this confirms the mustafin poizat conjecture and allows us to end up the description of omega stabilizers.
inspec,train_1161,model theory for hereditarily finite superstructures. we study model theoretic properties of hereditarily finite superstructures over models of not more than countable signatures. a question is answered in the negative inquiring whether theories of hereditarily finite superstructures which have a unique up to isomorphism hereditarily finite superstructure can be described via definable functions. yet theories for such superstructures admit a description in terms of iterated families tf and sf. these are constructed using a definable union taken over countable ordinals in the subsets which are unions of finitely many complete subsets and of finite subsets respectively. simultaneously we describe theories that share a unique up to isomorphism countable hereditarily finite superstructure.
inspec,train_1162,recognition of finite simple groups s sub 4 q by their element orders. it is proved that among simple groups s sub 4 q in the class of finite groups only the groups s sub 4 3 sup n  where n is an odd number greater than unity are recognizable by a set of their element orders. it is also shown that simple groups u sub 3 9  sup 3 d sub 4 2 g sub 2 4 s sub 6 3 f sub 4 2 and sup 2 e sub 6 2 are recognizable but l sub 3 3 is not.
inspec,train_1163,evaluating the complexity of index sets for families of general recursive functions in the arithmetic hierarchy. the complexity of index sets of families of general recursive functions is evaluated in the kleene mostowski arithmetic hierarchy.
inspec,train_1164,friedberg numberings of families of n computably enumerable sets. we establish a number of results on numberings in particular on friedberg numberings of families of d c e sets. first it is proved that there exists a friedberg numbering of the family of all d c e sets. we also show that this result patterned on friedberg s famous theorem for the family of all c e sets holds for the family of all n c e sets for any n 2. second it is stated that there exists an infinite family of d c e sets without a friedberg numbering. third it is shown that there exists an infinite family of c e sets treated as a family of d c e sets with a numbering which is unique up to equivalence. fourth it is proved that there exists a family of d c e sets with a least numbering under reducibility which is friedberg but is not the only numbering modulo reducibility.
inspec,train_1165,recognizing groups g sub 2 3 sup n by their element orders. it is proved that a finite group that is isomorphic to a simple non abelian group g g sub 2 3 sup n is up to isomorphism recognized by a set omega g of its element orders that is h approximately g if omega h omega g for some finite group h.
inspec,train_1166,embedding the outer automorphism group out f sub n of a free group of rank n in the group out f sub m for m n. it is proved that for every n or 1 the group out f sub n is embedded in the group out f sub m with m 1 n 1 k sup n  where k is an arbitrary natural number coprime to n 1.
inspec,train_1167,a new approach to the d mc problem. many real world systems are multi state systems composed of multi state components in which the reliability can be computed in terms of the lower bound points of level d called d mincuts d mcs. such systems electric power transportation etc may be regarded as flow networks whose arcs have independent discrete limited and multi valued random capacities. in this paper all mcs are assumed to be known in advance and the authors focused on how to verify each d mc candidate before using d mcs to calculate the network reliability. the proposed algorithm is more efficient than existing algorithms. the algorithm runs in o p sigma mn time a significant improvement over the previous o p sigma m sup 2 time bounds based on max flow min cut where p and or are the number of mcs and d mc candidates respectively. it is simple intuitive and uses no complex data structures. an example is given to show how all d mc candidates are found and verified by the proposed algorithm. then the reliability of this example is computed.
inspec,train_1168,computing failure probabilities. applications to reliability analysis. the paper presents one method for calculating failure probabilities with applications to reliability analysis. the method is based on transforming the initial set of variables to a n dimensional uniform random variable in the unit hypercube together with the limit condition set and calculating the associated probability using a recursive method based on the gauss legendre quadrature formulas to calculate the resulting multiple integrals. an example of application is used to illustrate the proposed method.
inspec,train_1169,an efficient algorithm for sequential generation of failure states in a network with multi mode components. in this work a new algorithm for the sequential generation of failure states in a network with multi mode components is proposed. the algorithm presented in the paper transforms the state enumeration problem into a k shortest paths problem. taking advantage of the inherent efficiency of an algorithm for shortest paths enumeration and also of the characteristics of the reliability problem in which it will be used an algorithm with lower complexity than the best algorithm in the literature for solving this problem was obtained. computational results will be presented for comparing the efficiency of both algorithms in terms of cpu time and for problems of different size.
inspec,train_117,multiresolution markov models for signal and image processing. reviews a significant component of the rich field of statistical multiresolution mr modeling and processing. these mr methods have found application and permeated the literature of a widely scattered set of disciplines and one of our principal objectives is to present a single coherent picture of this framework. a second goal is to describe how this topic fits into the even larger field of mr methods and concepts in particular making ties to topics such as wavelets and multigrid methods. a third goal is to provide several alternate viewpoints for this body of work as the methods and concepts we describe intersect with a number of other fields. the principle focus of our presentation is the class of mr markov processes defined on pyramidally organized trees. the attractiveness of these models stems from both the very efficient algorithms they admit and their expressive power and broad applicability. we show how a variety of methods and models relate to this framework including models for self similar and 1 f processes. we also illustrate how these methods have been used in practice.
inspec,train_1170,upper bound analysis of oblique cutting with nose radius tools. a generalized upper bound model for calculating the chip flow angle in oblique cutting using flat faced nose radius tools is described. the projection of the uncut chip area on the rake face is divided into a number of elements parallel to an assumed chip flow direction. the length of each of these elements is used to find the length of the corresponding element on the shear surface using the ratio of the shear velocity to the chip velocity. the area of each element is found as the cross product of the length and its width along the cutting edge. summing up the area of the elements along the shear surface the total shear surface area is obtained. the friction area is calculated using the similarity between orthogonal and oblique cutting in the equivalent plane that includes both the cutting velocity and chip velocity. the cutting power is obtained by summing the shear power and the friction power. the actual chip flow angle and chip velocity are obtained by minimizing the cutting power with respect to both these variables. the shape of the curved shear surface the chip cross section and the cutting force obtained from this model are presented.
inspec,train_1171,manufacturing data analysis of machine tool errors within a contemporary small manufacturing enterprise. the main focus of the paper is directed at the determination of manufacturing errors within the contemporary smaller manufacturing enterprise sector. the manufacturing error diagnosis is achieved through the manufacturing data analysis of the results obtained from the inspection of the component on a co ordinate measuring machine. this manufacturing data analysis activity adopts a feature based approach and is conducted through the application of a forward chaining expert system called the product data analysis distributed diagnostic expert system which forms part of a larger prototype feedback system entitled the production data analysis framework. the paper introduces the manufacturing error categorisations that are associated with milling type operations knowledge acquisition and representation conceptual structure and operating procedure of the prototype manufacturing data analysis facility. the paper concludes with a brief evaluation of the logic employed through the simulation of manufacturing error scenarios. this prototype manufacturing data analysis expert system provides a valuable aid for the rapid diagnosis and elimination of manufacturing errors on a 3 axis vertical machining centre in an environment where operator expertise is limited.
inspec,train_1172,marble cutting with single point cutting tool and diamond segments. an investigation has been undertaken into the frame sawing with diamond blades. the kinematic behaviour of the frame sawing process is discussed. under different cutting conditions cutting and indenting cutting tests are carried out by single point cutting tools and single diamond segments. the results indicate that the depth of cut per diamond grit increases as the blades move forward. only a few grits per segment can remove the material in the cutting process. when the direction of the stroke changes the cutting forces do not decrease to zero because of the residual plastic deformation beneath the diamond grits. the plastic deformation and fracture chipping of material are the dominant removal processes which can be explained by the fracture theory of brittle material indentation.
inspec,train_1173,a comprehensive chatter prediction model for face turning operation including tool wear effect. presents a three dimensional mechanistic frequency domain chatter model for face turning processes that can account for the effects of tool wear including process damping. new formulations are presented to model the variation in process damping forces along nonlinear tool geometries such as the nose radius. the underlying dynamic force model simulates the variation in the chip cross sectional area by accounting for the displacements in the axial and radial directions. the model can be used to determine stability boundaries under various cutting conditions and different states of flank wear. experimental results for different amounts of wear are provided as a validation for the model.
inspec,train_1174,optimization of cutting conditions for single pass turning operations using a deterministic approach. an optimization analysis strategy and cam software for the selection of economic cutting conditions in single pass turning operations are presented using a deterministic approach. the optimization is based on criteria typified by the maximum production rate and includes a host of practical constraints. it is shown that the deterministic optimization approach involving mathematical analyses of constrained economic trends and graphical representation on the feed speed domain provides a clearly defined strategy that not only provides a unique global optimum solution but also the software that is suitable for on line cam applications. a numerical study has verified the developed optimization strategies and software and has shown the economic benefits of using optimization.
inspec,train_1175,prediction of tool and chip temperature in continuous and interrupted machining. a numerical model based on the finite difference method is presented to predict tool and chip temperature fields in continuous machining and time varying milling processes. continuous or steady state machining operations like orthogonal cutting are studied by modeling the heat transfer between the tool and chip at the tool rake face contact zone. the shear energy created in the primary zone the friction energy produced at the rake face chip contact zone and the heat balance between the moving chip and stationary tool are considered. the temperature distribution is solved using the finite difference method. later the model is extended to milling where the cutting is interrupted and the chip thickness varies with time. the proposed model combines the steady state temperature prediction in continuous machining with transient temperature evaluation in interrupted cutting operations where the chip and the process change in a discontinuous manner. the mathematical models and simulation results are in satisfactory agreement with experimental temperature measurements reported in the literature.
inspec,train_1176,a summary of methods applied to tool condition monitoring in drilling. presents a summary of the monitoring methods signal analysis and diagnostic techniques for tool wear and failure monitoring in drilling that have been tested and reported in the literature. the paper covers only indirect monitoring methods such as force vibration and current measurements. signal analysis techniques cover all the methods that have been used with indirect measurements including e g statistical parameters and fast fourier and wavelet transform. only a limited number of automatic diagnostic tools have been developed for diagnosis of the condition of the tool in drilling. all of these rather diverse approaches that have been available are covered in this study. only in a few of the papers have attempts been made to compare the chosen approach with other methods. many of the papers only present one approach and unfortunately quite often the test material of the study is limited especially in what comes to the cutting process parameter variation and also workpiece material.
inspec,train_1177,comparative statistical analysis of hole taper and circularity in laser percussion drilling. investigates the relationships and parameter interactions between six controllable variables on the hole taper and circularity in laser percussion drilling. experiments have been conducted on stainless steel workpieces and a comparison was made between stainless steel and mild steel. the central composite design was employed to plan the experiments in order to achieve required information with reduced number of experiments. the process performance was evaluated. the ratio of minimum to maximum feret s diameter was considered as circularity characteristic of the hole. the models of these three process characteristics were developed by linear multiple regression technique. the significant coefficients were obtained by performing analysis of variance anova at 1 5 and 7 levels of significance. the final models were checked by complete residual analysis and finally were experimentally verified. it was found that the pulse frequency had a significant effect on the hole entrance diameter and hole circularity in drilling stainless steel unlike the drilling of mild steel where the pulse frequency had no significant effect on the hole characteristics.
inspec,train_1178,network centric systems. the author describes a graduate level course that addresses cutting edge issues in network centric systems while following a more traditional graduate seminar format.
inspec,train_1179,evolution complexity of the elementary cellular automaton rule 18. cellular automata are classes of mathematical systems characterized by discreteness in space time and state values determinism and local interaction. using symbolic dynamical theory we coarse grain the temporal evolution orbits of cellular automata. by means of formal languages and automata theory we study the evolution complexity of the elementary cellular automaton with local rule number 18 and prove that its width 1 evolution language is regular but for every n or 2 its width n evolution language is not context free but context sensitive.
inspec,train_118,sensorless control of induction motor drives. controlled induction motor drives without mechanical speed sensors at the motor shaft have the attractions of low cost and high reliability. to replace the sensor the information on the rotor speed is extracted from measured stator voltages and currents at the motor terminals. vector controlled drives require estimating the magnitude and spatial orientation of the fundamental magnetic flux waves in the stator or in the rotor. open loop estimators or closed loop observers are used for this purpose. they differ with respect to accuracy robustness and sensitivity against model parameter variations. dynamic performance and steady state speed accuracy in the low speed range can be achieved by exploiting parasitic effects of the machine. the overview in this paper uses signal flow graphs of complex space vector quantities to provide an insightful description of the systems used in sensorless control of induction motors.
inspec,train_1180,decomposition of additive cellular automata. finite additive cellular automata with fixed and periodic boundary conditions are considered as endomorphisms over pattern spaces. a characterization of the nilpotent and regular parts of these endomorphisms is given in terms of their minimal polynomials. generalized eigenspace decomposition is determined and relevant cyclic subspaces are described in terms of symmetries. as an application the lengths and frequencies of limit cycles in the transition diagram of the automaton are calculated.
inspec,train_1181,dynamic neighborhood structures in parallel evolution strategies. parallelizing is a straightforward approach to reduce the total computation time of evolutionary algorithms. finding an appropriate communication network within spatially structured populations for improving convergence speed and convergence probability is a difficult task. a new method that uses a dynamic communication scheme in an evolution strategy will be compared with conventional static and dynamic approaches. the communication structure is based on a so called diffusion model approach. the links between adjacent individuals are dynamically chosen according to deterministic or probabilistic rules. due to self organization effects efficient and stable communication structures are established that perform robustly and quickly on a multimodal test function.
inspec,train_1182,optimization of the memory weighting function in stochastic functional self organized sorting performed by a team of autonomous mobile agents. the activity of a team of autonomous mobile agents formed by identical robot like ant individuals capable of performing a random walk through an environment that are able to recognize and move different objects is modeled. the emergent desired behavior is a distributed sorting and clustering based only on local information and a memory register that records the past objects encountered. an optimum weighting function for the memory registers is theoretically derived. the optimum time dependent weighting function allows sorting and clustering of the randomly distributed objects in the shortest time. by maximizing the average speed of a texture feature the contrast we check the central assumption the intermediate steady states hypothesis of our theoretical result. it is proved that the algorithm optimization based on maximum speed variation of the contrast feature gives relationships similar to the theoretically derived annealing law.
inspec,train_1183,evolving robust asynchronous cellular automata for the density task. in this paper the evolution of three kinds of asynchronous cellular automata are studied for the density task. results are compared with those obtained for synchronous automata and the influence of various asynchronous update policies on the computational strategy is described. how synchronous and asynchronous cellular automata behave is investigated when the update policy is gradually changed showing that asynchronous cellular automata are more adaptable. the behavior of synchronous and asynchronous evolved automata are studied under the presence of random noise of two kinds and it is shown that asynchronous cellular automata implicitly offer superior fault tolerance.
inspec,train_1184,measuring return revealing roi. the most critical part of the return on investment odyssey is to develop metrics that matter to the business and to measure systems in terms of their ability to help achieve those business goals. everything must flow from those key metrics. and do n t forget to revisit those every now and then too. since all systems wind down over time it s important to keep tabs on how well your automation investment is meeting the metrics established by your company. manufacturers are clamoring for a tool to help quantify returns and analyze the results.
inspec,train_1185,trading exchanges online marketplaces evolve. looks at how trading exchanges are evolving rapidly to help manufacturers keep up with customer demand.
inspec,train_1186,implementing it s all about processes. looks at how the key to successful technology deployment can be found in a set of four basic disciplines.
inspec,train_1187,ethernet networks getting down to business. while it seems pretty clear that ethernet has won the battle for the mindshare as the network of choice for the factory floor there s still a war to be won in implementation as cutting edge manufacturers begin to adopt the technology on a widespread basis.
inspec,train_1188,it s time to buy. there is an upside to a down economy over zealous suppliers are willing to make deals that were unthinkable a few years ago. that s because vendors are experiencing the same money squeeze as manufacturers which makes the year 2002 the perfect time to invest in new technology. the author states that when negotiating the deal provisions for unexpected costs an exit strategy and even shared risk with the vendor should be on the table.
inspec,train_1189,crm approaching zenith. looks at how manufacturers are starting to warm up to the concept of customer relationship management. crm has matured into what is expected to be big business. as crm software evolves to its second some say third generation it s likely to be more valuable to holdouts in manufacturing and other sectors.
inspec,train_119,jpeg2000 standard for interactive imaging. jpeg2000 is the latest image compression standard to emerge from the joint photographic experts group jpeg working under the auspices of the international standards organization. although the new standard does offer superior compression performance to jpeg jpeg2000 provides a whole new way of interacting with compressed imagery in a scalable and interoperable fashion. this paper provides a tutorial style review of the new standard explaining the technology on which it is based and drawing comparisons with jpeg and other compression standards. the paper also describes new work exploiting the capabilities of jpeg2000 in client server systems for efficient interactive browsing of images over the internet.
inspec,train_1190,buying into the relationship business software. choosing the right software to improve business processes can have a huge impact on a company s efficiency and profitability. while it is sometimes hard to get beyond vendor hype about software features and functionality and know what to realistically expect it is even more difficult to determine if the vendor is the right vendor to partner with. thus picking the right software is important but companies have to realize that what they are really buying into is a relationship with the vendor.
inspec,train_1191,on the monotonicity conservation in numerical solutions of the heat equation. it is important to choose such numerical methods in practice that mirror the characteristic properties of the described process beyond the stability and convergence. the investigated qualitative property in this paper is the conservation of the monotonicity in space of the initial heat distribution. we prove some statements about the monotonicity conservation and total monotonicity of one step vector iterations. then applying these results we consider the numerical solutions of the one dimensional heat equation. our main theorem formulates the necessary and sufficient condition of the uniform monotonicity conservation. the sharpness of the conditions is demonstrated by numerical examples.
inspec,train_1192,construction of two sided bounds for initial boundary value problems. this paper extends the bounding operator approach developed for boundary value problems to the case of initial boundary value problems ibvps. following the general principle of bounding operators enclosing methods for the case of partial differential equations are discussed. in particular continuous discretization methods with an appropriate error bound controlled shift and monotone extensions of rothe s method for parabolic problems are investigated.
inspec,train_1193,operator splitting and approximate factorization for taxis diffusion reaction models. in this paper we consider the numerical solution of 2d systems of certain types of taxis diffusion reaction equations from mathematical biology. by spatial discretization these pde systems are approximated by systems of positive nonlinear odes method of lines. the aim of this paper is to examine the numerical integration of these ode systems for low to moderate accuracy by means of splitting techniques. an important consideration is maintenance of positivity. we apply operator splitting and approximate matrix factorization using low order explicit runge kutta methods and linearly implicit runge kutta rosenbrock methods. as a reference method the general purpose solver vodpk is applied.
inspec,train_1194,new methods for oscillatory problems based on classical codes. the numerical integration of differential equations with oscillatory solutions is a very common problem in many fields of the applied sciences. some methods have been specially devised for this kind of problem. in most of them the calculation of the coefficients needs more computational effort than the classical codes because such coefficients depend on the step size in a not simple manner. on the contrary in this work we present new algorithms specially designed for perturbed oscillators whose coefficients have a simple dependence on the step size. the methods obtained are competitive when comparing with classical and special codes.
inspec,train_1195,sharpening the estimate of the stability constant in the maximum norm of the crank nicolson scheme for the one dimensional heat equation. this paper is concerned with the stability constant c sub infinity in the maximum norm of the crank nicolson scheme applied. to the one dimensional heat equation. a well known result due to s j serdyukova is that c sub infinity  23. in the present paper by using a sharp resolvent estimate for the discrete laplacian together with the cauchy formula it is shown that 3 or c sub infinity  4 325. this bound also holds when the heat equation is considered on a bounded interval along with dirichlet or neumann boundary conditions.
inspec,train_1196,multiple shooting using a dichotomically stable integrator for solving differential algebraic equations. in previous work by the first author it has been established that a dichotomically stable discretization is needed when solving a stiff boundary value problem in ordinary differential equations odes when sharp boundary layers may occur at each end of the interval. a dichotomically stable implicit runge kutta method using the 3 stage fourth order lobatto iiia formulae has been implemented in a variable step size initial value integrator which could be used in a multiple shooting approach. in the case of index one differential algebraic equations daes the use of the lobatto iiia formulae has an advantage over a comparable gaussian method that the order is the same for both differential and algebraic variables and there is no need to treat them separately. the ode integrator has been adapted for the solution of index one daes and the resulting integrator symdae has been inserted into the multiple shooting code mshdae previously developed by r lamour for differential algebraic boundary value problems. the standard version of mshdae uses a bdf integrator which is not dichotomically stable and for some stiff test problems this fails to integrate across the interval of interest while the dichotomically stable integrator symdae encounters no difficulty. indeed for such problems the modified version of mshdae produces an accurate solution and within limits imposed by computer word length the efficiency of the solution process improves with increasing stiffness. for some nonstiff problems the solution is also entirely satisfactory.
inspec,train_1197,numerical behaviour of stable and unstable solitary waves. in this paper we analyse the behaviour in time of the numerical approximations to solitary wave solutions of the generalized benjamin bona mahony equation. this equation possesses an important property the stability of these solutions depends on their velocity. we identify the error propagation mechanisms in both the stable and unstable case. in particular we show that in the stable case numerical methods that preserve some conserved quantities of the problem are more appropriate for the simulation of this kind of solutions.
inspec,train_1198,post projected runge kutta methods for index 2 differential algebraic equations. a new projection technique for runge kutta methods applied to index 2 differential algebraic equations is presented in which the numerical approximation is projected only as part of the output process. it is shown that for methods that are strictly stable at infinity the order of convergence is unaffected compared to standard projected methods. gauss methods for which this technique is of special interest when some symmetry is to be preserved are studied in more detail.
inspec,train_1199,quasi stage order conditions for sdirk methods. the stage order condition is a simplifying assumption that reduces the number of order conditions to be fulfilled when designing a runge kutta rk method. because a dirk diagonally implicit rk method can not have stage order greater than 1 we introduce quasi stage order conditions and derive some of their properties for dirks. we use these conditions to derive a low order dirk method with embedded error estimator. numerical tests with stiff odes and daes of index 1 and 2 indicate that the method is competitive with other rk methods for low accuracy tolerances.
inspec,train_12,national learning systems a new approach on technological change in late industrializing economies and evidences from the cases of brazil and south korea. the paper has two intertwined parts. the first one is a proposal for a conceptual and theoretical framework to understand technical change in late industrializing economies. the second part develops a kind of empirical test of the usefulness of that new framework by means of a comparative study of the brazilian and south korean cases. all the four types of macroevidences of the technical change processes of brazil and korea corroborate directly or indirectly the hypothesis of the existence of actual cases of national learning systems nlss of passive and active nature as it is shown to be the cases of brazil and south korea respectively. the contrast between the two processes of technical change prove remarkable despite both processes being essentially confined to learning. the concepts of passive and active nlss show how useful they are to apprehend the diversity of those realities and consequently to avoid for instance interpretations that misleadingly suppose based on conventional economic theory that those countries have a similar lack of technological dynamism.
inspec,train_120,self organized critical traffic in parallel computer networks. in a recent paper we analysed the dynamics of traffic flow in a simple square lattice architecture. it was shown that a phase transition takes place between a free and a congested phase. the transition point was shown to exhibit optimal information transfer and wide fluctuations in time with scale free properties. in this paper we further extend our analysis by considering a generalization of the previous model in which the rate of packet emission is regulated by the local congestion perceived by each node. as a result of the feedback between traffic congestion and packet release the system is poised at criticality. many well known statistical features displayed by internet traffic are recovered from our model in a natural way.
inspec,train_1200,from continuous recovery to discrete filtering in numerical approximations of conservation laws. modern numerical approximations of conservation laws rely on numerical dissipation as a means of stabilization. the older alternative approach is the use of central differencing with a dose of artificial dissipation. in this paper we review the successful class of weighted essentially non oscillatory finite volume schemes which comprise sophisticated methods of the first kind. new developments in image processing have made new devices possible which can serve as highly nonlinear artificial dissipation terms. we view artificial dissipation as discrete filter operation and introduce several new algorithms inspired by image processing.
inspec,train_1201,moving into the mainstream product lifecycle management. product lifecycle management plm is widely recognised by most manufacturing companies as manufacturers begin to identify and implement targeted projects intended to deliver return on investment in a timely fashion. vendors are also releasing second generation plm products that are packaged out of the box solutions.
inspec,train_1202,more than the money software project. experiences creating budgets for large software projects have taught manufacturers that it is not about the money it is about what one really needs. before a company can begin to build a budget for a software. project it has to have a good understanding of what business issues need to be addressed and what the business objectives are. this step is critical because it defines the business goals outlines the metrics for success sets the scope for the project and defines the criteria for selecting the right software.
inspec,train_1203,technology decisions 2002. the paper looks at the critical hardware software and services choices manufacturers are making as they begin to emerge from the recession and position themselves for the future.
inspec,train_1204,design and prototype of a performance tool interface for openmp. this paper proposes a performance tools interface for openmp similar in spirit to the mpi profiling interface in its intent to define a clear and portable api that makes openmp execution events visible to runtime performance tools. we present our design using a source level instrumentation approach based on openmp directive rewriting. rules to instrument each directive and their combination are applied to generate calls to the interface consistent with directive semantics and to pass context information e g source code locations in a portable and efficient way. our proposed openmp performance api further allows user functions and arbitrary code regions to be marked and performance measurement to be controlled using new openmp directives. to prototype the proposed openmp performance interface we have developed compatible performance libraries for the expert automatic event trace analyzer 17 18 and the tau performance analysis framework 13. the directive instrumentation transformations we define are implemented in a source to source translation tool called opari. application examples are presented for both expert and tau to show the openmp performance interface and opari instrumentation tool in operation. when used together with the mpi profiling interface as the examples also demonstrate our proposed approach provides a portable and robust solution to performance analysis of openmp and mixed mode openmp mpi applications.
inspec,train_1205,hpcview a tool for top down analysis of node performance. it is increasingly difficult for complex scientific programs to attain a significant fraction of peak performance on systems that are based on microprocessors with substantial instruction level parallelism and deep memory hierarchies. despite this trend performance analysis and tuning tools are still not used regularly by algorithm and application designers. to a large extent existing performance tools fail to meet many user needs and are cumbersome to use. to address these issues we developed hpcview a toolkit for combining multiple sets of program profile data correlating the data with source code and generating a database that can be analyzed anywhere with a commodity web browser. we argue that hpcview addresses many of the issues that have limited the usability and the utility of most existing tools. we originally built hpcview to facilitate our own work on data layout and optimizing compilers. now in addition to daily use within our group hpcview is being used by several code development teams in dod and doe laboratories as well as at ncsa.
inspec,train_1206,the magnet toolkit design implementation and evaluation. the current trend in constructing high performance computing systems is to connect a large number of machines via a fast interconnect or a large scale network such as the internet. this approach relies on the performance of the interconnect or internet to enable fast large scale distributed computing. a detailed understanding of the communication traffic is required in order to optimize the operation of the entire system. network researchers traditionally monitor traffic in the network to gain the insight necessary to optimize network operations. recent work suggests additional insight can be obtained by also monitoring traffic at the application level. the monitor for application generated network traffic toolkit magnet we describe here monitors application traffic patterns in production systems thus enabling more highly optimized networks and interconnects for the next generation of high performance computing systems.
inspec,train_1207,packet spacing an enabling mechanism for delivering multimedia content in computational grids. streaming multimedia with udp has become increasingly popular over distributed systems like the internet. scientific applications that stream multimedia include remote computational steering of visualization data and video on demand teleconferencing over the access grid. however udp does not possess a self regulating congestion control mechanism and most best effort traffic is served by congestion controlled tcp. consequently udp steals bandwidth from tcp such that tcp flows starve for network resources. with the volume of internet traffic continuing to increase the perpetuation of udp based streaming will cause the internet to collapse as it did in the mid 1980 s due to the use of non congestion controlled tcp. to address this problem we introduce the counter intuitive notion of inter packet spacing with control feedback to enable udp based applications to perform well in the next generation internet and computational grids. when compared with traditional udp based streaming we illustrate that our approach can reduce packet loss over 50 without adversely affecting delivered throughput.
inspec,train_1208,a virtual test facility for the simulation of dynamic response in materials. the center for simulating dynamic response of materials at the california institute of technology is constructing a virtual shock physics facility for studying the response of various target materials to very strong shocks. the virtual test facility vtf is an end to end fully three dimensional simulation of the detonation of high explosives he shock wave propagation solid material response to pressure loading and compressible turbulence. the vtf largely consists of a parallel fluid solver and a parallel solid mechanics package that are coupled together by the exchange of boundary data. the eulerian fluid code and lagrangian solid mechanics model interact via a novel approach based on level sets. the two main computational packages are integrated through the use of pyre a problem solving environment written in the python scripting language. pyre allows application developers to interchange various computational models and solver packages without recompiling code and it provides standardized access to several data visualization engines and data input mechanisms. in this paper we outline the main components of the vtf discuss their integration via pyre and describe some recent accomplishments in large scale simulation using the vtf.
inspec,train_1209,high level language support for user defined reductions. the optimized handling of reductions on parallel supercomputers or clusters of workstations is critical to high performance because reductions are common in scientific codes and a potential source of bottlenecks. yet in many high level languages a mechanism for writing efficient reductions remains surprisingly absent. further when such mechanisms do exist they often do not provide the flexibility a programmer needs to achieve a desirable level of performance. in this paper we present a new language construct for arbitrary reductions that lets a programmer achieve a level of performance equal to that achievable with the highly flexible but low level combination of fortran and mpi. we have implemented this construct in the zpl language and evaluate it in the context of the initialization of the nas mg benchmark. we show a 45 times speedup over the same code written in zpl without this construct. in addition performance on a large number of processors surpasses that achieved in the nas implementation showing that our mechanism provides programmers with the needed flexibility.
inspec,train_121,formula dependent equivalence for compositional ctl model checking. we present a polytime computable state equivalence that is defined with respect to a given ctl formula. since it does not attempt to preserve all ctl formulas like bisimulation does we can expect to compute coarser equivalences. this equivalence can be used to reduce the complexity of model checking a system of interacting fsm. additionally we show that in some cases our techniques can detect if a formula passes or fails without forming the entire product machine. the method is exact and fully automatic and handles full ctl.
inspec,train_1210,adaptive optimizing compilers for the 21st century. historically compilers have operated by applying a fixed set of optimizations in a predetermined order. we call such an ordered list of optimizations a compilation sequence. this paper describes a prototype system that uses biased random search to discover a program specific compilation sequence that minimizes an explicit external objective function. the result is a compiler framework that adapts its behavior to the application being compiled to the pool of available transformations to the objective function and to the target machine. this paper describes experiments that attempt to characterize the space that the adaptive compiler must search. the preliminary results suggest that optimal solutions are rare and that local minima are frequent. if this holds true biased random searches such as a genetic algorithm should find good solutions more quickly than simpler strategies such as hill climbing.
inspec,train_1211,hybrid decision tree. in this paper a hybrid learning approach named hybrid decision tree hdt is proposed. hdt simulates human reasoning by using symbolic learning to do qualitative analysis and using neural learning to do subsequent quantitative analysis. it generates the trunk of a binary hdt according to the binary information gain ratio criterion in an instance space defined by only original unordered attributes. if unordered attributes can not further distinguish training examples falling into a leaf node whose diversity is beyond the diversity threshold then the node is marked as a dummy node. after all those dummy nodes are marked a specific feedforward neural network named fannc that is trained in an instance space defined by only original ordered attributes is exploited to accomplish the learning task. moreover this paper distinguishes three kinds of incremental learning tasks. two incremental learning procedures designed for example incremental learning with different storage requirements are provided which enables hdt to deal gracefully with data sets where new data are frequently appended. also a hypothesis driven constructive induction mechanism is provided which enables hdt to generate compact concept descriptions.
inspec,train_1212,tcrm diagnosing tuple inconsistency for granulized datasets. many approaches to granularization have been presented for knowledge discovery. however the inconsistent tuples that exist in granulized datasets are hardly ever revealed. we developed a model tuple consistency recognition model tcrm to help efficiently detect inconsistent tuples for datasets that are granulized. the main outputs of the developed model include explored inconsistent tuples and consumed processing time. we further conducted an empirical test where eighteen continuous real life datasets granulized by the equal width interval technique that embedded s plus histogram binning algorithm shba and largest binning size algorithm lbsa binning algorithms were diagnosed. remarkable results almost 40 of the granulized datasets contain inconsistent tuples and 22 have the amount of inconsistent tuples more than 20.
inspec,train_1213,a knowledge intensive multi agent framework for cooperative collaborative design modeling and decision support of assemblies. multi agent modeling has emerged as a promising discipline for dealing with the decision making process in distributed information system applications. one of such applications is the modeling of distributed design or manufacturing processes which can link up various designs or manufacturing processes to form a virtual consortium on a global basis. this paper proposes a novel knowledge intensive multi agent cooperative collaborative framework for concurrent intelligent design and assembly planning which integrates product design design for assembly assembly planning assembly system design and assembly simulation subjected to econo technical evaluations. an ai protocol based method is proposed to facilitate the integration of intelligent agents for assembly design planning evaluation and simulation processes. a unified class of knowledge intensive petri nets is defined using the oo knowledge based petri net approach and used as an ai protocol for handling both the integration and the negotiation problems among multi agents. the detailed cooperative collaborative mechanism and algorithms are given based on the knowledge object cooperation formalisms. as such the assembly oriented design system can easily be implemented under the multi agent based knowledge intensive petri net framework with concurrent integration of multiple cooperative knowledge sources and software. thus product design and assembly planning can be carried out simultaneously and intelligently in an entirely computer aided concurrent design and assembly planning system.
inspec,train_1214,multi agent collaboration for b2b workflow monitoring. business to business b2b application environments are exceedingly dynamic and competitive. this dynamism is manifested in the form of changing process requirements and time constraints. however current workflow management technologies have difficulties trying to solve problems such as how to deal with the dynamic nature of b2b commerce processes how to manage the distributed knowledge and recourses and how to reduce the transaction risk. in this paper a collaborative multi agent system is proposed. multiple intelligent agents in our system can work together not only to identify the workflow problems but also to solve such problems by applying business rules such as re organizing the procurement and the transaction processes and making necessary workflow process changes.
inspec,train_1215,a knowledge based approach for business process reengineering shamash. we present an overview of shamash a process modelling tool for business process reengineering. the main features that differentiate it from most current related tools are its ability to define and use organisation standards functional structure and develop automatic model simulation and optimisation. shamash is a knowledge based system and we include a discussion on how knowledge acquisition takes place. furthermore we introduce a high level description of the architecture the conceptual model and other important modules of the system.
inspec,train_1216,knowledge flow management for distributed team software development. cognitive cooperation is often neglected in current team software development processes. this issue becomes more important than ever when team members are globally distributed. this paper presents a notion of knowledge flow and the related management mechanism for realizing an ordered knowledge sharing and cognitive cooperation in a geographically distributed team software development process. the knowledge flow can carry and accumulate knowledge when it goes through from one team member to another. the coordination between the knowledge flow process and the workflow process of a development team provides a new way to improve traditional team software development processes. a knowledge grid platform has been implemented to support the knowledge flow management across the internet.
inspec,train_1217,a knowledge based approach for managing urban infrastructures. this paper presents a knowledge e based approach dedicated to the efficient management regulation interactive and dynamic monitoring of urban infrastructures. this approach identifies the data and related treatments common to several municipal activities and defines the requirements and functionalities of the computer tools developed to improve the delivery and coordination of municipal services to the population. the resulting cooperative system called sigiu is composed of a set of integrated operating systems sydex and the global planning and coordination system sygec. the objective is to integrate the set of sydex and the sygec into a single coherent system for all the sigiu s users according to their tasks their roles and their responsibilities within the municipal administration. sigiu is provided by different measurement and monitoring instruments installed on some system s elements to be supervised. in this context the information can be presented in different forms video pictures data and alarms. one of sigiu s objectives is the real time management of urban infrastructures control mechanisms. to carry out this process the alarm control agent creates a mobile agent associated with the alarm which is sent to a mobile station and warns an operator. preliminary implementation results show that sigiu supports effectively and efficiently the decision making process related to managing urban infrastructures.
inspec,train_1218,knowledge acquisition for expert systems in accounting and financial problem domains. since the mid 1980s expert systems have been developed for a variety of problems in accounting and finance. the most commonly cited problems in developing these systems are the unavailability of the experts and knowledge engineers and difficulties with the rule extraction process. within the field of artificial intelligence this has been called the knowledge acquisition ka problem and has been identified as a major bottleneck in the expert system development process. recent empirical research reveals that certain ka techniques are significantly more efficient than others in helping to extract certain types of knowledge within specific problem domains. this paper presents a mapping between these empirical studies and a generic taxonomy of expert system problem domains. to accomplish this we first examine the range of problem domains and suggest a mapping of accounting and finance tasks to a generic problem domain taxonomy. we then identify and describe the most prominent ka techniques employed in developing expert systems in accounting and finance. after examining and summarizing the existing empirical ka work we conclude by showing how the empirical ka research in the various problem domains can be used to provide guidance to developers of expert systems in the fields of accounting and finance.
inspec,train_1219,knowledge organisation of product design blackboard systems via graph decomposition. knowledge organisation plays an important role in building a knowledge based product design blackboard system. well organised knowledge sources will facilitate the effectiveness and efficiency of communication and data exchange in a blackboard system. in a previous investigation an approach for constructing blackboard systems for product design using a non directed graph decomposition algorithm was proposed. in this paper the relationship between graph decomposition and the resultant blackboard system is further studied. a case study of a number of hypothetical blackboard systems that comprise different knowledge organisations is provided.
inspec,train_122,a formal framework for viewpoint consistency. multiple viewpoint models of system development are becoming increasingly important. each viewpoint offers a different perspective on the target system and system development involves parallel refinement of the multiple views. viewpoint related approaches have been considered in a number of different guises by a spectrum of researchers. our work particularly focuses on the use of viewpoints in open distributed processing odp which is an iso itu standardisation framework. the requirements of viewpoint modelling in odp are very broad and hence demanding. multiple viewpoints though prompt the issue of consistency between viewpoints. this paper describes a very general interpretation of consistency which we argue is broad enough to meet the requirements of consistency in odp. we present a formal framework for this general interpretation highlight basic properties of the interpretation and locate restricted classes of consistency. strategies for checking consistency are also investigated. throughout we illustrate our theory using the formal description technique lotos. thus the paper also characterises the nature of and options for consistency checking in lotos.
inspec,train_1220,modeling discourse in collaborative work support systems a knowledge representation and configuration perspective. collaborative work processes usually raise a lot of intricate debates and negotiations among participants whereas conflicts of interest are inevitable and support for achieving consensus and compromise is required. individual contributions brought up by parties with different backgrounds and interests need to be appropriately structured and maintained. this paper presents a model of discourse acts that participants use to communicate their attitudes to each other or affect the attitudes of others in such environments. the first part deals with the knowledge representation and communication aspects of the problem while the second one in the context of an already implemented system namely hermes with issues related to the configuration of the contributions asserted at each discourse instance. the overall work focuses on the machinery needed in a computer assisted collaborative work environment the aim being to further enhance the human computer interaction.
inspec,train_1221,an approach to developing computational supports for reciprocal tutoring. this study presents a novel approach to developing computational supports for reciprocal tutoring. reciprocal tutoring is a collaborative learning activity where two participants take turns to play the role of a tutor and a tutee. the computational supports include scaffolding tools for the tutor and a computer simulated virtual participant. the approach including system architecture implementations of scaffolding tools for the tutor and of a virtual participant is presented herein. furthermore a system for reciprocal tutoring is implemented as an example of the approach.
inspec,train_1222,mining the optimal class association rule set. we define an optimal class association rule set to be the minimum rule set with the same predictive power of the complete class association rule set. using this rule set instead of the complete class association rule set we can avoid redundant computation that would otherwise be required for mining predictive association rules and hence improve the efficiency of the mining process significantly. we present an efficient algorithm for mining the optimal class association rule set using an upward closure property of pruning weak rules before they are actually generated. we have implemented the algorithm and our experimental results show that our algorithm generates the optimal class association rule set whose size is smaller than 1 17 of the complete class association rule set on average in significantly less time than generating the complete class association rule set. our proposed criterion has been shown very effective for pruning weak rules in dense databases.
inspec,train_1223,formalising optimal feature weight setting in case based diagnosis as linear programming problems. many approaches to case based reasoning cbr exploit feature weight setting algorithms to reduce the sensitivity to distance functions. we demonstrate that optimal feature weight setting in a special kind of cbr problems can be formalised as linear programming problems. therefore the optimal weight settings can be calculated in polynomial time instead of searching in exponential weight space using heuristics to get sub optimal settings. we also demonstrate that our approach can be used to solve classification problems.
inspec,train_1224,formalization of weighted factors analysis. weighted factors analysis wefa has been proposed as a new approach for elicitation representation and manipulation of knowledge about a given problem generally at a high and strategic level. central to this proposal is that a group of experts in the area of the problem can identify a hierarchy of factors with positive or negative influences on the problem outcome. the tangible output of wefa is a directed weighted graph called a wefa graph. this is a set of nodes denoting factors that can directly or indirectly influence an overall aim of the graph. the aim is also represented by a node. each directed arc is a direct influence of one factor on another. a chain of directed arcs indicates an indirect influence. the influences may be identified as either positive or negative. for example sales and costs are two factors that influence the aim of profitability in an organization. sales has a positive influence on profitability and costs has a negative influence on profitability. in addition the relative significance of each influence is represented by a weight. we develop binary wefa which is a variant of wefa where the factors in the graph are restricted to being either true or false. imposing this restriction on a wefa graph allows us to be more precise about the meaning of the graph and of reasoning in it. binary wefa is a new proposal that provides a formal yet sufficiently simple language for logic based argumentation for use by business people in decision support and knowledge management. whilst binary wefa is expressively simpler than other logic based argumentation formalisms it does incorporate a novel formalization of the notion of significance.
inspec,train_1225,bt voices its support for ip. btexact s chief technology officer mick reeve gives his views on the future for voice over dsl services and virtual private networks and defends the slow rollout of public access wlans.
inspec,train_1226,temp it chief rallies troops mori. the appointment of a highly qualified interim it manager enabled market research company mori to rapidly restructure its it department. now the resulting improvements are allowing it to support an increasing role for technology in the assimilation and analysis of market research.
inspec,train_1227,will new palms win laurels.. palmsource s latest operating system for mobile devices harnesses the arm architecture to support more powerful business software but there are concerns over compatibility with older applications.
inspec,train_1228,outsourced backup saves time. to increase the efficiency of its data backup and to free staff to concentrate on core business the gadget shop is relying on a secure automated system hosted by a third party.
inspec,train_1229,dot net makes slow progress. microsoft s windows. net enterprise server release candidate i which was released at the end of last month provides an early glimpse of the system that will eventually replace windows 200 advanced server. the software has been improved so that active directory is more flexible and easier to deploy and security scalability and management have also been enhanced.
inspec,train_123,a new identification approach for fir models. the identification of stochastic discrete systems disturbed with noise is discussed in this brief. the concept of general prediction error gpe criterion is introduced for the time domain estimate with optimal frequency estimation ofe introduced for the frequency domain estimate. the two estimation methods are combined to form a new identification algorithm which is called the empirical frequency domain optimal parameter efop estimate for the finite impulse response fir model interfered by noise. the algorithm theoretically provides the global optimum of the model frequency domain estimate. some simulation examples are given to illustrate the new identification method.
inspec,train_1230,server safeguards tax service. peterborough based tax consultancy ie taxguard wanted real time failover protection for important windows based applications. its solution was to implement a powerful failover server from uk supplier neverfail in order to provide real time backup for three core production servers.
inspec,train_1231,efficient parallel programming on scalable shared memory systems with high performance fortran. openmp offers a high level interface for parallel programming on scalable shared memory smp architectures. it provides the user with simple work sharing directives while it relies on the compiler to generate parallel programs based on thread parallelism. however the lack of language features for exploiting data locality often results in poor performance since the non uniform memory access times on scalable smp machines can not be neglected. high performance fortran hpf the de facto standard for data parallel programming offers a rich set of data distribution directives in order to exploit data locality but it has been mainly targeted towards distributed memory machines. in this paper we describe an optimized execution model for hpf programs on smp machines that avails itself with mechanisms provided by openmp for work sharing and thread parallelism while exploiting data locality based on user specified distribution directives. data locality does not only ensure that most memory accesses are close to the executing threads and are therefore faster but it also minimizes synchronization overheads especially in the case of unstructured reductions. the proposed shared memory execution model for hpf relies on a small set of language extensions which resemble the openmp work sharing features. these extensions together with an optimized shared memory parallelization and execution model have been implemented in the adaptor hpf compilation system and experimental results verify the efficiency of the chosen approach.
inspec,train_1232,techniques for compiling and implementing all nas parallel benchmarks in hpf. the nas parallel benchmarks npb are a well known benchmark set for high performance machines. much effort has been made to implement them in high performance fortran hpf. in previous attempts however the hpf versions did not include the complete set of benchmarks and the performance was not always good. in this study we implement all eight benchmarks of the npb in hpf and parallelize them using an hpf compiler that we have developed. this report describes the implementation techniques and compiler features necessary to achieve good performance. we evaluate the hpf version on the hitachi sr2201 a distributed memory parallel machine. with 16 processors the execution time of the hpf version is within a factor of 1 5 of the hand parallelized version of the npb 2 3 beta.
inspec,train_1233,advanced optimization strategies in the rice dhpf compiler. high performance fortran hpf was envisioned as a vehicle for modernizing legacy fortran codes to achieve scalable parallel performance. to a large extent today s commercially available hpf compilers have failed to deliver scalable parallel performance for a broad spectrum of applications because of insufficiently powerful compiler analysis and optimization. substantial restructuring and hand optimization can be required to achieve acceptable performance with an hpf port of an existing fortran application even for regular data parallel applications. a key goal of the rice dhpf compiler project has been to develop optimization techniques that enable a wide range of existing scientific applications to be ported easily to efficient hpf with minimal restructuring. this paper describes the challenges to effective parallelization presented by complex but regular data parallel applications and then describes how the novel analysis and optimization technologies in the dhpf compiler address these challenges effectively without major rewriting of the applications. we illustrate the techniques by describing their use for parallelizing the nas sp and bt benchmarks. the dhpf compiler generates multipartitioned parallelizations of these codes that are approaching the scalability and efficiency of sophisticated hand coded parallelizations.
inspec,train_1234,achieving performance under openmp on ccnuma and software distributed shared memory systems. openmp is emerging as a viable high level programming model for shared memory parallel systems. it was conceived to enable easy portable application development on this range of systems and it has also been implemented on cache coherent non uniform memory access ccnuma architectures. unfortunately it is hard to obtain high performance on the latter architecture particularly when large numbers of threads are involved. in this paper we discuss the difficulties faced when writing openmp programs for ccnuma systems and explain how the vendors have attempted to overcome them. we focus on one such system the sgi origin 2000 and perform a variety of experiments designed to illustrate the impact of the vendor s efforts. we compare codes written in a standard loop level parallel style under openmp with alternative versions written in a single program multiple data spmd fashion also realized via openmp and show that the latter consistently provides superior performance. a carefully chosen set of language extensions can help us translate programs from the former style to the latter or to compile directly but in a similar manner. syntax for these extensions can be borrowed from hpf and some aspects of hpf compiler technology can help the translation process. it is our expectation that an extended language if well compiled would improve the attractiveness of openmp as a language for high performance computation on an important class of modern architectures.
inspec,train_1235,finding performance bugs with the tno hpf benchmark suite. high performance fortran hpf has been designed to provide portable performance on distributed memory machines. an important aspect of portable performance is the behavior of the available hpf compilers. ideally a programmer may expect comparable performance between different hpf compilers given the same program and the same machine. to test the performance portability between compilers we have designed a special benchmark suite called the tno hpf benchmark suite. it consists of a set of hpf programs that test various aspects of efficient parallel code generation. the benchmark suite consists of a number of template programs that are used to generate test programs with different array sizes alignments distributions and iteration spaces. it ranges from very simple assignments to more complex assignments such as triangular iteration spaces convex iteration spaces coupled subscripts and indirection arrays. we have run the tno hpf benchmark suite on three compilers the prepare prototype compiler the pgi hpf compiler and the gmd adaptor hpf compiler. results show performance differences that can be quite large up to two orders of magnitude for the same test program. closer inspection reveals that the origin of most of the differences in performance is due to differences in local enumeration and storage of distributed array elements.
inspec,train_1236,compatibility comparison and performance evaluation for japanese hpf compilers using scientific applications. the lack of compatibility of high performance fortran hpf between vender implementations has been disheartening scientific application users so as to hinder the development of portable programs. thus parallel computing is still unpopular in the computational science community even though parallel programming is common to the computer science community. as users would like to run the same source code on parallel machines with different architectures as fast as possible we have investigated the compatibility of source codes for japanese hpf compilers nec fujitsu and hitachi with two real world applications a 3d fluid code and a 2d particle code. we have found that the source level compatibility between japanese hpf compilers is almost preserved but more effort will be needed to sustain complete compatibility. we have also evaluated parallel performance and found that hpf can achieve good performance for the 3d fluid code with almost the same source code. for the 2d particle code good results have also been obtained with a small number of processors but some changes in the original source code and the addition of interface blocks is required.
inspec,train_1237,high performance numerical pricing methods. the pricing of financial derivatives is an important field in finance and constitutes a major component of financial management applications. the uncertainty of future events often makes analytic approaches infeasible and hence time consuming numerical simulations are required. in the aurora financial management system pricing is performed on the basis of lattice representations of stochastic multidimensional scenario processes using the monte carlo simulation and backward induction methods the latter allowing for the exploitation of shared memory parallelism. we present the parallelization of a backward induction numerical pricing kernel on a cluster of smps using hpf  an extended version of high performance fortran. based on language extensions for specifying a hierarchical mapping of data onto an smp cluster the compiler generates a hybrid parallel program combining distributed memory and shared memory parallelism. we outline the parallelization strategy adopted by the vfc compiler and present an experimental evaluation of the pricing kernel on an nec sx 5 vector supercomputer and a linux smp cluster comparing a pure mpi version to a hybrid parallel mpi openmp version.
inspec,train_1238,optimization of element by element fem in hpf 1 1. in this study poisson s equation is numerically evaluated by the element by element ebe finite element method in a parallel environment using hpf 1 1 high performance fortran. in order to achieve high parallel efficiency the data structures have been altered to node based data instead of mixtures of node and element based data representing a node based ebe finite element scheme nebe. the parallel machine used in this study was the nec sx 4 and experiments were performed on a single node having 32 processors sharing common memory. the hpf compiler used in the experiments is hpf sx rev 2 0 released in 1997 unofficial which supports hpf 1 1. models containing approximately 200 000 and 1 500 000 degrees of freedom were analyzed in order to evaluate the method. the calculation time parallel efficiency and memory used were compared. the performance of hpf in the conjugate gradient solver for the large model using the nec sx 4 compiler option noshrunk was about 85 that of the message passing interface.
inspec,train_1239,three dimensional global mhd simulation code for the earth s magnetosphere using hpf ja. we have translated a three dimensional magnetohydrodynamic mhd simulation code of the earth s magnetosphere from vpp fortran to hpf ja on the fujitsu vpp5000 56 vector parallel supercomputer and the mhd code was fully vectorized and fully parallelized in vpp fortran. the entire performance and capability of the hpf mhd code could be shown to be almost comparable to that of vpp fortran. a three dimensional global mhd simulation of the earth s magnetosphere was performed at a speed of over 400 gflops with an efficiency of 76 5 using 56 processing elements of the fujitsu vpp5000 56 in vector and parallel computation that permitted comparison with catalog values. we have concluded that fluid and mhd codes that are fully vectorized and fully parallelized in vpp fortran can be translated with relative ease to hpf ja and a code in hpf ja may be expected to perform comparably to the same code written in vpp fortran.
inspec,train_124,high speed cmos circuits with parallel dynamic logic and speed enhanced skewed static logic. in this paper we describe parallel dynamic logic pdl which exhibits high speed without charge sharing problem. pdl uses only parallel connected transistors for fast logic evaluation and is a good candidate for high speed low voltage operation. it has less back bias effect compared to other logic styles which use stacked transistors. furthermore pdl needs no signal ordering or tapering. pdl with speed enhanced skewed static logic renders straightforward logic synthesis without the usual area penalty due to logic duplication. our experimental results on two 32 bit carry lookahead adders using 0 25 mu m cmos technology show that pdl with speed enhanced skewed static sss look reduces the delay over clock delayed cd domino by 15 27 and the power delay product by 20 37.
inspec,train_1240,implementation and evaluation of hpf sx v2. we are developing hpf sx v2 a high performance fortran hpf compiler for vector parallel machines. it provides some unique extensions as well as the features of hpf 2 0 and hpf ja. in particular this paper describes four of them 1 the on directive of hpf 2 0 2 the reflect and local directives of hpf ja 3 vectorization directives and 4 automatic parallelization. we evaluate these features through some benchmark programs on nec sx 5. the results show that each of them achieved a 5 8 times speedup in 8 cpu parallel execution and the four features are useful for vector parallel execution. we also evaluate the overall performance of hpf sx v2 by using over 30 well known benchmark programs from hpfbench apr benchmarks genesis benchmarks and nas parallel benchmarks. about half of the programs showed good performance while the other half suggest weakness of the compiler especially on its runtimes. it is necessary to improve them to put the compiler to practical use.
inspec,train_1241,code generator for the hpf library and fortran 95 transformational functions. one of the language features of the core language of hpf 2 0 high performance fortran is the hpf library. the hpf library consists of 55 generic functions. the implementation of this library presents the challenge that all data types data kinds array ranks and input distributions need to be supported. for instance more than 2 billion separate functions are required to support copy scatter fully. the efficient support of these billions of specific functions is one of the outstanding problems of hpf. we have solved this problem by developing a library generator which utilizes the mechanism of parameterized templates. this mechanism allows the procedures to be instantiated at compile time for arguments with a specific type kind rank and distribution over a specific processor array. we describe the algorithms used in the different library functions. the implementation gives the ease of generating a large number of library routines from a single template. the templates can be extended with special code for specific combinations of the input arguments. we describe in detail the implementation and performance of the matrix multiplication template for the fujitsu vpp5000 platform.
inspec,train_1242,vpp fortran and the design of hpf ja extensions. vpp fortran is a data parallel language that has been designed for the vpp series of supercomputers. in addition to pure data parallelism it contains certain low level features that were designed to extract high performance from user programs. a comparison of vpp fortran and high performance fortran hpf 2 0 shows that these low level features are not available in hpf 2 0. the features include asynchronous interprocessor communication explicit shadow and the local directive. they were shown in vpp fortran to be very useful in handling real world applications and they have been included in the hpf ja extensions. they are described in the paper. the hpf ja language specification version 1 0 is an extension of hpf 2 0 to achieve practical performance for real world applications and is a result of collaboration in the japan association for hpf jahpf. some practical programming and tuning procedures with the hpf ja language specification are described using the nas parallel benchmark bt as an example.
inspec,train_1243,hpf ja extensions of high performance fortran for accelerating real world applications. this paper presents a set of extensions on high performance fortran hpf to make it more usable for parallelizing real world production codes. hpf has been effective for programs that a compiler can automatically optimize efficiently. however once the compiler can not there have been no ways for the users to explicitly parallelize or optimize their programs. in order to resolve the situation we have developed a set of hpf extensions hpf ja to give the users more control over sophisticated parallelization and communication optimizations. they include parallelization of loops with complicated reductions asynchronous communication user controllable shadow and communication pattern reuse for irregular remote data accesses. preliminary experiments have proved that the extensions are effective at increasing hpf s usability.
inspec,train_1244,applied ethics in business information units. the primary thesis of this paper is that business information professionals commonly overlook ethical dilemmas in the workplace. although the thesis remains unproven the author highlights by way of real and hypothetical case studies a number of situations in which ethical tensions can be identified and suggests that information professionals need to be more aware of the moral context of their actions. resolving ethical dilemmas should be one of the aims of competent information professionals and their managers although it is recognized that dilemmas often can not easily be resolved. a background to the main theories of applied ethics forms the framework for later discussion.
inspec,train_1245,a brief guide to competitive intelligence how to gather and use information on competitors. the author outlines the processes involved in competitive intelligence and discusses what it is how to do it and gives examples of what happens when companies fail to monitor their competitive environment effectively. the author presents a case study showing how the company that produced the pre cursor to the barbie doll failed to look at their business environment and how this led to the firm s failure. the author discusses what competitive intelligence is and what it is not and why it is important for businesses and presents three models used to describe the competitive intelligence process going through the various steps involved in defining intelligence requirements and collecting analyzing communicating and utilizing competitive intelligence.
inspec,train_1246,why information departments are becoming academic. this article outlines the increasing convergence between academia and business over the last decade or so and the mutual benefits that this closer association has brought. it also looks at the growing importance of the information profession suggesting that this is leading to a greater need for specialist skills as reflected by the rise in academic courses in this area. however it argues that increasing specialization must not lead to insularity if information professionals are truly concerned with gaining a competitive advantage they must not close their minds to the potential benefits of working with external non specialist partners. the benefits that business has reaped from academia it is contended suggest that this may also be a fruitful avenue for information departments to explore.
inspec,train_1247,the changing landscape for multi access portals. discusses the factors that have made life difficult for consumer portal operators in recent years causing them like others in the telecommunications media and technology sector to take a close look at their business models following the dot com crash and the consequent reassessment of internet related project financing by the venture capital community. while the pressure is on to generate income from existing customers and users portal operators must reach new markets and find realistic revenue streams. this search for real revenues has led to a move towards charging for content a strategy being pursued by a large number of horizontal portal players including msn and terra lycos. this trend is particularly noticeable in china where chinadotcom operates a mainland portal and plans a range of fee based services including electronic mail. the nature of advertising itself is changing with portals seeking blue chip sponsorship and marketing deals that span a number of years. players are struggling to redefine and reinvent themselves as a result of the changing environment and even the term portal is believed to be obsolete partly due to its dot com crash associations. multi access portals are expected to dominate the consumer sector becoming bigger and better overall than their predecessors and playing a more powerful role in the consumer environment.
inspec,train_1248,public business libraries the next chapter. traces the history of the provision of business information by leeds public libraries uk from the opening of the public commercial and technical library in 1918 to the revolutionary impact of the internet in the 1990s. describes how the library came to terms with the need to integrate the internet into its mainstream business information services with particular reference to its limitations and to the provision of company information market research british standards information press cuttings and articles from specialized trade and scientific journals and patents information. focuses on some of the reasons why the public business library is still needed as a service to businesses even after the introduction of the internet and considers the library s changing role and the need to impress on all concerned especially government the continuing value of these services. looks to the partnerships formed by the library over the years and the ways in which these are expected to assist in realizing future opportunities in particular the fact that all public libraries in england gained free internet access at the end of 2001. offers some useful ideas about how the library could develop noting that sinto a sheffield based information network formed in 1938 and originally a partnership between the public library the two sheffield universities and various leading steel companies of the time is being examined as a model for future services in leeds. concludes that the way forward can be defined in terms of five actions redefinition of priorities marketing budgets resources and the use of information technology it.
inspec,train_1249,aggregators versus disintermediators battling it out in the information superhighstreet. perhaps the future of large scale content aggregators is now no longer in doubt but this was not the case 10 years ago when many leading industry experts were much more pessimistic in their predictions. in the year that dialog celebrates its thirtieth anniversary as the world s oldest and largest professional online information service it is appropriate to look back at these changing perceptions the reasons for these changes and why the experts got it wrong. we also look at the present day the value that large scale content aggregators bring to the information supply chain and we discuss why users would choose to use aggregators as opposed to going directly to the publishers.
inspec,train_125,a fast implementation of correlation of long data sequences for coherent receivers. coherent reception depends upon matching of phase between the transmitted and received signal. fast convolution techniques based on fast fourier transform fft are widely used for extracting time delay information from such matching. the latency in processing a large data window of the received signal is a serious overhead for mission critical real time applications. the implementation of a parallel algorithm for correlation of long data sequences in multiprocessor environment is demonstrated here. the algorithm does processing while acquiring the received signal and reduces the computation overhead considerably because of inherent parallelism.
inspec,train_1250,the impact and implementation of xml on business to business commerce. this paper discusses the impact analysis of the extensible markup language xml. each business partner within a supply chain will be allowed to generate its own data exchange format by adopting an xml meta data management system in the local side. followed after a brief introduction of the information technology for business to customer b2c and business to business b2b electronic commerce ec the impact of xml on the tomorrow business world is discussed. a real case study for impact analysis on information exchange platform microsoft s biztalk platform which is actually an xml schema builder and the implementation of xml commerce application will provide an interest insight for users future implementation.
inspec,train_1251,a synergic analysis for web based enterprise resources planning systems. as the central nervous system for managing an organization s mission and critical business data enterprise resource planning erp system has evolved to become the backbone of e business implementation. since an erp system is multimodule application software that helps a company manage its important business functions it should be versatile enough to automate every aspect of business processes including e business.
inspec,train_1252,an agent oriented and service oriented environment for deploying dynamic distributed systems. this paper presents jase a java based agent oriented and service oriented environment for deploying dynamic distributed systems. jase utilizes two important concepts in the field of distributed computing the concept of services and remote programming with mobile agents. in jase mobile agents are used to support applications and service interface agents are used to wrap services. service inter face agents can dynamically register their services in service server. mobile agent locates a specific service interface agent by submitting requests to the service server with descriptions of required services. jase uses xml to describe both service descriptions and the mobile agent s queries. jase supports two kinds of communication facility tuple space and asynchronous messages. in this paper the design and implementation of jase are described. an application shows the suitability and the effectiveness of the jase and performance evaluation is also made. finally related work and some conclusions are given.
inspec,train_1253,application of xml for neural network exchange. this article introduces a framework for the interchange of trained neural network models. an xml based language neural network markup language for the neural network model description is offered. it allows to write down all the components of neural network model which are necessary for its reproduction. we propose to use xml notation for the full description of neural models including data dictionary properties of training sample preprocessing methods details of network structure and parameters and methods for network output interpretation.
inspec,train_1254,supporting unified interface to wrapper generator in integrated information retrieval. given the ever increasing scale and diversity of information and applications on the internet improving the technology of information retrieval is an urgent research objective. retrieved information is either semi structured or unstructured in format and its sources are extremely heterogeneous. in consequence the task of efficiently gathering and extracting information from documents can be both difficult and tedious. given this variety of sources and formats many choose to use mediator wrapper architecture but its use demands a fast means of generating efficient wrappers. in this paper we present a design for an automatic extensible markup language xml based framework with which to generate wrappers rapidly. wrappers created with this framework support a unified interface for a meta search information retrieval system based on the internet search service using the common object request broker architecture corba standard. greatly advantaged by the compatibility of corba and xml a user can quickly and easily develop information gathering applications such as a meta search engine or any other information source retrieval method. the two main things our design provides are a method of wrapper generation that is fast simple and efficient and a wrapper generator that is corba and xml compliant and that supports a unified interface.
inspec,train_1255,succession in standardization grafting xml onto sgml. succession in standardization is often a problem. the advantages of improvements must be weighed against those of compatibility. if compatibility considerations dominate a grafting process takes place. according to our taxonomy of succession there are three types of outcomes. a type i succession where grafting is successful entails compatibility between successors technical paradigm compliance and continuity in the standards trajectory. in this paper we examine issues of succession and focus on the extensible markup language xml. it was to be grafted on the standard generalized markup language sgml a stable standard since 1988. however xml was a profile a subset and an extension of sgml 1988. adaptation of sgml was needed sgml 1999 to forge full downward compatibility with xml 1998. we describe the grafting efforts and analyze their outcomes. our conclusion is that although sgml was a technical exemplar for xml developers full compatibility was not achieved. the widespread use of hypertext mark up language html exemplified the desirability of simplicity in xml standardization. this and html s user market largely explain the discontinuity in sgml xml succession.
inspec,train_1256,high speed consistency checking for hypothetical reasoning systems using inference path network. hypothetical reasoning is popular in fault diagnostics and design systems but slow reasoning speed is its drawback. the goal of the current study is developing hypothetical reasoning based on an inference path network which would overcome this drawback. in hypothetical reasoning systems based on an inference path network there is much room for improvement regarding the computing costs of connotation processing and consistency checking. the authors of this study demonstrate improvement ideas regarding one of these problems namely consistency checking. first the authors obtained necessary and sufficient conditions under which inconsistencies occur during hypothesis composition. based on the obtained results the authors proposed an algorithm for speeding up the process of consistency checking. processing with this algorithm in its core consists of transforming the inference path network in such a way that inconsistencies do not occur during the hypothesis composition under the condition of unchanged solution hypotheses. the efficiency of this algorithm was confirmed by tests.
inspec,train_1257,definition of a similarity measure between cases based on auto cross fuzzy thesauri. a similarity measure between cases is needed in order to evaluate the degree of similarity when using past similar cases in order to resolve current problems. in similar case retrieval multiple indices are set up in order to characterize the queries and individual cases then terms are given as values to each. the similarity measure between cases commonly used is defined using the rate at which the values provided from the corresponding indices match. in practice however values can not be expected to be mutually exclusive. as a result a natural expansion of this approach is to have relationships in which mutually similar meanings are reflected in the similarity measure between cases. in this paper the authors consider an auto fuzzy thesaurus which gives the relationship for values between corresponding indices and a cross fuzzy thesaurus which gives the relationship for values between mutually distinct indices then defines a similarity measure between cases which considers the relationship of index values based on these thesauri. this definition satisfies the characteristics required for the operation of case based retrieval even when one value is not necessarily given in the index. finally using a test similar case retrieval system the authors perform a comparative analysis of the proposed similarity measure between cases and a conventional approach.
inspec,train_1258,implementation and performance evaluation of a fifo queue class library for time warp. the authors describe the implementation use and performance evaluation of a fifo queue class library by means of a high performance easy to use interface employed for queuing simulations in parallel discrete simulations based on the time warp method. various general purpose simulation libraries and languages have been proposed and among these some have the advantage of not requiring users to define anything other than the state vector and not needing awareness of rollback under a platform which performs state control based on copies. however because the state vectors must be defined as simple data structures without pointers dynamic data structures such as a fifo queue can not be handled directly. under the proposed class library both the platform and the user can handle such structures in the same fashion that embedded data structures are handled. in addition instead of all stored data just the operational history can be stored and recovered efficiently at an effectively minimal cost by taking advantage of the first in first out characteristics of the above data structures. when the kernel deletes past state histories during a simulation garbage collection is also performed transparently using the corresponding method.
inspec,train_1259,a mechanism for inferring approximate solutions under incomplete knowledge based on rule similarity. this paper proposes an inference method which can obtain an approximate solution even if the knowledge stored in the problem solving system is incomplete. when a rule needed for solving the problem does not exist the problem can be solved by using rules similar to the existing rules. in an implementation using the sld procedure a resolution is executed between a subgoal and a rule if an atom of the subgoal is similar to the consequence atom of the rule. similarities between atoms are calculated using a knowledge base of words with account of the reasoning situation and the reliability of the derived solution is calculated based on these similarities. if many solutions are obtained they are grouped into classes of similar solutions and a representative solution is then selected for each class. the proposed method was verified experimentally by solving simple problems.
inspec,train_126,a new architecture for implementing pipelined fir adf based on classification of coefficients. in this paper we propose a new method for implementing pipelined finite impulse response fir adaptive digital filter adf with an aim of reducing the maximum delay of the filtering portion of conventional delayed least mean square dlms pipelined adf. we achieve a filtering section with a maximum delay of one by simplifying a pre upsampled and a post downsampled fir filter using the concept of classification of coefficients. this reduction is independent of the order of the filter which is an advantage when the order of the filter is very large and as a result the method can also be applied to infinite impulse response iir filters. furthermore when the proposed method is compared with the transpose adf which has a filtering section with zero delay it is realized that it significantly reduces the maximum delay associated with updating the coefficients of fir adf. the effect of this is that the proposed method exhibits a higher convergence speed in comparison to the transpose fir adf.
inspec,train_1260,a dataflow computer which accelerates execution of sequential programs by precedent firing instructions. in the dataflow machine it is important to avoid degradation of performance in sequential processing and it is important from the viewpoint of hardware scale to reduce the number of waiting operands. this paper demonstrates that processing performance is degraded by sequential processing in the switching process and presents a method of remedy. precedent firing control is proposed as a means of remedy and it is shown by a simulation that the execution time and the total number of waiting operands can be reduced by the precedent firing control. then the hardware scale is examined as an evaluation of precedent firing control.
inspec,train_1261,topology adaptive modeling of objects using surface evolutions based on 3d mathematical morphology. level set methods were proposed mainly by mathematicians for constructing a model of a 3d object of arbitrary topology. however those methods are computationally inefficient due to repeated distance transformations and increased dimensions. in the paper we propose a new method of modeling fast objects of arbitrary topology by using a surface evolution approach based on mathematical morphology. given sensor data covering the whole object surface the method begins with an initial approximation of the object by evolving a closed surface into a model topologically equivalent to the real object. the refined approximation is then performed using energy minimization. the method has been applied in several experiments using range data and the results are reported in the paper.
inspec,train_1262,the development and evaluation of shoke2000 the pci based fpga card. this paper describes a pci based fpga card shoke2000 which was developed in order to study reconfigurable computing. since the latest field programmable gate arrays fpga consist of input output i o configurable blocks as well as internal configurable logic blocks they not only realize various user logic circuits but also connect with popular i o standards easily. these features enable fpga to connect several devices with different interfaces and thus new reconfigurable systems would be realizable by connecting the fpga with devices such as digital signal processors dsp and analog devices. this paper describes the basic functions of shoke2000 which was developed for realizing hybrid reconfigurable systems consisting of fpga dsp and analog devices. we also present application examples of shoke2000 including a simple image recognition application a distributed shared memory computer cluster and teaching materials for computer education.
inspec,train_1263,super high definition image whd wide double hd transmission system. this paper describes a whd image transmission system constructed from a display projector codecs and a camera system imaging a super high definition image whd wide double hd corresponding to two screen portions of common high vision images. this system was developed as a transmission system to communicate with or transmit information giving a reality enhanced feeling to a remote location by using images of super high definition. in addition the correction processing for the distortions of images occurring due to the structure of the camera system an outline of the transmission experiments using the proposed system and subjective evaluation experiments using whd images are presented.
inspec,train_1264,estimation of the vanishing point for automatic driving system using a cross ratio. this paper proposes a new method to estimate the vanishing point used as the vehicle heading which is essential in automatic driving systems. the proposed method uses a cross ratio comprised of a ratio of lengths from four collinear points for extracting the edges that shape the vanishing point. then lines that intersect at one point are fitted to the edges in a hough space. consequently the vanishing point is estimated robustly even when the lane markings are occluded by other vehicles. in the presence of lane markings the road boundaries are also estimated at the same time. experimental results from images of a real road scene show the effectiveness of the proposed method.
inspec,train_1265,optimization of requantization parameter for mpeg transcoding. this paper considers transcoding in which an mpeg stream is converted to a low bit rate mpeg stream and proposes a method in which the transcoding error can be reduced by optimally selecting the quantization parameter for each macroblock. in transcoding with a low compression ratio it is crucial to prohibit transcoding with a requantization parameter which is 1 to 2 times the quantization parameter of the input stream. consequently as the first step an optimization method for the requantization parameter is proposed which cares for the error propagation effect by interframe prediction. then the proposed optimization method is extended so that the method can also be applied to the case of a high compression ratio in which the rate distortion curve is approximated for each macroblock in the range of requantization parameters larger than 2 times the quantization parameter. it is verified by a simulation experiment that the psnr is improved by 0 5 to 0 8 db compared to the case in which a 6 mbit s mpeg stream is not optimized by twofold recompression.
inspec,train_1266,an intelligent information gathering method for dynamic information mediators. the internet is spreading into our society rapidly and is becoming one of the information infrastructures that are indispensable for our daily life. in particular the www is widely used for various purposes such as sharing personal information academic research business work and electronic commerce and the amount of available information is increasing rapidly. we usually utilize information sources on the internet as individual stand alone sources but if we can integrate them we can add more value to each of them. hence information mediators which integrate information distributed on the internet are drawing attention. in this paper under the assumption that the information sources to be integrated are updated frequently and asynchronously we propose an information gathering method that constructs an answer to a query from a user accessing information sources to be integrated properly within an allowable time period. the proposed method considers the reliability of data in the cache and the quality of answer in order to efficiently access information sources and to provide appropriate answers to the user. as evaluation we show the effectiveness of the proposed method by using an artificial information integration problem in which some parameters can be modified and a real world flight information service compared with a conventional fifo information gathering method.
inspec,train_1267,3d reconstruction from uncalibrated camera optical flow and its reliability evaluation. we present a scheme for reconstructing a 3d structure from optical flow observed by a camera with an unknown focal length in a statistically optimal way as well as evaluating the reliability of the computed shape. first the flow fundamental matrices are optimally computed from the observed flow. they are then decomposed into the focal length its rate of change and the motion parameters. next the flow is optimally corrected so that it satisfies the epipolar equation exactly. finally the 3d positions are computed and their covariance matrices are evaluated. by simulations and real image experiments we test the performance of our system and observe how the normalization gauge for removing indeterminacy affects the description of uncertainty.
inspec,train_1268,reachability in contextual nets. contextual nets or petri nets with read arcs are models of concurrent systems with context dependent actions. the problem of reachability in such nets consists in finding a sequence of transitions that leads from the initial marking of a given contextual net to a given goal marking. the solution to this problem that is presented in this paper consists in constructing a finite complete prefix of the unfolding of the given contextual net that is a finite prefix in which all the markings that are reachable from the initial marking are present and in searching in each branch of this prefix for the goal marking by solving an appropriate linear programming problem.
inspec,train_1269,minimizing the number of successor states in the stubborn set method. combinatorial explosion which occurs in parallel compositions of ltss can be alleviated by letting the stubborn set method construct on the fly a reduced lts that is cffd or csp equivalent to the actual parallel composition. this article considers the problem of minimizing the number of successor states of a given state in the reduced lts. the problem can be solved by constructing an and or graph with weighted vertices and by finding a set of vertices that satisfies a certain constraint such that no set of vertices satisfying the constraint has a smaller sum of weights. without weights the and or graph can be constructed in low degree polynomial time w r t the length of the input of the problem. however since actions can be nondeterministic and transitions can share target states it is not known whether the weights are generally computable in polynomial time. consequently it is an open problem whether minimizing the number of successor states is as easy as minimizing the number of successor transitions.
inspec,train_127,asymptotical stability in discrete time neural networks. in this work we present a proof of the existence of a fixed point and a generalized sufficient condition that guarantees the stability of it in discrete time neural networks by using the lyapunov function method. we also show that for both symmetric and asymmetric connections the unique attractor is a fixed point when several conditions are satisfied. this is an extended result of chen and aihara see physica d vol. 104 no 3 4 p 286 325 1997. in particular we further study the stability of equilibrium in discrete time neural networks with the connection weight matrix in form of an interval matrix. finally several examples are shown to illustrate and reinforce our theory.
inspec,train_1270,a comparison of different decision algorithms used in volumetric storm cells classification. decision algorithms useful in classifying meteorological volumetric radar data are discussed. such data come from the radar decision support system rdss database of environment canada and concern summer storms created in this country. some research groups used the data completed by rdss for verifying the utility of chosen methods in volumetric storm cells classification. the paper consists of a review of experiments that were made on the data from rdss database of environment canada and presents the quality of particular classifiers. the classification accuracy coefficient is used to express the quality. for five research groups that led their experiments in a similar way it was possible to compare received outputs. experiments showed that the support vector machine svm method and rough set algorithms which use object oriented reducts for rule generation to classify volumetric storm data perform better than other classifiers.
inspec,train_1271,verification of non functional properties of a composable architecture with petri nets. in this paper we introduce our concept of composability and present the mss architecture as an example for a composable architecture. mss claims to be composable with respect to timing properties. we discuss how to model and prove properties in such an architecture with time extended petrinets. as a result the first step of a proof of composability is presented as well as a new kind of petri net which is more suitable for modeling architectures like mss.
inspec,train_1272,global action rules in distributed knowledge systems. previously z ras and j m zytkow 2000 introduced and investigated query answering system based on distributed knowledge mining. the notion of an action rule was introduced by z ras and a wieczorkowska 2000 and its application domain e business was taken. in this paper we generalize the notion of action rules in a similar way to handling global queries. mainly when values of attributes for a given customer used in action rules can not be easily changed by business user definitions of these attributes are extracted from other sites of a distributed knowledge system. to be more precise attributes at every site of a distributed knowledge system are divided into two sets stable and flexible. values of flexible attributes for a given consumer sometime can be changed and this change can be influenced and controlled by a business user. however some of these changes for instance to the attribute profit can not be done directly to a chosen attribute. in this case definitions of such an attribute in terms of other attributes have to be learned. these new definitions are used to construct action rules showing what changes in values of flexible attributes for a given consumer are needed in order to re classify this consumer the way business user wants. but business user may be either unable or unwilling to proceed with actions leading to such changes. in all such cases we may search for definitions of these flexible attributes looking at either local or remote sites for help.
inspec,train_1273,towards an ontology of approximate reason. this article introduces structural aspects in an ontology of approximate reason. the basic assumption in this ontology is that approximate reason is a capability of an agent. agents are designed to classify information granules derived from sensors that respond to stimuli in the environment of an agent or received from other agents. classification of information granules is carried out in the context of parameterized approximation spaces and a calculus of granules. judgment in agents is a faculty of thinking about classifying the particular relative to decision rules derived from data. judgment in agents is reflective but not in the classical philosophical sense e g the notion of judgment in kant. in an agent a reflective judgment itself is an assertion that a particular decision rule derived from data is applicable to an object input. that is a reflective judgment by an agent is an assertion that a particular vector of attribute sensor values matches to some degree the conditions for a particular rule. in effect this form of judgment is an assertion that a vector of sensor values reflects a known property of data expressed by a decision rule. since the reasoning underlying a reflective judgment is inductive and surjective not based on a priori conditions or universals this form of judgment is reflective but not in the sense of kant. unlike kant a reflective judgment is surjective in the sense that it maps experimental attribute values onto the most closely matching descriptors conditions in a derived rule. again unlike kant s notion of judgment a reflective judgment is not the result of searching for a universal that pertains to a particular set of values of descriptors. rather a reflective judgment by an agent is a form of recognition that a particular vector of sensor values pertains to a particular rule in some degree. this recognition takes the form of an assertion that a particular descriptor vector is associated with a particular decision rule. these considerations can be repeated for other forms of classifiers besides those defined by decision rules.
inspec,train_1274,bounded model checking for the universal fragment of ctl. bounded model checking bmc has been recently introduced as an efficient verification method for reactive systems. bmc based on sat methods consists in searching for a counterexample of a particular length and generating a propositional formula that is satisfiable iff such a counterexample exists. this new technique has been introduced by e clarke et al for model checking of linear time temporal logic ltl. our paper shows how the concept of bounded model checking can be extended to actl the universal fragment of ctl. the implementation of the algorithm for elementary net systems is described together with the experimental results.
inspec,train_1275,modeling dynamic objects in distributed systems with nested petri nets. nested petri nets np nets is a petri net extension allowing tokens in a net marking to be represented by marked nets themselves. the paper discusses applicability of np nets for modeling task planning systems multi agent systems and recursive parallel systems. a comparison of np nets with some other formalisms such as opns of r valk 2000 recursive parallel programs of o kushnarenko and ph schnoebelen 1997 and process algebras is given. some aspects of decidability for object oriented petri net extensions are also discussed.
inspec,train_1276,a comparative study of some generalized rough approximations. in this paper we focus upon a comparison of some generalized rough approximations of sets where the classical indiscernibility relation is generalized to any binary reflexive relation. we aim at finding the best of several candidates for generalized rough approximation mappings where both definability of sets by elementary granules of information as well as the issue of distinction among positive negative and border regions of a set are taken into account.
inspec,train_1277,dynamic modification of object petri nets. an application to modelling protocols with fork join structures. in this paper we discuss possibilities of modelling protocols by objects in object based high level petri nets. some advantages of dynamically modifying the structure of token objects are discussed and the need for further investigations into mathematically rigorous foundations of object net formalisms incorporating facilities for such operations on its token nets is emphasised.
inspec,train_1278,verification of timed automata based on similarity. the paper presents a modification of the standard partitioning technique to generate abstract state spaces preserving similarity for timed automata. since this relation is weaker than bisimilarity most of the obtained models state spaces are smaller than bisimilar ones but still preserve the universal fragments of branching time temporal logics. the theoretical results are exemplified for strong delay and observational simulation relations.
inspec,train_1279,place transition petri net evolutions recording ways analysis and synthesis. four semantic domains for place transition petri nets and their relationships are considered. they are monoids of respectively firing sequences processes traces and dependence graphs. for each of them the analysis and synthesis problem is stated and solved. the monoid of processes is defined in a non standard way nets under consideration involve weights of arrows and capacities finite or infinite of places. however the analysis and synthesis tasks require nets to be pure i e each of their transition must have the pre set and post set disjoint.
inspec,train_128,a new result on the global convergence of hopfield neural networks. in this work we discuss hopfield neural networks investigating their global stability. some sufficient conditions for a class of hopfield neural networks to be globally stable and globally exponentially stable are given.
inspec,train_1280,products and polymorphic subtypes. this paper is devoted to a comprehensive study of polymorphic subtypes with products. we first present a sound and complete hilbert style axiomatization of the relation of being a subtype in presence of to  type constructors and the for all quantifier and we show that such axiornatization is not encodable in the system with to for all only. in order to give a logical semantics to such a subtyping relation we propose a new form of a sequent which plays a key role in a natural deduction and a gentzen style calculi. interestingly enough the sequent must have the form e implies t where e is a non commutative non empty sequence of typing assumptions and t is a finite binary tree of typing judgements each of them behaving like a pushdown store. we study basic metamathematical properties of the two logical systems such as subject reduction and cut elimination. some decidability undecidability issues related to the presented subtyping relation are also explored as expected the subtyping over to  for all is undecidable being already undecidable for the to for all fragment as proved in 15 but for the  for all fragment it turns out to be decidable.
inspec,train_1281,a notion of non interference for timed automata. the non interference property of concurrent systems is a security property concerning the flow of information among different levels of security of the system. in this paper we introduce a notion of timed non interference for real time systems specified by timed automata. the notion is presented using an automata based approach and then it is characterized also by operations and equivalence between timed languages. the definition is applied to an example of a time critical system modeling a simplified control of an airplane.
inspec,train_1282,completeness of timed mu crl. previously a straightforward extension of the process algebra mu crl was proposed to explicitly deal with time. the process algebra mu crl has been especially designed to deal with data in a process algebraic context. using the features for data only a minor extension of the language was needed to obtain a very expressive variant of time. previously it contained syntax operational semantics and axioms characterising timed mu crl. it did not contain an in depth analysis of theory of timed mu crl. this paper fills this gap by providing soundness and completeness results. the main tool to establish these is a mapping of timed to untimed mu crl and employing the completeness results obtained for untimed mu crl.
inspec,train_1283,upsilon universal programming system with incomplete lazy object notation. this paper presents a new model of computation that differs from prior models in that it emphasizes data over flow control has no named variables and has an object oriented flavor. we prove that this model is a complete and confluent acceptable programming system and has a usable type theory. a new data synchronization primitive is introduced in order to achieve the above properties. subtle variations of the model are shown to fall short of having all these necessary properties.
inspec,train_1284,a linear time special case for mc games. mc games are infinite duration two player games played on graphs. deciding the winner in mc games is equivalent to the the modal mu calculus model checking. in this article we provide a linear time algorithm for a class of mc games. we show that if all cycles in each strongly connected component of the game graph have at least one common vertex the winner can be found in linear time. our results hold also for parity games which are equivalent to mc games.
inspec,train_1285,on fractal dimension in information systems. toward exact sets in infinite information systems. the notions of an exact as well as a rough set are well grounded as basic notions in rough set theory. they are however defined in the setting of a finite information system i e an information system having finite numbers of objects as well as attributes. in theoretical studies e g of topological properties of rough sets one has to trespass this limitation and to consider information systems with potentially unbound number of attributes. in such setting the notions of rough and exact sets may be defined in terms of topological operators of interior and closure with respect to an appropriate topology following the ideas from the finite case where it is noticed that in the finite case rough set theoretic operators of lower and upper approximation are identical with the interior respectively closure operators in topology induced by equivalence classes of the indiscernibility relation. extensions of finite information systems are also desirable from application point of view in the area of knowledge discovery and data mining when demands of e g mass collaboration and or huge experimental data call for need of working with large data tables so the sound theoretical generalization of these cases is an information system with the number of attributes not bound in advance by a fixed integer i e an information system with countably but infinitely many attributes in large information systems a need arises for qualitative measures of complexity of concepts involved free of parameters cf e g applications for the vapnik czervonenkis dimension. we study here in the theoretical setting of infinite information system a proposal to apply fractal dimensions suitably modified as measures of concept complexity.
inspec,train_1286,self describing turing machines. after a sketchy historical account on the question of self describeness and self reproduction and after discussing the definition of suitable encodings for self describeness we give the construction of several self describing turing machines namely self describing machines with respectively 350 267 224 and 206 instructions.
inspec,train_1287,on average depth of decision trees implementing boolean functions. the article considers the representation of boolean functions in the form of decision trees. it presents the bounds on average time complexity of decision trees for all classes of boolean functions that are closed over substitution and the insertion and deletion of unessential variables. the obtained results are compared with the results developed by m ju. moshkov 1995 that describe the worst case time complexity of decision trees.
inspec,train_1288,a modal logic for indiscernibility and complementarity in information systems. in this paper we study indiscernibility relations and complementarity relations in information systems the first order characterization of indiscernibility and complementarity is obtained through a duality result between information systems and certain structures of relational type characterized by first order conditions. the modal analysis of indiscernibility and complementarity is performed through a modal logic which modalities correspond to indiscernibility relations and complementarity relations in information systems.
inspec,train_1289,combining pc control and hmi. integrating pc based control with human machine interface hmi technology can benefit a plant floor system. however before one decides on pc based control there are many things one should consider especially when using a soft programmable logic controller plc to command the input output. there are three strategies to integrate a pc based control system with an hmi treat the pc running the control application as if it were a plc integrate the system using standard pc interfaces or using application programming interfaces.
inspec,train_129,phase conditions for schur polynomials. the rate of change of phase of a real or complex schur polynomial evaluated along the unit circle traversed counterclockwise is strictly positive. for polynomials with real coefficients this bound can be tightened. these and some other fundamental bounds on the rate of change of phase are derived here using the tchebyshev representation of the image of a real polynomial evaluated on the unit circle.
inspec,train_1290,making the mis integration process work. focused cross functional teams that implement flexible and scalable information systems is can deliver a smooth lean manufacturing process. when integrating new technology into an existing facility one should always consider three things the hard infrastructure the soft infrastructure and information flow. hard infrastructure includes client and server hardware and network infrastructure. soft infrastructure includes operating systems existing or legacy software needed code customizations and the human resources to run support the system. information flow includes how data in the new system interacts with legacy systems and what legacy data the new system will require as well as who will want to receive access the information that is held by the system.
inspec,train_1291,taking back control scada system. most common way to implement a scada system is to go outside. however in the author s opinion to truly take control of a scada project in house personnel should handle as much of the job as possible. this includes design equipment specification installation and programming. the more of these tasks one does in house the more control and ownership one has. to accomplish this we first evaluated the existing scada system and investigated new technologies to establish a list of features the new system needed to incorporate.
inspec,train_1292,the heat is on building automation systems. integrating building automation systems bass can result in systems that have the ability to sense changes in the air temperature through a building s heating ventilation and air conditioning hvac systems. taking advantages of the internet using remote monitoring and building interoperability through open protocol systems are some of the issues discussed throughout the bas hvac community. by putting information over the internet facility managers get real time data on energy usage and performance issues.
inspec,train_1293,truss topology optimization by a modified genetic algorithm. this paper describes the use of a stochastic search procedure based on genetic algorithms for developing near optimal topologies of load bearing truss structures. most existing cases these publications express the truss topology as a combination of members. these methods however have the disadvantage that the resulting topology may include needless members or those which overlap other members. in addition to these problems the generated structures are not necessarily structurally stable. a new method which resolves these problems by expressing the truss topology as a combination of triangles is proposed in this paper. details of the proposed methodology are presented as well as the results of numerical examples that clearly show the effectiveness and efficiency of the method.
inspec,train_1294,multicriterion optimization of composite laminates for maximum failure margins with an interactive descent algorithm. an interactive multicriterion optimization method for composite laminates subjected to multiple loading conditions is introduced. laminate margins to initial failure first ply failure fpf with respect of the applied loading conditions are treated as criteria. the original problem is reduced to a bicriterion problem by introducing parameters to combine criteria in a linear manner. the problem is solved by using an interactive descent algorithm. both the conditions required for a discrete procedure to converge towards a pareto optimum and numerical examples are given.
inspec,train_1295,development of visual design steering as an aid in large scale multidisciplinary design optimization. ii. method validation. for pt. i see ibid pp 412 24. graph morphing the first concept developed under the newly proposed paradigm of visual design steering vds is applied to optimal design problems. graph morphing described in part i of this paper can be used to provide insights to a designer to improve efficiency reliability and accuracy of an optimal design in less cycle time. it is demonstrated in this part of the paper that graph morphing can be used to provide insights into design variable impact constraint redundancy reasonable values for constraint allowable limits and function smoothness that otherwise might not be attainable.
inspec,train_1296,development of visual design steering as an aid in large scale multidisciplinary design optimization. i method development. a modified paradigm of computational steering cs termed visual design steering vds is developed in this paper. the vds paradigm is applied to optimal design problems to provide a means for capturing and enabling designer insights. vds allows a designer to make decisions before during or after an analysis or optimization via a visual environment in order to effectively steer the solution process. the objective of vds is to obtain a better solution in less time through the use of designer knowledge and expertise. using visual representations of complex systems in this manner enables human experience and judgement to be incorporated into the optimal design process at appropriate steps rather than having traditional black box solvers return solutions from a prescribed input set. part i of this paper focuses on the research issues pertaining to the graph morphing visualization method created to represent an n dimensional optimization problem using 2 dimensional and 3 dimensional visualizations. part ii investigates the implementation of the vds paradigm using the graph morphing approach to improve an optimal design process. specifically the following issues are addressed impact of design variable changes on the optimal design space identification of possible constraint redundancies impact of constraint tolerances on the optimal solution and smoothness of the objective function contours. it is demonstrated that graph morphing can effectively reduce the complexity and computational time associated with some optimization problems.
inspec,train_1297,stochastic optimization of acoustic response a numerical and experimental comparison. the objective of the work presented is to compare results from numerical optimization with experimental data and to highlight and discuss the differences between two fundamentally different optimization methods. the problem domain is minimization of acoustic emission and the structure used in the work is a closed cylinder with forced vibration of one end. the optimization method used in this paper is simulated annealing sa a stochastic method. the results are compared with those from a gradient based method used on the same structure in an earlier paper tinnsten 2000.
inspec,train_1298,an analytical model for a composite adaptive rectangular structure using the heaviside function. the objective of this article is to describe a mathematical model based on the heaviside function and on the delta dirac distribution for a composite adaptive rectangular structure with embedded and or bonded piezoelectric actuators and sensors. in the adopted structure model the laminae are made up a configuration of rectangular nonpiezoelectric and piezoelectric patches. the laminae do not all have the same area nor do they present the same configuration such that there are points where there is no material. the equations of motion and the boundary conditions which describe the electromechanical coupling are based on the mindlin displacement field on the linear theory of piezoelectricity and on the hamilton principle.
inspec,train_1299,how much should publishers spend on technology. a study confirms that spending on publishing specific information technology it resources is growing much faster than it spending for general business activities at least among leading publishers in the scientific technical and medical stm market. the survey asked about information technology funding and staffing levels past present and future and also inquired about activities in content management web delivery computer support and customer relationship management. the results provide a starting point for measuring information technology growth and budget allocations in this publishing segment.
inspec,train_13,stability analysis of the characteristic polynomials whose coefficients are polynomials of interval parameters using monotonicity. we analyze the stability of the characteristic polynomials whose coefficients are polynomials of interval parameters via monotonicity methods. our stability conditions are based on frazer duncan s theorem and all conditions can be checked using only endpoint values of interval parameters. these stability conditions are necessary and sufficient under the monotonicity assumptions. when the monotonicity conditions do not hold on the whole parameter region we present an interval division method and a transformation algorithm in order to apply the monotonicity conditions. then our stability analysis methods can be applied to all characteristic polynomials whose coefficients are polynomials of interval parameters.
inspec,train_130,resolution of a current mode algorithmic analog to digital converter. errors limiting the resolution of current mode algorithmic analog to digital converters are mainly related to current mirror operation. while systematic errors can be minimized by proper circuit techniques random sources are unavoidable. in this paper a statistical analysis of the resolution of a typical converter is carried out taking into account process tolerances. to support the analysis a 4 bit adc realized in a 0 35 mu m cmos technology was exhaustively simulated. results were found to be in excellent agreement with theoretical derivations.
inspec,train_1300,will cpxe save the photofinishing market. a consortium of film suppliers and electronics firms has proposed the common picture exchange environment. it will let diverse providers cooperate via the internet to sell digital photo prints.
inspec,train_1301,integrate and fire neurons driven by correlated stochastic input. neurons are sensitive to correlations among synaptic inputs. however analytical models that explicitly include correlations are hard to solve analytically so their influence on a neuron s response has been difficult to ascertain. to gain some intuition on this problem we studied the firing times of two simple integrate and fire model neurons driven by a correlated binary variable that represents the total input current. analytic expressions were obtained for the average firing rate and coefficient of variation a measure of spike train variability as functions of the mean variance and correlation time of the stochastic input. the results of computer simulations were in excellent agreement with these expressions. in these models an increase in correlation time in general produces an increase in both the average firing rate and the variability of the output spike trains. however the magnitude of the changes depends differentially on the relative values of the input mean and variance the increase in firing rate is higher when the variance is large relative to the mean whereas the increase in variability is higher when the variance is relatively small. in addition the firing rate always tends to a finite limit value as the correlation time increases toward infinity whereas the coefficient of variation typically diverges. these results suggest that temporal correlations may play a major role in determining the variability as well as the intensity of neuronal spike trains.
inspec,train_1302,dynamics of the firing probability of noisy integrate and fire neurons. cortical neurons in vivo undergo a continuous bombardment due to synaptic activity which acts as a major source of noise. we investigate the effects of the noise filtering by synapses with various levels of realism on integrate and fire neuron dynamics. the noise input is modeled by white for instantaneous synapses or colored for synapses with a finite relaxation time noise. analytical results for the modulation of firing probability in response to an oscillatory input current are obtained by expanding a fokker planck equation for small parameters of the problem when both the amplitude of the modulation is small compared to the background firing rate and the synaptic time constant is small compared to the membrane time constant. we report the detailed calculations showing that if a synaptic decay time constant is included in the synaptic current model the firing rate modulation of the neuron due to an oscillatory input remains finite in the high frequency limit with no phase lag. in addition we characterize the low frequency behavior and the behavior of the high frequency limit for intermediate decay times. we also characterize the effects of introducing a rise time to the synaptic currents and the presence of several synaptic receptors with different kinetics. in both cases we determine using numerical simulations an effective decay time constant that describes the neuronal response completely.
inspec,train_1303,reply to carreira perpinan and goodhill mathematics in biology. in a paper by carreira perpinan and goodhill see ibid vol 14 no 7 p 1545 60 2002 the authors apply mathematical arguments to biology. swindale et al think it is inappropriate to apply the standards of proof required in mathematics to the acceptance or rejection of scientific hypotheses. to give some examples showing that data are well described by a linear model does not rule out an infinity of other possible models that might give better descriptions of the data. proving in a mathematical sense that the linear model was correct would require ruling out all other possible models a hopeless task. similarly to demonstrate that two dna samples come from the same individual it is sufficient to show a match between only a few regions of the genome even though there remains a very large number of additional comparisons that could be done any one of which might potentially disprove the match. this is unacceptable in mathematics but in the real world it is a perfectly reasonable basis for belief.
inspec,train_1304,center crossing recurrent neural networks for the evolution of rhythmic behavior. a center crossing recurrent neural network is one in which the null hyper surfaces of each neuron intersect at their exact centers of symmetry ensuring that each neuron s activation function is centered over the range of net inputs that it receives. we demonstrate that relative to a random initial population seeding the initial population of an evolutionary search with center crossing networks significantly improves both the frequency and the speed with which high fitness oscillatory circuits evolve on a simple walking task. the improvement is especially striking at low mutation variances. our results suggest that seeding with center crossing networks may often be beneficial since a wider range of dynamics is more likely to be easily accessible from a population of center crossing networks than from a population of random networks.
inspec,train_1305,learning nonregular languages a comparison of simple recurrent networks and lstm. rodriguez 2001 examined the learning ability of simple recurrent nets srns elman 1990 on simple context sensitive and context free languages. in response to rodriguez s 2001 article we compare the performance of simple recurrent nets and long short term memory recurrent nets on context free and context sensitive languages.
inspec,train_1306,scalable hybrid computation with spikes. we outline a hybrid analog digital scheme for computing with three important features that enable it to scale to systems of large complexity first like digital computation which uses several one bit precise logical units to collectively compute a precise answer to a computation the hybrid scheme uses several moderate precision analog units to collectively compute a precise answer to a computation. second frequent discrete signal restoration of the analog information prevents analog noise and offset from degrading the computation. third a state machine enables complex computations to be created using a sequence of elementary computations. a natural choice for implementing this hybrid scheme is one based on spikes because spike count codes are digital while spike time codes are analog. we illustrate how spikes afford easy ways to implement all three components of scalable hybrid computation. first as an important example of distributed analog computation we show how spikes can create a distributed modular representation of an analog number by implementing digital carry interactions between spiking analog neurons. second we show how signal restoration may be performed by recursive spike count quantization of spike time codes. third we use spikes from an analog dynamical system to trigger state transitions in a digital dynamical system which reconfigures the analog dynamical system using a binary control vector such feedback interactions between analog and digital dynamical systems create a hybrid state machine hsm. the hsm extends and expands the concept of a digital finite state machine to the hybrid domain. we present experimental data from a two neuron hsm on a chip that implements error correcting analog to digital conversion with the concurrent use of spike time and spike count codes. we also present experimental data from silicon circuits that implement hsm based pattern recognition using spike time synchrony. we outline how hsms may be used to perform learning vector quantization spike pattern recognition and generation and how they may be reconfigured.
inspec,train_1307,law librarians survey are academic law librarians in decline. the author reports on the results of one extra element in the biall sptl survey designed to acquire further information about academic law librarians. the survey has fulfilled the aim of providing a snapshot of the academic law library profession and has examined the concerns that have been raised. perhaps most importantly it has shown that more long term work needs to be done to monitor the situation effectively. we hope that biall will take on this challenge and help to maintain the status of academic law librarians and aid them in their work.
inspec,train_1308,sptl biall academic law library survey 2000 2001. the paper outlines the activities and funding of academic law libraries in the uk and ireland in the academic year 2000 2001. the figures have been taken from the results of a postal questionnaire undertaken by information services staff at cardiff university on behalf of biall.
inspec,train_1309,transcripts bane or boon. law reporting. because judge made law by its very nature is less immediately accessible than the law of codified statutory systems it calls for an efficient system of law reporting. of necessity any such system will be selective the majority of decisions going unreported. considerable power thereby comes to repose in the hands of the law reporters. the author shares his invaluable perception and extensive research on the difficulties which arise from the excess of access to judgments.
inspec,train_131,on biorthogonal nonuniform filter banks and tree structures. this paper concerns biorthogonal nonuniform filter banks. it is shown that a tree structured filter bank is biorthogonal if it is equivalent to a tree structured filter bank whose matching constituent levels on the analysis and synthesis sides are themselves biorthogonal pairs. we then show that a stronger statement can be made about dyadic filter banks in general that a dyadic filter bank is biorthogonal if both the analysis and synthesis banks can be decomposed into dyadic trees. we further show that these decompositions are stability and fir preserving. these results derived for filter banks having filters with rational transfer functions thus extend some of the earlier comparable results for orthonormal filter banks.
inspec,train_1310,cat and class what use are these skills to the new legal information professional. this article looks at the cataloguing and classification skills taught on information studies courses and the use these skills are to new legal information professionals. the article is based on the opinions of nine new legal information professionals from both academic and law firm libraries.
inspec,train_1311,blended implementation of block implicit methods for odes. in this paper we further develop a new approach for naturally defining the nonlinear splittings needed for the implementation of block implicit methods for odes which has been considered by brugnano j comput. appl. math. 116 2000 41 and by brugnano and trigiante in recent trends in numerical analysis nova science new york 2000 pp 81 105. the basic idea is that of defining the numerical method as the combination blending of two suitable component methods. by carefully choosing such methods it is shown that very efficient implementations can be obtained. moreover some of them characterized by a diagonal splitting are well suited for parallel computers. numerical tests comparing the performances of the proposed implementation with existing ones are also presented in order to make evident the potential of the approach.
inspec,train_1312,stability in the numerical solution of the heat equation with nonlocal boundary conditions. this paper deals with numerical methods for the solution of the heat equation with integral boundary conditions. finite differences are used for the discretization in space. the matrices specifying the resulting semidiscrete problem are proved to satisfy a sectorial resolvent condition uniformly with respect to the discretization parameter. using this resolvent condition unconditional stability is proved for the fully discrete numerical process generated by applying a theta stable one step methods to the semidiscrete problem. this stability result is established in the maximum norm it improves some previous results in the literature in that it is not subject to various unnatural restrictions which were imposed on the boundary conditions and on the one step methods.
inspec,train_1313,a collocation formulation of multistep methods for variable step size extensions. multistep methods are classically constructed by specially designed difference operators on an equidistant time grid. to make them practically useful they have to be implemented by varying the step size according to some error control algorithm. it is well known how to extend adams and bdf formulas to a variable step size formulation. in this paper we present a collocation approach to construct variable step size formulas. we make use of piecewise polynomials to show that every k step method of order k 1 has a variable step size polynomial collocation formulation.
inspec,train_1314,multi timescale internet traffic engineering. the internet is a collection of packet based hop by hop routed networks. internet traffic engineering is the process of allocating resources to meet the performance requirements of users and operators for their traffic. current mechanisms for doing so exemplified by tcp s congestion control or the variety of packet marking disciplines concentrate on allocating resources on a per packet basis or at data timescales. this article motivates the need for traffic engineering in the internet at other timescales namely control and management timescales and presents three mechanisms for this. it also presents a scenario to show how these mechanisms increase the flexibility of operators service offerings and potentially also ease problems of internet management.
inspec,train_1315,traffic engineering with traditional ip routing protocols. traffic engineering involves adapting the routing of traffic to network conditions with the joint goals of good user performance and efficient use of network resources. we describe an approach to intradomain traffic engineering that works within the existing deployed base of interior gateway protocols such as open shortest path first and intermediate system intermediate system. we explain how to adapt the configuration of link weights based on a networkwide view of the traffic and topology within a domain. in addition we summarize the results of several studies of techniques for optimizing ospf is is weights to the prevailing traffic. the article argues that traditional shortest path routing protocols are surprisingly effective for engineering the flow of traffic in large ip networks.
inspec,train_1316,understanding internet traffic streams dragonflies and tortoises. we present the concept of network traffic streams and the ways they aggregate into flows through internet links. we describe a method of measuring the size and lifetime of internet streams and use this method to characterize traffic distributions at two different sites. we find that although most streams about 45 percent of them are dragonflies lasting less than 2 seconds a significant number of streams have lifetimes of hours to days and can carry a high proportion 50 60 percent of the total bytes on a given link. we define tortoises as streams that last longer than 15 minutes. we point out that streams can be classified not only by lifetime dragonflies and tortoises but also by size mice and elephants and note that stream size and lifetime are independent dimensions. we submit that isps need to be aware of the distribution of internet stream sizes and the impact of the difference in behavior between short and long streams. in particular any forwarding cache mechanisms in internet routers must be able to cope with a high volume of short streams. in addition isps should realize that long running streams can contribute a significant fraction of their packet and byte volumes something they may not have allowed for when using traditional flat rate user bandwidth consumption approaches to provisioning and engineering.
inspec,train_1317,dynamic spectrum management for next generation dsl systems. the performance of dsl systems is severely constrained by crosstalk due to the electromagnetic coupling among the multiple twisted pairs making up a phone cable. in order to reduce performance loss arising from crosstalk dsl systems are currently designed under the assumption of worst case crosstalk scenarios leading to overly conservative dsl deployments. this article presents a new paradigm for dsl system design which takes into account the multi user aspects of the dsl transmission environment. dynamic spectrum management dsm departs from the current design philosophy by enabling transceivers to autonomously and dynamically optimize their communication settings with respect to both the channel and the transmissions of neighboring systems. along with this distributed optimization when an additional degree of coordination becomes available for future dsl deployment dsm will allow even greater improvement in dsl performance. implementations are readily applicable without causing any performance degradation to the existing dsls under static spectrum management. after providing an overview of the dsm concept this article reviews two practical dsm methods iterative water filling an autonomous distributed power control method enabling great improvement in performance which can be implemented through software options in some existing adsl and vdsl systems and vectored dmt a coordinated transmission reception technique achieving crosstalk free communication for dsl systems which brings within reach the dream of providing universal internet access at speeds close to 100 mb s to 500 m on 1 2 lines and beyond 1 km on 2 4 lines. dsm capable dsl thus enables the broadband age.
inspec,train_1318,network intrusion and fault detection a statistical anomaly approach. with the advent and explosive growth of the global internet and electronic commerce environments adaptive automatic network service intrusion and anomaly detection in wide area data networks and e commerce infrastructures is fast gaining critical research and practical importance. we present and demonstrate the use of a general purpose hierarchical multitier multiwindow statistical anomaly detection technology and system that operates automatically adaptively and proactively and can be applied to various networking technologies including both wired and wireless ad hoc networks. our method uses statistical models and multivariate classifiers to detect anomalous network conditions. some numerical results are also presented that demonstrate that our proposed methodology can reliably detect attacks with traffic anomaly intensity as low as 3 5 percent of the typical background traffic intensity thus promising to generate an effective early warning.
inspec,train_1319,routing security in wireless ad hoc networks. a mobile ad hoc network consists of a collection of wireless mobile nodes that are capable of communicating with each other without the use of a network infrastructure or any centralized administration. manet is an emerging research area with practical applications. however wireless manet is particularly vulnerable due to its fundamental characteristics such as open medium dynamic topology distributed cooperation and constrained capability. routing plays an important role in the security of the entire network. in general routing security in wireless manets appears to be a problem that is not trivial to solve. in this article we study the routing security issues of manets and analyze in detail one type of attack the black hole problem that can easily be employed against the manets. we also propose a solution for the black hole problem for ad hoc on demand distance vector routing protocol.
inspec,train_132,a unified view for vector rotational cordic algorithms and architectures based on angle quantization approach. vector rotation is the key operation employed extensively in many digital signal processing applications. in this paper we introduce a new design concept called angle quantization aq. it can be used as a design index for vector rotational operation where the rotational angle is known in advance. based on the aq process we establish a unified design framework for cost effective low latency rotational algorithms and architectures. several existing works such as conventional coordinate rotational digital computer cordic ar cordic mvr cordic and eeas based cordic can be fitted into the design framework forming a vector rotational cordic family. moreover we address four searching algorithms to solve the optimization problem encountered in the proposed vector rotational cordic family. the corresponding scaling operations of the cordic family are also discussed. based on the new design framework we can realize high speed low complexity rotational vlsi circuits whereas without degrading the precision performance in fixed point implementations.
inspec,train_1320,securing the internet routing infrastructure. the unprecedented growth of the internet over the last years and the expectation of an even faster increase in the numbers of users and networked systems resulted in the internet assuming its position as a mass communication medium. at the same time the emergence of an increasingly large number of application areas and the evolution of the networking technology suggest that in the near future the internet may become the single integrated communication infrastructure. however as the dependence on the networking infrastructure grows its security becomes a major concern in light of the increased attempt to compromise the infrastructure. in particular the routing operation is a highly visible target that must be shielded against a wide range of attacks. the injection of false routing information can easily degrade network performance or even cause denial of service for a large number of hosts and networks over a long period of time. different approaches have been proposed to secure the routing protocols with a variety of countermeasures which nonetheless have not eradicated the vulnerability of the routing infrastructure. in this article we survey the up to date secure routing schemes. that appeared over the last few years. our critical point of view and thorough review of the literature are an attempt to identify directions for future research on an indeed difficult and still largely open problem.
inspec,train_1323,editorial system vendors focus on adobe and the future. looking over the newspaper system market we note that the mac is getting new respect. adobe indesign has established itself as a solid alternative to quark xpress for pagination. positioning themselves for the long run developers are gradually shifting to new software architectures.
inspec,train_1324,a look at monacoprofiler 4. the newest profiling program from monaco software adds some valuable features support for up to 8 color printing profiling for digital cameras fine tuning of black generation and tweaking of profile transforms. we tested its ease of use and a few of the advanced functions. in all it s pretty good.
inspec,train_1325,x rite more than a graphic arts company. although it is well known as a maker of densitometers and spectrophotometers x rite is active in measuring light and shape in many industries. among them are automobile finishes paint and home improvements scientific instruments optical semiconductors and even cosmetic dentistry.
inspec,train_1326,verona lastre consolidation provides opening for a new plate vendor. fewer companies than ever are manufacturing ctp plates. the market has become globalized with just four big firms dominating the picture. to the samor group however globalization looked like an opportunity it reasoned that many a national and local distributor would welcome a small competitive regional manufacturer. a couple of years ago it formed a company verona lastre to exploit that opportunity. now vela as it s familiarly called has launched its line of high quality thermal plates and is busily lining up dealers in europe and the americas.
inspec,train_1328,tablet pcs on the way publishing markets. previews of hardware and software look promising for publishing markets.
inspec,train_1329,pageflex mediarich pagerich. layout and graphics innovators collaborate on fully variable combination. pageflex and equilibrium have melded their respective edit and mediarich technologies to make a variable data composition engine with a web interface. though a first generation effort it shows substantial promise.
inspec,train_133,l sub p stability and linearization. a theorem by hadamard gives a two part condition under which a map from one banach space to another is a homeomorphism. the theorem while often very useful is incomplete in the sense that it does not explicitly specify the family of maps for which the condition is met. recently under a typically weak additional assumption on the map it was shown that hadamard s condition is met if and only if the map is a homeomorphism with a lipschitz continuous inverse. here an application is given concerning the relation between the l sub p stability with 1 or p infinity of a nonlinear system and the stability of related linear systems. we also give a result that directs attention to a fundamental limitation concerning what can be proved about linearization and stability for a related familiar family of feedback systems.
inspec,train_1330,strobbe graphics next frontier ctp for commercial printers. strobbe is one of the more successful makers of newspaper platesetters which are sold by agfa under the polaris name. but the company also has a growing presence in commercial printing markets where it sells under its own name.
inspec,train_1331,enterprise content integration iii agari mediaware s media star. since we introduced the term enterprise content integration eci in january the concept has gained momentum in the market. in addition to context media s interchange platform and savantech s photon commerce agari mediaware s media star is in the fray. it is a middleware platform that allows large media companies to integrate their digital systems with great flexibility.
inspec,train_1332,personal cards for on line purchases. buying presents over the web has advantages for a busy person lots of choices 24 hour accessibility quick delivery and you do n t even have to wrap the gift. but many people like to select a card or write a personal note to go with their presents and the options for doing that have been limited. two companies have seen this limitation as an opportunity 4yoursoul. com and cardinthebox com.
inspec,train_1333,the crossing number of p n 3. it is proved that the crossing number of the generalized petersen graph p 3k h 3 is k h if h in 0 2 and k 3 if h 1 for each k or 3 with the single exception of p 9 3 whose crossing number is 2.
inspec,train_1334,a shy invariant of graphs. moving from a well known result of p l hammer et al 1982 we introduce a new graph invariant say lambda g referring to any graph g. it is a non negative integer which is non zero whenever g contains particular induced odd cycles or equivalently admits a particular minimum clique partition. we show that. g can be efficiently evaluated and that its determination allows one to reduce the hard problem of computing a minimum clique cover of a graph to an identical problem of smaller size and special structure. furthermore one has alpha g or theta g lambda g where alpha g and theta g respectively denote the cardinality of a maximum stable set of g and of a minimum clique partition of g.
inspec,train_1335,arranging solid balls to represent a graph. by solid balls we mean a set of balls in r sup 3 no two of which can penetrate each other. every finite graph g can be represented by arranging solid balls in the following way put red balls in r sup 3  one for each vertex of g and connect two red balls by a chain when they correspond to a pair of adjacent vertices of g where a chain means a finite sequence of blue solid balls in which each consecutive balls are tangent. we may omit the chain if the two red balls are already tangent. the ball number b g of g is the minimum number of balls red and blue necessary to represent g. if we put the balls and chains on a table so that all balls sit on the table then the minimum number of balls for g is denoted by bt g. among other things we prove that b k sub 6  8 b k sub 7  13 and b sub t k sub 5  8 b sub t k sub 6  14. we also prove that c sub 1 n sup 3  b k sub n  c sub 2 n sup 3 log n c sub 3 n sup 4  log n b sub t k sub n  c sub 4 n sup 4.
inspec,train_1336,on abelian branched coverings of the sphere. we obtain an enumeration formula for the number of weak equivalence classes of the branched a b covering of the sphere with m branch points when a and b are finite abelian groups with a  b  1. from this we can deduce an explicit formula for enumerating the weak equivalence classes of pseudofree spherical zp zq actions on a given surface when p and q are distinct primes.
inspec,train_1337,some properties of hadamard matrices coming from dihedral groups. h kimura 1996 introduced a method to construct hadamard matrices of degree 8n 4 from the dihedral group of order 2n. in this paper we study some properties of this construction.
inspec,train_1338,the chromatic spectrum of mixed hypergraphs. a mixed hypergraph is a triple h x c d where x is the vertex set and each of c d is a list of subsets of x. a strict k coloring of h is a surjection c x 1  k such that each member of le has two vertices assigned a common value and each member of d has two vertices assigned distinct values. the feasible set of h is k h has a strict k coloring. among other results we prove that a finite set of positive integers is the feasible set of some mixed hypergraph if and only if it omits the number i or is an interval starting with 1. for the set s t with 2 or s or t 2 the smallest realization has 2t s vertices. when every member of c union d is a single interval in an underlying linear order on the vertices the feasible set is also a single interval of integers.
inspec,train_1339,edge colorings with no large polychromatic stars. given a graph g and a positive integer r let f sub r g denote the largest number of colors that can be used in a coloring of e g such that each vertex is incident to at most r colors. for all positive integers n and r we determine f sub r k sub n n exactly and f sub r k sub n within 1. in doing so we disprove a conjecture by y manoussakis et al 1996.
inspec,train_134,a model of periodic oscillation for genetic regulatory systems. in this paper we focus on modeling and explaining periodic oscillations in gene protein systems with a simple nonlinear model and on analyzing effects of time delay on the stability of oscillations. our main model of genetic regulation comprises of a two gene system with an autoregulatory feedback loop. we exploit multiple time scales and hysteretic properties of the model to construct periodic oscillations with jumping dynamics and analyze the possible mechanism according to the singular perturbation theory. as shown in this paper periodic oscillations are mainly generated by nonlinearly negative and positive feedback loops in gene regulatory systems whereas the jumping dynamics is generally caused by time scale differences among biochemical reactions. this simple model may actually act as a genetic oscillator or switch in gene protein networks because the dynamics are robust for parameter perturbations or environment variations. we also explore effects of time delay on the stability of the dynamics showing that the time delay generally increases the stability region of the oscillations thereby making the oscillations robust to parameter changes. two examples are also provided to numerically demonstrate our theoretical results.
inspec,train_1340,orthogonal decompositions of complete digraphs. a family g of isomorphic copies of a given digraph g is said to be an orthogonal decomposition of the complete digraph d sub n by g if every arc of d sub n belongs to exactly one member of g and the union of any two different elements from g contains precisely one pair of reverse arcs. given a digraph h an h family mh is the vertex disjoint union of m copies of h. in this paper we consider orthogonal decompositions by h families. our objective is to prove the existence of such an orthogonal decomposition whenever certain necessary conditions hold and m is sufficiently large.
inspec,train_1341,stem secure telephony enabled middlebox. dynamic applications including ip telephony have not seen wide acceptance within enterprises because of problems caused by the existing network infrastructure. static elements including firewalls and network address translation devices are not capable of allowing dynamic applications to operate properly. the secure telephony enabled middlebox stem architecture is an enhancement of the existing network design to remove the issues surrounding static devices. the architecture incorporates an improved firewall that can interpret and utilize information in the application layer of packets to ensure proper functionality. in addition to allowing dynamic applications to function normally the stem architecture also incorporates several detection and response mechanisms for well known network based vulnerabilities. this article describes the key components of the architecture with respect to the sip protocol.
inspec,train_1342,defending against flooding based distributed denial of service attacks a tutorial. flooding based distributed denial of service ddos attack presents a very serious threat to the stability of the internet. in a typical ddos attack a large number of compromised hosts are amassed to send useless packets to jam a victim or its internet connection or both. in the last two years it was discovered that ddos attack methods and tools are becoming more sophisticated effective and also more difficult to trace to the real attackers. on the defense side current technologies are still unable to withstand large scale attacks. the main purpose of this article is therefore twofold. the first one is to describe various ddos attack methods and to present a systematic review and evaluation of the existing defense mechanisms. the second is to discuss a longer term solution dubbed the internet firewall approach that attempts to intercept attack packets in the internet core well before reaching the victim.
inspec,train_1343,estimating the intrinsic dimension of data with a fractal based method. in this paper the problem of estimating the intrinsic dimension of a data set is investigated. a fractal based approach using the grassberger procaccia algorithm is proposed. since the grassberger procaccia algorithm 1983 performs badly on sets of high dimensionality an empirical procedure that improves the original algorithm has been developed. the procedure has been tested on data sets of known dimensionality and on time series of santa fe competition.
inspec,train_1344,restoration of archival documents using a wavelet technique. this paper addresses a problem of restoring handwritten archival documents by recovering their contents from the interfering handwriting on the reverse side caused by the seeping of ink. we present a novel method that works by first matching both sides of a document such that the interfering strokes are mapped with the corresponding strokes originating from the reverse side. this facilitates the identification of the foreground and interfering strokes. a wavelet reconstruction process then iteratively enhances the foreground strokes and smears the interfering strokes so as to strengthen the discriminating capability of an improved canny edge detector against the interfering strokes. the method has been shown to restore the documents effectively with average precision and recall rates for foreground text extraction at 84 percent and 96 percent respectively.
inspec,train_1345,infrared image classification using hidden markov trees. an image of a three dimensional target is generally characterized by the visible target subcomponents with these dictated by the target sensor orientation target pose. an image often changes quickly with variable pose. we define a class as a set of contiguous target sensor orientations over which the associated target image is relatively stationary with aspect. each target is in general characterized by multiple classes. a distinct set of wiener filters are employed for each class of images to identify the presence of target subcomponents. a karhunen loeve representation is used to minimize the number of filters templates associated with a given subcomponent. the statistical relationships between the different target subcomponents are modeled via a hidden markov tree hmt. the hmt classifier is discussed and example results are presented for forward looking infrared flir imagery of several vehicles.
inspec,train_1346,automatic multilevel thresholding for image segmentation by the growing time adaptive self organizing map. in this paper a growing tasom time adaptive self organizing map network called gtasom along with a peak finding process is proposed for automatic multilevel thresholding. the proposed gtasom is tested for image segmentation. experimental results demonstrate that the gtasom is a reliable and accurate tool for image segmentation and its results outperform other thresholding methods.
inspec,train_1347,a maximum likelihood surface estimator for dense range data. describes how to estimate 3d surface models from dense sets of noisy range data taken from different points of view i e multiple range maps. the proposed method uses a sensor model to develop an expression for the likelihood of a 3d surface conditional on a set of noisy range measurements. optimizing this likelihood with respect to the model parameters provides an unbiased and efficient estimator. the proposed numerical algorithms make this estimation computationally practical for a wide variety of circumstances. the results from this method compare favorably with state of the art approaches that rely on the closest point or perpendicular distance metric a convenient heuristic that produces biased solutions and fails completely when surfaces are not sufficiently smooth as in the case of complex scenes or noisy range measurements. empirical results on both simulated and real ladar data demonstrate the effectiveness of the proposed method for several different types of problems. furthermore the proposed method offers a general framework that can accommodate extensions to include surface priors more sophisticated noise models and other sensing modalities such as sonar or synthetic aperture radar.
inspec,train_1348,reconstructing surfaces by volumetric regularization using radial basis functions. we present a new method of surface reconstruction that generates smooth and seamless models from sparse noisy nonuniform and low resolution range data. data acquisition techniques from computer vision such as stereo range images and space carving produce 3d point sets that are imprecise and nonuniform when compared to laser or optical range scanners. traditional reconstruction algorithms designed for dense and precise data do not produce smooth reconstructions when applied to vision based data sets. our method constructs a 3d implicit surface formulated as a sum of weighted radial basis functions. we achieve three primary advantages over existing algorithms 1 the implicit functions we construct estimate the surface well in regions where there is little data 2 the reconstructed surface is insensitive to noise in data acquisition because we can allow the surface to approximate rather than exactly interpolate the data and 3 the reconstructed surface is locally detailed yet globally smooth because we use radial basis functions that achieve multiple orders of smoothness.
inspec,train_1349,efficient simplicial reconstructions of manifolds from their samples. an algorithm for manifold learning is presented. given only samples of a finite dimensional differentiable manifold and no a priori knowledge of the manifold s geometry or topology except for its dimension the goal is to find a description of the manifold. the learned manifold must approximate the true manifold well both geometrically and topologically when the sampling density is sufficiently high. the proposed algorithm constructs a simplicial complex based on approximations to the tangent bundle of the manifold. an important property of the algorithm is that its complexity depends on the dimension of the manifold rather than that of the embedding space. successful examples are presented in the cases of learning curves in the plane curves in space and surfaces in space in addition a case when the algorithm fails is analyzed.
inspec,train_135,hysteretic threshold logic and quasi delay insensitive asynchronous design. we introduce the class of hysteretic linear threshold hlt logic functions as a novel extension of linear threshold logic and prove their general applicability for constructing state holding boolean functions. we then demonstrate a fusion of hlt logic with the quasi delay insensitive style of asynchronous circuit design complete with logical design examples. future research directions are also identified.
inspec,train_1350,generalized mosaicing wide field of view multispectral imaging. we present an approach to significantly enhance the spectral resolution of imaging systems by generalizing image mosaicing. a filter transmitting spatially varying spectral bands is rigidly attached to a camera. as the system moves it senses each scene point multiple times each time in a different spectral band. this is an additional dimension of the generalized mosaic paradigm which has demonstrated yielding high radiometric dynamic range images in a wide field of view using a spatially varying density filter. the resulting mosaic represents the spectrum at each scene point. the image acquisition is as easy as in traditional image mosaics. we derive an efficient scene sampling rate and use a registration method that accommodates the spatially varying properties of the filter. using the data acquired by this method we demonstrate scene rendering under different simulated illumination spectra. we are also able to infer information about the scene illumination. the approach was tested using a standard 8 bit black white video camera and a fixed spatially varying spectral interference filter.
inspec,train_1351,analytic pca construction for theoretical analysis of lighting variability in images of a lambertian object. we analyze theoretically the subspace best approximating images of a convex lambertian object taken from the same viewpoint but under different distant illumination conditions. we analytically construct the principal component analysis for images of a convex lambertian object explicitly taking attached shadows into account and find the principal eigenmodes and eigenvalues with respect to lighting variability. our analysis makes use of an analytic formula for the irradiance in terms of spherical harmonic coefficients of the illumination and shows under appropriate assumptions that the principal components or eigenvectors are identical to the spherical harmonic basis functions evaluated at the surface normal vectors. our main contribution is in extending these results to the single viewpoint case showing how the principal eigenmodes and eigenvalues are affected when only a limited subset the upper hemisphere of normals is available and the spherical harmonics are no longer orthonormal over the restricted domain. our results are very close both qualitatively and quantitatively to previous empirical observations and represent the first essentially complete theoretical explanation of these observations.
inspec,train_1352,elastically adaptive deformable models. we present a technique for the automatic adaptation of a deformable model s elastic parameters within a kalman filter framework for shape estimation applications. the novelty of the technique is that the model s elastic parameters are not constant but spatio temporally varying. the variation of the elastic parameters depends on the distance of the model from the data and the rate of change of this distance. each pass of the algorithm uses physics based modeling techniques to iteratively adjust both the geometric and the elastic degrees of freedom of the model in response to forces that are computed from the discrepancy between the model and the data. by augmenting the state equations of an extended kalman filter to incorporate these additional variables we are able to significantly improve the quality of the shape estimation. therefore the model s elastic parameters are always initialized to the same value and they are subsequently modified depending on the data and the noise distribution. we present results demonstrating the effectiveness of our method for both two dimensional and three dimensional data.
inspec,train_1353,generalized spatio chromatic diffusion. a framework for diffusion of color images is presented. the method is based on the theory of thermodynamics of irreversible transformations which provides a suitable basis for designing correlations between the different color channels. more precisely we derive an equation for color evolution which comprises a purely spatial diffusive term and a nonlinear term that depends on the interactions among color channels over space. we apply the proposed equation to images represented in several color spaces such as rgb cielab opponent colors and ihs.
inspec,train_1354,design and analysis of optimal material distribution policies in flexible manufacturing systems using a single agv. modern automated manufacturing processes employ automated guided vehicles agvs for material handling which serve several machine centres mc in a factory. optimal scheduling of agvs can significantly help to increase the efficiency of the manufacturing process by minimizing the idle time of mcs waiting for the raw materials. we analyse the requirements for an optimal schedule and then provide a mathematical framework for an efficient schedule of material delivery by an agv. a mathematical model is developed and then a strategy for optimal material distribution of the available raw material to the mcs is derived. with this model the optimal number of mcs to be utilized is also determined. finally the material delivery schedule employing multiple journeys to the mcs by the agv is carried out. through rigorous analysis and simulation experiments we show that such a delivery strategy will optimize the overall performance.
inspec,train_1355,comparison of push and pull systems with transporters a metamodelling approach. analyses push and pull systems with transportation consideration. a multiproduct multiline multistage production system was used to compare the two systems. the effects of four factors processing time variation demand variation transporters batch size on throughput rate average waiting time in the system and machine utilization were studied. the study uses metamodels to compare the two systems. they serve a dual purpose of expressing system performance measures in the form of a simple equation and reducing computational time when comparing the two systems. research shows that the number of transporters used and the batch size have a significant effect on the performance measures of both systems.
inspec,train_1356,five axis nc milling of ruled surfaces optimal geometry of a conical tool. the side milling of ruled surfaces using a conical milling cutter was studied. this is a field that has largely been ignored by research scientists but it is much used in industry especially to machine turbine blades. we first suggest an improved positioning with respect to the directrices of the ruled surface. as compared with the methods already developed for the cylindrical cutter this positioning enables the error between the cutter and the work piece to be reduced. an algorithm is then introduced to calculate error so one can determine the cutter dimensions cone radius and angle in order to respect the tolerance interval imposed by the design office. this study provides an opportunity to determine cutters with greater dimensions thus alleviating bending problems during milling.
inspec,train_1357,work sequencing in a manufacturing cell with limited labour constraints. this study focuses on the analysis of group scheduling heuristics in a dual constrained automated manufacturing cell where labour utilization is limited to setups tear downs and loads unloads. this scenario is realistic in today s automated manufacturing cells. the results indicate that policies for allocating labour to tasks have very little impact in such an environment. furthermore the performance of efficiency oriented exhaustive group scheduling heuristics deteriorated while the performance of the more complex non exhaustive heuristics improved. thus it is recommended that production managers use the simplest labour scheduling policy and instead focus their efforts to activities such as job scheduling and production planning in such environments.
inspec,train_1358,analysis of the surface roughness and dimensional accuracy capability of fused deposition modelling processes. building up materials in layers poses significant challenges from the viewpoint of material science heat transfer and applied mechanics. however numerous aspects of the use of these technologies have yet to be studied. one of these aspects is the characterization of the surface roughness and dimensional precision obtainable in layered manufacturing processes. in this paper a study of roughness parameters obtained through the use of these manufacturing processes was made. prototype parts were manufactured using fdm techniques and an experimental analysis of the resulting roughness average r sub a and rms roughness r sub q obtained through the use of these manufacturing processes was carried out. dimensional parameters were also studied in order to determine the capability of the fused deposition modelling process for manufacturing parts.
inspec,train_1359,on fuzzy and probabilistic control charts. in this article different procedures of constructing control charts for linguistic data based on fuzzy and probability theory are discussed. three sets of membership functions with different degrees of fuzziness are proposed for fuzzy approaches. a comparison between fuzzy and probability approaches based on the average run length and samples under control is conducted for real data. contrary to the conclusions of raz and wang 1990 the choice of degree of fuzziness affected the sensitivity of control charts.
inspec,train_136,design of 1 d and 2 d variable fractional delay allpass filters using weighted least squares method. in this paper a weighted least squares method is presented to design one dimensional and two dimensional variable fractional delay allpass filters. first each coefficient of the variable allpass filter is expressed as the polynomial of the fractional delay parameter. then the nonlinear phase error is approximated by a weighted equation error such that the cost function can be converted into a quadratic form. next by minimizing the weighted equation error the optimal polynomial coefficients can be obtained iteratively by solving a set of linear simultaneous equations at each iteration. finally the design examples are demonstrated to illustrate the effectiveness of the proposed approach.
inspec,train_1360,automated post bonding inspection by using machine vision techniques. inspection plays an important role in the semiconductor industry. in this paper we focus on the inspection task after wire bonding in packaging. the purpose of wire bonding w b is to connect the bond pads with the lead fingers. two major types of defects are 1 bonding line missing and 2 bonding line breakage. the numbers of bonding lines and bonding balls are used as the features for defect classification. the proposed method consists of image preprocessing orientation determination connection detection bonding line detection bonding ball detection and defect classification. the proposed method is simple and fast. the experimental results show that the proposed method can detect the defects effectively.
inspec,train_1361,adaptive scheduling of batch servers in flow shops. batch servicing is a common way of benefiting from economies of scale in manufacturing operations. good examples of production systems that allow for batch processing are ovens found in the aircraft industry and in semiconductor manufacturing. in this paper we study the issue of dynamic scheduling of such systems within the context of multi stage flow shops. so far a great deal of research has concentrated on the development of control strategies which only address the batch stage. this paper proposes an integral scheduling approach that also includes succeeding stages. in this way we aim for shop optimization instead of optimizing performance for a single stage. our so called look ahead strategy adapts its scheduling decision to shop status which includes information on a limited number of near future arrivals. in particular we study a two stage flow shop in which the batch stage is succeeded by a serial stage. the serial stage may be realized by a single machine or by parallel machines. through an extensive simulation study it is demonstrated how shop performance can be improved by the proposed strategy relative to existing strategies.
inspec,train_1362,process planning for reliable high speed machining of moulds. a method of generating nc programs for the high speed milling of moulds is investigated. forging dies and injection moulds whether plastic or aluminium have a complex surface geometry. in addition they are made of steels of hardness as much as 30 or even 50 hrc. since 1995 high speed machining has been much adopted by the die making industry which with this technology can reduce its use of sinking electrodischarge machining sedm. edm in general calls for longer machining times. the use of high speed machining makes it necessary to redefine the preliminary stages of the process. in addition it affects the methodology employed in the generation of nc programs which requires the use of high level cam software. the aim is to generate error free programs that make use of optimum cutting strategies in the interest of productivity and surface quality. the final result is a more reliable manufacturing process. there are two risks in the use of high speed milling on hardened steels. one of these is tool breakage which may be very costly and may furthermore entail marks on the workpiece. the other is collisions between the tool and the workpiece or fixtures the result of which may be damage to the ceramic bearings in the spindles. in order to minimize these risks it is necessary that new control and optimization steps be included in the cam methodology. there are three things that the firm adopting high speed methods should do. it should redefine its process engineering it should systematize access by its cam programmers to high speed knowhow and it should take up the use of process simulation tools. in the latter case it will be very advantageous to use tools for the estimation of cutting forces. the new work methods proposed in this article have made it possible to introduce high speed milling hsm into the die industry. examples are given of how the technique has been applied with cam programming re engineered as here proposed with an explanation of the novel features and the results.
inspec,train_1363,heuristics for single pass welding task sequencing. welding task sequencing is a prerequisite in the offline programming of robot arc welding. single pass welding task sequencing can be modelled as a modified travelling salesman problem. owing to the difficulty of the resulting arc routing problems effective local search heuristics are developed. computational speed becomes important because robot arc welding is often part of an automated process planning procedure. generating a reasonable solution in an acceptable time is necessary for effective automated process planning. several different heuristics are proposed for solving the welding task sequencing problem considering both productivity and the potential for welding distortion. constructive heuristics based on the nearest neighbour concept and tabu search heuristics are developed and enhanced using improvement procedures. the effectiveness of the heuristics developed is tested and verified on actual welded structure problems and random problems.
inspec,train_1364,an adaptive sphere fitting method for sequential tolerance control. the machining of complex parts typically involves a logical and chronological sequence of n operations on m machine tools. because manufacturing datums can not always match design constraints some of the design specifications imposed on the part are usually satisfied by distinct subsets of the n operations prescribed in the process plan. conventional tolerance control specifies a fixed set point for each operation and a permissible variation about this set point to insure compliance with the specifications whereas sequential tolerance control stc uses real time measurement information at the completion of one stage to reposition the set point for subsequent operations. however it has been shown that earlier sphere fitting methods for stc can lead to inferior solutions when the process distributions are skewed. this paper introduces an extension of stc that uses an adaptive sphere fitting method that significantly improves the yield in the presence of skewed distributions as well as significantly reducing the computational effort required by earlier probabilistic search methods.
inspec,train_1365,deadlock free scheduling in flexible manufacturing systems using petri nets. this paper addresses the deadlock free scheduling problem in flexible manufacturing systems. an efficient deadlock free scheduling algorithm was developed using timed petri nets for a class of fmss called systems of sequential systems with shared resources s sup 4 r. the algorithm generates a partial reachability graph to find the optimal or near optimal deadlock free schedule in terms of the firing sequence of the transitions of the petri net model. the objective is to minimize the mean flow time mft. an efficient truncation technique based on the siphon concept has been developed and used to generate the minimum necessary portion of the reachability graph to be searched. it has been shown experimentally that the developed siphon truncation technique enhances the ability to develop deadlock free schedules of systems with a high number of deadlocks which can not be achieved using standard petri net scheduling approaches. it may be necessary in some cases to relax the optimality condition for large fmss in order to make the search effort reasonable. hence a user control factor ucf was defined and used in the scheduling algorithm. the objective of using the ucf is to achieve an acceptable trade off between the solution quality and the search effort. its effect on the mft and the cpu time has been investigated. randomly generated examples are used for illustration and comparison. although the effect of ucf did not affect the mean flow time it was shown that increasing it reduces the search effort cpu time significantly.
inspec,train_1366,a fuzzy soft learning vector quantization for control chart pattern recognition. this paper presents a supervised competitive learning network approach called a fuzzy soft learning vector quantization for control chart pattern recognition. unnatural patterns in control charts mean that there are some unnatural causes for variations in statistical process control spc. hence control chart pattern recognition becomes more important in spc in order to detect effectively the patterns for the six main types of control charts pham and oztemel 1994 described a class of pattern recognizers for control charts based on the learning vector quantization lvq such as lvq lvq2 and lvq x etc. in this paper we propose a new supervised lvq for control charts based on a fuzzy soft competitive learning network. the proposed fuzzy soft lvq fs lvq uses a fuzzy relaxation technique and simultaneously updates all neurons. it can increase correct recognition accuracy and also decrease the learning time. comparisons between lvq lvq x and fs lvq are made.
inspec,train_1367,the set of just in time management strategies an assessment of their impact on plant level productivity and input factor substitutability using variable cost function estimates. many manufacturers in the automobile industry around the world have adopted the just in time jit set of management strategies in an effort to improve productivity efficiency and product quality. the paper provides empirical evidence that supports the idea that jit manufacturing environments are in fact more productive than their non jit counterparts. plant level cross sectional data from auto parts manufacturing firms are used to estimate variable cost functions for a jit group as well as for a non jit group of plants. differences in cost function characteristics between the two groups are examined and discussed.
inspec,train_1368,exploratory study of the adoption of manufacturing technology innovations in the usa and the uk. manufacturing technologies appropriately implemented provide competitive advantage to manufacturers. the use of manufacturing technologies across countries is difficult to compare. one such comparison has been provided in the literature with a study of us and japanese practices in advanced manufacturing technology use using a common questionnaire. the present study compares the use of 17 different technologies in similar industries in the usa n 1025 and uk n 166 using a common questionnaire. largely there are remarkable similarities between the two countries. this may partly correlate with the heavy traffic in foreign direct investment between the two nations. notable differences are 1 across the board us manufacturers are ahead of the uk firms in computerized integration with units inside and outside manufacturing organizations 2 us manufacturers show higher labour productivity which is consistent with macro economic data and 3 more uk manufacturers report the use of soft technologies such as just in time total quality manufacturing and manufacturing cells. hypotheses for future investigation are proposed.
inspec,train_1369,use of bayesian belief networks when combining disparate sources of information in the safety assessment of software based systems. the paper discusses how disparate sources of information can be combined in the safety assessment of software based systems. the emphasis is put on an emerging methodology relevant for intelligent product support systems to combine information about disparate evidences systematically based on bayesian belief networks. the objective is to show the link between basic information and the confidence one can have in a system. how one combines the bayesian belief net bbn method with a software safety standard rtca do 178 b for safety assessment of software based systems is also discussed. finally the applicability of the bbn methodology and experiences from cooperative research work together with kongsberg defence aerospace and det norske veritas and ongoing research with vtt automation are presented.
inspec,train_137,an efficient dipie algorithm for cad of electrostatically actuated mems devices. pull in parameters are important properties of electrostatic actuators. efficient and accurate analysis tools that can capture these parameters for different design geometries are therefore essential. current simulation tools approach the pull in state by iteratively adjusting the voltage applied across the actuator electrodes. the convergence rate of this scheme gradually deteriorates as the pull in state is approached. moreover the convergence is inconsistent and requires many mesh and accuracy refinements to assure reliable predictions. as a result the design procedure of electrostatically actuated mems devices can be time consuming. in this paper a novel displacement iteration pull in extraction dipie scheme is presented. the dipie scheme is shown to converge consistently and far more rapidly than the voltage iterations vi scheme 100 times faster.. the dipie scheme requires separate mechanical and electrostatic field solvers. therefore it can be easily implemented in existing moems cad packages. moreover using the dipie scheme the pull in parameters extraction can be performed in a fully automated mode and no user input for search bounds is required.
inspec,train_1370,integrated support based on task models for the design evaluation and documentation of interactive safety critical systems a case study in the air traffic control domain. this paper presents an approach to using task models in both the design and the evaluation phases of interactive safety critical applications. we explain how it is possible to use information contained in task models to support the design and development of effective user interfaces. moreover we show how task models can also support a systematic inspection based usability assessment by examining possible deviations that can occur while users interact with the system an important issue especially when coping with the peculiar requirements of safety critical applications. such evaluation provides useful technical documentation to help users achieve an in depth understanding of the system and its design rationale. lastly a description of the application of our approach to a real case study in the air traffic control domain will illustrate the main features of the proposed method. in particular we discuss examples taken from an application for air traffic controllers in an aerodrome supported by graphical user interfaces for data link communications with pilots.
inspec,train_1371,design methodology for diagnostic strategies for industrial systems. this paper presents a method for the construction of diagnostic systems for complex industrial applications. the approach has been explicitely developed to shorten the design cycle and meet some specific requirements such as modularity flexibility and the possibility of merging many different sources of information. the method allows one to consider multiple simultaneous failures and is specifically designed to make easier the coordination and simplification of local diagnostic algorithms developed by different teams.
inspec,train_1372,knowledge acquisition and ontology modelling for construction of a control and monitoring expert system. this paper presents the processes of knowledge acquisition and ontology development for structuring the knowledge base of an expert system. ontological engineering is a process that facilitates construction of the knowledge base of an intelligent system. ontology is the study of the organization and classification of knowledge. ontological engineering in artificial intelligence has the practical goal of constructing frameworks for knowledge that allow computational systems to tackle knowledge intensive problems and it supports knowledge sharing and reuse. to illustrate the process of conceptual modelling using the inferential modelling technique as a basis for ontology construction the tool and processes are applied to build an expert system in the domain of monitoring of a petroleum production facility.
inspec,train_1373,agent based product support logistics system using xml and rdf. the capability of the timely provision of maintenance services and service parts is critical to the competitiveness of industrial systems. to enhance the timely operations in a product support logistics chain business partners equipment manufacturers parts distributors customers may have to collaborate for the efficient exchange of relevant information. we propose the architecture of an agent based product support logistics system. emphasis is placed on the problems of sharing and exchanging information through agent communication. we adopt the resource description framework rdf schema for information modelling in product support logistics domain. the extensible markup language xml serialization generates messages for agent communication. the use of xml and rdf enables software agents to understand the contents of messages correctly and consistently. we demonstrate the feasibility of our agent architecture using a scenario in logistical support processes. we believe that the approach can provide a promising way to the automation of business processes in product support logistics through seamless communication among the partners.
inspec,train_1374,using technology to facilitate the design and delivery of warnings. this paper describes several ways in which new technologies can assist in the design and delivery of warnings. there are four discussion points 1 current product information can be delivered via the internet 2 computer software and hardware are available to assist in the design construction and production of visual and auditory warnings 3 various detection devices can be used to recognize instances in which warnings might be delivered and 4 a warning presentation can be modified to fit conditions and persons. implications example applications and future prospects of these points are described.
inspec,train_1375,evaluation of the usability of digital maintenance manuals developed without either user input or a task analysis. the primary objective was to investigate the value that can be added to a low cost digital maintenance manual by the addition of a navigational aid. two versions of a digital maintenance manual were developed the difference between them being the number of design heuristics observed when designing navigational aids. neither version was based on an analysis of the tasks carried out by users nor were users involved in the design process. instead the manuals were developed directly from the digital information used to produce the existing paper manual. usability trials were carried out to test both versions according to the time taken and errors committed by users during typical information retrieval tasks. users were questioned to determine their ease of use eou perceptions for each manual. the main outcomes were that the navigation aid used in the second version reduced the time taken to use the manual but increased the number of errors made by users. the navigational aid also seemed to reduce the perceived eou compared with the first version. in both cases the perceived eou was lower than for a previous digital manual that had been developed using a task analysis and user input. the paper concludes by recommending the development of a generic task model of user interaction with digital maintenance manuals.
inspec,train_1376,enhanced product support through intelligent product manuals. the scope of this paper is the provision of intelligent product support within the distributed intranet internet environment. from the point of view of user requirements the limitations of conventional product manuals and methods of authoring them are first outlined. it is argued that enhanced product support requires new technology solutions both for product manuals and for their authoring and presentation. the concept and the architecture of intelligent product manuals are then discussed. a prototype system called proartweb is presented to demonstrate advanced features of intelligent product manuals. next the problem of producing such manuals in a cost effective way is addressed and a concurrent engineering approach to their authoring is proposed. an integrated environment for collaborative authoring called proauthor is described to illustrate the approach suggested and to show how consistent up to date and user oriented product manuals can be designed. the solutions presented here enable product knowledge to be captured and delivered to users and developers of product manuals when where and in the form they need it.
inspec,train_1377,open hypermedia for product support. as industrial systems become increasingly more complex the maintenance and operating information increases both in volume and complexity. with the current pressures on manufacturing the management of information resources has become a critical issue. in particular ensuring that personnel can access current information quickly and effectively when undertaking a specific task. this paper discusses some of the issues involved in and the benefits of using open hypermedia to manage and deliver a diverse range of information. while the paper concentrates on the problems specifically associated with manufacturing organizations the problems are generic across other business sectors such as healthcare defence and finance. the open hypermedia approach to information management and delivery allows a multimedia resource base to be used for a range of applications and it permits a user to have controlled access to the required information in an easily accessible and structured manner. recent advancement in hypermedia also permits just in time support in the most appropriate format for all users. our approach is illustrated by the discussion of a case study in which an open hypermedia system delivers maintenance and process information to factory floor users to support the maintenance and operation of a very large manufacturing cell.
inspec,train_1378,development of an internet based intelligent design support system for rolling element bearings. this paper presents a novel approach to developing an intelligent agile design system for rolling bearings based on artificial intelligence ai internet and web technologies and expertise. the underlying philosophy of the approach is to use ai technology and web based design support systems as smart tools from which design customers can rapidly and responsively access the systems built in design expertise. the approach is described in detail with a novel ai model and system implementation issues. the major issues in implementing the approach are discussed with particular reference to using ai technologies network programming client server technology and open computing of bearing design and manufacturing requirements.
inspec,train_1379,web based intelligent helpdesk support environment. with the advent of internet technology it is now feasible to provide effective and efficient helpdesk service over the global internet to meet customers requirements and satisfaction. in this research we have designed and developed a web based intelligent helpdesk support environment webhotline to support the customer service centre of a large multinational corporation in the electronics industry. the paper describes the basic architecture of the environment that supports the major functions of web based fault information retrieval online multilingual translation capability different operating modes of video conferencing for enhanced support and direct intelligent fault diagnosis by customers or customer support engineers. as a result webhotline helps to save cost in eliminating the expensive overseas telephone charges reduction in machine down time and number of on site visits by service engineers as in traditional helpdesk environment.
inspec,train_138,optical actuation of a bistable mems. this paper presents an optical actuation scheme for mems devices based on the well established fact that light possesses momentum and hence imparts a force equal to 2 w c when reflected by a surface. here w is the total power of the reflected light and c is the speed of light. radiation pressure as it is known is nearly insignificant for most macroscale applications but it can be quite significant for mems devices. in addition light actuation offers a new paradigm. first intersecting light beams do not interfere in contrast to electrical conductors which short when they come into contact. second light can operate in high temperature and high radiation environments far outside the capability of solid state electronic components. this actuation method is demonstrated both in air and in vacuum by switching the state of a bistable mems device. the associated heat transfer model is also presented.
inspec,train_1380,a feature preserving volumetric technique to merge surface triangulations. several extensions and improvements to surface merging procedures based on the extraction of isosurfaces from a distance map defined on an adaptive background grid are presented. the main objective is to extend the application of these algorithms to surfaces with sharp edges and comers. in order to deal with objects of different length scales the initial background grids are created using a delaunay triangulation method and local voxelizations. a point enrichment technique that introduces points into the background grid along detected surface features such as ridges is used to ensure that these features are preserved in the final merged surface. the surface merging methodology is extended to include other boolean operations between surface triangulations. the iso surface extraction algorithms are modified to obtain the correct iso surface for multi component objects. the procedures are demonstrated with various examples ranging from simple geometrical entities to complex engineering applications. the present algorithms allow realistic modelling of a large number of complex engineering geometries using overlapping components defined discretely i e via surface triangulations. this capability is very useful for grid generation starting from data originated in measurements or images.
inspec,train_1381,an augmented spatial digital tree algorithm for contact detection in computational mechanics. based on the understanding of existing spatial digital tree based contact detection approaches and the alternating digital tree adt algorithm in particular a more efficient algorithm termed the augmented spatial digital tree asdt algorithm is proposed in the present work. the asdt algorithm adopts a different point representation scheme that uses only the lower comer vertex to represent a hyper rectangle with the upper comer vertex serving as the augmented information. consequently the asdt algorithm can keep the working space the same as the original n dimensional space and in general a much better balanced tree can be expected. this together with the introduction of an additional bounding subregion for the rectangles associated with each tree node makes it possible to significantly reduce the number of node visits in the region search although each node visit may be slightly more expensive. three examples arising in computational mechanics are presented to provide an assessment of the performance of the asdt. the numerical results indicate that the asdt is at least over 3 9 times faster than the adt.
inspec,train_1382,loop restructuring for data i o minimization on limited on chip memory embedded processors. in this paper we propose a framework for analyzing the flow of values and their reuse in loop nests to minimize data traffic under the constraints of limited on chip memory capacity and dependences. our analysis first undertakes fusion of possible loop nests intra procedurally and then performs loop distribution. the analysis discovers the closeness factor of two statements which is a quantitative measure of data traffic saved per unit memory occupied if the statements were under the same loop nest over the case where they are under different loop nests. we then develop a greedy algorithm which traverses the program dependence graph to group statements together under the same loop nest legally to promote maximal reuse per unit of memory occupied. we implemented our framework in petit a tool for dependence analysis and loop transformations. we compared our method with one based on tiling of fused loop nest and one based on a greedy strategy to purely maximize reuse. we show that our methods work better than both of these strategies in most cases for processors such as tms320cxx which have a very limited amount of on chip memory. the improvements in data i o range from 10 to 30 percent over tiling and from 10 to 40 percent over maximal reuse for jpeg loops.
inspec,train_1383,semantic data broadcast for a mobile environment based on dynamic and adaptive chunking. database broadcast is an effective and scalable approach to disseminate information of high affinity to a large collection of mobile clients. a common problem of existing broadcast approaches is the lack of knowledge for a client to determine if all data items satisfying its query could be obtained from the broadcast. we therefore propose a semantic based broadcast approach. a semantic descriptor is attached to each broadcast unit called a data chunk. this semantic descriptor allows a client to determine if a query can be answered entirely based on broadcast items and if needed identify the precise definition of the remaining items in the form of a supplementary query. data chunks can be of static or dynamic sizes and organized hierarchically. their boundary can be determined on the fly adaptive to the nature of client queries. we investigate different ways of organizing the data chunks over a broadcast channel to improve access performance. we introduce the data affinity index metric which more accurately reflects client perceived performance. a simulation model is built to evaluate our semantic based broadcast schemes.
inspec,train_1384,data allocation on wireless broadcast channels for efficient query processing. data broadcast is an excellent method for efficient data dissemination in the mobile computing environment. the application domain of data broadcast will be widely expanded in the near future where the client is expected to perform complex queries or transactions on the broadcast data. to reduce the access latency for processing the complex query it is beneficial to place the data accessed in a query close to each other on the broadcast channel. in this paper we propose an efficient algorithm to determine the allocation of the data on the broadcast channel such that frequently co accessed data are not only allocated close to each other but also in a particular order which optimizes the performance of query processing. our mechanism is based on the well known problem named optimal linear ordering. experiments are performed to justify the benefit of our approach.
inspec,train_1385,cache invalidation and replacement strategies for location dependent data in mobile environments. mobile location dependent information services ldiss have become increasingly popular in recent years. however data caching strategies for ldiss have thus far received little attention. in this paper we study the issues of cache invalidation and cache replacement for location dependent data under a geometric location model. we introduce a new performance criterion called caching efficiency and propose a generic method for location dependent cache invalidation strategies. in addition two cache replacement policies pa and paid are proposed. unlike the conventional replacement policies pa and paid take into consideration the valid scope area of a data value. we conduct a series of simulation experiments to study the performance of the proposed caching schemes. the experimental results show that the proposed location dependent invalidation scheme is very effective and the pa and paid policies significantly outperform the conventional replacement policies.
inspec,train_1386,when the unexpected happens disaster planning in banks. a business disruption can be as simple as a power failure or as complex as a terrorist attack. regardless you will need to have a plan to minimize interruptions to both your bank and your customers. marketers have a role in this readiness process.
inspec,train_1389,the case for activity based management. in today s stormy economic climate businesses need activity based management abm more than ever before. in an economic downturn it is a vital tool for pinpointing a business most profitable customers products regions or channels as well as uncovering the costs of individual business processes that may need to be improved in order to drive higher profit levels. changes may be afoot in the abm market but armstrong laing group ceo mike sherratt argues that businesses need specialists with an abm focus to keep up with their requirements in such a climate. he looks at what benefits a best of breed abm system can offer businesses and contends that businesses must choose carefully when going down the abm route and also ask themselves the question whether generalist organisations will be able to deliver the best possible abm solution.
inspec,train_139,equilibrium swelling and kinetics of ph responsive hydrogels models experiments and simulations. the widespread application of ionic hydrogels in a number of applications like control of microfluidic flow development of muscle like actuators filtration separation and drug delivery makes it important to properly understand these materials. understanding hydrogel properties is also important from the standpoint of their similarity to many biological tissues. typically gel size is sensitive to outer solution ph and salt concentration. in this paper we develop models to predict the swelling deswelling of hydrogels in buffered ph solutions. an equilibrium model has been developed to predict the degree of swelling of the hydrogel at a given ph and salt concentration in the solution. a kinetic model has been developed to predict the rate of swelling of the hydrogel when the solution ph is changed. experiments are performed to characterize the mechanical properties of the hydrogel in different ph solutions. the degree of swelling as well as the rate of swelling of the hydrogel are also studied through experiments. the simulations are compared with experimental results and the models are found to predict the swelling deswelling processes accurately.
inspec,train_1390,data quality unlocking the roi in crm. while many organisations realise their most valuable asset is their customers many more fail to realise the importance of auditing maintaining and updating the information contained in their customer databases. today s growing awareness in the importance of data quality in relation to crm and roi will help change this attitude. in response crm vendors will follow suit and begin to differentiate themselves by offering data quality as part of an enterprise wide data management methodology.
inspec,train_1391,government budget and accounting information policy and practice in taiwan. the principal government budget and accounting information policies in taiwan are founded on the ability to provide integrated consistent and timely information for government managers to make more rational decisions concerning national resource allocation and evaluation. a specific accounting organization system has been designed for this purpose. this paper analyzes information policies and practices according to the relevant laws and regulations identifies issues regarding the policies and presents strategies to resolve the issues.
inspec,train_1392,enlisting on line residents expanding the boundaries of e government in a japanese rural township. the purpose of this article is to analyze and learn from an unusual way in which local bureaucrats in a japanese rural township are using the internet to serve their constituents by enlisting the support of on line residents. successful e government requires not only rethinking the potential uses of computer technology but in adopting new patterns of decision making power sharing and office management that many bureaucrats may not be predisposed to make. the main thesis of this article is that necessity and practicality can play a powerful motivational role in facilitating the incorporation of information technology it at the level of local government. this case study of how bureaucrats in towa cho a small agricultural town in northeastern japan have harnessed the internet demonstrates clearly the fundamentals of building a successful e government framework in this rural municipality similar to many communities in europe and north america today.
inspec,train_1393,erp systems implementation best practices in canadian government organizations. erp enterprise resource planning systems implementation is a complex exercise in organizational innovation and change management. government organizations are increasing their adoption of these systems for various benefits such as integrated real time information better administration and result based management. government organizations due to their social obligations higher legislative and public accountability and unique culture face many specific challenges in the transition to enterprise systems. this motivated the authors to explore the key considerations and typical activities in government organizations adopting erp systems. the article adopts the innovation process theory framework as well as the markus tanis 2000 model as a basis to delineate the erp adoption process. although each adopting organization has a distinct set of objectives for its systems the study found many similarities in motivations concerns and strategies across organizations.
inspec,train_1394,subject access to government documents in an era of globalization intellectual bundling of entities affected by the decisions of supranational organizations. as a result of the growing influence of supranational organizations there is a need for a new model for subject access to government information in academic libraries. rulings made by supranational bodies such as the world trade organization wto and rulings determined under the auspices of transnational economic agreements such as the north american free trade agreement nafta often supersede existing law resulting in obligatory changes to national provincial state and municipal legislation. just as important is the relationship among private sector companies third party actors such as nongovernmental organizations ngos and governments. the interaction among the various entities affected by supranational rulings could potentially form the basis of a new model for subject access to government information.
inspec,train_1395,work in progress developing policies for access to government information in the new south africa. following south africa s transition to democracy in 1994 the sa government has adopted policies supporting freedom of expression and freedom of access to information. the bill of rights in the new constitution includes a constitutional right of access to information held by the state. since 1994 various initiatives have been taken by government and other bodies to promote such access. these include moves to reorganize government printing and publishing restructure the government s public information services make government information available on the internet and extend telephony and internet access to poor communities. sa s new legal deposit act 1997 makes provision for the creation of official publications depositories. the promotion of access to information act 2000 was enacted to ensure access to information held by the state and public bodies. however despite much activity it has proved difficult to translate principles into practical and well coordinated measures to improve access to government information. a specific concern is the failure of policy makers to visualize a role for libraries.
inspec,train_1396,construction of double sampling s control charts for agile manufacturing. double sampling ds x control charts are designed to allow quick detection of a small shift of process mean and provides a quick response in an agile manufacturing environment. however the ds x control charts assume that the process standard deviation remains unchanged throughout the entire course of the statistical process control. therefore a complementary ds chart that can be used to monitor the process variation caused by changes in process standard deviation should be developed. in this paper the development of the ds s charts for quickly detecting small shift in process standard deviation for agile manufacturing is presented. the construction of the ds s charts is based on the same concepts in constructing the ds x charts and is formulated as an optimization problem and solved with a genetic algorithm. the efficiency of the ds s control chart is compared with that of the traditional s control chart. the results show that the ds s control charts can be a more economically preferable alternative in detecting small shifts than traditional s control charts.
inspec,train_1397,computer program for calculating the p value in testing process capability index c sub pmk. many process capability indices including c sub p  c sub pk  and c sub pm  have been proposed to provide numerical measures on the process potential and performance. combining the advantages of these indices pearn et al 1992 introduced a new capability index called c sub pmk  which has been shown to be a useful capability index for processes with two sided specification limits. in this paper the authors implement the theory of a testing hypothesis using the natural estimator of c sub pmk  and provide an efficient maple computer program to calculate the p values. they also provide tables of the critical values for some commonly used capability requirements. based on the test they develop a simple step by step procedure for in plant applications. the practitioners can use the proposed procedure to determine whether their process meets the preset capability requirement and make reliable decisions.
inspec,train_1398,swamped by data storage. while the cost of storage has plummeted the demand continued to climb and there are plenty of players out there offering solutions to a company s burgeoning storage needs.
inspec,train_14,application of hybrid models for prediction and optimization of enzyme fermentation process. a comparative study. the paper presents a comparison of the biotechnological process prediction and optimization results obtained by using different structure hybrid mathematical models for modeling of the same bioprocess. the hybrid models under investigation consist of the product mass balance equation in which different means an artificial neural network fuzzy neural network and cell age distribution based calculation scheme are incorporated for modeling the specific biosynthesis rate of a desired product. experimental data from alpha amylase laboratory and industrial fermentation processes are used for model parameter identification and the process prediction tests.
inspec,train_140,a high resolution high frequency monolithic top shooting microinjector free of satellite drops part ii fabrication implementation and characterization. for pt. i see ibid vol. 11 no 5 p 427 36 2002. describes the fabrication implementation and characterization of a thermal driven microinjector featuring a bubble check valve and monolithic fabrication. microfabrication of this microinjector is based on bulk surface combined micromachining of the silicon wafer free of the bonding process that is commonly used in the fabrication of commercial printing head so that even solvents and fuels can be ejected. droplet ejection sequences of two microinjectors have been studied along with a commercial inkjet printhead for comparison. the droplet ejection of our microinjector with 10 mu m diameter nozzle has been characterized at a frequency over 35 khz at least 3 times higher than those of commercial counterparts. the droplet volume from this device is smaller than 1 pl 10 times smaller than those of commercial inkjets employed in the consumer market at the time of testing. visualization results have verified that our design although far from being optimized operates in the frequency several times higher than those of commercial products and reduces the crosstalk among neighboring chambers.
inspec,train_1402,web talk is cheap. web technology provides a wealth of opportunities for reaching potential customers. so how do you make it work for your business.
inspec,train_1403,it utilities. a look at five utilities to make your pcs more efficient effective and efficacious.
inspec,train_1404,creating the right mail model. if you know your post room is not as efficiently organised as it might be but you are not sure how best to go about making improvements then consider this advice from john edgar of consultant mcs.
inspec,train_1405,winning post mail systems. businesses that take their mail for granted can end up wasting money as well as opportunities. mike stecyk vp of marketing and lines of business at pitney bowes suggests strategies for making more of a great opportunity.
inspec,train_1406,bluetooth bites back. it is now more than four years since we started to hear about bluetooth and from the user s point of view very little seems to have happened since then. paul haddlesey looks at the progress and the role bluetooth may eventually play in your firm s communications strategy.
inspec,train_1407,soft options for software upgrades. several new products claim to take the work out of installing software and patches and even migrating operating systems. software migration products fall into two broad categories. the drive imaging type is designed to make exact copies of a hard disk either an entire drive or certain directories so you can use it to back up data. the application management type is designed for more incremental upgrades and often provides additional features such as the ability to monitor or control users access to applications.
inspec,train_1408,pki coming to an enterprise near you. for many years public key infrastructure pki deployments were the provenance of governments and large security conscious corporations and financial institutions. these organizations have the financial and human resources necessary to successfully manage the complexities of a public key system. lately however several forces have converged to encourage a broader base of enterprises to take a closer look at pki. these forces are discussed. pki vendors are now demonstrating to customers how they can make essential business applications faster and more efficient by moving them to the internet without sacrificing security. those applications usually include secure remote access secure messaging electronic document exchange transaction validation and network authentication. after a brief discussion of pki basics the author reviews various products available on the market.
inspec,train_1409,north american carrier survey simply the best. network magazine carried out a north american carrier survey. thousands of network engineers gave information on providers strengths and weaknesses across seven services private lines frame relay atm vpns dedicated internet access ethernet services and web hosting. respondents also ranked providers on their ability to perform in up to eight categories including customer service reliability and price. users rated more than a dozen providers for each survey. carriers needed to receive at least 30 votes for inclusion in the survey. readers were asked to rate carriers on up to nine categories using a scale of 1 unacceptable to 5 excellent. not all categories are equally important. to try and get at these differences network magazine asked readers to assign a weight to each category. the big winners were vpns.
inspec,train_141,a high resolution high frequency monolithic top shooting microinjector free of satellite drops part i concept design and model. introduces an innovative microinjector design featuring a bubble valve which entails superior droplet ejection characteristics and monolithic fabrication which allows handling of a wide range of liquids. this new microinjector uses asymmetric bubbles to reduce crosstalk increase frequency response and eliminate satellite droplets. during a firing i e droplet ejection the virtual valve closes by growing a thermal bubble in the microchannel to isolate the microchamber from the liquid supply and neighboring chambers. between firings however the virtual valve opens by collapsing the bubble to reduce flow restriction for fast refilling of the microchamber. the use of bubble valves brings about fast and reliable device operation without imposing the significant complication fabrication of physical microvalves would call for. in addition through a special heater configuration and chamber designs bubbles surrounding the nozzle cut off the tail of the droplets being ejected and completely eliminate satellite droplets. a simple one dimensional model of the operation of the microinjector is used to estimate the bubble formation and liquid refilling.
inspec,train_1410,wam net private pipes for electronic media. we are the digital version of fedex. we offer storage and intelligent workflow. the united states military especially during war time is pretty careful about the way it handles its workflow and communications. before a company is awarded a government contract the company and its technology are screened and verified. if the technology or its creators are n t trustworthy and secure chances are they are n t getting by uncle sam. record companies and publishing houses tend to feel the same way. after all security is just as important to a record executive as it is to a navy commander. wam net a wide area media network hence the name passes muster with both. the company which employs about 320 employees around the world has 15000 customers including the us navy and a host of record labels publishing companies healthcare providers and advertising agencies all of whom use its network as a way to transport store and receive data. we are the digital version of fedex. we offer storage and intelligent workflow  says murad velani executive vice president of sales and marketing for wam net. we started out as purely transport and we ve become a digital platform.
inspec,train_1411,speedera web without the wait. there s no greater testament to the utility of the internet than the fact that hundreds of millions of people worldwide are willing to wait for web pages as they build incrementally on screen. but while users may put up with the world wide wait  they definitely do n t like it. that s where content delivery networks come in. cdns ca n t turn a footpath into a freeway but they can help data in transit take advantage of shortcuts and steer clear of traffic jams. and while enhancing the responsiveness of web interaction cdns also enhance the prospects of their clients who need engaged visitors to keep their web based business models afloat. our mission is to improve the quality of the internet experience for end users  says gordon smith vice president of marketing at speedera networks in santa clara california  and to enable web site operators to provide better delivery quality performance scalability and security through an outsourced service model that slashes it costs.
inspec,train_1412,arbortext enabler of multichannel publishing. a company has a document say dosage instructions for a prescription drug or a troubleshooting sheet for a dvd drive. that document starts its life in a predictable format probably microsoft word or wordperfect but then to meet the needs of readers who nowadays demand access via multiple devices the material has to be translated into many more formats html pagemaker or quark possibly rtf almost certainly pdf and nowadays next generation devices cell phones handheld computers also impose their own requirements. and what if suddenly the dosage levels change or new workarounds emerge to handle dvd problems. that s when a company should put in a call to arbortext a 20 year old ann arbor michigan based company that exists to solve a single problem helping clients automate multichannel publishing.
inspec,train_1413,web content extraction. a whizbang. approach. the extraction technology that whizbang uses consists of a unique approach to scouring the web for current very specific forms of information. flipdog for example checks company web sites for hyperlinks to pages that list job opportunities. it then crawls to the deeper page and using the whizbang. extraction framework extracts the key elements of the postings such as job title name of employer job category and job function. click on a job and you are transferred to the company web site to view the job description as it appears there.
inspec,train_1414,survey says. online world of polls and surveys. many content managers miss the fundamental interactivity of the web by not using polls and surveys. using interactive features like a poll or quiz offers your readers an opportunity to become more engaged in your content. using a survey to gather feedback about your content provides cost effective data to help make modifications or plot the appropriate course of action. the web has allowed us to take traditional market research and turn it on its ear. surveys and polls can be conducted faster and cheaper than with telephone and mail. but if you are running a web site should you care about polls and surveys. do you know the difference between the two in web speak.
inspec,train_1415,the disconnect continues digital content providers. the relationships between the people who buy digital content and those who sell it are probably more acrimonious than ever before says dick curtis a director and lead analyst for the research firm outsell inc where he covers econtent contract and negotiation strategies. several buyers agree with his observation. they cite aggressive sales tactics an unwillingness to deliver content in formats buyers need a reluctance to provide licensing terms that take into account the structure of today s corporations and inadequate service and support as a few of the factors underlying the acrimony. still many buyers remain optimistic that compromises can be reached on some of these issues. but first they say sellers must truly understand the econtent needs of today s enterprises.
inspec,train_1416,look into the future of content management. predictions of consolidation in the content management cm vendor arena have appeared in nearly every major industry prognosis over the past two years. gartner group for example recently reiterated its prediction that half the cm vendors in existence in mid 2001 would leave the marketplace by the end of 2002. analysts consistently advise prospective cm buyers to tread carefully because their vendor may not stick around. but fortunately the story goes fewer vendor choices will finally bring greater clarity and sharper differentiators to this otherwise very messy product landscape. in fact the number of cm vendors continues to rise. industry growth has come through greater demand among cm buyers but also expanding product functionality as well as successful partnerships. the marketplace certainly can not sustain its current breadth of vendors in the long run yet it remains unclear when and how any serious industry consolidation will occur. in the meantime evolving business models and feature sets have created just the kind of clearer segmentation and transparent product differences that were supposed to emerge following an industry contraction.
inspec,train_1417,craigslist virtual community maintains human touch. if it works why change it. this might have been the thought on the minds of dot com executives back when internet businesses were booming and most of the web content was free. web sites were overflowing with advertisements of every kind and size. now that dot com principals know better web ads are no longer the only path to revenue generation. community portals however never seemed to have many ads to begin with and their content stayed truer to who they served. many of them started off as simple places for users to list announcements local events want ads real estate and mingle with other local users. the author saw the need for san franciscans to have a place to do all of that for free without any annoying advertising and ended up offering much more to his community with the creation of craigslist. polling users was a good way for us to connect with our members this is the way to operate successfully in situations like these your members come first.
inspec,train_1418,documentum completes cm trifecta. daily people participating in clinical trials for drug companies fill out forms describing how they feel physically and emotionally. for some trials there are hundreds possibly thousands of participants. the drug companies must compile all the forms and submit them electronically to the fda. that s where documentum comes in. we ve streamlined the whole process of managing clinical trial content for companies such as johnson johnson bristol myers squibb and pfizer  notes documentum s president and ceo dave de walt. and by the way the fda also is one of our customers as well as the epa and the faa. and there are about 1 300 other organizations in various industries worldwide that rely on documentum s technologies consulting and training services. the company s products are designed to manage digital content and facilitate online transactions partner and supplier relationships and ebusiness interactions.
inspec,train_1419,packetvideo. one step ahead of the streaming wireless market. go beyond the hype however and it s clear that packetvideo is making strides in delivering streaming multimedia content to wireless devices. for one thing its technology based on the industry standard motion pictures expert group 4 mpeg 4 video encoder decoder actually works as promised. secondly the company has forged a broad based band of alliances that not only will eventually help it reach potential customers down the road but provides it financial support until the company can ramp up sales. the list of packetvideo s technology partners who are also investors and who have pumped more than 121 million into the company includes not just wireless device manufacturers but content providers and semiconductor vendors all of whom stand to benefit by increased sales of handheld wireless terminals.
inspec,train_142,surface micromachined paraffin actuated microvalve. normally open microvalves have been fabricated and tested which use a paraffin microactuator as the active element. the entire structure with nominal dimension of phi 600 mu m 30 mu m is batch fabricated by surface micromachining the actuator and channel materials on top of a single substrate. gas flow rates in the 0 01 0 1 sccm range have been measured for several devices with actuation powers ranging from 50 to 150 mw on glass substrates. leak rates as low as 500 mu sccm have been measured. the normally open blocking microvalve structure has been used to fabricate a precision flow control system of microvalves consisting of four blocking valve structures. the control valve is designed to operate over a 0 01 5 0 sccm flow range at a differential pressure of 800 torr. flow rates ranging from 0 02 to 4 996 sccm have been measured. leak rates as low as 3 2 msccm for the four valve system have been measured.
inspec,train_1420,pdf subscriptions bolster revenue. in 1999 sd times offered prospective subscribers the option of receiving their issues as adobe acrobat pdf files. what set the proposal apart from what other publishers were doing electronically on the web was that readers would get the entire version of the paper including both advertising and editorial just as it looked when it was laid out and went to press. sd times is only one of a small but growing number of publications that are taking on the electronic world and finding success. in the past six months alone the new york times popular mechanics trade magazine electronic buyers news and the harvard business review have launched digital versions of their newspapers and magazines to augment their online and print versions. the reasons are as varied as the publishers themselves. some companies are finding that readers do n t like their web based versions either due to poor navigation or missing graphics and images. others want to expand their publications nationally and internationally but do n t want the added cost of postage and printing. still others are looking for ways to give advertisers additional visibility and boost advertising and subscription revenues. no matter what the reason it s a trend worth watching.
inspec,train_1421,extracting linguistic dna nstein goes to work for upi. it s a tantalizing problem for categorization. united press international upi has more than 700 correspondents creating thousands of stories every week running the gamut from business news to sports to entertainment to global coverage of america s war on terrorism. and while upi and others news services have mechanisms for adding keywords and categorizing their content upi recognized a need to add more automation to the process. with the recent growth and improvement in tools for computer aided indexing cai upi undertook a process of looking at its needs and evaluating the many cai tools out there. in the end they chose technology from montreal based nstein technologies. our main objective was to acquire the best cai tool to help improve our customers access and interaction with our content  says steve sweet cio at upi. we examined a number of solutions and nstein s nserver suite clearly came out on top. the combination of speed scalability accuracy and flexibility was what really sold us.
inspec,train_1422,taxonomy s role in content management. a taxonomy is simply a way of classifying things. still there is a rapidly growing list of vendors offering taxonomy software and related applications. they promise many benefits especially to enterprise customers content management will be more efficient. corporate portals will be enhanced by easily created yahoo like directories of internal information. and the end user experience will be dramatically improved by more successful content retrieval and more effective knowledge discovery. but today s taxonomy products represent emerging technologies. they are not out of the box solutions. and even the most automated systems require some manual assistance from people who know how to classify content.
inspec,train_1423,p2p is dead long live p2p. picture the problem a sprawling multinational has hundreds of offices thousands of workers and countless amounts of intellectual property scattered here there everywhere. in kuala lumpur an executive needs to see an internally generated report on oil futures in central asia but where is it. london. new york. moscow. with a few clicks of the mouse and the right p2p technology deployed in house that executive will find and retrieve the report. without p2p that might be impossible certainly it would be time consuming and right there the argument for p2p implementations inside enterprises becomes clear. who are the players. no companies have managed to stake out clear leads and the fact is that the p2p marketplace now is up for grabs but the exciting news is that a range of small and startup businesses are trying to grab turf and quite probably if the analysts are right a few of these now little known companies will emerge as digital content stars within the next few years. cases in point groove networks avaki worldstreet yaga nextpage and kontiki. very different companies their approach to the markets radically differ but say the analysts each is worth a close look because among them they are defining the future of p2p.
inspec,train_1424,financialcontent. credibility is king. if you went to a site named financialcontent com you d probably expect to find well financial content. maybe stock prices or company earnings or market charts or economic statistics or corporate news reports. well you d be partially correct. financialcontent com does deal in financial information but its main objective is not to distribute its financial content to individual investors but to distribute it through other web sites. in other words financialcontent is a wholesaler not a retailer. as an aggregator financialcontent provides partner sites with financial information that is tailored to that individual web site.
inspec,train_1425,kontiki. shortcuts for content s trip to the edge. when electronic files get zapped from one location to another you probably are n t thinking about the physical distance they must travel or how that distance might affect the time it takes to get there. but if you work for cdn company kontiki this is just about all you think about. championing a p2p like bandwidth harvesting technology kontiki has figured out how to not only quickly distribute content to the edge but to utilize a combination of centralized servers and a network of enduser machines to collect or harvest  underutilized bandwidth and make redundant file requests more efficient.
inspec,train_1426,groove networks. matching technology with human needs. if what has been occurring in information technology during the past decade or so can be classified as the information age  then going forward i believe it s going to be viewed more as the connection age  says ray ozzie ceo and chairman of groove networks the beverly massachusetts company that produces collaboration software. we re all going to be thinking more about the connections between people and the connections between companies  ozzie says. our mission has two parts to help businesses achieve a greater return on connection from their relationships with customers vendors and partners and to help individuals strengthen online connections with the people with whom they interact.
inspec,train_1427,training for trouble. in a security context one example of digitized video s integration into a networked knowledge base is found in the accident response group arg at sandia national labs. a national security laboratory headquartered in albuquerque new mexico sandia is operated by lockheed martin and primarily funded by the u s department of energy. the organization handles research design and development of all non nuclear components used in u s nuclear weapons programs and is involved as well in programs related to energy critical infrastructure non proliferation materials control and emerging threats. arg s searchable video database has been implemented using the screening room package of applications from convera in vienna virginia. formed in december 2000 from excalibur technologies and intel s interactive media services division convera targets corporate and institutional markets with products for securely accessing indexing and searching rich media content text images audio and video across interconnected computer networks. among its public sector clients are the fbi nasa the nuclear regulatory commission u s military services the departments of justice and state and various domestic and foreign intelligence agencies.
inspec,train_1428,syndicators turn to the enterprise. syndicators have started reshaping offerings products and services towards the marketplace that was looking for enterprise wide content syndication technology and service. syndication companies are turning themselves into infrastructure companies. many syndication companies are now focusing their efforts on enterprise clients instead of the risky dot coms.
inspec,train_1429,online coverage of the olympic games. in 1956 a new medium was evolving which helped shape not only the presentation of the games to a worldwide audience but created entirely new avenues for marketing and sponsorship which changed the entire economic relevance of the games. the medium in 1956 was television and the medium now of course is the internet. not since 1956 has olympic coverage been so impacted by the onset of new technology as the current olympiad has been. but now the ioc finds itself in another set of circumstances not altogether different from 1956.
inspec,train_143,an automated irradiation device for use in cyclotrons. two cyclotrons are being operated at ipen cnen sp one model cv 28 capable of accelerating protons with energies up to 24 mev and beam currents up to 30 mu a and three other particles the other one model cyclone 30 accelerates protons with energy of 30 mev and currents up to 350 mu a both have the objective of irradiating targets both for radioisotope production for use in nuclear medicine and general research. the development of irradiating systems completely automatized was the objective of this work always aiming to reduce the radiation exposition dose to the workers and to increase the reliability of use of these systems.
inspec,train_1430,the free lunch is over online content subscriptions on the rise. high need rather than high use may be what really determines a user s willingness to pay. retooling and targeting content may be a sharper strategy than trying to re educate users that it is time to pay up for material that has been free. waiting for a paradigm shift in general user attitudes about paying for online content could be a fool s errand.
inspec,train_1431,cataloguing to help law library users. the author takes a broader view of the catalogue than is usual we can include within it items that have locations other than the office library itself. this may well start with internet resources but can perfectly appropriately continue with standard works not held in the immediate collection but available in some other accessible collection such as the local reference library. the essential feature is to include entries for the kind of material sought by users with the addition of a location mark indicating where they can find it.
inspec,train_1432,to classify or not to classify that is the question. in addressing classification issues the librarian needs to decide what best suits the purpose and requirements of the user group and the organisation they work in. the author has used the well established moys classification scheme. this gives the level of detail required for current stock and allows for the incorporation of new material as the firm s specialisations develop. the scheme is widely used in other firms as well as in the local law society library so it will be familiar to many users.
inspec,train_1433,the role and future of subject classification the exploitation of resources. it is imperative that the library information systems lis profession and lis educators appreciate fully the contribution that classification makes to the discipline and that it is no longer seen as the domain of the academic isolated theorist but becomes an integral part of our understanding of the contribution that the lis community can make to society as a whole as well as to particular areas such as legal information.
inspec,train_1434,a simple etalon stabilized visible laser diode. visible laser diodes lds are inexpensively available with single transverse mode single longitudinal mode operation with a coherence length in the metre range. with constant current bias and constant operating temperature the optical output power and operating wavelength are stable. a simple and inexpensive way is developed to maintain a constant ld temperature as the temperature of the local environment varies by monitoring the initially changing wavelength with an external etalon and using this information to apply a heating correction to the monitor photodiode commonly integral to the ld package. the fractional wavelength stability achieved is limited by the solid etalon to 7 10 sup 6 degrees c sup 1.
inspec,train_1435,experimental investigations on monitoring and control of induction heating process for semi solid alloys using the heating coil as sensor. a method of monitoring the state of metal alloys during induction heating and control of the heating process utilizing the heating coil itself as a sensor is proposed and its usefulness and effectiveness were experimentally investigated using aluminium a357 billets for the semi solid metal ssm casting processes. the impedance of the coil containing the billet was continuously measured by the proposed method in the temperature range between room temperature and 700 degrees c. it was found that the reactance component of the impedance varied distinctively according to the billet state and could clearly monitor the deformation of the billet while the resistance component increased with temperature reflecting the variation of the resistivity of the billet which has strong correlation to the solid liquid fraction of the billets. the measured impedance is very sensitive to the billet states such as temperature deformation and solid liquid fraction and could be used as a parameter to monitor and control the heating process for ssms.
inspec,train_1436,modelling tomographic cone beam projection data from a polyhedral phantom. analytical phantoms are used to generate projection data for testing reconstruction accuracy in computed axial tomography. a circular source locus equivalent to rotating specimen with a fixed source provides insufficient data for exact reconstruction in cone beam transmission tomography thus phantom data are useful for studying the consequent errors and also for investigating alternative scanning loci and reconstruction techniques. we present an algorithm that can compute phantom cone beam projection data from a phantom comprising geometrically defined polyhedra. each polyhedron is defined as a set of polygons enclosing a volume of fixed linear attenuation coefficient. the algorithm works by projecting each polygon in turn onto the modelled detector array which accumulates the product of source to polygon intersection distance for the rays intersecting each detector element linear attenuation coefficient and sign of projected polygon area indicating whether rays enter or exit the polyhedron at this face. the phantom data are rotated according to the projection angle whilst the source location and detector plane remain fixed. polyhedra can be of simple geometric form or complex surfaces derived from 3d images of real specimens. this algorithm is illustrated using a phantom comprising 989 238 polygons representing an iso surface generated from a microtomographic reconstruction of a piece of walrus tusk.
inspec,train_1437,improving the frequency stability of microwave oscillators by utilizing the dual mode sapphire loaded cavity resonator. the design and experimental testing of a novel control circuit to stabilize the temperature of a sapphire loaded cavity whispering gallery resonator oscillator and improve its medium term frequency stability is presented. finite element software was used to predict frequencies and quality factors of wge sub 7 0 0 and the wgh sub 9 0 0 modes near 9 ghz and separated in frequency by approximately 80 mhz. calculations show that the novel temperature control circuits from the difference frequency can result in a frequency stability of better than one part in 10 sup 13 at 270 k also we present details on the best way to couple orthogonally to two modes of similar frequency but different polarization.
inspec,train_1438,three dimensional particle image tracking for dilute particle liquid flows in a pipe. a three dimensional 3d particle image tracking technique was used to study the coarse spherical particle liquid flows in a pipe. the flow images from both the front view and the normal side view which was reflected into the front view by a mirror were recorded with a ccd camera and digitized by a pc with an image grabber card. an image processing program was developed to enhance and segment the flow image and then to identify the particles. over 90 of all the particles can be identified and located from the partially overlapped particle images using the circular hough transform. then the 3d position of each detected particle was determined by matching its front view image to its side view image. the particle velocity was then obtained by pairing its images in successive video fields. the measurements for the spherical expanded polystyrene particle oil flows show that the particles like the spherical bubbles in laminar bubbly flows tend to conglomerate near the pipe wall and to line up to form the particle clusters. as liquid velocity decreases the particle clusters disperse and more particles are distributed in the pipe centre region.
inspec,train_1439,on line robust processing techniques for elimination of measurement drop out. when processing measurement data it is usually assumed that some amount of normally distributed measurement noise is present. in some situations outliers are present in the measurements and consequently the noise is far from normally distributed. in this case classical least squares procedures for estimating fourier spectra or derived quantities like the frequency response function can give results which are inaccurate or even useless. in this paper a novel technique for the on line processing of measurement outliers will be proposed. both the computation speed and the accuracy of the technique presented will be compared with different classical approaches for handling outliers in measurement data i e filtering techniques outlier rejection techniques and robust regression techniques. in particular all processing techniques will be validated by applying them to the problem of speckle drop out in optical vibration measurements performed with a laser doppler vibrometer which typically causes outliers in the measurements.
inspec,train_144,development of a 3 5 inch magneto optical disk with a capacity of 2 3 gb. the recording capacity of gigamo media was enlarged from 1 3 gb to 2 3 gb for 3 5 inch magneto optical mo disks while maintaining downward compatibility. for the new gigamo technology a land and groove recording method was applied in addition to magnetically induced super resolution msr media. furthermore a novel address format suitable for the land and groove recording method was adopted. the specifications of the new gigamo media were examined to satisfy requirements for practical use with respect to margins. durability of more than 10 sup 6 rewritings and an enough lifetime were confirmed.
inspec,train_1440,application of ultrasonic sensors in the process industry. continuous process monitoring in gaseous liquid or molten media is a fundamental requirement for process control. besides temperature and pressure other process parameters such as level flow concentration and conversion are of special interest. more qualified information obtained from new or better sensors can significantly enhance the process quality and thereby product properties. ultrasonic sensors or sensor systems can contribute to this development. the state of the art of ultrasonic sensors and their advantages and disadvantages will be discussed. commercial examples will be presented. among others applications in the food chemical and pharmaceutical industries are described. possibilities and limitations of ultrasonic process sensors are discussed.
inspec,train_1441,handles and exception safety part 1. a simple handle class. every c program that uses inheritance must manage memory somehow. the most obvious way to do so is directly but programmers who create complicated data structures often have trouble figuring out what parts of those data structures are safe to delete when. the classical method of dealing with such complexity is to hide it in a class. such classes are typically called handles the idea is to attach a handle object to another object that contains the actual data. the simplest form of a handle which we have discussed in this article is one in which each handle object corresponds to a single object from the inheritance hierarchy. such handles are straightforward to use and to implement and tend to be intrinsically exception safe in almost all respects. the one exception hazard in such a class is typically the assignment operator. assignment operators often test for self assignment to avoid aliasing problems. as herb sutter has observed 2000 programs that need such tests are almost always exception unsafe. by rewriting the assignment operator we ensure that we do not do anything irrevocable until the possibility of throwing an exception has passed. this strategy ensures that if an exception occurs while our assignment operator is executing we do not corrupt the rest of our system.
inspec,train_1442,using constructed types in c unions. the c standard states that a union type can not have a member with a nontrivial constructor or destructor. while at first this seems unreasonable further thought makes it clear why this is the case the crux of the problem is that unions do n t have built in semantics for denoting when a member is the current member of the union. therefore the compiler ca n t know when it s appropriate to call constructors or destructors on the union members. still there are good reasons for wanting to use constructed object types in a union. for example you might want to implement a scripting language with a single variable type that can either be an integer a string or a list. a union is the perfect candidate for implementing such a composite type but the restriction on constructed union members may prevent you from using an existing string or list class for example from the stl to provide the underlying functionality. luckily a feature of c called placement new can provide a workaround.
inspec,train_1443,c and c a case for compatibility. modern c and c are sibling languages descended from classic c. in many people s minds they are wrongly but understandably fused into the mythical c c  programming language. there is no c c  language but there is a c c  community. previously the author described some of the incompatibilities that complicate the work of developers within that c c  community. in this article he discusses some of the underlying myths that help perpetuate these incompatibilities. he also shows why more compatibility ideally full compatibility is in the best interest of the c c  community. in the next paper he presents some examples of how the incompatibilities in c and c might be resolved.
inspec,train_1444,adaptable dialog boxes for cross platform programming. the author presents a framework for building dialog boxes that adapt to the look and feel of their platform. this method also helps with a few related problems specifying cross platform resources and handling dialog size changes due to localization. he uses a combination of xml automatic layout and run time dialog creation to give you most of the benefits of platform specific resources without the associated pain. source code with an implementation of the layout engine for mac os 9 1 carbon  mac os x and microsoft windows can be downloaded from the cuj website at www cuj com code. you can use this code as is or as a starting point for your own more complete implementation.
inspec,train_1445,applying bgl to computational geometry. the author applies boost graph library to the domain of computational geometry. first he formulates a concrete problem in graph terms. second he develops a way to transform the output of an existing algorithm into an appropriate boost graph library data structure. finally he implements two new algorithms for my boost graph library graph. the first algorithm gets the job done but could have been written in any programming language. the second algorithm however shows the power of boost graph library s generic programming approach graphs graphics and generic programming combine in this novel use of the boost graph library.
inspec,train_1446,the tattletale technique. practical experience has taught many java developers one thing critical resources mutexes database connections transactions file handles etc require timely and systematic release. unfortunately java s garbage collector is not up to that job. according to the java language specification there are no guarantees when a garbage collector will run when it will collect an object or when it will finalize an object if ever. even more unfortunately java s counterpart to the c destructor the finally block is both tedious and error prone requiring developers to constantly remember and duplicate resource releasing code. consequently even good java developers can forget to release critical resources. there is a light at the end of the tunnel. java may make it easier to leak critical resources but it also provides the necessary mechanisms to easily track them down. the tattletale technique is a simple method for designing new classes and retrofitting existing classes to quickly and easily detect the offending code responsible for leaking resources.
inspec,train_1447,international swinging making swing components locale sensitive. although java and its gui library swing provide software developers with a highly customizable framework for creating truly international applications the swing library is not sensitive to locale switches it can not automatically change an application s appearance to conform to the conventions of a specific locale at run time. several types of applications benefit from the ability to easily switch the language at run time. training applications and other programs that run on computers in public spaces such as libraries airports or government offices may need to support multiple languages. other applications like travel dictionaries or translation programs are inherently multilingual and are specifically designed to support users of dissimilar tongues. such applications would greatly benefit if the user interface language could be customized at run time. the article shows you how to customize swing to support locale switching at run time. the author has created a new look and feel called the mlmetallookandfeel where ml stands for multilingual. this new look and feel extends the standard metal look and feel but is locale sensitive at run time.
inspec,train_1448,implementing equals for mixed type comparison. the idea of comparing objects of different types is not entirely off base in particular for classes from the same class hierarchy. after all objects from the same class hierarchy and by class hierarchy we mean all classes derived from a common superclass other than object have something in common namely at least the superclass part. as we demonstrated in a previous paper 2002 providing a correct implementation of a mixed type comparison is a non trivial task. in this article we will show one way of implementing a mixed type comparison of objects from the same class hierarchy that meets the requirements of the equals contract.
inspec,train_1449,raising the standard of management education for electronic commerce professionals. the teaching of electronic commerce in universities has become a growth industry in itself. the rapid expansion of electronic commerce programmes raises the question of what actually is being taught. the association of electronic commerce as primarily a technical or information technology it phenomenon has not been sufficient to constrain it to it and information systems departments. business schools have been keen entrants into the electronic commerce coursework race and they are developing electronic commerce programmes in an environment where there is no agreed definition of the term. this paper draws on the work of kenneth boulding who argued that the dynamics of change in society are largely a product of changing skills and the way these skills are arranged into roles at the organizational level. it is argued that an overly technical interpretation of electronic commerce narrows the skills being acquired as part of formal education. universities under pressure from the market and technological change are changing their roles resulting in a further narrowing of the breadth of issues that is seen as legitimate to be included as electronic commerce. the outcome is that aspiring electronic commerce professionals are not being exposed to a wide enough agenda of ideas and concepts that will assist them to make better business decisions.
inspec,train_145,if the redboot fits open source rom monitor. many embedded developers today use a rom or flash resident software program that provides functionality such as loading and running application software scripting read write access to processor registers and memory dumps. a rom monitor as it is often called can be a useful and far less expensive debugging tool than an in circuit emulator. this article describes the redboot rom monitor. it takes a look at the features offered by the redboot rom monitor and sees how it can be configured. it also walks through the steps of rebuilding and installing a new redboot image on a target platform. finally it looks at future enhancements that are coming in new releases and how to get support and additional information when using redboot. although redboot uses software modules from the ecos real time operating system rtos and is often used in systems running embedded linux it is completely independent of both operating systems. redboot can be used with any operating system or rtos or even without one.
inspec,train_1450,networking in the palm of your hand pda buyer s guide. as pdas move beyond the personal space and into the enterprise you need to get a firm grip on the options available for your users. what operating system do you choose. what features do you and your company need. how will these devices fit into the existing corporate infrastructure. what about developer support.
inspec,train_1451,from information gateway to digital library management system a case analysis. this paper discusses the design implementation and evolution of the cornell university library gateway using the case analysis method. it diagnoses the gateway within the conceptual framework of definitions and best practices associated with information gateways portals and emerging digital library management systems in particular the product encompass.
inspec,train_1452,creating web based listings of electronic journals without creating extra work. creating up to date listings of electronic journals is challenging due to frequent changes in titles available and in urls for electronic journal titles. however many library users may want to browse web pages which contain listings of electronic journals arranged by title and or academic disciplines. this case study examines the development of a system which automatically exports data from the online catalog and incorporates it into dynamically generated web sites. these sites provide multiple access points for journals include web based interfaces enabling subject specialists to manage the list of titles which appears in their subject area. because data are automatically extracted from the catalog overlap in updating titles and urls is avoided. following the creation of this system usage of electronic journals dramatically increased and feedback has been positive. future challenges include developing more frequent updates and motivating subject specialists to more regularly monitor new titles.
inspec,train_1453,mobile banking s tough sell. banks are having to put their mobile commerce projects on hold because the essential technology to make the services usable in particular gprs general packet radio service has n t become widely available. it is estimated that by the end of 2002 only 5 per cent of adults will have gprs phones. this will have a knock on effect for other technologies such as clickable icons and multimedia messaging. in fact banking via wap wireless application protocol has proved to be a frustrating and time consuming process for the customer. financial firms hopes for higher mobile usage are stymied by the fact that improvements to the systems wo n t happen as fast as they want and the inadequacies of the system go beyond immature technology. financial services institutions should not wait for customers to become au fait with their wap. instead they should be the ones driving the traffic.
inspec,train_1455,a wizard idea internet in finance. new technology is set to become an ever more important area of work for brokers. lawrie holmes looks at how the internet is driving change and opportunity.
inspec,train_1456,look who s talking voice recognition. voice recognition could be the answer to the problem of financial fraud but in the world of biometric technology money talks.
inspec,train_1457,a discontinuous galerkin method for transient analysis of wave propagation in unbounded domains. a technique based on the discontinuous galerkin finite element method is developed and applied to the derivation of an absorbing boundary condition for the analysis of transient wave propagation. the condition is exact in that only discretization error is involved. furthermore the computational cost associated with use of the condition is an order of magnitude lower than for conditions based on green functions. the time stepping scheme resulting from an implicit method in conjunction with this boundary condition appears to be unconditionally stable.
inspec,train_1458,direct gear tooth contact analysis for hypoid bevel gears. a new methodology for tooth contact analysis based on a very general mathematical model of the generating process is proposed. considering the line of action as a first order singularity of a certain operator equation we develop first and second order conditions for a pair of generated gear tooth flanks to be in contact. the constructive approach allows the direct computation of the paths of contact as the solution of a nonlinear equation system including the exact determination of the bounds of the paths of contact. the transmission error as well as curvature properties in the contact points are obtained in a convenient way. the resulting contact ellipses approximate the bearing area. through the use of automatic differentiation all the geometric quantities are calculable within the machine accuracy of the computer.
inspec,train_1459,wave propagation related to high speed train. a scaled boundary fe approach for unbounded domains. analysis of wave propagation in solid materials under moving loads is a topic of great interest in railway engineering. the objective of the paper is three dimensional modelling of high speed train related ground vibrations in particular the question of how to account for the unbounded media is addressed. for efficient and accurate modelling of railway structural components taking the unbounded media into account a hybrid method based on a combination of the conventional finite element method and scaled boundary finite element method is established. in the paper element matrices and solution procedures for the scaled boundary finite element method sbfem are derived. a non linear finite element iteration scheme using lagrange multipliers and coupling between the unbounded domain and the finite element domain are also discussed. two numerical examples including one example demonstrating the dynamical response of a railroad section are presented to demonstrate the performance of the proposed method.
inspec,train_146,design patterns for high availability. it is possible to achieve five nines reliability with everyday commercial quality hardware and software. the key is the way in which these components are combined. the design of high availability systems is based on a combination of redundant hardware components and software to manage fault detection and correction without human intervention. the author quickly reviews some definitions tied to high availability and fault management and then goes on to discuss some hardware and software design patterns for fault tolerant systems.
inspec,train_1460,detection of flaws in composites from scattered elastic wave field using an improved mu ga and a local optimizer. an effective technique for flaw detection of composites is proposed. in this technique the detection problem is formulated as an optimization problem minimizing the difference between the measured and calculated surface displacement response derived from scattered elastic wave fields. a combined optimization technique using an improved mu ga and a local optimizer is developed to solve the optimization problem so as to obtain the flaw parameters defining flaw configurations. guidelines for implementing the detection technique including formulation of the objective function of the optimization problem using different error norms improvement of mu ga convergence performance switching from mu ga to local optimizer in the optimization process and suppression of the effect of noise on detection results are addressed in detail. numerical examples are presented to demonstrate the effectiveness and efficiency of the proposed detection technique.
inspec,train_538,polarization of the rf field in a human head at high field a study with a quadrature surface coil at 7 0 t. the rf field intensity distribution in the human brain becomes inhomogeneous due to wave behavior at high field. this is further complicated by the spatial distribution of rf field polarization that must be considered to predict image intensity distribution. an additional layer of complexity is involved when a quadrature coil is used for transmission and reception. to study such complicated rf field behavior a computer modeling method was employed to investigate the rf field of a quadrature surface coil at 300 mhz. theoretical and experimental results for a phantom and the human head at 7 0 t are presented. the results are theoretically important and practically useful for high field quadrature coil design and application.
inspec,train_539,perfusion quantification using gaussian process deconvolution. the quantification of perfusion using dynamic susceptibility contrast mri dsc mri requires deconvolution to obtain the residual impulse response function irf. in this work a method using the gaussian process for deconvolution gpd is proposed. the fact that the irf is smooth is incorporated as a constraint in the method. the gpd method which automatically estimates the noise level in each voxel has the advantage that model parameters are optimized automatically. the gpd is compared to singular value decomposition svd using a common threshold for the singular values and to svd using a threshold optimized according to the noise level in each voxel. the comparison is carried out using artificial data as well as data from healthy volunteers. it is shown that gpd is comparable to svd with a variable optimized threshold when determining the maximum of the irf which is directly related to the perfusion. gpd provides a better estimate of the entire irf. as the signal to noise ratio snr increases or the time resolution of the measurements increases gpd is shown to be superior to svd. this is also found for large distribution volumes.
inspec,train_54,controls help harmonic spray do ok removing residues. looks at how innovative wafer cleaning equipment hit the market in a timely fashion thanks in part to controls maker rockwell automation.
inspec,train_540,ventilation perfusion ratio of signal intensity in human lung using oxygen enhanced and arterial spin labeling techniques. this study investigates the distribution of ventilation perfusion v q signal intensity si ratios using oxygen enhanced and arterial spin labeling asl techniques in the lungs of 10 healthy volunteers. ventilation and perfusion images were simultaneously acquired using the flow sensitive alternating inversion recovery fair method as volunteers alternately inhaled room air and 100 oxygen. images of the t sub 1 distribution were calculated for five volunteers for both selective t sub 1f and nonselective t sub 1 inversion. the average t sub 1 was 1360 ms or 116 ms and the average t sub 1f was 1012 ms or 112 ms yielding a difference that is statistically significant p 0 002. excluding large pulmonary vessels the average v q si ratios were 0 355 or 0 073 for the left lung and 0 371 or 0 093 for the right lung which are in agreement with the theoretical v q si ratio. plots of the wo si ratio are similar to the logarithmic normal distribution obtained by multiple inert gas elimination techniques with a range of ratios matching ventilation and perfusion. this mri v q technique is completely noninvasive and does not involve ionized radiation. a limitation of this method is the nonsimultaneous acquisition of perfusion and ventilation data with oxygen administered only for the ventilation data.
inspec,train_541,virtual reality based multidimensional therapy for the treatment of body image disturbances in binge eating disorders a preliminary controlled study. the main goal of this paper is to preliminarily evaluate the efficacy of a virtual reality vr based multidimensional approach in the treatment of body image attitudes and related constructs. the female binge eating disorder bed patients n 20 involved in a residential weight control treatment including low calorie diet 1200 cal day and physical training were randomly assigned either to the multidimensional vr treatment or to psychonutritional groups based on the cognitive behavior approach. patients were administered a battery of outcome measures assessing eating disorders symptomathology attitudes toward food body dissatisfaction level of anxiety motivation for change level of assertiveness and general psychiatric symptoms. in the short term the vr treatment was more effective than the traditional cognitive behavioral psychonutritional groups in improving the overall psychological state of the patients. in particular the therapy was more effective in improving body satisfaction self efficacy and motivation for change. no significant differences were found in the reduction of the binge eating behavior. the possibility of inducing a significant change in body image and its associated behaviors using a vr based short term therapy can be useful to improve the body satisfaction in traditional weight reduction programs. however given the nature of this research that does not include a followup study the obtained results are preliminary only.
inspec,train_542,the treatment of fear of flying a controlled study of imaginal and virtual reality graded exposure therapy. the goal of this study was to determine if virtual reality graded exposure therapy vrget was equally efficacious more efficacious or less efficacious than imaginal exposure therapy in the treatment of fear of flying. thirty participants age 39 8 or 9 7 with confirmed dsm iv diagnosis of specific phobia fear of flying were randomly assigned to one of three groups vrget with no physiological feedback vrgetno vrget with physiological feedback vrgetpm or systematic desensitization with imaginal exposure therapy iet. eight sessions were conducted once a week. during each session physiology was measured to give an objective measurement of improvement over the course of exposure therapy. in addition self report questionnaires subjective ratings of anxiety suds and behavioral observations included here as flying behavior before beginning treatment and at a three month posttreatment followup were included. in the analysis of results the chi square test of behavioral observations based on a three month posttreatment followup revealed a statistically significant difference in flying behavior between the groups chi sup 2 4 19 41 p 0 001. only one participant 10 who received iet eight of the ten participants 80 who received vrgetno and ten out of the ten participants 100 who received vrgetpm reported an ability to fly without medication or alcohol at three month followup. although this study included small sample sizes for the three groups the results showed vrget was more effective than iet in the treatment of flying. it also suggests that physiological feedback may add to the efficacy of vr treatment.
inspec,train_543,the development of virtual reality therapy vrt system for the treatment of acrophobia and therapeutic case. virtual reality therapy vrt based on this sophisticated technology has been used in the treatment of subjects diagnosed with acrophobia a disorder that is characterized by marked anxiety upon exposure to heights and avoidance of heights. conventional vr systems for the treatment of acrophobia have limitations over costly devices or somewhat unrealistic graphic scenes. the goal of this study was to develop an inexpensive and more realistic virtual environment ve in which to perform exposure therapy for acrophobia. it is based on a personal computer and a virtual scene of a bunge jump tower in the middle of a large city. the virtual scenario includes an open lift surrounded by props beside a tower which allows the patient to feel a sense of heights. the effectiveness of the ve was evaluated through the clinical treatment of a subject who was suffering from the fear of heights. as a result it was proved that this vr environment was effective and realistic at overcoming acrophobia according not only to the comparison results of a variety of questionnaires before and after treatment but also to the subject s comments that the ve seemed to evoke more fearful feelings than the real situation.
inspec,train_544,virtual reality treatment of flying phobia. flying phobia fp might become a very incapacitating and disturbing problem in a person s social working and private areas. psychological interventions based on exposure therapy have proved to be effective but given the particular nature of this disorder they bear important limitations. exposure therapy for fp might be excessively costly in terms of time money and efforts. virtual reality vr overcomes these difficulties as different significant environments might be created where the patient can interact with what he or she fears while in a totally safe and protected environment the therapist s consulting room. this paper intends on one hand to show the different scenarios designed by our team for the vr treatment of fp and on the other to present the first results supporting the effectiveness of this new tool for the treatment of fp in a multiple baseline study.
inspec,train_545,interaction and presence in the clinical relationship virtual reality vr as communicative medium between patient and therapist. the great potential offered by virtual reality vr to clinical psychologists derives prevalently from the central role in psychotherapy occupied by the imagination and by memory. these two elements which are fundamental in our life present absolute and relative limits to the individual potential. using vr as an advanced imaginal system an experience that is able to reduce the gap existing between imagination and reality it is possible to transcend these limits. in this sense vr can improve the efficacy of a psychological therapy for its capability of reducing the distinction between the computer s reality and the conventional reality. two are the core characteristics of this synthetic imaginal experience the perceptual illusion of nonmediation and the possibility of building and sharing a common ground. in this sense experiencing presence in a clinical virtual environment ve such as a shared virtual hospital requires more than reproduction of the physical features of external reality. it requires the creation and sharing of the cultural web that makes meaningful and therefore visible both people and objects populating the environment. the paper outlines a framework for supporting the development and tuning of clinically oriented vr systems.
inspec,train_546,real time quasi 2 d inversion of array resistivity logging data using neural network. we present a quasi 2 d real time inversion algorithm for a modern galvanic array tool via dimensional reduction and neural network simulation. using reciprocity and superposition we apply a numerical focusing technique to the unfocused data. the numerically focused data are much less subject to 2 d and layering effects and can be approximated as from a cylindrical 1 d earth. we then perform 1 d inversion on the focused data to provide approximate information about the 2 d resistivity structure. a neural network is used to perform forward modeling in the 1 d inversion which is several hundred times faster than conventional numerical forward solutions. testing our inversion algorithm on both synthetic and field data shows that this fast inversion algorithm is useful for providing formation resistivity information at a well site.
inspec,train_547,excess energy cooling system. the designers retrofitting a comfort cooling system to offices in hertfordshire have been able to make use of the waste heat rejected. what s more they re now making it a standard solution for much larger projects.
inspec,train_548,cool and green air conditioning. in these days of global warming air conditioning engineers need to specify not just for the needs of the occupants but also to maximise energy efficiency. julian brunnock outlines the key areas to consider for energy efficient air conditioning systems.
inspec,train_549,taking it to the max ventilation systems. raising the volumetric air supply rate is one way of increasing the cooling capacity of displacement ventilation systems. david butler and michael swainson explore how different types of diffusers can help make this work.
inspec,train_55,self testing chips take a load off ate. looks at how chipmakers get more life out of automatic test equipment by embedding innovative circuits in silicon.
inspec,train_550,market watch air conditioning. after a boom period in the late nineties the air conditioning market finds itself in something of a lull at present but manufacturers are n t panicking.
inspec,train_551,access privilege management in protection systems. we consider the problem of managing access privileges on protected objects. we associate one or more locks with each object one lock for each access right defined by the object type. possession of an access right on a given object is certified by possession of a key for this object if this key matches one of the object locks. we introduce a number of variants to this basic key lock technique. polymorphic access rights make it possible to decrease the number of keys required to certify possession of complex access privileges that are defined in terms of several access rights. multiple locks on the same access right allow us to exercise forms of selective revocation of access privileges. a lock conversion function can be used to reduce the number of locks associated with any given object to a single lock. the extent of the results obtained is evaluated in relation to alternative methodologies for access privilege management.
inspec,train_552,anatomy of the coupling query in a web warehouse. to populate a data warehouse specifically designed for web data i e web warehouse it is imperative to harness relevant documents from the web. in this paper we describe a query mechanism called coupling query to glean relevant web data in the context of our web warehousing system called warehouse of web data whoweda. a coupling query may be used for querying both html and xml documents. important features of our query mechanism are the ability to query metadata content internal and external hyperlink structure of web documents based on partial knowledge ability to express constraints on tag attributes and tagless segment of data ability to express conjunctive as well as disjunctive query conditions compactly ability to control execution of a web query and preservation of the topological structure of hyperlinked documents in the query results. we also discuss how to formulate a query graphically and in textual form using a coupling graph and coupling text respectively.
inspec,train_553,application of traditional system design techniques to web site design. after several decades of computer program construction there emerged a set of principles that provided guidance to produce more manageable programs. with the emergence of the plethora of internet web sites one wonders if similar guidelines are followed in their construction. since this is a new technology no apparent universally accepted methods have emerged to guide the designer in web site construction. this paper reviews the traditional principles of structured programming and the preferred characteristics of web sites. finally a mapping of how the traditional guidelines may be applied to web site construction is presented. the application of the traditional principles of structured programming to the design of a web site can provide a more usable site for the visitors to the site. the additional benefit of using these time honored techniques is the creation of a web site that will be easier to maintain by the development staff.
inspec,train_554,a scalable and lightweight qos monitoring technique combining passive and active approaches on the mathematical formulation of compact monitor. to make a scalable and lightweight qos monitoring system we 2002 have proposed a new qos monitoring technique called the change of measure based passive active monitoring compact monitor which is based on the change of measure framework and is an active measurement transformed by using passively monitored data. this technique enables us to measure detailed qos information for individual users applications and organizations in a scalable and lightweight manner. in this paper we present the mathematical foundation of compact monitor. in addition we show its characteristics through simulations in terms of typical implementation issues for inferring the delay distributions. the results show that compact monitor gives accurate qos estimations with only a small amount of extra traffic for active measurement.
inspec,train_555,computing transient gating charge movement of voltage dependent ion channels. the opening of voltage gated sodium potassium and calcium ion channels has a steep relationship with voltage. in response to changes in the transmembrane voltage structural movements of an ion channel that precede channel opening generate a capacitative gating current. the net gating charge displacement due to membrane depolarization is an index of the voltage sensitivity of the ion channel activation process. understanding the molecular basis of voltage dependent gating of ion channels requires the measurement and computation of the gating charge q. we derive a simple and accurate semianalytic approach to computing the voltage dependence of transient gating charge movement q v relationship of discrete markov state models of ion channels using matrix methods. this approach allows rapid computation of q v curves for finite and infinite length step depolarizations and is consistent with experimentally measured transient gating charge. this computational approach was applied to shaker potassium channel gating including the impact of inactivating particles on potassium channel gating currents.
inspec,train_556,coarse grained reduction and analysis of a network model of cortical response i drifting grating stimuli. we present a reduction of a large scale network model of visual cortex developed by mclaughlin shapley shelley and wielaard. the reduction is from many integrate and fire neurons to a spatially coarse grained system for firing rates of neuronal subpopulations. it accounts explicitly for spatially varying architecture ordered cortical maps such as orientation preference that vary regularly across the cortical layer and disordered cortical maps such as spatial phase preference or stochastic input conductances that may vary widely from cortical neuron to cortical neuron. the result of the reduction is a set of nonlinear spatiotemporal integral equations for phase averaged firing rates of neuronal subpopulations across the model cortex derived asymptotically from the full model without the addition of any extra phenomological constants. this reduced system is used to study the response of the model to drifting grating stimuli where it is shown to be useful for numerical investigations that reproduce at far less computational cost the salient features of the point neuron network and for analytical investigations that unveil cortical mechanisms behind the responses observed in the simulations of the large scale computational model. for example the reduced equations clearly show 1 phase averaging as the source of the time invariance of cortico cortical conductances 2 the mechanisms in the model for higher firing rates and better orientation selectivity of simple cells which are near pinwheel centers 3 the effects of the length scales of cortico cortical coupling and 4 the role of noise in improving the contrast invariance of orientation selectivity.
inspec,train_557,noise and the psth response to current transients ii. integrate and fire model with slow recovery and application to motoneuron data. for pt i see ibid vol 11 no 2 p 135 151 2001. a generalized version of the integrate and fire model is presented that qualitatively reproduces firing rates and membrane trajectories of motoneurons. the description is based on the spike response model and includes three different time constants the passive membrane time constant a recovery time of the input conductance after each spike and a time constant of the spike afterpotential. the effect of stochastic background input on the peristimulus time histogram psth response to spike input is calculated analytically. model results are compared with the experimental data of poliakov et al 1996. the linearized theory shows that the psth response to an input spike is proportional to a filtered version of the postsynaptic potential generated by the input spike. the shape of the filter depends on the background activity. the full nonlinear theory is in close agreement with simulated psth data.
inspec,train_558,os porting and application development for soc. to deliver improved usability in high end portable consumer products the use of an appropriate consumer operating system os is becoming far more widespread. using a commercially supported os also vastly increases the availability of supported applications. for the device developer this trend adds major complexity to the problem of system implementation. porting a complete operating system to a new hardware design adds significantly to the development burden increasing both time to market and expense. even for those familiar with the integration of a real time os the porting validation and support of a complex platform os is a formidable task.
inspec,train_559,is open source more or less secure. networks dominate today s computing landscape and commercial technical protection is lagging behind attack technology. as a result protection programme success depends more on prudent management decisions than on the selection of technical safeguards. the paper takes a management view of protection and seeks to reconcile the need for security with the limitations of technology.
inspec,train_56,new thinking on rendering. looks at how graphics hardware solves a range of rendering problems.
inspec,train_560,citizen centric identity management chip tricks. accelerating and harmonizing the diffusion and acceptance of electronic services in europe in a secure and practical way has become a priority of several initiatives in the past few years and a critical factor for citizen and business information society services. as identification and authentication is a critical element in accessing public services the combination of public key infrastructure pki and smart cards emerges as the solution of choice for egovernment in europe. national governments and private initiatives alike vouch their support for this powerful combination to deliver an essential layer of reliable electronic services and address identity requirements in a broad range of application areas. a recent study suggests that several egovernment implementations point to the direction of electronic citizen identity management as an up and coming challenge. the paper discusses the egovernment needs for user identification applicability and the need for standardization.
inspec,train_561,subseven s honey pot program. a serious security threat today are malicious executables especially new unseen malicious executables often arriving as email attachments. these new malicious executables are created at the rate of thousands every year and pose a serious threat. current anti virus systems attempt to detect these new malicious programs with heuristics generated by hand. this approach is costly and often ineffective. we introduce the trojan horse subseven its capabilities and influence over intrusion detection systems. a honey pot program is implemented simulating the subseven server. the honey pot program provides feedback and stores data to and from the subseven s client.
inspec,train_562,the advanced encryption standard implementation and transition to a new cryptographic benchmark. cryptography is the science of coding information to create unintelligible ciphers that conceal or hide messages. the process that achieves this goal is commonly referred to as encryption. although encryption processes of various forms have been employed for centuries to protect the exchange of messages the advent of the information age has underscored the importance of strong cryptography as a process to secure data exchanged through electronic means and has accentuated the demand for products offering these services. this article describes the process that has led to the development of the latest cryptographic benchmark the advanced encryption standard aes. the article briefly examines the requirements set forth for its development defines how the new standard is implemented and describes how government business and industry can transition to aes with minimum impact to operations.
inspec,train_563,getting the most out of intrusion detection systems. intrusion detection systems ids can play a very valuable role in the defence of a network. however it is important to understand not just what it will do and how it does it but what it wo n t do and why. this article does not go into the technical working of ids in too much detail rather it limits itself to a discussion of some of the capabilities and failings of the technology.
inspec,train_564,development of a computer aided manufacturing system for profiled edge lamination tooling. profiled edge lamination pel tooling is a promising rapid tooling rt method involving the assembly of an array of laminations whose top edges are simultaneously profiled and beveled based on a cad model of the intended tool surface. to facilitate adoption of this rt method by industry a comprehensive pel tooling development system is proposed. the two main parts of this system are 1 iterative tool design based on thermal and structural models and 2 fabrication of the tool using a computer aided manufacturing cam software and abrasive water jet cutting. cam software has been developed to take lamination slice data profiles from any proprietary rp software in the form of polylines and create smooth kinematically desirable cutting trajectories for each tool lamination. two cutting trajectory algorithms called identical equidistant profile segmentation and adaptively vector profiles projection avpp were created for this purpose. by comparing the performance of both algorithms with a benchmark part shape the avpp algorithm provided better cutting trajectories for complicated tool geometries. a 15 layer aluminum pel tool was successfully fabricated using a 5 axis cnc awj cutter and nc code generated by the cam software.
inspec,train_565,control of thin film growth in chemical vapor deposition manufacturing systems a feasibility study. a study is carried out to design and optimize chemical vapor deposition cvd systems for material fabrication. design and optimization of the cvd process is necessary to satisfying strong global demand and ever increasing quality requirements for thin film production. advantages of computer aided optimization include high design turnaround time flexibility to explore a larger design space and the development and adaptation of automation techniques for design and optimization. a cvd reactor consisting of a vertical impinging jet at atmospheric pressure for growing titanium nitride films is studied for thin film deposition. numerical modeling and simulation are used to determine the rate of deposition and film uniformity over a wide range of design variables and operating conditions. these results are used for system design and optimization. the optimization procedure employs an objective function characterizing film quality productivity and operational costs based on reactor gas flow rate susceptor temperature and precursor concentration. parameter space mappings are used to determine the design space while a minimization algorithm such as the steepest descent method is used to determine optimal operating conditions for the system. the main features of computer aided design and optimization using these techniques are discussed in detail.
inspec,train_566,sensing and control of double sided arc welding process. the welding industry is driven to improve productivity without sacrificing quality. for thick material welding the current practice is to use backing or multiple passes. the laser welding process capable of achieving deep narrow penetration can significantly improve welding productivity for such applications by reducing the number of passes. however its competitiveness in comparison with traditional arc welding is weakened by its high cost strict fit up requirement and difficulty in welding large structures. in this work a different method referred to as double sided arc welding dsaw is developed to improve the arc concentration for arc welding. a sensing and control system is developed to achieve deep narrow penetration under variations in welding conditions. experiments verified that the pulsed keyhole dsaw system developed is capable of achieving deep narrow penetration on a 1 2 inch thick square butt joint in a single pass.
inspec,train_567,hidden markov model based tool wear monitoring in turning. this paper presents a new modeling framework for tool wear monitoring in machining processes using hidden markov models hmms. feature vectors are extracted from vibration signals measured during turning. a codebook is designed and used for vector quantization to convert the feature vectors into a symbol sequence for the hidden markov model. a series of experiments are conducted to evaluate the effectiveness of the approach for different lengths of training data and observation sequence. experimental results show that successful tool state detection rates as high as 97 can be achieved by using this approach.
inspec,train_568,modeling cutting temperatures for turning inserts with various tool geometries and materials. temperatures are of interest in machining because cutting tools often fail by thermal softening or temperature activated wear. many models for cutting temperatures have been developed but these models consider only simple tool geometries such as a rectangular slab with a sharp corner. this report describes a finite element study of tool temperatures in cutting that accounts for tool nose radius and included angle effects. a temperature correction factor model that can be used in the design and selection of inserts is developed to account for these effects. a parametric mesh generator is used to generate the finite element models of tool and inserts of varying geometries. the steady state temperature response is calculated using nastran solver. several finite element analysis fea runs are performed to quantify the effects of inserts included angle nose radius and materials for the insert and the tool holder on the cutting temperature at the insert rake face. the fea results are then utilized to develop a temperature correction factor model that accounts for these effects. the temperature correction factor model is integrated with an analytical temperature model for rectangular inserts to predict cutting temperatures for contour turning with inserts of various shapes and nose radii. finally experimental measurements of cutting temperature using the tool work thermocouple technique are performed and compared with the predictions of the new temperature model. the comparisons show good agreement.
inspec,train_569,application of an internally consistent material model to determine the effect of tool edge geometry in orthogonal machining. it is well known that the edge geometry of a cutting tool affects the forces measured in metal cutting. two experimental methods have been suggested in the past to extract the ploughing non cutting component from the total measured force 1 the extrapolation approach and 2 the dwell force technique. this study reports the behavior of zinc during orthogonal machining using tools of controlled edge radius. applications of both the extrapolation and dwell approaches show that neither produces an analysis that yields a material response consistent with the known behavior of zinc. further analysis shows that the edge geometry modifies the shear zone of the material and thereby modifies the forces. when analyzed this way the measured force data yield the expected material response without requiring recourse to an additional ploughing component.
inspec,train_57,speaker adaptive modeling by vocal tract normalization. this paper presents methods for speaker adaptive modeling using vocal tract normalization vtn along with experimental tests on three databases. we propose a new training method for vtn by using single density acoustic models per hmm state for selecting the scale factor of the frequency axis we avoid the problem that a mixture density tends to learn the scale factors of the training speakers and thus can not be used for selecting the scale factor. we show that using single gaussian densities for selecting the scale factor in training results in lower error rates than using mixture densities. for the recognition phase we propose an improvement of the well known two pass strategy by using a non normalized acoustic model for the first recognition pass instead of a normalized model lower error rates are obtained. in recognition tests this method is compared with a fast variant of vtn. the two pass strategy is an efficient method but it is suboptimal because the scale factor and the word sequence are determined sequentially. we found that for telephone digit string recognition this suboptimality reduces the vtn gain in recognition performance by 30 relative. in summary on the german spontaneous speech task verbmobil the wsj task and the german telephone digit string corpus sietill the proposed methods for vtn reduce the error rates significantly.
inspec,train_570,prediction and compensation of dynamic errors for coordinate measuring machines. coordinate measuring machines cmms are already widely utilized as measuring tools in the modem manufacturing industry. rapidly approaching now is the trend for next generation cmms. however the increases in measuring velocity of cmm applications are limited by dynamic errors that occur in cmms. in this paper a systematic approach for modeling the dynamic errors of a touch trigger probe cmm is developed through theoretical analysis and experimental study. an overall analysis of the dynamic errors of cmms is conducted with weak components of the cmm identified by a laser interferometer. the probing process as conducted with a touch trigger probe is analyzed. the dynamic errors are measured modeled and predicted using neural networks. the results indicate that using this mode it is possible to compensate for the dynamic errors of cmms.
inspec,train_571,control of transient thermal response during sequential open die forging a trajectory optimization approach. a trajectory optimization approach is applied to the design of a sequence of open die forging operations in order to control the transient thermal response of a large titanium alloy billet. the amount of time the billet is soaked in furnace prior to each successive forging operation is optimized to minimize the total process time while simultaneously satisfying constraints on the maximum and minimum values of the billet temperature distribution to avoid microstructural defects during forging. the results indicate that a differential heating profile is the most effective at meeting these design goals.
inspec,train_572,characterization of sheet buckling subjected to controlled boundary constraints. a wedge strip test is designed to study the onset and post buckling behavior of a sheet under various boundary constraints. the device can be easily incorporated into a conventional tensile test machine and material resistance to buckling is measured as the buckling height versus the in plane strain state. the design yields different but consistent buckling modes with easy changes of boundary conditions either clamped or freed and sample geometry. experimental results are then used to verify a hybrid approach to buckling prediction i e the combination of the fem analysis and an energy based analytical wrinkling criterion. the fem analysis is used to obtain the stress field and deformed geometry in a complex forming condition while the analytical solution is to provide the predictions less sensitive to artificial numerical parameters. a good agreement between experimental data and numerical predictions is obtained.
inspec,train_573,ecg gated sup 18 f fdg positron emission tomography. single test evaluation of segmental metabolism function and contractile reserve in patients with coronary artery disease and regional dysfunction. sup 18 f fluorodeoxyglucose sup 18 f fdg positron emission tomography pet provides information about myocardial glucose metabolism to diagnose myocardial viability. additional information about the functional status is necessary. comparison of tomographic metabolic pet with data from other imaging techniques is always hampered by some transfer uncertainty and scatter. we wanted to evaluate a new fourier based ecg gated pet technique using a high resolution scanner providing both metabolic and functional data with respect to feasibility in patients with diseased left ventricles. forty five patients with coronary artery disease and at least one left ventricular segment with severe hypokinesis or akinesis at biplane cineventriculography were included. a new fourier based ecg gated metabolic sup 18 f fdg pet was performed in these patients. function at rest and sup 18 f fdg uptake were examined in the pet study using a 36 segment model. segmental comparison with ventriculography revealed a high reliability in identifying dysfunctional segments 96. sup 18 f fdg uptake of normokinetic hypokinetic akinetic segments was 75 4 or 7 5 65 3 or 10 5 and 35 9 or 15 2 p 0 001. in segments or 70  sup 18 f fdg uptake no akinesia was observed. no residual function was found below 40  sup 18 f fdg uptake. an additional dobutamine test was performed and revealed inotropic reserve viability in 42 akinetic segments and 45 hypokinetic segments. ecg gated metabolic pet with pixel based fourier smoothing provides reliable data on regional function. assessment of metabolism and function makes complete judgement of segmental status feasible within a single study without any transfer artefacts or test to test variability. the results indicate the presence of considerable amounts of viable myocardium in regions with an uptake of 40 50  sup 18 f fdg.
inspec,train_574,a novel approach for the detection of pathlines in x ray angiograms the wavefront propagation algorithm. presents a new pathline approach based on the wavefront propagation principle and developed in order to reduce the variability in the outcomes of the quantitative coronary artery analysis. this novel approach called wavepath reduces the influence of the user defined start and endpoints of the vessel segment and is therefore more robust and improves the reproducibility of the lesion quantification substantially. the validation study shows that the wavepath method is totally constant in the middle part of the pathline even when using the method for constructing a bifurcation or sidebranch pathline. furthermore the number of corrections needed to guide the wavepath through the correct vessel is decreased from an average of 0 44 corrections per pathline to an average of 0 12 per pathline. therefore it can be concluded that the wavepath algorithm improves the overall analysis substantially.
inspec,train_575,a new voltage vector selection algorithm in direct torque control of induction motor drives. ac drives based on direct torque control of induction machines allow high dynamic performance to be obtained with very simple control schemes. the drive behavior in terms of current flux and torque ripple is dependent on the utilised voltage vector selection strategy and the operating conditions. in this paper a new voltage vector selection algorithm which allows a sensible reduction of the rms value of the stator current ripple without increasing the average value of the inverter switching frequency and without the need of a pwm pulse generator block is presented numerical simulations have been carried out to validate the proposed method.
inspec,train_576,application of sugeno fuzzy logic controller to the stator field oriented doubly fed asynchronous motor drive. this study deals with the application of the fuzzy control theory to wound rotor asynchronous motor with both its stator and rotor fed by two pwm voltage source inverters in which the system operates in stator field oriented control. thus after determining the model of the machine we present two types of fuzzy controller mamdani and sugeno controllers. the training of the last one is carried out starting from the first. simulation study is conducted to show the effectiveness of the proposed method.
inspec,train_577,a robust h sub infinity control approach for induction motors. this paper deals with the robustness and stability of an induction motor control structure against internal and external disturbances. in the proposed control scheme we have used an h sub infinity controller with field orientation and input output linearization to achieve the above specified features. simulation results are included to illustrate the control approach performances.
inspec,train_578,new approach to standing phase angle reduction for power system restoration. during power system restoration it is necessary to check the phase angle between two buses before closing circuit breakers to connect a line between them. these angles may occur across a tie line between two systems or between two connected subsystems within a system. in case of large standing phase angle spa difference the synchro check relay does not allow closing of the breaker for this line. therefore this excessive spa has to be reduced before attempting to connect the line. in this paper a new and fast method for reducing spa is presented. for this purpose the standing phase angle difference between two specific buses is represented in terms of sensitivity factors associated with the change in active power generations and consumption at the buses. then the proposed method reschedule generation of selected units or shed load of selected buses to reduce excessive spa difference between two buses based on sensitivity factors.
inspec,train_579,steinmetz system design under unbalanced conditions. this paper studies and develops general analytical expressions to obtain three phase current symmetrization under unbalanced voltage conditions. it proposes two procedures for this symmetrization the application of the traditional expressions assuming symmetry conditions and the use of optimization methods based on the general analytical equations. specifically the paper applies and evaluates these methods to analyze the steinmetz system design. several graphics evaluating the error introduced by assumption of balanced voltage in the design are plotted and an example is studied to compare both procedures. in the example the necessity to apply the optimization techniques in highly unbalanced conditions is demonstrated.
inspec,train_58,robust speech recognition using probabilistic union models. this paper introduces a new statistical approach namely the probabilistic union model for speech recognition involving partial unknown frequency band corruption. partial frequency band corruption accounts for the effect of a family of real world noises. previous methods based on the missing feature theory usually require the identity of the noisy bands. this identification can be difficult for unexpected noise with unknown time varying band characteristics. the new model combines the local frequency band information based on the union of random events to reduce the dependence of the model on information about the noise. this model partially accomplishes the target offering robustness to partial frequency band corruption while requiring no information about the noise. this paper introduces the theory and implementation of the union model and is focused on several important advances. these new developments include a new algorithm for automatic order selection a generalization of the modeling principle to accommodate partial feature stream corruption and a combination of the union model with conventional noise reduction techniques to deal with a mixture of stationary noise and unknown nonstationary noise. for the evaluation we used the tidigits database for speaker independent connected digit recognition. the utterances were corrupted by various types of additive noise stationary or time varying assuming no knowledge about the noise characteristics. the results indicate that the new model offers significantly improved robustness in comparison to other models.
inspec,train_580,a genetic approach to the optimization of automatic generation control parameters for power systems. this paper presents a method based on genetic algorithm for the automatic generation control of power systems. the technique is applied to control a system which includes two areas tied together through a power line. as a consequence of continuous load variation the frequency of the power system changes with time. in conventional studies frequency transients are minimized by using integral controllers and thus zero steady state error is obtained. in this paper integral controller gains and frequency bias factors are determined by using the genetic algorithm. the results of simulation reveal the application of the genetic algorithm having easy implementation to find the global optimum values of the control parameters.
inspec,train_581,successive expansion method of network planning applying symbolic analysis method. the conventional power system network successive expansion planning method is discussed in the context of the new paradigm of competitive electric power energy and service market. in sequel the paper presents an application of the conceptually new computer program based on the symbolic analysis of load flows in power system networks. the network parameters and variables are defined as symbols. the symbolic analyzer which models analytically the power system dc load flows enables the sensitivity analysis of the power system to parameter and variable variations costs transfers injections a valuable tool for the expansion planning analysis. that virtue could not be found within the conventional approach relying on compensation methods precalculated distribution factors and so on. this novel application sheds some light on the traditional power system network expansion planning method as well as on its possible application within the system network expansion planning in the new environment assuming the competitive electric power market.
inspec,train_582,optimal estimation of a finite sample of a discrete chaotic process. the synthesis of optimal algorithms for estimating discrete chaotic processes specified by a finite sample is considered various possible approaches are discussed. expressions determining the potential accuracy in estimating a single value of the chaotic process are derived. an example of the application of the general equations obtained is given.
inspec,train_583,neural networks in optimal filtration. the combined use and mutual influence of neural networks and optimal filtering is considered the neural network and filtering approaches are compared by solving two simple optimal filtering problems linear filtering and the filtering of a binary telegraph signal corresponding to observations in discrete white noise.
inspec,train_584,hybrid fuzzy modeling of chemical processes. fuzzy models have been proved to have the ability of modeling all plants without any priori information. however the performance of conventional fuzzy models can be very poor in the case of insufficient training data due to their poor extrapolation capacity. in order to overcome this problem a hybrid grey box fuzzy modeling approach is proposed in this paper to combine expert experience local linear models and historical data into a uniform framework. it consists of two layers. the expert fuzzy model constructed from linguistic information the local linear model and the t s type fuzzy model constructed from data are all put in the first layer. layer 2 is a fuzzy decision module that is used to decide which model in the first layer should be employed to make the final prediction. the output of the second layer is the output of the hybrid fuzzy model. with the help of the linguistic information the poor extrapolation capacity problem caused by sparse training data for conventional fuzzy models can be overcome. simulation result for ph neutralization process demonstrates its modeling ability over the linear models the expert fuzzy model and the conventional fuzzy model.
inspec,train_585,fuzzy system modeling in pharmacology an improved algorithm. in this paper we propose an improved fuzzy system modeling algorithm to address some of the limitations of the existing approaches identified during our modeling with pharmacological data. this algorithm differs from the existing ones in its approach to the cluster validity problem i e number of clusters the projection schema i e input membership assignment and rule determination and significant input determination. the new algorithm is compared with the bazoon turksen model which is based on the well known sugeno yasukawa approach. the comparison was made in terms of predictive performance using two different data sets. the first comparison was with a two variable nonlinear function prediction problem and the second comparison was with a clinical pharmacokinetic modeling problem. it is shown that the proposed algorithm provides more precise predictions. determining the degree of significance for each input variable allows the user to distinguish their relative importance.
inspec,train_586,a strategy for a payoff switching differential game based on fuzzy reasoning. in this paper a new concept of a payoff switching differential game is introduced. in this new game any one player at any time may have several choices of payoffs for the future. moreover the payoff switching process including the time of payoff switching and the outcome payoff of any one player is unknown to the other. indeed the overall payoff which is a sequence of several payoffs is unknown until the game ends. an algorithm for determining a reasoning strategy based on fuzzy reasoning is proposed. in this algorithm the fuzzy theory is used to estimate the behavior of one player during a past time interval. by deriving two fuzzy matrices gsm game similarity matrix and vgsm variation of gsm the behavior of the player can be quantified. two weighting vectors are selected to weight the relative importance of the player s behavior at each past time instant. finally a simple fuzzy inference rule is adopted to generate a linear reasoning strategy. the advantage of this algorithm is that it provides a flexible way for differential game specialists to convert their knowledge into a reasonable strategy. a practical example of guarding three territories is given to illustrate our main ideas.
inspec,train_587,an improved self organizing cpn based fuzzy system with adaptive back propagation algorithm. this paper describes an improved self organizing cpn based counter propagation network fuzzy system. two self organizing algorithms iusocpn and issocpn being unsupervised and supervised respectively are introduced. the idea is to construct the neural fuzzy system with a two phase hybrid learning algorithm which utilizes a cpn based nearest neighbor clustering scheme for both structure learning and initial parameters setting and a gradient descent method with adaptive learning rate for fine tuning the parameters. the obtained network can be used in the same way as a cpn to model and control dynamic systems while it has a faster learning speed than the original back propagation algorithm. the comparative results on the examples suggest that the method is fairly efficient in terms of simple structure fast learning speed and relatively high modeling accuracy.
inspec,train_588,an accurate cog defuzzifier design using lamarckian co adaptation of learning and evolution. this paper proposes a design technique of optimal center of gravity cog defuzzifier using the lamarckian co adaptation of learning and evolution. the proposed cog defuzzifier is specified by various design parameters such as the centers widths and modifiers of mfs. the design parameters are adjusted with the lamarckian co adaptation of learning and evolution where the learning performs a local search of design parameters in an individual cog defuzzifier but the evolution performs a global search of design parameters among a population of various cog defuzzifiers. this co adaptation scheme allows to evolve much faster than the non learning case and gives a higher possibility of finding an optimal solution due to its wider searching capability. an application to the truck backer upper control problem of the proposed co adaptive design method of cog defuzzifier is presented. the approximation ability and control performance are compared with those of the conventionally simplified cog defuzzifier in terms of the fuzzy logic controller s approximation error and the average tracing distance respectively.
inspec,train_589,hierarchical neuro fuzzy quadtree models. hybrid neuro fuzzy systems have been in evidence during the past few years due to its attractive combination of the learning capacity of artificial neural networks with the interpretability of the fuzzy systems. this article proposes a new hybrid neuro fuzzy model named hierarchical neuro fuzzy quadtree hnfq which is based on a recursive partitioning method of the input space named quadtree. the article describes the architecture of this new model presenting its basic cell and its learning algorithm. the hnfq system is evaluated in three well known benchmark applications the sinc x y function approximation the mackey glass chaotic series forecast and the two spirals problem. when compared to other neuro fuzzy systems the hnfq exhibits competing results with two major advantages it automatically creates its own structure and it is not limited to few input variables.
inspec,train_59,efficient tracking of the cross correlation coefficient. in many audio processing algorithms involving manipulation of discrete time signals the performance can vary strongly over the repertoire that is used. this may be the case when the signals from the various channels are allowed to be strongly positively or negatively correlated. we propose and analyze a general formula for tracking the time dependent correlation between two signals. some special cases of this formula lead to classical results known from the literature others are new. this formula is recursive in nature and uses only the instantaneous values of the two signals in a low cost and low complexity manner in particular there is no need to take square roots or to carry out divisions. furthermore this formula can be modified with respect to the occurrence of the two signals so as to further decrease the complexity and increase ease of implementation. the latter modification comes at the expense that not the actual correlation is tracked but rather a somewhat deformed version of it. to overcome this problem we propose for a number of instances of the tracking formula a simple warping operation on the deformed correlation. now we obtain at least for sinusoidal signals the correct value of the correlation coefficient. special attention is paid to the convergence behavior of the algorithm for stationary signals and the dynamic behavior if there is a transition to another stationary state the latter is considered to be important to study the tracking abilities to nonstationary signals. we illustrate tracking algorithm by using it for stereo music fragments obtained from a number of digital audio recordings.
inspec,train_590,universal approximation by hierarchical fuzzy system with constraints on the fuzzy rule. this paper presents a special hierarchical fuzzy system where the outputs of the previous layer are not used in the if parts but used only in the then parts of the fuzzy rules of the current layer. the proposed scheme can be shown to be a universal approximator to any continuous function on a compact set if complete fuzzy sets are used in the if parts of the fuzzy rules with singleton fuzzifier and center average defuzzifier. from the simulation of ball and beam control system it is demonstrated that the proposed scheme approximates with good accuracy the model nonlinear controller with fewer fuzzy rules than the centralized fuzzy system and its control performance is comparable to that of the nonlinear controller.
inspec,train_591,approximation theory of fuzzy systems based upon genuine many valued implications mimo cases. it is constructively proved that the multi input multi output fuzzy systems based upon genuine many valued implications are universal approximators they are called boolean type fuzzy systems in this paper. the general approach to construct such fuzzy systems is given that is through the partition of the output region by the given accuracy. two examples are provided to demonstrate the way in which fuzzy systems are designed to approximate given functions with a given required approximation accuracy.
inspec,train_592,approximation theory of fuzzy systems based upon genuine many valued implications siso cases. it is proved that the single input and single output siso fuzzy systems based upon genuine many valued implications are universal approximators. it is shown theoretically that fuzzy control systems based upon genuine many valued implications are equivalent to those based upon t norm implications the general approach to construct fuzzy systems is given. it is also shown that defuzzifier based upon center of areas is not appropriate to the fuzzy systems based upon genuine many valued implications.
inspec,train_593,fuzzy systems with overlapping gaussian concepts approximation properties in sobolev norms. in this paper the approximating capabilities of fuzzy systems with overlapping gaussian concepts are considered. the target function is assumed to be sampled either on a regular gird or according to a uniform probability density. by exploiting a connection with radial basis functions approximators a new method for the computation of the system coefficients is provided showing that it guarantees uniform approximation of the derivatives of the target function.
inspec,train_594,improved analysis for the nonlinear performance of cmos current mirrors with device mismatch. the nonlinear performance of the simple and complementary mosfet current mirrors are analyzed. closed form expressions are obtained for the harmonic and intermodulation components resulting from a multisinusoidal input current. these expressions can be used for predicting the limiting values of the input current under prespecified conditions of threshold voltage mismatches and or transconductance mismatches. the case of a single input sinusoid is discussed in detail and the results are compared with spice simulations.
inspec,train_595,six common enterprise programming mistakes. instead of giving you tips to use in your programming at least directly i want to look at some common mistakes made in enterprise programming. instead of focusing on what to do i want to look at what you should not do. most programmers take books like mine and add in the good things but they leave their mistakes in the very same programs. so i touch on several common errors i see in enterprise programming and then briefly mention how to avoid those mistakes.
inspec,train_596,copyright management in the digital age. listening to and buying music online is becoming increasingly popular with consumers. so much so that merrill lynch forecasts the value of the online music market will explode from 8 million in 2001 to 1 409 million in 2005. but online delivery is not without problems the issue of copyright management in particular has become a serious thorn in the side for digital content creators. martin brass ex music producer and senior industry consultant at syntegra explains.
inspec,train_597,quick media response averts pr disaster. sometimes it s not what you do but how you do it. after hackers broke the blocking code on the home version of its popular cyber patrol internet filtering software and posted it on the internet marketers at microsystems software pulled out a playbook of standard crisis management and pr techniques. but the cyber patrol pr team including outside pr counsel and the company s outside law firm used those tools aggressively in order to turn the tide of public and media opinion away from the hackers who initially were hailed as folk heroes and in favor of the company s interests to save the product s and the company s reputations and inherent value. and the entire team managed to move at internet speed the crisis was essentially over in about three weeks.
inspec,train_598,from free to fee online advertising market. as the online advertising market continues to struggle many online content marketers are wrestling with the issue of how to add at least some level of paid subscription income to their revenue mix in order to reach or improve profitability. since the business of selling content online is still in its infancy and many consumers clearly still think of web content as simply and rightfully free few roadmaps are available to show the way to effective marketing strategies but some guiding principles have emerged.
inspec,train_599,keen but confused workflow content management. it users find workflow content and business process management software appealing but by no means straightforward to implement. pat sweet reports on our latest research.
inspec,train_6,sbc gets more serious on regulatory compliance. with one eye on the past and the other on its future sbc communications last week created a unit it hopes will bring a cohesiveness and efficiency to its regulatory compliance efforts that previously had been lacking. the carrier also hopes the new regulatory compliance unit will help it accomplish its short term goal of landing fcc approval. to provide long distance service throughout its region and its longer term goal of reducing the regulatory burdens under which it and currently operate.
inspec,train_60,perceptual audio coding using adaptive pre and post filters and lossless compression. this paper proposes a versatile perceptual audio coding method that achieves high compression ratios and is capable of low encoding decoding delay. it accommodates a variety of source signals including both music and speech with different sampling rates. it is based on separating irrelevance and redundancy reductions into independent functional units. this contrasts traditional audio coding where both are integrated within the same subband decomposition. the separation allows for the independent optimization of the irrelevance and redundancy reduction units. for both reductions we rely on adaptive filtering and predictive coding as much as possible to minimize the delay. a psycho acoustically controlled adaptive linear filter is used for the irrelevance reduction and the redundancy reduction is carried out by a predictive lossless coding scheme which is termed weighted cascaded least mean squared wclms method. experiments are carried out on a database of moderate size which contains mono signals of different sampling rates and varying nature music speech or mixed. they show that the proposed wclms lossless coder outperforms other competing lossless coders in terms of compression ratios and delay as applied to the pre filtered signal. moreover a subjective listening test of the combined pre filter lossless coder and a state of the art perceptual audio coder pac shows that the new method achieves a comparable compression ratio and audio quality with a lower delay.
inspec,train_600,development of railway vr safety simulation system. abnormal conditions occur in railway transportation due to trouble or accidents and it affects a number of passengers. it is very important therefore to quickly recover and return to normal train operation. for this purpose we developed a system  computer vr simulation system for the safety of railway transportation. it is a new type simulation system to evaluate measures to be taken under abnormal conditions. users of this simulation system cooperate with one another to correct the abnormal conditions that have occurred in virtual reality. this paper reports the newly developed simulation system.
inspec,train_601,recent researches of human science on railway systems. this paper presents research of human science on railway systems at rtri. they are roughly divided into two categories research to improve safety and those to improve comfort. on the former subject for the safeguard against accidents caused by human errors we have promoted studies of psychological aptitude test various research to evaluate train drivers working conditions and environments and new investigations to minimize the risk of passenger casualties at train accidents. on the latter subject we have developed new methods to evaluate the riding comfort including that of tilt train and started research on the improvement of railway facilities for the aged and the disabled from the viewpoint of universal design.
inspec,train_602,image fusion between sup 18 fdg pet and mri ct for radiotherapy planning of oropharyngeal and nasopharyngeal carcinomas. accurate diagnosis of tumor extent is important in three dimensional conformal radiotherapy. this study reports the use of image fusion between 18 f fluoro 2 deoxy d glucose positron emission tomography sup 18 fdg pet and magnetic resonance imaging computed tomography mri ct for better targets delineation in radiotherapy planning of head and neck cancers. the subjects consisted of 12 patients with oropharyngeal carcinoma and 9 patients with nasopharyngeal carcinoma npc who were treated with radical radiotherapy between july 1999 and february 2001. image fusion between sup 18 fdg pet and mri ct was performed using an automatic multimodality image registration algorithm which used the brain as an internal reference for registration. gross tumor volume gtv was determined based on clinical examination and sup 18 fdg uptake on the fusion images. clinical target volume ctv was determined following the usual pattern of lymph node spread for each disease entity along with the clinical presentation of each patient. except for 3 cases with superficial tumors all the other primary tumors were detected by sup 18 fdg pet. the gtv volumes for primary tumors were not changed by image fusion in 19 cases 89  increased by 49 in one npc and decreased by 45 in another npc. normal tissue sparing was more easily performed based on clearer gtv and ctv determination on the fusion images. in particular parotid sparing became possible in 15 patients 71 whose upper neck areas near the parotid glands were tumor free by sup 18 fdg pet. within a mean follow up period of 18 months no recurrence occurred in the areas defined as ctv which was treated prophylactically except for 1 patient who experienced nodal recurrence in the ctv and simultaneous primary site recurrence. in conclusion this preliminary study showed that image fusion between sup 18 fdg pet and mri ct was useful in gtv and ctv determination in conformal rt thus sparing normal tissues.
inspec,train_603,pge helps customers reduce energy costs. a new service from portland general electric pge portland oregon us is saving customers tens of thousands of dollars in energy costs. pge created e manager to allow facility managers to analyze their energy consumption online at 15 minute intervals. customers can go to the web for complete data powerful analysis tools and charts helping them detect abnormal energy use and focus on costly problem areas.
inspec,train_604,srp rolls out reliability and asset management initiative. reliability planning analysis at the salt river project srp tempe arizona us prioritizes geographic areas for preventive inspections based on a cost benefit model. however srp wanted a new application system to prioritize inspections and to predict when direct buried cable would fail using the same cost benefit model. in the business cases the represented type of kilowatt load residential commercial or critical circuit determines the cost benefit per circuit. the preferred solution was to develop a geographical information system gis application allowing for a circuit query for the specific geographic areas it crosses and the density of load points of a given type within those areas. the query returns results based on the type of equipment analysis execution wood pole preventive maintenance for a line or cable replacement. this differentiation insures that all the facilities relevant to a specific analysis type influence prioritization of the geographic areas.
inspec,train_605,hew selects network management software. for more than 100 years hamburgische electricitats werke ag hew has provided a reliable electricity service to the city of hamburg germany. today the company supplies electricity to some 1 7 million inhabitants via 285000 connections. during 1999 the year the energy market was started in germany hew needed to operate and maintain a safe and reliable network cheaply. the development and implementation of a distribution management system dms is key to the success of hew. hew s strategy was to obtain efficient new software for network management that also offered a good platform for future applications. following a pilot and prequalification phase hew invited several companies to process the requirements catalog and to submit a detailed tender. the network information management system xpower developed by tekla oyj successfully passed hew s test program and satisfied all the performance and system capacity requirements. the system met all hew s conditions by presenting the reality of a network with the attributes of the operating resources. xpower platform provides the ability to integrate future applications.
inspec,train_606,taiwan power company phases into am fm. to face the challenges and impact of the inevitable trend toward privatization and deregulation the taiwan power co tpc devised short and long term strategic computerization development plans. these development efforts created a master plan that included building an automated mapping and facilities management am fm system for taipei city district office tcdo. this project included a pilot project followed by evaluation before the roll out to the complete service territory of tcdo. the pilot project took three years to install commission and via the evaluation process reach the conclusion that am fm was technologically feasible.
inspec,train_607,a building block approach to automated engineering. shenandoah valley electric cooperative svec mt crawford virginia us recognized the need to automate engineering functions and create an interactive model of its distribution system in the early 1990s. it had used milsoft s da software for more than 10 years to make engineering studies and had a landis and gyr scada system and a hybrid load management system for controlling water heater switches. with the development of gis and facilities management fm applications svec decided this should be the basis for an information system that would model its physical plant and interface with its accounting and billing systems. it could add applications such as outage management staking line design and metering to use this information and interface with these databases. however based on svec s size it was not feasible to implement a sophisticated and expensive gis fm system. over the past nine years svec has had success with a building block approach and its customers and employees are realizing the benefits of the automated applications. this building block approach is discussed in this article including the gis outage management system mapviewer and a staking package. the lessons learned and future expansion are discussed.
inspec,train_608,how closely can a personal computer clock track the utc timescale via the internet. nowadays many software packages allow you to keep the clock of your personal computer synchronized to time servers spread over the internet. we present how a didactic laboratory can evaluate in a statistical sense the minimum synch error of this process the other extreme the maximum is guaranteed by the code itself. the measurement set up utilizes the global positioning system satellite constellation in common view between two similar timing stations one acts as a time server for the other so the final timing difference at the second station represents the total synch error through the internet. data recorded over batches of 10000 samples show a typical rms value of 35 ms this measurement configuration allows students to obtain a much better understanding of the synch task and pushes them at all times to look for an experimental verification of data results even when they come from the most sophisticated black boxes now readily available off the shelf.
inspec,train_609,chemical production in the superlative formaldehyde plant process control system and remote i o system. basf commissioned the largest formaldehyde production plant in the world in december 2000 with an annual capacity of 180000 t. the new plant built to meet the growing demand for formaldehyde sets new standards. its size technology and above all its cost effectiveness give it a leading position internationally. to maintain such high standards by the automation technology in addition to the trail blazing simatic pcs 7 process control system from siemens basf selected the innovative remote i o system i s 1 from r stahl schaltgerate gmbh to record and to output field signals in hazardous areas zone 1 and 2. this combination completely satisfied all technical requirements and also had the best price performance ratio of all the solutions. 25 remote i o field stations were designed and matched to the needs of the formaldehyde plant.
inspec,train_61,application of time frequency principal component analysis to text independent speaker identification. we propose a formalism called vector filtering of spectral trajectories that allows the integration of a number of speech parameterization approaches cepstral analysis delta and delta delta parameterizations auto regressive vector modeling  under a common formalism. we then propose a new filtering called contextual principal components cpc or time frequency principal components tfpc. this filtering consists in extracting the principal components of the contextual covariance matrix which is the covariance matrix of a sequence of vectors expanded by their context. we apply this new filtering in the framework of closed set speaker identification using a subset of the polycost database. when using speaker dependent tfpc filters our results show a relative improvement of approximately 20 compared to the use of the classical cepstral coefficients augmented by their delta coefficients which is significantly better with a 90 confidence level.
inspec,train_610,agc for autonomous power system using combined intelligent techniques. in the present work two intelligent load frequency controllers have been developed to regulate the power output and system frequency by controlling the speed of the generator with the help of fuel rack position control. the first controller is obtained using fuzzy logic fl only whereas the second one by using a combination of fl genetic algorithms and neural networks. the aim of the proposed controller s is to restore in a very smooth way the frequency to its nominal value in the shortest time possible whenever there is any change in the load demand etc. the action of these controller s provides a satisfactory balance between frequency overshoot and transient oscillations with zero steady state error. the design and performance evaluation of the proposed controller s structure are illustrated with the help of case studies applied without loss of generality to a typical single area power system. it is found that the proposed controllers exhibit satisfactory overall dynamic performance and overcome the possible drawbacks associated with other competing techniques.
inspec,train_611,intelligent optimal sieving method for facts device control in multi machine systems. a multi target oriented optimal control strategy for facts devices installed in multi machine power systems is presented in this paper which is named the intelligent optimal sieving control iosc method. this new method divides the facts device output region into several parts and selects one typical value from each part which is called output candidate. then an intelligent optimal sieve is constructed which predicts the impacts of each output candidate on a power system and sieves out an optimal output from all of the candidates. the artificial neural network technologies and fuzzy methods are applied to build the intelligent sieve. finally the real control signal of facts devices is calculated according to the selected optimal output through inverse system method. simulation has been done on a three machine power system and the results show that the proposed iosc controller can effectively attenuate system oscillations and enhance the power system transient stability.
inspec,train_612,analysis and operation of hybrid active filter for harmonic elimination. this paper presents a hybrid active filter topology and its control to suppress the harmonic currents from entering the power source. the adopted hybrid active filter consists of one active filter and one passive filter connected in series. by controlling the equivalent output voltage of active filter the harmonic currents generated by the nonlinear load are blocked and flowed into the passive filter. the power rating of the converter is reduced compared with the pure active filters to filter the harmonic currents. the harmonic current detecting approach and dc link voltage regulation are proposed to obtain equivalent voltage of active filter. the effectiveness of the adopted topology and control scheme has been verified by the computer simulation and experimental results in a scaled down laboratory prototype.
inspec,train_613,comparison between discrete stft and wavelets for the analysis of power quality events. this paper deals with the comparison of signal processing tools for power quality analysis. two signal processing techniques are considered the wavelet filters and the discrete short time fourier transforms stft. then examples of the two most frequent disturbances met in the power system are chosen. an adjustable speed drive with a six pulse converter using emtp atp is designed and normal energizing of utility capacitors is presented. the analysis is tested on a system consisting of 13 buses and is representative of a medium sized industrial plant. finally each kind of electrical disturbance is analyzed with examples representing each tool. a qualitative comparison of results shows the advantages and drawbacks of each signal processing technique applied to power quality analysis.
inspec,train_614,an on line distributed intelligent fault section estimation system for large scale power networks. in this paper a novel distributed intelligent system is suggested for on line fault section estimation fse of large scale power networks. as the first step a multi way graph partitioning method based on weighted minimum degree reordering is proposed for effectively partitioning the original large scale power network into the desired number of connected sub networks with quasi balanced fse burdens and minimum frontier elements. after partitioning a distributed intelligent system based on radial basis function neural network rbf nn and companion fuzzy system is suggested for fse. the relevant theoretical analysis and procedure are presented in the paper. the proposed distributed intelligent fse method has been implemented with sparse storage technique and tested on the ieee 14 30 and 118 bus systems respectively. computer simulation results show that the proposed fse method works successfully for large scale power networks.
inspec,train_615,an intelligent tutoring system for a power plant simulator. in this paper an intelligent tutoring system its is proposed for a power plant simulator. with a well designed its the need for an instructor is minimized and the operator may readily and efficiently take in real time the control of simulator with appropriate messages he she gets from the tutoring system. using simulink and based on object oriented programming oop and c programming language a fossil fuelled power plant simulator with an its is proposed. promising results are demonstrated for a typical power plant.
inspec,train_616,an overview of modems. this paper describes cursory glance of different types of modems classified for application range line type operating mode synchronizing mode modulation etc highly useful for all engineering students of communication electrical computer science and information technology students. this paper also describes the standards and protocols used and the future trend.
inspec,train_617,estimation of trifocal tensor using gmm. a novel estimation of a trifocal tensor based on the gaussian mixture model gmm is presented. the mixture model is built assuming that the residuals of inliers and outliers belong to different gaussian distributions. the bayesian rule is then employed to detect the inliers for re estimation. experiments show that the presented method is more precise and relatively unaffected by outliers.
inspec,train_618,blind source separation applied to image cryptosystems with dual encryption. blind source separation bss is explored to add another encryption level besides the existing encryption methods for image cryptosystems. the transmitted images are covered with a noise image by specific mixing before encryption and then recovered through bss after decryption. simulation results illustrate the validity of the proposed method.
inspec,train_619,wavelet based image segment representation. an efficient representation method for arbitrarily shaped image segments is proposed. this method includes a smart way to select a wavelet basis to approximate the given image segment with improved image quality and reduced computational load.
inspec,train_62,text independent speaker verification using utterance level scoring and covariance modeling. this paper describes a computationally simple method to perform text independent speaker verification using second order statistics. the suggested method called utterance level scoring uls allows one to obtain a normalized score using a single pass through the frames of the tested utterance. the utterance sample covariance is first calculated and then compared to the speaker covariance using a distortion measure. subsequently a distortion measure between the utterance covariance and the sample covariance of data taken from different speakers is used to normalize the score. experimental results from the 2000 nist speaker recognition evaluation are presented for uls used with different distortion measures and for a gaussian mixture model gmm system. the results indicate that uls as a viable alternative to gmm whenever the computational complexity and verification accuracy needs to be traded.
inspec,train_620,adaptive image enhancement for retinal blood vessel segmentation. retinal blood vessel images are enhanced by removing the nonstationary background which is adaptively estimated based on local neighbourhood information. the result is a much better segmentation of the blood vessels with a simple algorithm and without the need to obtain a priori illumination knowledge of the imaging system.
inspec,train_621,mpeg 4 video object based rate allocation with variable temporal rates. in object based coding bit allocation is performed at the object level and temporal rates of different objects may vary. the proposed algorithm deals with these two issues when coding multiple video objects mvos. the proposed algorithm is able to successfully achieve the target bit rate effectively code arbitrarily shaped mvos with different temporal rates and maintain a stable buffer level.
inspec,train_622,source channel coding of still images using lapped transforms and block classification. a novel scheme for joint source channel coding of still images is proposed. by using efficient lapped transforms channel optimised robust quantisers and classification methods it is shown that significant improvements over traditional source channel coding of images can be obtained while keeping the complexity low.
inspec,train_623,stochastic recurrences of jackpot keno. we describe a mathematical model and simulation study for jackpot keno as implemented by jupiters network gaming jng in the australian state of queensland and as controlled by the queensland office of gaming regulation qogr http www qogr qld gov au keno shtml. the recurrences for the house net hold are derived and it is seen that these are piecewise linear with a ternary domain split and further the split points are stochastic in nature. since this structure is intractable brockett and levine statistics probability their applications cbs college publishing 1984 estimation of house net hold obtained through an appropriately designed simulator using a random number generator with desirable properties is described. since the model and simulation naturally derives hold given payscale but jng and qogr require payscale given hold an inverse problem was required to be solved. this required development of a special algorithm which may be described as a stochastic binary search. experimental results are presented in which the simulator is used to determine jackpot pay scales so as to satisfy legal requirements of approximately 75 of net revenue returned to the players i e 25 net hold for the house jng. details of the algorithm used to solve this problem are presented and notwithstanding the stochastic nature of the simulation convergence to a specified hold for the inverse problem has been achieved to within 0 1 in all cases of interest to date.
inspec,train_624,a hybrid ml em algorithm for calculation of maximum likelihood estimates in semiparametric shared frailty models. this paper describes a generalised hybrid ml em algorithm for the calculation of maximum likelihood estimates in semiparametric shared frailty models the cox proportional hazard models with hazard functions multiplied by a parametric frailty random variable. this hybrid method is much faster than the standard em method and faster than the standard direct maximum likelihood method ml newton raphson for large samples. we have previously applied this method to semiparametric shared gamma frailty models and verified by simulations the asymptotic and small sample statistical properties of the frailty variance estimates. let theta sub 0 be the true value of the frailty variance parameter. then the asymptotic distribution is normal for theta sub 0  0 while it is a 50 50 mixture between a point mass at zero and a normal random variable on the positive axis for theta sub 0  0. for small samples simulations suggest that the frailty variance estimates are approximately distributed as an x 100 x mixture 0 or x or 50 between a point mass at zero and a normal random variable on the positive axis even for theta sub 0  0. we apply this method and verify by simulations these statistical results for semiparametric shared log normal frailty models. we also apply the semiparametric shared gamma and log normal frailty models to busselton health study coronary heart disease data.
inspec,train_625,identifying multivariate discordant observations a computer intensive approach. the problem of identifying multiple outliers in a multivariate normal sample is approached via successive testing using p values rather than tabled critical values. caroni and prescott appl. statist. 41 p 355 1992 proposed a generalization of the edr esd procedure of rosner technometrics 25 1983. venter and viljoen comput. statist. data anal. 29 p 261 1999 introduced a computer intensive method to identify outliers in a univariate outlier situation. we now generalize this method to the multivariate outlier situation and compare this new procedure with that of caroni and prescott appl. statist. 4 p 355 1992.
inspec,train_626,approximate confidence intervals for one proportion and difference of two proportions. constructing a confidence interval for a binomial proportion or the difference of two proportions is a routine exercise in daily data analysis. the best known method is the wald interval based on the asymptotic normal approximation to the distribution of the observed sample proportion though it is known to have bad performance for small to medium sample sizes. agresti et al 1998 2000 proposed an adding 4 method 4 pseudo observations are added with 2 successes and 2 failures and then the resulting pseudo sample proportion is used. the method is simple and performs extremely well. here we propose an approximate method based on a t approximation that takes account of the uncertainty in estimating the variance of the observed pseudo sample proportion. it follows the same line of using a t test rather than z test in testing the mean of a normal distribution with an unknown variance. for some circumstances our proposed method has a higher coverage probability than the adding 4 method.
inspec,train_627,comparison of non stationary time series in the frequency domain. in this paper we compare two nonstationary time series using nonparametric procedures. evolutionary spectra are estimated for the two series. randomization tests are performed on groups of spectral estimates for both related and independent time series. simulation studies show that in certain cases the tests perform reasonably well. the tests are applied to observed geological and financial time series.
inspec,train_628,rank tests of association for exchangeable paired data. we describe two rank tests of association for paired exchangeable data motivated by the study of lifespans in twins. the pooled sample is ranked. the nonparametric test of association is based on r sup  the sum of the smaller within pair ranks. a second measure l sup  is the sum of within pair rank products. under the null hypothesis of within pair independence the two test statistics are approximately normally distributed. expressions for the exact means and variances of r sup  and l sup  are given. we describe the power of these two statistics under a close alternative hypothesis to that of independence. both the r sup  and l sup  tests indicate nonparametric statistical evidence of positive association of longevity in identical twins and a negligible relationship between the lifespans of fraternal twins listed in the danish twin registry. the statistics are also applied to the analysis of a clinical trial studying the time to failure of ventilation tubes in children with bilateral otitis media.
inspec,train_629,calibrated initials for an em applied to recursive models of categorical variables. the estimates from an em when it is applied to a large causal model of 10 or more categorical variables are often subject to the initial values for the estimates. this phenomenon becomes more serious as the model structure becomes more complicated involving more variables. as a measure of compensation for this it has been recommended in literature that ems are implemented several times with different sets of initial values to obtain more appropriate estimates. we propose an improved approach for initial values. the main idea is that we use initials that are calibrated to data. a simulation result strongly indicates that the calibrated initials give rise to the estimates that are far closer to the true values than the initials that are not calibrated.
inspec,train_63,geometric source separation merging convolutive source separation with geometric beamforming. convolutive blind source separation and adaptive beamforming have a similar goal extracting a source of interest or multiple sources while reducing undesired interferences. a benefit of source separation is that it overcomes the conventional cross talk or leakage problem of adaptive beamforming. beamforming on the other hand exploits geometric information which is often readily available but not utilized in blind algorithms. we propose to join these benefits by combining cross power minimization of second order source separation with geometric linear constraints used in adaptive beamforming. we find that the geometric constraints resolve some of the ambiguities inherent in the independence criterion such as frequency permutations and degrees of freedom provided by additional sensors. we demonstrate the new method in performance comparisons for actual room recordings of two and three simultaneous acoustic sources.
inspec,train_630,score tests for zero inflated poisson models. in many situations count data have a large proportion of zeros and the zero inflated poisson regression zip model may be appropriate. a simple score test for zero inflation comparing the zip model with a constant proportion of excess zeros to a standard poisson regression model was given by van den broek 1995. we extend this test to the more general situation where the zero probability is allowed to depend on covariates. the performance of this test is evaluated using a simulation study. to identify potentially important covariates in the zero inflation model a composite test is proposed. the use of the general score test and the composite procedure is illustrated on two examples from the literature. the composite score test is found to suggest appropriate models.
inspec,train_631,a modified fieller interval for the interval estimation of effective doses for a logistic dose response curve. interval estimation of the gamma effective dose mu sub gamma say is often based on the asymptotic variance of the maximum likelihood estimator delta interval or fieller s theorem fieller interval. sitter and wu 1993 compared the delta and fieller intervals for the median effective dose mu sub 50 assuming a logistic dose response curve. their results indicated that although fieller intervals are generally superior to delta intervals they appear to be conservative. here an adjusted form of the fieller interval for mu sub gamma termed an adjusted fieller af interval is introduced. a comparison of the af interval with the delta and fieller intervals is provided and the properties of these three interval estimation methods are investigated.
inspec,train_632,modelling dependencies in paired comparison data a log linear approach. in many bradley terry models a more or less explicit assumption is that all decisions of the judges are independent. an assumption which might be questionable at least for the decisions of a given judge. in paired comparison studies a judge chooses among objects several times and in such cases judgements made by the same judge are likely to be dependent. a log linear representation for the bradley terry model is developed which takes into account dependencies between judgements. the modelling of the dependencies is embedded in the analysis of multiple binomial responses which has the advantage of interpretability in terms of conditional odds ratios. furthermore the modelling is done in the framework of generalized linear models thus parameter estimation and the assessment of goodness of fit can be obtained in the standard way by using e g glim or another standard software.
inspec,train_633,using k nearest neighbor classification in the leaves of a tree. we construct a hybrid composite classifier by combining two classifiers in common use classification trees and k nearest neighbor k nn. in our scheme we divide the feature space up by a classification tree and then classify test set items using the k nn rule just among those training items in the same leaf as the test item. this reduces somewhat the computational load associated with k nn and it produces a classification rule that performs better than either trees or the usual k nn in a number of well known data sets.
inspec,train_634,an approximation to the f distribution using the chi square distribution. for the cumulative distribution function c d f of the f distribution f x k n with associated degrees of freedom k and n a shrinking factor approximation sfa g lambda kx k is proposed for large n and any fixed k where g x k is the chi square c d f with degrees of freedom k and lambda lambda kx n is the shrinking factor. numerical analysis indicates that for n k or 3 approximation accuracy of the sfa is to the fourth decimal place for most small values of k. this is a substantial improvement on the accuracy that is achievable using the normal ordinary chi square and scheffe tukey approximations. in addition it is shown that the theoretical approximation error of the sfa  f x k n g lambda kx k  is o 1 n sup 2 uniformly over x.
inspec,train_635,detection and estimation of abrupt changes in the variability of a process. detection of change points in normal means is a well studied problem. the parallel problem of detecting changes in variance has had less attention. the form of the generalized likelihood ratio test statistic has long been known but its null distribution resisted exact analysis. in this paper we formulate the change point problem for a sequence of chi square random variables. we describe a procedure that is exact for the distribution of the likelihood ratio statistic for all even degrees of freedom and gives upper and lower bounds for odd and also for non integer degrees of freedom. both the liberal and conservative bounds for chi sub 1  sup 2 degrees of freedom are shown through simulation to be reasonably tight. the important problem of testing for change in the normal variance of individual observations corresponds to the chi sub 1  sup 2 case. the non null case is also covered and confidence intervals for the true change point are derived. the methodology is illustrated with an application to quality control in a deep level gold mine. other applications include ambulatory monitoring of medical data and econometrics.
inspec,train_636,flid dl congestion control for layered multicast. we describe fair layered increase decrease with dynamic layering flid dl a new multirate congestion control algorithm for layered multicast sessions. flid dl generalizes the receiver driven layered congestion control protocol rlc introduced by vicisano et al proc. ieee infocom san francisco ca  p 996 1003 mar 1998 ameliorating the problems associated with large internet group management protocol igmp leave latencies and abrupt rate increases. like rlc flid dl is a scalable receiver driven congestion control mechanism in which receivers add layers at sender initiated synchronization points and leave layers when they experience congestion. flid dl congestion control coexists with transmission control protocol tcp flows as well as other flid dl sessions and supports general rates on the different multicast layers. we demonstrate via simulations that our congestion control scheme exhibits better fairness properties and provides better throughput than previous methods. a key contribution that enables flid dl and may be useful elsewhere is dynamic layering dl which mitigates the negative impact of long igmp leave latencies and eliminates the need for probe intervals present in rlc. we use dl to respond to congestion much faster than igmp leave operations which have proven to be a bottleneck in practice for prior work.
inspec,train_637,a digital fountain approach to asynchronous reliable multicast. the proliferation of applications that must reliably distribute large rich content to a vast number of autonomous receivers motivates the design of new multicast and broadcast protocols. we describe an ideal fully scalable protocol for these applications that we call a digital fountain. a digital fountain allows any number of heterogeneous receivers to acquire content with optimal efficiency at times of their choosing. moreover no feedback channels are needed to ensure reliable delivery even in the face of high loss rates. we develop a protocol that closely approximates a digital fountain using two new classes of erasure codes that for large block sizes are orders of magnitude faster than standard erasure codes. we provide performance measurements that demonstrate the feasibility of our approach and discuss the design implementation and performance of an experimental system.
inspec,train_638,scalable secure group communication over ip multicast. we introduce and analyze a scalable rekeying scheme for implementing secure group communications internet protocol multicast. we show that our scheme incurs constant processing message and storage overhead for a rekey operation when a single member joins or leaves the group and logarithmic overhead for bulk simultaneous changes to the group membership. these bounds hold even when group dynamics are not known a priori. our rekeying algorithm requires a particular clustering of the members of the secure multicast group. we describe a protocol to achieve such clustering and show that it is feasible to efficiently cluster members over realistic internet like topologies. we evaluate the overhead of our own rekeying scheme and also of previously published schemes via simulation over an internet topology map containing over 280 000 routers. through analysis and detailed simulations we show that this rekeying scheme performs better than previous schemes for a single change to group membership. further for bulk group changes our algorithm outperforms all previously known schemes by several orders of magnitude in terms of actual bandwidth usage processing costs and storage requirements.
inspec,train_639,distributed servers approach for large scale secure multicast. in order to offer backward and forward secrecy for multicast applications i e a new member can not decrypt the multicast data sent before its joining and a former member can not decrypt the data sent after its leaving the data encryption key has to be changed whenever a user joins or leaves the system. such a change has to be made known to all the current users. the bandwidth used for such re key messaging can be high when the user pool is large. we propose a distributed servers approach to minimize the overall system bandwidth and complexity by splitting the user pool into multiple groups each served by a logical server. after presenting an analytic model for the system based on a hierarchical key tree we show that there is an optimal number of servers to achieve minimum system bandwidth. as the underlying user traffic fluctuates we propose a simple dynamic scheme with low overhead where a physical server adaptively splits and merges its traffic into multiple groups each served by a logical server so as to minimize its total bandwidth. our results show that a distributed servers approach is able to substantially reduce the total bandwidth required as compared with the traditional single server approach especially for those applications with a large user pool short holding time and relatively low bandwidth of a data stream as in the internet stock quote applications.
inspec,train_64,speech enhancement using a mixture maximum model. we present a spectral domain speech enhancement algorithm. the new algorithm is based on a mixture model for the short time spectrum of the clean speech signal and on a maximum assumption in the production of the noisy speech spectrum. in the past this model was used in the context of noise robust speech recognition. in this paper we show that this model is also effective for improving the quality of speech signals corrupted by additive noise. the computational requirements of the algorithm can be significantly reduced essentially without paying performance penalties by incorporating a dual codebook scheme with tied variances. experiments using recorded speech signals and actual noise sources show that in spite of its low computational requirements the algorithm shows improved performance compared to alternative speech enhancement algorithms.
inspec,train_640,scribe a large scale and decentralized application level multicast infrastructure. this paper presents scribe a scalable application level multicast infrastructure. scribe supports large numbers of groups with a potentially large number of members per group. scribe is built on top of pastry a generic peer to peer object location and routing substrate overlayed on the internet and leverages pastry s reliability self organization and locality properties. pastry is used to create and manage groups and to build efficient multicast trees for the dissemination of messages to each group. scribe provides best effort reliability guarantees and we outline how an application can extend scribe to provide stronger reliability. simulation results based on a realistic network topology model show that scribe scales across a wide range of groups and group sizes. also it balances the load on the nodes while achieving acceptable delay and link stress when compared with internet protocol multicast.
inspec,train_641,multiecho segmented epi with z shimmed background gradient compensation mesbac pulse sequence for fmri. a multiecho segmented epi with z shimmed background gradient compensation mesbac pulse sequence is proposed and validated for functional mri fmri study in regions suffering from severe susceptibility artifacts. this sequence provides an effective tradeoff between spatial and temporal resolution and reduces image distortion and signal dropout. the blood oxygenation level dependent bold weighted fmri signal can be reliably obtained in the region of the orbitofrontal cortex ofc. to overcome physiological motion artifacts during prolonged multisegment epi acquisition two sets of navigator echoes were acquired in both the readout and phase encoding directions. ghost artifacts generally produced by single shot epi acquisition were eliminated by separately placing the even and odd echoes in different k space trajectories. unlike most z shim methods that focus on increasing temporal resolution for event related functional brain mapping the mesbac sequence simultaneously addresses problems of image distortion and signal dropout while maintaining sufficient temporal resolution. the mesbac sequence will be particularly useful for pharmacological and affective fmri studies in brain regions such as the ofc nucleus accumbens amygdala para hippocampus etc.
inspec,train_642,reconstruction of mr images from data acquired on an arbitrary k space trajectory using the same image weight. a sampling density compensation function denoted same image si weight is proposed to reconstruct mr images from the data acquired on an arbitrary k space trajectory. an equation for the si weight is established on the si criterion and an iterative scheme is developed to find the weight. the si weight is then used to reconstruct images from the data calculated on a random trajectory in a numerical phantom case and from the data acquired on interleaved spirals in an in vivo experiment respectively. in addition pipe and menon s weight mrm 1999 41 179 186 is also used in the reconstructions to make a comparison. the images obtained with the si weight were found to be slightly more accurate than those obtained with pipe s weight.
inspec,train_643,time resolved contrast enhanced imaging with isotropic resolution and broad coverage using an undersampled 3d projection trajectory. time resolved contrast enhanced 3d mr angiography mra methods have gained in popularity but are still limited by the tradeoff between spatial and temporal resolution. a method is presented that greatly reduces this tradeoff by employing undersampled 3d projection reconstruction trajectories. the variable density k space sampling intrinsic to this sequence is combined with temporal k space interpolation to provide time frames as short as 4 s. this time resolution reduces the need for exact contrast timing while also providing dynamic information. spatial resolution is determined primarily by the projection readout resolution and is thus isotropic across the fov which is also isotropic. although undersampling the outer regions of k space introduces aliased energy into the image which may compromise resolution this is not a limiting factor in high contrast applications such as mra. results from phantom and volunteer studies are presented demonstrating isotropic resolution broad coverage with an isotropic field of view fov minimal projection reconstruction artifacts and temporal information. in one application a single breath hold exam covering the entire pulmonary vasculature generates high resolution isotropic imaging volumes depicting the bolus passage.
inspec,train_644,three dimensional spiral mr imaging application to renal multiphase contrast enhanced angiography. a fast mr pulse sequence with spiral in plane readout and conventional 3d partition encoding was developed for multiphase contrast enhanced magnetic resonance angiography ce mra of the renal vasculature. compared to a standard multiphase 3d ce mra with flash readout an isotropic in plane spatial resolution of 1 4 1 4 mm sup 2 over 2 0 1 4 mm sup 2 could be achieved with a temporal resolution of 6 sec. the theoretical gain of spatial resolution by using the spiral pulse sequence and the performance in the presence of turbulent flow was evaluated in phantom measurements. multiphase 3d ce mra of the renal arteries was performed in five healthy volunteers using both techniques. a deblurring technique was used to correct the spiral raw data. thereby the off resonance frequencies were determined by minimizing the imaginary part of the data in image space. the chosen correction algorithm was able to reduce image blurring substantially in all mra phases. the image quality of the spiral ce mra pulse sequence was comparable to that of the flash ce mra with increased spatial resolution and a 25 reduced contrast to noise ratio. additionally artifacts specific to spiral mri could be observed which had no impact on the assessment of the renal arteries.
inspec,train_645,oxygen enhanced mri of the brain. blood oxygenation level dependent bold contrast mri is a potential method for a physiological characterization of tissue beyond mere morphological representation. the purpose of this study was to develop evaluation techniques for such examinations using a hyperoxia challenge. administration of pure oxygen was applied to test these techniques as pure oxygen can be expected to induce relatively small signal intensity si changes compared to co sub 2  containing gases and thus requires very sensitive evaluation methods. fourteen volunteers were investigated by alternating between breathing 100 o sub 2 and normal air using two different paradigms of administration. changes ranged from 30 in large veins to 1 71  or 0 14 in basal ganglia and 0 82  or 0 08 in white matter. to account for a slow physiological response function a reference for correlation analysis was derived from the venous reaction. an objective method is presented that allows the adaptation of the significance threshold to the complexity of the paradigm used. reference signal characteristics in representative brain tissue regions were established. as the presented evaluation scheme proved its applicability to small si changes induced by pure oxygen it can readily be used for similar experiments with other gases.
inspec,train_646,vibration control of structure by using tuned mass damper development of system which suppress displacement of auxiliary mass. in vibration control of a structure by using an active tuned mass damper atmd stroke of the auxiliary mass is so limited that it is difficult to control the vibration in the case of large disturbance input. in this paper two methods are proposed for the problem. one of the methods is a switching control system by two types of controllers. one of the controllers is a normal controller under small relative displacement of the auxiliary mass and the other is not effective only for first mode of vibration under large relative displacement of the auxiliary mass. new variable gain control system is constructed by switching these two controllers. the other method is the brake system. in active vibration control it is necessary to use actuator for active control. by using the actuator the proposed system puts on the brake to suppress displacement increase of the auxiliary mass under large disturbance input. finally the systems are designed and the effectiveness of the systems is confirmed by the simulation.
inspec,train_647,experimental design methodology and data analysis technique applied to optimise an organic synthesis. the study was aimed at maximising the yield of a michaelis becker dibromoalkane monophosphorylation reaction. in order to save time and money we first applied a full factorial experimental design to search for the optimum conditions while performing a small number of experiments. we then used the principal component analysis pca technique to evidence two uncontrolled factors. lastly a special experimental design that took into account all the influential factors allowed us to determine the maximum yield experimental conditions. this study also evidenced the complementary nature of experimental design methodology and data analysis techniques.
inspec,train_648,study of ambiguities inherent to the spectral analysis of voigt profiles a modified simplex approach. in pulsed spectrometries temporal transients are often analyzed directly in the temporal domain assuming they consist only of purely exponentially decaying sinusoids. when experimental spectra actually consist of gaussian or voigt profiles gauss lorentz profiles we show that the direct methods may erroneously interpret such lines as the sum of two or more lorentzian profiles. using a nelder and mead simplex method modified by introducing new means to avoid degeneracies and quenchings in secondary minima we demonstrate that a large number of different solutions can be obtained with equivalent accuracy over the limited acquisition time interval with final peak parameters devoid of physical or chemical meaning.
inspec,train_649,methods for outlier detection in prediction. if a prediction sample is different from the calibration samples it can be considered as an outlier in prediction. in this work two techniques the use of uncertainty estimation and the convex hull method are studied to detect such prediction outliers. classical techniques mahalanobis distance and x residuals potential functions and robust techniques are used for comparison. it is concluded that the combination of the convex hull method and uncertainty estimation offers a practical way for detecting outliers in prediction. by adding the potential function method inliers can also be detected.
inspec,train_65,the use of subtypes and stereotypes in the uml model. based on users experiences of version 1 3 of the unified modeling language uml of the object management group omg a request for information in 1999 elicited several responses which were asked to identify problems but not to offer any solutions. one of these responses is examined for problems relating to the uml metamodel and here some solutions to the problems identified there are proposed. specifically we evaluate the metamodel relating to stereotypes versus subtypes the various kinds of classifier particularly types interfaces and classes the introduction of a new subtype for the whole part relationship as well as identifying areas in the metamodel where the uml seems to have been used inappropriately in the very definition of the uml s metamodel.
inspec,train_650,molecular descriptor selection combining genetic algorithms and fuzzy logic application to database mining procedures. a new algorithm devoted to molecular descriptor selection in the context of data mining problems has been developed. this algorithm is based on the concepts of genetic algorithms ga for descriptor hyperspace exploration and combined with a stepwise approach to get local convergence. its selection power was evaluated by a fitness function derived from a fuzzy clustering method. different training and test sets were randomly generated at each ga generation. the fitness score was derived by combining the scores of the training and test sets. the ability of the proposed algorithm to select relevant subsets of descriptors was tested on two data sets. the first one an academic example corresponded to the artificial problem of bullseye the second was a real data set including 114 olfactory compounds divided into three odor categories. in both cases the proposed method allowed to improve the separation between the different data set classes.
inspec,train_651,application layer multicasting with delaunay triangulation overlays. application layer multicast supports group applications without the need for a network layer multicast protocol. here applications arrange themselves in a logical overlay network and transfer data within the overlay. we present an application layer multicast solution that uses a delaunay triangulation as an overlay network topology. an advantage of using a delaunay triangulation is that it allows each application to locally derive next hop routing information without requiring a routing protocol in the overlay. a disadvantage of using a delaunay triangulation is that the mapping of the overlay to the network topology at the network and data link layer may be suboptimal. we present a protocol called delaunay triangulation dt protocol which constructs delaunay triangulation overlay networks. we present measurement experiments of the dt protocol for overlay networks with up to 10 000 members that are running on a local pc cluster with 100 linux pcs. the results show that the protocol stabilizes quickly e g an overlay network with 10 000 nodes can be built in just over 30 s. the traffic measurements indicate that the average overhead of a node is only a few kilobits per second if the overlay network is in a steady state. results of throughput experiments of multicast transmissions using tcp unicast connections between neighbors in the overlay network show an achievable throughput of approximately 15 mb s in an overlay with 100 nodes and 2 mb s in an overlay with 1000 nodes.
inspec,train_652,a case for end system multicast. the conventional wisdom has been that internet protocol ip is the natural protocol layer for implementing multicast related functionality. however more than a decade after its initial proposal ip multicast is still plagued with concerns pertaining to scalability network management deployment and support for higher layer functionality such as error flow and congestion control. we explore an alternative architecture that we term end system multicast where end systems implement all multicast related functionality including membership management and packet replication. this shifting of multicast support from routers to end systems has the potential to address most problems associated with ip multicast. however the key concern is the performance penalty associated with such a model. in particular end system multicast introduces duplicate packets on physical links and incurs larger end to end delays than ip multicast. we study these performance concerns in the context of the narada protocol. in narada end systems self organize into an overlay structure using a fully distributed protocol. further end systems attempt to optimize the efficiency of the overlay by adapting to network dynamics and by considering application level performance. we present details of narada and evaluate it using both simulation and internet experiments. our results indicate that the performance penalties are low both from the application and the network perspectives. we believe the potential benefits of transferring multicast functionality from end systems to routers significantly outweigh the performance penalty incurred.
inspec,train_653,indexing neglected and poorly understood. the growth of the internet has highlighted the use of machine indexing. the difficulties in using the internet as a searching device can be frustrating. the use of the term python is given as an example. machine indexing is noted as rotten and human indexing as capricious. the problem seems to be a lack of a theoretical foundation for the art of indexing. what librarians have learned over the last hundred years has yet to yield a consistent approach to what really works best in preparing index terms and in the ability of our customers to search the various indexes. an attempt is made to consider the elements of indexing their pros and cons. the argument is made that machine indexing is far too prolific in its production of index terms. neither librarians nor computer programmers have made much progress to improve internet indexing. human indexing has had the same problems for over fifty years.
inspec,train_654,a question of perspective assigning library of congress subject headings to classical literature and ancient history. this article explains the concept of world view and shows how the world view of cataloguers influences the development and assignment of subject headings to works about other cultures and civilizations using works from classical literature and ancient history as examples. cataloguers are encouraged to evaluate the headings they assign to works in classical literature and ancient history in terms of the world views of ancient greece and rome so that headings reflect the contents of the works they describe and give fuller expression to the diversity of thoughts and themes that characterize these ancient civilizations.
inspec,train_655,mapping ccf to marc21 an experimental approach. the purpose of this article is to raise and address a number of issues pertaining to the conversion of common communication format ccf into marc21. in this era of global resource sharing exchange of bibliographic records from one system to another is imperative in today s library communities. instead of using a single standard to create machine readable catalogue records more than 20 standards have emerged and are being used by different institutions. because of these variations in standards sharing of resources and transfer of data from one system to another among the institutions locally and globally has become a significant problem. addressing this problem requires keeping in mind that countries such as india and others in southeast asia are using the ccf as a standard for creating bibliographic cataloguing records. this paper describes a way to map the bibliographic catalogue records from ccf to marc21 although 100 mapping is not possible. in addition the paper describes an experimental approach that enumerates problems that may occur during the mapping of records exchanging of records and how these problems can be overcome.
inspec,train_656,the cataloger s workstation revisited utilizing cataloger s desktop. a few years into the development of cataloger s desktop an electronic cataloging tool aggregator available through the library of congress is an opportune time to assess its impact on cataloging operations. a search for online cataloging tools on the internet indicates a proliferation of cataloging tool aggregators which provide access to online documentation related to cataloging practices and procedures. cataloger s desktop stands out as a leader among these aggregators. results of a survey to assess 159 academic arl and large public libraries reasons for use or non use of cataloger s desktop highlight the necessity of developing strategies for its successful implementation including training staff providing documentation and managing technical issues.
inspec,train_657,the web services agenda. even the most battle scarred of cios have become excited at the prospect of what web services can do for their businesses. but there are still some shortcomings to be addressed.
inspec,train_658,process pioneers agile business. by managing it infrastructures along so called top down lines organisations can streamline their business processes eliminate redundant tasks and increase automation.
inspec,train_659,integration no longer a barrier. agile business. web services will be a critical technology for enabling the agile business.
inspec,train_66,regression testing of database applications. database applications features such as structured query language or sql exception programming integrity constraints and table triggers pose difficulties for maintenance activities especially for regression testing that follows modifications to database applications. in this work we address these difficulties and propose a two phase regression testing methodology. in phase 1 we explore control flow and data flow analysis issues of database applications. then we propose an impact analysis technique that is based on dependencies that exist among the components of database applications. this analysis leads to selecting test cases from the initial test suite for regression testing the modified application. in phase 2 further reduction in the regression test cases is performed by using reduction algorithms. we present two such algorithms. the graph walk algorithm walks through the control flow graph of database modules and selects a safe set of test cases to retest. the call graph firewall algorithm uses a firewall for the inter procedural level. finally a maintenance environment for database applications is described. our experience with this regression testing methodology shows that the impact analysis technique is adequate for selecting regression tests and that phase 2 techniques can be used for further reduction in the number of theses tests.
inspec,train_660,at your service agile businesses. senior software executives from three of the world s leading software companies and one smaller entrepreneurial software developer explain the impact that web services business process management and integrated application architectures are having on their product development plans and share their vision of the roles these products will play in creating agile businesses.
inspec,train_661,all change agile business. what does it take for an organisation to become an agile business. its employees probably need to adhere to new procurement policies work more closely with colleagues in other departments meet more exacting sales targets and offer higher standards of customer service and support. in short they need to change the way they work. implementing technologies to support agile business models and underpin new practices is a complex task in itself. but getting employees to adopt new practices is far harder and one that requires careful handling says barry o connell general manager of business to employee b2e solutions at systems vendor hewlett packard hp.
inspec,train_663,the road ahead supply chains. executive supply chain managers says david metcalfe of forrester research need the skills and precision of mongolian archers on horseback. they must be able to hit their target in this case customer demand while moving at great speed. but what is wrong with the supply chains companies have in place already. according to metcalfe current manufacturing models are too inflexible. a recent survey conducted by forrester research supports this claim. it found that 42 of respondents could not transfer production from one plant to another in the event of a glitch in the supply chain. a further 32 said it would be possible but extremely costly.
inspec,train_664,the agile revolution business agility. there is a new business revolution in the air. the theory is there the technology is evolving fast. it is all about agility.
inspec,train_67,metaschemas for er orm and uml data models a comparison. this paper provides metaschemas for some of the main database modeling notations used in industry. two entity relationship er notations information engineering and barker are examined in detail as well as object role modeling orm conceptual schema diagrams. the discussion of optionality cardinality and multiplicity is widened to include unified modeling language uml class diagrams. issues addressed in the metamodel analysis include the normalization impact of non derived constraints on derived associations the influence of orthogonality on language transparency and trade offs between simplicity and expressibility. to facilitate comparison the same modeling notation is used to display each metaschema. for this purpose orm is used because of its greater expressibility and clarity.
inspec,train_671,expert advice how can my organisation take advantage of reverse auctions without jeopardising existing supplier relationships. in a recent survey amr research found that companies that use reverse auctions to negotiate prices with suppliers typically achieve savings of between 10 and 15 on direct goods and between 20 and 25 on indirect goods and can slash sourcing cycle times from months to weeks. suppliers however are less enthusiastic. they believe that these savings are achieved only by stripping the human element out of negotiations and evaluating bids on price alone which drives down their profit margins. as a result reverse auctions carry the risk of jeopardising long term and trusted relationships. suppliers that have not been involved in a reverse auction before typically fear the bidding event itself arguably the most theatrical and therefore most hyped up part of the process. although it may only last one hour weeks of preparation go into setting up a successful bidding event.
inspec,train_673,the information age interview capital one. credit card company capital one attributes its rapid customer growth to the innovative use of cutting edge technology. european cio catherine doran talks about the systems that have fuelled that runaway success.
inspec,train_674,portal payback. the benefits of deploying a corporate portal are well documented access to applications and content is centralised so users do not spend hours searching for information the management of disparate applications is also centralised and by allowing users to access self service applications in areas such as human resources and procurement organisations spend less time on manual processing tasks. but how far can prospective customers rely on the roi figures presented to them by portal technology vendors. in particular how reliable are the roi calculators these vendors supply on their web sites.
inspec,train_675,application foundations application servers. the changing role of application servers means choosing the right platform has become a complex challenge.
inspec,train_676,impossible choice web hosting service provider. selecting a telecoms and web hosting service provider has become a high stakes game of chance.
inspec,train_677,acts to facts catalogue. the paper shows a way to satisfy users changing and specific information needs by providing the modified format author collaborators title series subject facts. catalogue instead of the traditional author collaborator title series subjects acts catalogue.
inspec,train_678,marketing in csir libraries and information centres a study on promotional efforts. this paper examines the attitudes of librarians towards the promotional aspects in several csir libraries and information centres of india. the issues related to promotional activities of these libraries have been evaluated to determine the extent to which they are being practised. librarians hold positive attitudes about promotional aspects of libraries and often practise them without knowing they are practising marketing concepts. suggestions and strategies for improving the promotional activities in libraries and information services are put forth so as to meet the information needs and demands of clientele.
inspec,train_679,himalayan information system a proposed model. the information explosion and the development in information technology force us to develop information systems in various fields. the research on himalaya has achieved phenomenal growth in recent years in india. the information requirements of himalayan researchers are divergent in nature. in order to meet these divergent needs all information generated in various himalayan research institutions has to be collected and organized to facilitate free flow of information. this paper describes the need for a system for himalayan information. it also presents the objectives of himalayan information system himis. it discusses in brief the idea of setting up a himis and explains its utility to the users. it appeals to the government for supporting the development of such system.
inspec,train_68,human factors research on data modeling a review of prior research an extended framework and future research directions. this study reviews and synthesizes human factors research on conceptual data modeling. in addition to analyzing the variables used in earlier studies and summarizing the results of this stream of research we propose a new framework to help with future efforts in this area. the study finds that prior research has focused on issues that are relevant when conceptual models are used for communication between systems analysts and developers analyst developer models whereas the issues important for models that are used to facilitate communication between analysts and users user analyst models have received little attention and hence require a significantly stronger role in future research. in addition we emphasize the importance of building a strong theoretical foundation and using it to guide future empirical work in this area.
inspec,train_680,information needs of the working journalists in orissa a study. provides an insight into the various information needs of working journalists in orissa. analyses data received from 226 working journalists representing 40 newspaper organisations. also depicts the specialisation of working journalists their frequency of information requirement mode of dissemination preferred information sources explored mode of services opted and their information privations. the study asserts that subjects primarily concerned with the professional work and image of the working journalists are rated utmost significant.
inspec,train_681,construction of information retrieval thesaurus for family planning terms using cds isis. the thesaurus as a tool for information retrieval and as an alternative to the existing scheme of classifications in information retrieval is discussed. the paper considers the emergence of the information retrieval thesaurus and its definition. family planning is a multidisciplinary subject covering socio economic cultural psychological and medical fields. this necessitated the construction of a thesaurus for the family planning discipline. the construction is based on unisist iso 2788 and bs 5723 guidelines by using cds isis software.
inspec,train_682,information and information technology. this paper reveals the concepts of information and information technology. it also describes the close relationship between information and information technology. it explains a basic mechanism of different devices of information technology and connotes how they are useful to store process and retrieve the information. in addition of this the paper shows the present status of information technology and indian universities.
inspec,train_683,knowledge management. the article defines knowledge management discusses its role and describes its functions. it also explains the principles of knowledge management enumerates the strategies involved in knowledge management and traces its history in brief. the focus is on its interdisciplinary nature. the steps involved in knowledge management i e identifying collecting and capturing selecting organizing and storing sharing applying and creating are explained. the pattern of knowledge management initiatives is also considered.
inspec,train_684,individual decision making using fuzzy set theory. the paper shows the importance of decision making by an individual and highlights the prime domain of decision making where fuzzy set theory can be used as a tool. fuzzy set theory has been used on rational model of decision making to arrive at the desired conclusion.
inspec,train_685,robotically enhanced placement of left ventricular epicardial electrodes during implantation of a biventricular implantable cardioverter defibrillator system. biventricular pacing has gained increasing acceptance in advanced heart failure patients. one major limitation of this therapy is positioning the left ventricular stimulation lead via the coronary sinus. this report demonstrates the feasibility of totally endoscopic direct placement of an epicardial stimulation lead on the left ventricle using the davinci surgical system.
inspec,train_686,technology cad of sige heterojunction field effect transistors. a 2d virtual wafer fabrication simulation suite has been employed for the technology cad of sige channel heterojunction field effect transistors hfets. complete fabrication process of sige p hfets has been simulated. the sige material parameters and mobility model were incorporated to simulate si sige p hfets with a uniform germanium channel having an l sub eff of 0 5 mu m. a significant improvement in linear transconductance is observed when compared to control silicon p mosfets.
inspec,train_687,image reconstruction of simulated specimens using convolution back projection. this paper reports the reconstruction of cross sections of composite structures. the convolution back projection cbp algorithm has been used to capture the attenuation field over the specimen. five different test cases have been taken up for evaluation. these cases represent varying degrees of complexity. in addition the role of filters on the nature of the reconstruction errors has also been discussed. numerical results obtained in the study reveal that cbp algorithm is a useful tool for qualitative as well as quantitative assessment of composite regions encountered in engineering applications.
inspec,train_688,active vibration control of piezolaminated smart beams. this paper deals with the active vibration control of beam like structures with distributed piezoelectric sensor and actuator layers bonded on top and bottom surfaces of the beam. a finite element model based on euler bernoulli beam theory has been developed. the contribution of the piezoelectric sensor and actuator layers on the mass and stiffness of the beam is considered. three types of classical control strategies namely direct proportional feedback constant gain negative velocity feedback and lyapunov feedback and an optimal control strategy linear quadratic regulator lqr scheme are applied to study their control effectiveness. also the control performance with different types of loading such as impulse loading step loading harmonic and random loading is studied.
inspec,train_689,continuous time linear systems folklore and fact. we consider a family of continuous input output maps representing linear time invariant systems that take a set of signals into itself. it is shown that this family contains maps whose impulse response is the zero function but which take certain inputs into nonzero outputs. it is shown also that this family contains members whose input output properties are not described by their frequency domain response functions and that the maps considered need not even commute.
inspec,train_69,sensitivity calibration of ultrasonic detectors based using add diagrams. the paper considers basic problems related to utilization of add diagrams in calibrating sensitivity of ultrasonic detectors. we suggest that a convenient tool for solving such problems can be the software package add universal. version 2 1 designed for plotting individual add diagrams for normal and slanted transducers. the software is compatible with the contemporary operational system windows 95 98. reference signals for calibration are generated in a sample with cylindrical holes.
inspec,train_690,robust kalman filter design for discrete time delay systems. the problem of finite and infinite horizon robust kalman filtering for uncertain discrete time systems with state delay is addressed. the system under consideration is subject to time varying norm bounded parameter uncertainty in both the state and output matrices. we develop a new methodology for designing a linear filter such that the error variance of the filter is guaranteed to be within a certain upper bound for any allowed uncertainty and time delay. the solution is given in terms of two riccati equations. multiple time delay systems are also investigated.
inspec,train_691,robust output feedback control for linear continuous uncertain state delayed systems with unknown time delay. the state delayed time often is unknown and independent of other variables in most real physical systems. a new stability criterion for uncertain systems with a state time varying delay is proposed. then a robust observer based control law based on this criterion is constructed via the sequential quadratic programming method. we also develop a separation property so that the state feedback control law and observer can be independently designed and maintain closed loop system stability. an example illustrates the availability of the proposed design method.
inspec,train_692,a partial converse to hadamard s theorem on homeomorphisms. a theorem by hadamard gives a two part condition under which a map from one banach space to another is a homeomorphism. the theorem while often very useful is incomplete in the sense that it does not explicitly specify the family of maps for which the condition is met. here under a typically weak additional assumption on the map we show that hadamard s condition is met if and only if the map is a homeomorphism with a lipschitz continuous inverse. an application is given concerning the relation between the stability of a nonlinear system and the stability of related linear systems.
inspec,train_693,lifting factorization of discrete w transform. a general method is proposed to factor the type iv discrete w transform dwt iv into lifting steps and additions. then based on the relationships among various types of dwts four types of dwts are factored into lifting steps and additions. after approximating the lifting matrices we get four types of new integer dwts intdwt i intdwt ii intdwt iii and intdwt iv which are floating point multiplication free. integer to integer transforms ii dwt which approximate to dwt are also proposed. fast algorithms are given for the new transforms and their computational complexities are analyzed.
inspec,train_694,a novel genetic algorithm for the design of a signed power of two coefficient quadrature mirror filter lattice filter bank. a novel genetic algorithm ga for the design of a canonical signed power of two spt coefficient lattice structure quadrature mirror filter bank is presented. genetic operations may render the spt representation of a value noncanonical. a new encoding scheme is introduced to encode the spt values. in this new scheme the canonical property of the spt values is preserved under genetic operations. additionally two new features that drastically improve the performance of our ga are introduced. 1 an additional level of natural selection is introduced to simulate the effect of natural selection when sperm cells compete to fertilize an ovule this dramatically improves the offspring survival rate. a conventional ga is analogous to intracytoplasmic sperm injection and has an extremely low offspring survival rate resulting in very slow convergence. 2 the probability of mutation for each codon of a chromosome is weighted by the reciprocal of its effect. because of these new features the performance of our new ga outperforms conventional gas.
inspec,train_695,design of high performance wavelets for image coding using a perceptual time domain criterion. this paper presents a new biorthogonal linear phase wavelet design for image compression. instead of calculating the prototype filters as spectral factors of a half band filter the design is based on the direct optimization of the low pass analysis filter using an objective function directly related to a perceptual criterion for image compression. this function is defined as the product of the theoretical coding gain and an index called the peak to peak ratio which was shown to have high correlation with perceptual quality. a distinctive feature of the proposed technique is a procedure by which given a good starting filter  good filters of longer lengths are generated. the results are excellent showing a clear improvement in perceptual image quality. also we devised a criterion for constraining the coefficients of the filters in order to design wavelets with minimum ringing.
inspec,train_696,design and implementation of a new sliding mode observer for speed sensorless control of induction machine. in this letter a new sliding mode sensorless control algorithm is proposed for the field oriented induction machine drive. in the proposed algorithm the terms containing flux speed and rotor time constant which are common in both current and flux equations in the current model of the induction machine are estimated by a sliding function. the flux and speed estimation accuracy is guaranteed when the error between the actual current and observed current converges to zero. hence the fourth order system is reduced to two second order systems and the speed estimation becomes very simple and robust to the parameter uncertainties. the new approach is verified by simulation and experimental results.
inspec,train_697,schedulability analysis of real time traffic in worldfip networks an integrated approach. the worldfip protocol is one of the profiles that constitute the european fieldbus standard en 50170. it is particularly well suited to be used in distributed computer controlled systems where a set of process variables must be shared among network devices. to cope with the real time requirements of such systems the protocol provides communication services based on the exchange of periodic and aperiodic identified variables. the periodic exchanges have the highest priority and are executed at run time according to a cyclic schedule. therefore the respective schedulability can be determined at pre run time when building the schedule table. concerning the aperiodic exchanges the situation is different since their priority is lower and they are bandied according to a first come first served policy. in this paper a response time based schedulability analysis for the real time traffic is presented. such analysis considers both types of traffic in an integrated way according to their priorities. furthermore a fixed priorities based policy is also used to schedule the periodic traffic. the proposed analysis represents an improvement relative to previous work and it can be evaluated online as part of a traffic online admission control. this feature is of particular importance when a planning scheduler is used instead of the typical offline static scheduler to allow online changes to the set of periodic process variables.
inspec,train_698,robust stability analysis for current programmed regulators. uncertainty models for the three basic switch mode converters buck boost and buck boost are given in this paper. the resulting models are represented by linear fractional transformations with structured dynamic uncertainties. uncertainties are assumed for the load resistance r r sub o 1 delta sub r  inductance l l sub o 1 delta sub l  and capacitance c c sub o 1 delta sub c. the interest in these models is clearly motivated by the need to have models for switch mode dc dc converters that are compatible with robust control analysis which require a model structure consisting of a nominal model and a norm bounded modeling uncertainty. therefore robust stability analysis can be realized using standard mu tools. at the end of the paper an illustrative example is given which shows the simplicity of the procedure.
inspec,train_699,novel line conditioner with voltage up down capability. in this paper a novel pulsewidth modulated line conditioner with fast output voltage control is proposed. the line conditioner is made up of an ac chopper with reversible voltage control and a transformer for series voltage compensation. in the ac chopper a proper switching operation is achieved without the commutation problem. to absorb energy stored in line stray inductance a regenerative dc snubber can be utilized which has only one capacitor without discharging resistors or complicated regenerative circuit for snubber energy. therefore the proposed ac chopper gives high efficiency and reliability. the output voltage of the line conditioner is controlled using a fast sensing technique of the output voltage. it is also shown via some experimental results that the presented line conditioner gives good dynamic and steady state performance for high quality of the output voltage.
inspec,train_7,anti spam suit attempts to hold carriers accountable. a lawsuit alleges that sprint has violated utah s new anti spam act. the action could open the door to new regulations on telecom service providers.
inspec,train_70,it security issues the need for end user oriented research. considerable attention has been given to the technical and policy issues involved with it security issues in recent years. the growth of e commerce and the internet as well as widely publicized hacker attacks have brought it security into prominent focus and routine corporate attention. yet much more research is needed from the end user eu perspective. this position paper is a call for such research and outlines some possible directions of interest.
inspec,train_700,digital stochastic realization of complex analog controllers. stochastic logic is based on digital processing of a random pulse stream where the information is codified as the probability of a high level in a finite sequence. this binary pulse sequence can be digitally processed exploiting the similarity between boolean algebra and statistical algebra. given a random pulse sequence any boolean operation among individual pulses will correspond to an algebraic expression among the variables represented by their respective average pulse rates. subsequently this pulse stream can be digitally processed to perform analog operations. in this paper we propose a stochastic approach to the digital implementation of complex controllers using programmable devices as an alternative to traditional digital signal processors. as an example a practical realization of nonlinear dissipative controllers for a series resonant converter is presented.
inspec,train_701,high dynamic control of a three level voltage source converter drive for a main strip mill. a high dynamic control system for the alspa vdm 7000 medium voltage drive was implemented which provides fast torque response times of a few milliseconds despite the typically low switching frequency of gate turn off thyristors which is necessary to achieve high efficiency. the drive system consists of a three level voltage source converter with active front end and a synchronous motor. the drive has most recently been applied to a main strip mill. it provides a maximum of 8 3 mw mechanical power with a rated motor voltage of 3 kv. besides motor torque as the main control objective the control system has to comply with a number of additional objectives and constraints like dc link voltage regulation and balancing current and torque harmonics motor flux and excitation.
inspec,train_702,a comparison of high power converter topologies for the implementation of facts controllers. this paper compares four power converter topologies for the implementation of flexible ac transmission system facts controllers three multilevel topologies multipoint clamped mpc chain and nested cell and the well established multipulse topology. in keeping with the need to implement very high power inverters switching frequency is restricted to line frequency. the study addresses device count dc filter ratings restrictions on voltage control active power transfer through the dc link and balancing of dc link voltages. emphasis is placed on capacitor sizing because of its impact on the cost and size of the facts controller. a method for the dimensioning the dc capacitor filter is presented. it is found that the chain converter is attractive for the implementation of a static compensator or a static synchronous series compensator. the mpc converter is attractive for the implementation of a unified power flow controller or an interline power flow controller but a special arrangement is required to overcome the limitations on voltage control.
inspec,train_703,direct self control with minimum torque ripple and high dynamics for a double three level gto inverter drive. a highly dynamic control scheme with very low torque ripple direct self control dsc with torque hysteresis control for very high power medium voltage induction motor drives fed by a double three level inverter d3li is presented. in this arrangement two three level inverters that are connected in parallel at their dc sides are feeding the open motor windings. the dsc well known from two and three level inverters is adapted to the d3li and optimized for a minimum torque ripple. an 18 corner trajectory is chosen for the stator flux of the induction machine since it is approaching the ideal circle much better than the hexagon known from dsc for two level inverters without any detriment to the torque ripple. the machine and inverter control are explained and the proposed torque quality and dynamics are verified by measurements on a 180 kw laboratory drive.
inspec,train_704,multicell converters active control and observation of flying capacitor voltages. the multicell converters introduced more than ten years ago make it possible to distribute the voltage constraints among series connected switches and to improve the output waveforms increased number of levels and apparent frequency. the balance of the constraints requires an appropriate distribution of the flying voltages. this paper presents some solutions for the active control of the voltages across the flying capacitors in the presence of rapid variation of the input voltage. the latter part of this paper is dedicated to the observation of these voltages using an original modeling of the converter.
inspec,train_705,use of extra degrees of freedom in multilevel drives. multilevel converters with series connection of semiconductors allow power electronics to reach medium voltages 1 10 kv with relatively standard components. the increase of the number of semiconductors provides extra degrees of freedom which can be used to improve different characteristics. this paper is focused on variable speed drives and it is shown that with the proposed multilevel direct torque control strategy dicoif the tradeoff between the performances of the drive harmonic distortions torque dynamics voltage step gradients etc and the switching frequency of the semiconductors is improved. then a slightly modified strategy reducing common mode voltage and bearing currents is presented.
inspec,train_706,enhancing the reliability of modular medium voltage drives. a method to increase the reliability of modular medium voltage induction motor drives is discussed by providing means to bypass a failed module. the impact on reliability is shown. a control which maximizes the output voltage available after bypass is described and experimental results are given.
inspec,train_707,vector algebra proofs for geometry theorems. vector mathematics can generate simple and powerful proofs of theorems in plane geometry. these proofs can also be used to generalize plane geometry theorems to higher dimensions. we present three vector proofs that show the power of this technique. 1. for any quadrilateral the sum of the squares of the diagonals is less than or equal to the sum of the squares of the sides. 2. the area of a quadrilateral is half the product of the diagonals multiplied by the sine of an included angle. 3. one quarter of all triangles are acute based upon the options detailed below with respect to the relative lengths of the sides. this paper presents a set of examples of vector mathematics applied to geometry problems. some of the most beautiful and sophisticated proofs in mathematics involve using multiple representations of the same data. by leveraging the advantages of each representation one finds new and useful mathematical facts.
inspec,train_708,sufficient conditions on nonemptiness and boundedness of the solution set of the p sub 0 function nonlinear complementarity problem. the p sub 0 function nonlinear complementarity problem ncp has attracted a lot of attention among researchers. various assumed conditions which ensure that the ncp has a solution have been proposed. in this paper by using the notion of an exceptional family of elements we develop a sufficient condition which ensures that the solution set of the p sub 0 function ncp is nonempty and bounded. in particular we prove that many existing assumed conditions imply this sufficient condition. thus these conditions imply that the solution set of the p sub 0 function ncp is nonempty and bounded. in addition we also prove directly that a few existence conditions imply that the solution set of the p sub 0 function ncp is bounded.
inspec,train_709,cooperative mutation based evolutionary programming for continuous function optimization. an evolutionary programming ep algorithm adapting a new mutation operator is presented. unlike most previous eps in which each individual is mutated on its own each individual in the proposed algorithm is mutated in cooperation with the other individuals. this not only enhances convergence speed but also gives more chance to escape from local minima.
inspec,train_71,a study of computer attitudes of non computing students of technical colleges in brunei darussalam. the study surveyed 268 non computing students among three technical colleges in brunei darussalam. the study validated an existing instrument to measure computer attitudes of non computing students and identified factors that contributed to the formation of their attitudes. the findings show that computer experience and educational qualification are associated with students computer attitudes. in contrast variables such as gender age ownership of a personal computer pc geographical location of institution and prior computer training appeared to have no impact on computer attitudes.
inspec,train_710,optimal allocation of runs in a simulation metamodel with several independent variables. cheng and kleijnen 1999 propose a very general regression metamodel for modelling the output of a queuing system. its main limitations are that the regression function is based on a polynomial and that it can use only one independent variable. these limitations are removed here. we derive an explicit formula for the optimal way of assigning simulation runs to the different design points.
inspec,train_711,on bivariate dependence and the convex order. we investigate the interplay between variability in the sense of the convex order and dependence in a bivariate framework extending some previous results in this area. we exploit the fact that discrete uniform distributions are dense in the space of probability measures in the topology of weak convergence to prove our central result. we also obtain a partial result in the general multivariate case. our findings can be interpreted in terms of the impact of component variability on the mean life of correlated serial and parallel systems.
inspec,train_712,waiting time distribution of a discrete time multiserver queue with correlated arrivals and deterministic service times d map d k system. we derive the waiting time distribution of a discrete time multiserver queue with correlated arrivals and deterministic or constant service times. we show that the procedure for obtaining the waiting time distribution of a multiserver queue is reduced to that of a single server queue. we present a complete solution to the waiting time distribution of d map d k queue together with some computational results.
inspec,train_713,efficient feasibility testing for dial a ride problems. dial a ride systems involve dispatching a vehicle to satisfy demands from a set of customers who call a vehicle operating agency requesting that an item tie picked up from a specific location and delivered to a specific destination. dial a ride problems differ from other routing and scheduling problems in that they typically involve service related constraints. it is common to have maximum wait time constraints and maximum ride time constraints. in the presence of maximum wait time and maximum ride time restrictions it is not clear how to efficiently determine given a sequence of pickups and deliveries whether a feasible schedule exists. we demonstrate that this in fact can be done in linear time.
inspec,train_714,embeddings of planar graphs that minimize the number of long face cycles. we consider the problem of finding embeddings of planar graphs that minimize the number of long face cycles. we prove that for any k or 4 it is np complete to find an embedding that minimizes the number of face cycles of length at least k.
inspec,train_715,the quadratic 0 1 knapsack problem with series parallel support. we consider various special cases of the quadratic 0 1 knapsack problem qkp for which the underlying graph structure is fairly simple. for the variant with edge series parallel graphs we give a dynamic programming algorithm with pseudo polynomial time complexity and a fully polynomial time approximation scheme. in strong contrast to this the variant with vertex series parallel graphs is shown to be strongly np complete.
inspec,train_716,algorithmic results for ordered median problems. in a series of papers a new type of objective function in location theory called ordered median function has been introduced and analyzed. this objective function unifies and generalizes most common objective functions used in location theory. in this paper we identify finite dominating sets for these models and develop polynomial time algorithms together with a detailed complexity analysis.
inspec,train_717,a network simplex algorithm with o n consecutive degenerate pivots. we suggest a pivot rule for the primal simplex algorithm for the minimum cost flow problem known as the network simplex algorithm. due to degeneracy cycling may occur in the network simplex algorithm. the cycling can be prevented by maintaining strongly feasible bases proposed by cunningham 1976 however if we do not impose any restrictions on the entering variables the algorithm can still perform an exponentially long sequence of degenerate pivots. this phenomenon is known as stalling. researchers have suggested several pivot rules with the following bounds on the number of consecutive degenerate pivots m n sup 2  k k 1 2 where n is the number of nodes in the network m is the number of arcs in the network and k is the number of degenerate arcs in the basis. observe that k or n in this paper we describe an anti stalling pivot rule that ensures that the network simplex algorithm performs at most k consecutive degenerate pivots. this rule uses a negative cost augmenting cycle to identify a sequence of entering variables.
inspec,train_718,new water management system begins operation at us projects. the us army corps of engineers has developed a new automated information system to support its water control management mission. the new system provides a variety of decision support tools enabling water control managers to acquire transform verify store display analyse and disseminate data and information efficiently and around the clock.
inspec,train_719,war games the truth network security. with al qaeda on the tip of tongues around the world find out how terror groups could target your network. what are the dangers and how do you fight them.
inspec,train_72,a three tier technology training strategy in a dynamic business environment. as end user training becomes increasingly important in today s technology intensive business environment progressive companies remain alert to find ways to provide their end users with timely training and resources. this paper describes an innovative training strategy adopted by one midsize organization to provide its end users with adequate flexible and responsive training. the paper then compares the three tier strategy with other models described in technology training literature. managers who supervise technology end users in organizations comparable to the one in the study may find the three tier strategy workable and may want to use it in their own training programs to facilitate training and improve end user skills. researchers and scholars may find that the idea of three tier training generates new opportunities for research.
inspec,train_720,19in monitors crt survey. upgrade your monitor from as little as pounds 135. with displays on test and ranging up to pounds 400 whether you re after the last word in quality or simply looking for again this labs holds the answer. looks at adi microscan m900 ctx pr960f eizo flexscan t766 hansol 920d hansol920p hitachi cm715et hitachi cm721fet liyama vision master pro 454 lg flatron 915ft plus mitsubishi diamond pro 920 nec multisync fe950  philips 109s40 samsung syncmaster 959nf sony multiscan cpd g420 and viewsonic g90f.
inspec,train_721,the results of experimental studies of the reflooding of fuel rod assemblies from above and problems for future investigations. problems in studying the reflooding of assemblies from above conducted at foreign and russian experimental installations are considered. the efficiency of cooling and flow reversal under countercurrent flow of steam and water as well as the scale effect are analyzed. the tasks for future experiments that are necessary for the development of modern correlations for the loss of coolant accident loca computer codes are stated.
inspec,train_722,updating systems for monitoring and controlling power equipment on the basis of the firmware system sargon. the economic difficulties experienced by the power industry of russia has considerably retarded the speed of commissioning new capacities and reconstructing equipment in service. the increasing deterioration of the equipment at power stations makes the problem of its updating very acute. the main efforts of organizations working in the power industry are now focused on updating all kinds of equipment installed at power installations. the necessary condition for the efficient operation of power equipment is to carry out serious modernization of systems for monitoring and control smc of technological processes. the specialists at zao nvt avtomatika have developed efficient technology for updating the smc on the basis of the firmware system sargon which ensures the fast introduction of high quality systems of automation with a minimal payback time of the capital outlay. this paper discusses the updating of equipment using sargon.
inspec,train_723,simulation of physicochemical processes of erosion corrosion of metals in two phase flows. a computational model for the erosion corrosion of the metals used in power equipment in two phase flows ramek 2 was developed. the results of calculations of the dependency of the intensity of the erosion corrosion of structural steels as a function of the thermodynamic hydrodynamic and water chemistry parameters of these flows in the working paths of thermal power stations and nuclear power stations are presented in a three dimensional space. on the basis of mathematical models application software was created for forecasting the erosion corrosion resource and for optimizing the rules on diagnosis and protective maintenance of erosion corrosion of the elements of the wet steam path in power stations.
inspec,train_724,banking on sma funds separately managed accounts. from investment management to technology to back office services outsourcers are elbowing their way into the sma business. small banks are paying attention and hoping to reap the rewards.
inspec,train_725,banks pin their back office hopes on successors to screen scrapers. the big name in account aggregation has been yodlee based in redwood shores ca. it pioneered the art of screen scraping or pulling data off web sites and aggregating it into a single statement. that data however is a snapshot and does not include a customer s investment history. also because web sites update data at different times scraping them can provide an inaccurate picture of a customer s financial situation making it difficult for reps seeking to provide timely and accurate advice. the objective is to access both fresh and historical data across a client s financial spectrum from investments to checking accounts and loans to insurance policies a complete customer balance sheet. at least two technology vendors are progressing in that direction each coming from different directions. one is advent based in san francisco another is fincentric out of vancouver.
inspec,train_726,new wrinkle on the web. hmm. banking. the financial sector produced its share of technology hype during the new economy years. you. ca n t blame folks if the next next thing a wave of internet related innovation called web services is being met with healthy skepticism. many gurus are placing their bets on web services to drive the next chapter of finance technology dramatically upgrading disappointing automated customer management strategies by electronically breaking down barriers between products firms and customers and perhaps creating a whole new line of business in the process. but it s not a magic wand. it does n t change the need for a bank to reorganize and streamline its operations.
inspec,train_727,life after bankruptcy telecom carriers. how comeback telecom carriers are changing industry economics and why others may have no choice but to follow their lead.
inspec,train_728,questioning the rfp process telecom. in the current climate the most serious concern about the purchasing habits of telecom carriers is obviously the lack of spending. even against a backdrop of economic constraints and financial struggles however genuine concerns about the purchasing process itself are being raised by some of those closest to it.
inspec,train_73,how does attitude impact it implementation a study of small business owners. according to previous studies attitude towards information technology it among small business owners appears to be a key factor in achieving high quality it implementations. in an effort to extend this stream of research we conducted case studies with small business owners and learned that high quality it implementations resulted with owners who had positive or negative attitudes toward it but not with owners who had uncertain attitudes. owners with apolar attitude either positive or negative all took action to temper the uncertainty and risk surrounding the use of new it in their organization. in contrast owners with uncertain attitudes did not make mitigating attempts to reduce uncertainty and risk. a consistent finding among those with high quality it implementations was an entrepreneurial or shared management style. it is proposed based on case study data that small business owners with an uncertain attitude towards it might experience higher quality it results in their organizations through practicing a more entrepreneurial or shared management style. the study provides insights for both computer specialists and small business owners planning it implementations.
inspec,train_730,multi hour design of survivable classical ip networks. most of internet intra domain routing protocols ospf rip and is is are based on shortest path routing. the path length is defined as the sum of metrics associated with the path links. these metrics are often managed by the network administrator. in this context the design of an internet backbone network consists in dimensioning the network routers and transmission links and establishing the metric. many requirements have to be satisfied. first internet traffic is not static as significant variations can be observed during the day. second many failures can occur cable cuts hardware failures software failures etc. we present algorithms meta heuristics and greedy heuristic to design internet backbone networks taking into account the multi hour behaviour of traffic and some survivability requirements. many multi hour and protection strategies are studied and numerically compared. our algorithms can be extended to integrate other quality of service constraints.
inspec,train_731,aggregate bandwidth estimation in stored video distribution systems. multimedia applications like video on demand distance learning internet video broadcast etc will play a fundamental role in future broadband networks. a common aspect of such applications is the transmission of video streams that require a sustained relatively high bandwidth with stringent requirements of quality of service. in this paper various original algorithms for evaluating in a video distribution system a statistical estimation of aggregate bandwidth needed by a given number of smoothed video streams are proposed and discussed. the variable bit rate traffic generated by each video stream is characterized by its marginal distribution and by conditional probabilities between rates of temporary closed streams. the developed iterative algorithms evaluate an upper and lower bound of needed bandwidth for guaranteeing a given loss probability. the obtained results are compared with simulations and with other results based on similar assumptions already presented in the literature. some considerations on the developed algorithms are made in order to evaluate the effectiveness of the proposed methods.
inspec,train_732,a unifying co operative web caching architecture. network caching of objects has become a standard way of reducing network traffic and latency in the web. however web caches exhibit poor performance with a hit rate of about 30. a solution to improve this hit rate is to have a group of proxies form co operation where objects can be cached for later retrieval. a cooperative cache system includes protocols for hierarchical and transversal caching. the drawback of such a system lies in the resulting network load due to the number of messages that need to be exchanged to locate an object. this paper proposes a new co operative web caching architecture which unifies previous methods of web caching. performance results shows that the architecture achieve up to 70 co operative hit rate and accesses the cached object in at most two hops. moreover the architecture is scalable with low traffic and database overhead.
inspec,train_733,voip makeover transforms ugly duckling network. surrey county council s swan project is europe s biggest implementation of voice over ip. six wans and countless lans are are being consolidated into a single network covering 6 000 users at 200 sites. the contract was signed in october 2001 for pounds 13m over five years and rollout will be completed in may 2003.
inspec,train_734,web services boost integration. microsoft and ibm have announced products to help their database software co exist with competitors offerings. the products use web services technology allowing users to improve integration between databases and application software from rival vendors.
inspec,train_735,it at the heart of joined up policing. police it is to shift from application focused to component based technology. the change of strategy part of the valiant programme will make information held by individual forces available on a national basis.
inspec,train_736,the year of the racehorse china telecom. does china really offer the telecoms industry a route out of the telecoms slump. according to the chinese government it has yet to receive a single application from foreign companies looking to invest in the country s domestic telecoms sector since the country joined the world trade organisation.
inspec,train_737,what s in a name. mobile telephony branding. mobile operators are frantically consolidating businesses into single international brands.
inspec,train_738,playing for time 3g networks. the delays in rolling out 3g networks across europe should not always be seen with a negative slant.
inspec,train_739,disposable mobiles. after many delays the reusable recyclable disposable mobile phone is finally going on sale in the us. but with a business model largely dependent on niche markets elizabeth biddlecombe asks if these simplified handsets will be good enough to survive a brutal market.
inspec,train_74,end user perspectives on the uptake of computer supported cooperative working. researchers in information systems have produced a rich collection of meta analyses and models to further understanding of factors influencing the uptake of information technologies. in the domain of cscw however these models have largely been neglected and while there are many case studies no systematic account of uptake has been produced. we use findings from information systems research to structure a meta analysis of uptake issues as reported in cscw case studies supplemented by a detailed re examination of one of our own case studies from this perspective. this shows that while there are some factors which seem to be largely specific to cscw introductions many of the case study results are very similar to standard is findings. we conclude by suggesting how the two communities of researchers might build on each other s work and finally propose activity theory as a means of integrating the two perspectives.
inspec,train_740,the malaysian model. japan s first third generation service foma is unlikely to be truly attractive to consumers until 2005. that still falls well within the financial planning of its operator docomo. but where does that leave european 3g operators looking for reassurance. malaysia says simon marshall.
inspec,train_741,mothball mania 3g licences. telefonica moviles has frozen its 3g operations in germany austria italy and switzerland. with other 3g licence holders questioning the logic of entering already saturated markets with unproven technology emma mcclune asks if the mothball effect is set to snowball any further.
inspec,train_742,second term international telecommunication union. later this month yoshio utsumi is expected to be re elected for a second four year term as secretary general of the international telecommunication union. here he talks to matthew may about getting involved in internet addressing the prospects for 3g the need for further reform of his organisation and the translating telephone.
inspec,train_743,local satellite. consumer based mobile satellite phone services went from boom to burn up in twelve months despite original forecasts predicting 10 million to 40 million users by 2005. julian bright wonders what prospects the technology has now and if going regional might be one answer.
inspec,train_744,a virtual victory virtual networks. newly fashionable virtual network operators look all set to clean up in the corporate sector.
inspec,train_745,intensity based affine registration including feature similarity for spatial normalization. this paper presents a new spatial normalization with affine transformation. the quantitative comparison of brain architecture across different subjects requires a common coordinate system. for the analysis of a specific brain area it is necessary to normalize and compare a region of interest and the global brain. the intensity based registration method matches the global brain well but a region of interest may not be locally normalized compared to the feature based method. the method in this paper uses feature similarities of local regions as well as intensity similarities. the lateral ventricle and central gray nuclei of the brain including the corpus callosum which is used for features in schizophrenia detection is appropriately normalized. our method reduces the difference of feature areas such as the corpus callosum 7 7  2 4 and lateral ventricle 8 2  13 5 compared with mutual information and talairach methods.
inspec,train_746,real time transmission of pediatric echocardiograms using a single isdn line. we tested the adequacy of a videoconferencing system using a single integrated systems digital network isdn line 128 kilobits per second for the remote diagnosis of children with suspected congenital heart disease chd. real time echocardiogram interpretation was compared to subsequent videotape review in 401 studies with concordance in 383 95 5 studies. a new diagnosis of chd was made in 98 studies. immediate patient transfer was arranged based upon a real time diagnosis in five studies. in 300 studies a normal diagnosis obviated further evaluation. a single isdn line is adequate for transmission of pediatric echocardiograms and it allows for remote management of patients with chd.
inspec,train_747,simulation of cardiovascular physiology the diastolic function s of the heart. the cardiovascular system was simulated by using an equivalent electronic circuit. four sets of simulations were performed. the basic variables investigated were cardiac output and stroke volume. they were studied as functions i of right ventricular capacitance and negative intrathoracic pressure ii of left ventricular relaxation and of heart rate and iii of left ventricle failure. it seems that a satisfactory simulation of systolic and diastolic functions of the heart is possible. presented simulations improve our understanding of the role of the capacitance of both ventricles and of the diastolic relaxation in cardiovascular physiology.
inspec,train_748,simulation study of the cardiovascular functional status in hypertensive situation. an extended cardiovascular model was established based on our previous work to study the consequences of physiological or pathological changes to the homeostatic functions of the cardiovascular system. to study hemodynamic changes in hypertensive situations the impacts of cardiovascular parameter variations peripheral vascular resistance arterial vessel wall stiffness and baroreflex gain upon hemodynamics and the short term regulation of the cardiovascular system were investigated. for the purpose of analyzing baroregulation function the short term regulation of arterial pressure in response to moderate dynamic exercise for normotensive and hypertensive cases was studied through computer simulation and clinical experiments. the simulation results agree well with clinical data. the results of this work suggest that the model presented in this paper provides a useful tool to investigate the functional status of the cardiovascular system in normal or pathological conditions.
inspec,train_749,numerical modeling of the flow in stenosed coronary artery. the relationship between main hemodynamic parameters. the severity of coronary arterial stenosis is usually measured by either simple geometrical parameters such as percent diameter stenosis or hemodynamically based parameters such as the fractional flow reserve ffr or coronary flow reserve cfr. the present study aimed to establish a relationship between actual hemodynamic conditions and the parameters that define stenosis severity in the clinical setting. we used a computational model of the blood flow in a vessel with a blunt stenosis and an autoregulated vascular bed to simulate a stenosed blood vessel. a key point in creating realistic simulations is to properly model arterial autoregulation. a constant flow regulation mechanism resulted in cfr and ffr values that were within the physiological range while a constant wall shear stress model yielded unrealistic values. the simulation tools developed in the present study may be useful in the clinical assessment of single and multiple stenoses by means of minimally invasive methods.
inspec,train_75,a portable auto attendant system with sophisticated dialog structure. an attendant system connects the caller to the party he she wants to talk to. traditional systems require the caller to know the full name of the party. if the caller forgets the name the system fails to provide service for the caller. in this paper we propose a portable auto attendant system aas with sophisticated dialog structure that gives a caller more flexibility while calling. the caller may interact with the system to request a phone number by providing just a work area specialty surname or title etc. if the party is absent the system may provide extra information such as where he went when he will be back and what he is doing. the system is built modularly with components such as speech recognizer language model dialog manager and text to speech that can be replaced if necessary. by simply changing the personnel record database the system can easily be ported to other companies. the sophisticated dialog manager applies many strategies to allow natural interaction between user and system. functions such as fuzzy request user repairing and extra information query which are not provided by other systems are integrated into our system. experimental results and comparisons to other systems show that our approach provides a more user friendly and natural interaction for auto attendant system.
inspec,train_750,automated cerebrum segmentation from three dimensional sagittal brain mr images. we present a fully automated cerebrum segmentation algorithm for full three dimensional sagittal brain mr images. first cerebrum segmentation from a midsagittal brain mr image is performed utilizing landmarks anatomical information and a connectivity based threshold segmentation algorithm as previously reported. recognizing that the cerebrum in laterally adjacent slices tends to have similar size and shape we use the cerebrum segmentation result from the midsagittal brain mr image as a mask to guide cerebrum segmentation in adjacent lateral slices in an iterative fashion. this masking operation yields a masked image preliminary cerebrum segmentation for the next lateral slice which may truncate brain region s. truncated regions are restored by first finding end points of their boundaries by comparing the mask image and masked image boundaries and then applying a connectivity based algorithm. the resulting final extracted cerebrum image for this slice is then used as a mask for the next lateral slice. the algorithm yielded satisfactory fully automated cerebrum segmentations in three dimensional sagittal brain mr images and had performance superior to conventional edge detection algorithms for segmentation of cerebrum from 3d sagittal brain mr images.
inspec,train_751,a new method of regression on latent variables. application to spectral data. several applications are based on the assessment of a linear model linking a set of variables y to a set of predictors x. in the presence of strong colinearity among predictors as in the case with spectral data several alternative procedures to ordinary least squares ols are proposed we discuss a new alternative approach which we refer to as regression models through constrained principal components analysis rm cpca. this method basically shares certain common characteristics with pls regression as the dependent variables play a central role in determining the latent variables to be used as predictors. unlike pls however the approach discussed leads to straightforward models. this method also bears some similarity to latent root regression analysis lrr that was discussed by several authors. moreover a tuning parameter that ranges between 0 and 1 is introduced and the family of models thus formed includes several other methods as particular cases.
inspec,train_752,presenting a better mousetrap leeza outboard video signal processor. scaling interlaced video to match high resolution plasma lcd and dlp displays is a tough job but key digital s leeza is zip to the tack. and it s digitally bilingual too. there s no question that outboard video signal processors like leeza help overcome the inherent limitations of fixed pixel displays. being able to match a native display rate with heavily processed video makes the viewing experience much more enjoyable. but it seemed that 70 of the improvement in image quality came from using a digital interface to the dvd player as most noise and picture artifacts are introduced in the analog video encoding process.
inspec,train_753,in medias res dvd formats. four years in the making the dvd format war rages on no winner insight. meanwhile the spoils of war abound and dvd media manufacturers stand poised to profit.
inspec,train_754,record makers uk health records. plans for a massive cradle to grave electronic records project have been revealed by the government. is the scheme really viable.
inspec,train_755,hardware and software platform for real time processing and visualization of echographic radiofrequency signals. in this paper the architecture of a hardware and software platform for ultrasonic investigation is presented. the platform used in conjunction with an analog front end hardware for driving the ultrasonic transducers of any commercial echograph having the radiofrequency echo signal access make it possible to dispose of a powerful echographic system for experimenting any processing technique also in a clinical environment in which real time operation mode is an essential prerequisite. the platform transforms any echograph into a test system for evaluating the diagnostic effectiveness of new investigation techniques. a particular user interface was designed in order to allow a real time and simultaneous visualization of the results produced in the different stages of the chosen processing procedure. this is aimed at obtaining a better optimization of the processing algorithm. the most important platform aspect which also constitutes the basic differentiation with respect to similar systems is the direct processing of the radiofrequency echo signal which is essential for a complete analysis of the particular ultrasound media interaction phenomenon. the platform completely integrates the architecture of a personal computer pc giving rise to several benefits such as the quick technological evolution in the pc field and an extreme degree of programmability for different applications. the pc also constitutes the user interface as a flexible and intuitive visualization support and performs some software signal processing by custom algorithms and commercial libraries. the realized close synergy between hardware and software allows the acquisition and real time processing of the echographic radiofrequency rf signal with fast data representation.
inspec,train_756,a new high resolution color flow system using an eigendecomposition based adaptive filter for clutter rejection. we present a new signal processing strategy for high frequency color flow mapping in moving tissue environments. a new application of an eigendecomposition based clutter rejection filter is presented with modifications to deal with high blood to clutter ratios bcr. additionally a new method for correcting blood velocity estimates with an estimated tissue motion profile is detailed. the performance of the clutter filter and velocity estimation strategies is quantified using a new swept scan signal model. in vivo color flow images are presented to illustrate the potential of the system for mapping blood flow in the microcirculation with external tissue motion.
inspec,train_757,ultrafast compound imaging for 2 d motion vector estimation application to transient elastography. this paper describes a new technique for two dimensional 2 d imaging of the motion vector at a very high frame rate with ultrasound. its potential is experimentally demonstrated for transient elastography. but beyond this application it also could be promising for color flow and reflectivity imaging. to date only axial displacements induced in human tissues by low frequency vibrators were measured during transient elastography. the proposed technique allows us to follow both axial and lateral displacements during the shear wave propagation and thus should improve young s modulus image reconstruction. the process is a combination of several ideas well known in ultrasonic imaging ultra fast imaging multisynthetic aperture beamforming 1 d speckle tracking and compound imaging. classical beamforming in the transmit mode is replaced here by a single plane wave insonification increasing the frame rate by at least a factor of 128. the beamforming is achieved only in the receive mode on two independent subapertures. comparison of successive frames by a classical 1 d speckle tracking algorithm allows estimation of displacements along two different directions linked to the subapertures beams. the variance of the estimates is finally improved by tilting the emitting plane wave at each insonification thus allowing reception of successive decorrelated speckle patterns.
inspec,train_758,four terminal quantum resistor network for electron wave computing. interconnected ultrathin conducting wires or equivalently interconnected quasi one dimensional electron waveguides which form a quantum resistor network are presented here in four terminal configurations. the transmission behaviors through such four terminal networks are evaluated and classified. in addition we show that such networks can be used as the basic building blocks for a possible massive wave computing machine in the future. in a network each interconnection a node point is an elastic scatterer that routes the electron wave. routing and rerouting of electron waves in a network is described in the framework of quantum transport from landauer buttiker theory in the presence of multiple elastic scatterers. transmissions through various types of four terminal generalized clean aharonov bohm rings are investigated at zero temperature. useful logic functions are gathered based on the transmission probability to each terminal with the use of the buttiker symmetry rule. in the generalized rings even and odd numbers of terminals can possess some distinctly different transmission characteristics as we have shown here and earlier. just as an even or odd number of atoms in a ring is an important quantity for classifying the transmission behavior we show here that whether the number of terminals is an even or an odd number is just as important in understanding the physics of transmission through such a ring. furthermore we show that there are three basic classes of four terminal rings and the scaling relation for each class is provided. in particular the existence of equitransmission among all four terminals is shown here. this particular physical phenomena can not exist in any three terminal ring. comparisons and discussions of transmission characteristics between three terminal and four terminal rings are also presented. the node equation approach by considering the kirchhoff current conservation law at each node point is used for this analysis. many useful logic functions for electron wave computing are shown here. in particular we show that a full adder can be constructed very simply using the equitransmission property of the four terminal ring. this is in sharp contrast with circuits based on transistor logic.
inspec,train_759,mathematical properties of dominant ahp and concurrent convergence method. this study discusses the mathematical structure of the dominant ahp and the concurrent convergence method which were originally developed by kinoshita and nakanishi. they introduced a new concept of a regulating alternative into an analyzing tool for a simple evaluation problem with a criterion set and an alternative set. although the original idea of the dominant ahp and the concurrent convergence method is unique the dominant ahp and the concurrent convergence method are not sufficiently analyzed in mathematical theory. this study shows that the dominant ahp consists of a pair of evaluation rules satisfying a certain property of overall evaluation vectors. this study also shows that the convergence of concurrent convergence method is guaranteed theoretically.
inspec,train_76,reaching strong consensus in a general network. the strong consensus sc problem is a variant of the conventional distributed consensus problem also known as the byzantine agreement problem. the sc problem requires that the agreed value among fault free processors be one of the fault free processor s initial values. originally the problem was studied in a fully connected network with malicious faulty processors. in this paper the sc problem is re examined in a general network in which the components processors and communication links may be subjected to different faulty types simultaneously also called the hybrid fault model or mixed faulty types and the network topology does not have to be fully connected. the proposed protocol can tolerate the maximum number of tolerable faulty components such that each fault free processor obtains a common value for the sc problem in a general network.
inspec,train_760,an improved fuzzy mcdm model based on ideal and anti ideal concepts. liang presented 1999 a fuzzy multiple criteria decision making mcdm method based on the concepts of ideal and anti ideal points. despite its merits liang method has the following limitations i the objective criteria are converted into dimensionless indices and the subjective criteria are not converted which may prevent compatibility for these criteria ii the formulas for converting objective criteria are not reliable and iii an unreliable ranking method i e maximizing set and minimizing set is applied to rank the fuzzy numbers. this paper applies the hsu and chen method and suggests a fuzzy number ranking method to propose an improved fuzzy mcdm model based on ideal and anti ideal concepts to overcome the shortcomings of the liang method. numerical examples demonstrate the effectiveness and feasibility of the proposed ranking method and the improved model respectively.
inspec,train_761,towards a nmr implementation of a quantum lattice gas algorithm. recent theoretical results suggest that an array of quantum information processors communicating via classical channels can be used to solve fluid dynamics problems. quantum lattice gas algorithms qlga running on such architectures have been shown to solve the diffusion equation and the nonlinear burgers equations. in this report we describe progress towards an ensemble nuclear magnetic resonance nmr implementation of a qlga that solves the diffusion equation. the methods rely on nmr techniques to encode an initial mass density into an ensemble of two qubit quantum information processors. using standard pulse techniques the mass density can then manipulated and evolved through the steps of the algorithm. we provide the experimental results of our first attempt to realize the nmr implementation. the results qualitatively follow the ideal simulation but the observed implementation errors highlight the need for improved control.
inspec,train_762,quantum computing with spin qubits in semiconductor structures. we survey recent work on designing and evaluating quantum computing implementations based on nuclear or bound electron spins in semiconductor heterostructures at low temperatures and in high magnetic fields. general overview is followed by a summary of results of our theoretical calculations of decoherence time scales and spin spin interactions. the latter were carried out for systems for which the two dimensional electron gas provides the dominant carrier for spin dynamics via exchange of spin excitons in the integer quantum hall regime.
inspec,train_763,a quantum full adder for a scalable nuclear spin quantum computer. we demonstrate a strategy for implementation a quantum full adder in a spin chain quantum computer. as an example we simulate a quantum full adder in a chain containing 201 spins. our simulations also demonstrate how one can minimize errors generated by non resonant effects.
inspec,train_764,lattice boltzmann schemes for quantum applications. we review the basic ideas behind the quantum lattice boltzmann equation lbe and present a few thoughts on the possible use of such an equation for simulating quantum many body problems on both parallel electronic and quantum computers.
inspec,train_765,simulating fermions on a quantum computer. the real time probabilistic simulation of quantum systems in classical computers is known to be limited by the so called dynamical sign problem a problem leading to exponential complexity. in 1981 richard feynman raised some provocative questions in connection to the exact imitation of such systems using a special device named a quantum computer. feynman hesitated about the possibility of imitating fermion systems using such a device. here we address some of his concerns and in particular investigate the simulation of fermionic systems. we show how quantum computers avoid the sign problem in some cases by reducing the complexity from exponential to polynomial. our demonstration is based upon the use of isomorphisms of algebras. we present specific quantum algorithms that illustrate the main points of our algebraic approach.
inspec,train_766,physical quantum algorithms. i review the differences between classical and quantum systems emphasizing the connection between no hidden variable theorems and superior computational power of quantum computers. using quantum lattice gas automata as examples i describe possibilities for efficient simulation of quantum and classical systems with a quantum computer. i conclude with a list of research directions.
inspec,train_767,quantum computation for physical modeling. one of the most famous american physicists of the twentieth century richard feynman in 1982 was the first to propose using a quantum mechanical computing device to efficiently simulate quantum mechanical many body dynamics a task that is exponentially complex in the number of particles treated and is completely intractable by any classical computing means for large systems of many particles. in the two decades following his work remarkable progress has been made both theoretically and experimentally in the new field of quantum computation.
inspec,train_768,critical lines identification on voltage collapse analysis. this paper deals with critical lines identification on voltage collapse analysis. it is known from the literature that voltage collapse is a local phenomenon that spreads around an initial neighborhood therefore identifying the system critical bus plays an important role on voltage collapse prevention. for this purpose the system critical transmission lines should also be identified in this paper these issues are addressed yielding reliable results in a short computational time. tests are done with the help of the ieee 118 bus and the southeastern brazilian systems.
inspec,train_769,permission grids practical error bounded simplification. we introduce the permission grid a spatial occupancy grid which can be used to guide almost any standard polygonal surface simplification algorithm into generating an approximation with a guaranteed geometric error bound. in particular all points on the approximation are guaranteed to be within some user specified distance from the original surface. such bounds are notably absent from many current simplification methods and are becoming increasingly important for applications in scientific computing and adaptive level of detail control. conceptually simple the permission grid defines a volume in which the approximation must lie and does not permit the underlying simplification algorithm to generate approximations outside the volume. the permission grid makes three important practical improvements over current error bounded simplification methods. first it works on arbitrary triangular models handling all manners of mesh degeneracies gracefully. further the error tolerance may be easily expanded as simplification proceeds allowing the construction of an error bounded level of detail hierarchy with vertex correspondences among all levels of detail. and finally the permission grid has a representation complexity independent of the size of the input model and a small running time overhead making it more practical and efficient than current methods with similar guarantees.
inspec,train_77,modeling frequently accessed wireless data with weak consistency. to reduce the response times of wireless data access in a mobile network caches are utilized in wireless handheld devices. if the original data entry has been updated the cached data in the handheld device becomes stale. thus a mechanism is required to predict when the cached copy will expire. this paper studies a weakly consistent data access mechanism that computes the time to live ttl interval to predict the expiration time. we propose an analytic model to investigate this ttl based algorithm for frequently accessed data. the analytic model is validated against simulation experiments. our study quantitatively indicates how the ttl based algorithm reduces the wireless communication cost by increasing the probability of stale accesses. depending on the requirements of the application appropriate parameter values can be selected based on the guidelines provided.
inspec,train_770,the 3d visibility complex. visibility problems are central to many computer graphics applications. the most common examples include hidden part removal for view computation shadow boundaries mutual visibility of objects for lighting simulation. in this paper we present a theoretical study of 3d visibility properties for scenes of smooth convex objects. we work in the space of light rays or more precisely of maximal free segments. we group segments that see the same object this defines the 3d visibility complex. the boundaries of these groups of segments correspond to the visual events of the scene limits of shadows disappearance of an object when the viewpoint is moved etc. we provide a worst case analysis of the complexity of the visibility complex of 3d scenes as well as a probabilistic study under a simple assumption for normal scenes. we extend the visibility complex to handle temporal visibility. we give an output sensitive construction algorithm and present applications of our approach.
inspec,train_771,pareto optimal formulations for cost versus colorimetric accuracy trade offs in printer color management. color management for the printing of digital images is a challenging task due primarily to nonlinear ink mixing behavior and the presence of redundant solutions for print devices with more than three inks. algorithms for the conversion of image data to printer specific format are typically designed to achieve a single predetermined rendering intent such as colorimetric accuracy. we present two cielab to cmyk color conversion schemes based on a general pareto optimal formulation for printer color management. the schemes operate using a 149 color characterization data set selected to efficiently capture the entire cmyk gamut. the first scheme uses artificial neural networks as transfer functions between the cielab and cmyk spaces. the second scheme is based on a reformulation of tetrahedral interpolation as an optimization problem. characterization data are divided into tetrahedra for the interpolation based approach using the program qhull which removes the common restriction that characterization data be well organized. both schemes offer user control over trade off problems such as cost versus reproduction accuracy allowing for user specified print objectives and the use of constraints such as maximum allowable ink and maximum allowable ae  sub ab. a formulation for minimization of ink is shown to be particularly favorable integrating both a clipping and gamut compression features into a single methodology.
inspec,train_772,meshed atlases for real time procedural solid texturing. we describe an implementation of procedural solid texturing that uses the texture atlas a one to one mapping from an object s surface into its texture space. the method uses the graphics hardware to rasterize the solid texture coordinates as colors directly into the atlas. a texturing procedure is applied per pixel to the texture map replacing each solid texture coordinate with its corresponding procedural solid texture result. the procedural solid texture is then mapped back onto the object surface using standard texture mapping. the implementation renders procedural solid textures in real time and the user can design them interactively. the quality of this technique depends greatly on the layout of the texture atlas. a broad survey of texture atlas schemes is used to develop a set of general purpose mesh atlases and tools for measuring their effectiveness at distributing as many available texture samples as evenly across the surface as possible. the main contribution of this paper is a new multiresolution texture atlas. it distributes all available texture samples in a nearly uniform distribution. this multiresolution texture atlas also supports mip mapped minification antialiasing and linear magnification filtering.
inspec,train_773,topology reducing surface simplification using a discrete solid representation. this paper presents a new approach for generating coarse level approximations of topologically complex models. dramatic topology reduction is achieved by converting a 3d model to and from a volumetric representation. our approach produces valid error bounded models and supports the creation of approximations that do not interpenetrate the original model either being completely contained in the input solid or bounding it. several simple to implement versions of our approach are presented and discussed. we show that these methods perform significantly better than other surface based approaches when simplifying topologically rich models such as scene parts and complex mechanical assemblies.
inspec,train_774,keeping web accessibility in mind i r services for all. after presenting three compelling reasons for making web sites accessible to persons with a broad range of disabilities it s the morally right thing to do it s the smart thing to do from an economic perspective and it s required by law the author discusses design issues that impact persons with particular types of disabilities. she presents practical advice for assessing and addressing accessibility problems. an extensive list of resources for further information is appended as is a list of sites which simulate the impact of specific accessibility problems on persons with disabilities.
inspec,train_775,disability related special libraries. one of the ways that the federal government works to improve services to people with disabilities is to fund disability related information centers and clearinghouses that provide information resources and referrals to disabled individuals their family members service providers and the general public. the teaching research division of western oregon university operates two federally funded information centers for people with disabilities obirn the oregon brain injury resource network and db link the national information clearinghouse on children who are deaf blind. both have developed in depth library collections and services in addition to typical clearinghouse services. the authors describe how obirn and db link were designed and developed and how they are currently structured and maintained. both information centers use many of the same strategies and tools in day to day operations but differ in a number of ways including materials and clientele.
inspec,train_776,information access for all meeting the needs of deaf and hard of hearing people. discusses the nature of deafness and hearing impairments with particular reference to the impact which the onset of hearing loss presents at various ages. the author goes on to present practical tips for interacting with deaf and hard of hearing clients in various communication contexts including sightreading tty communications and asl interpreters. an annotated list of suggested readings is appended.
inspec,train_777,access to information for blind and visually impaired clients. this article guides i r providers in establishing effective communication techniques for working with visually impaired consumers. the authors discuss common causes of vision impairment and the functional implications of each and offer information on disability etiquette and effective voice accessible media and in person communication. there is an overview of assistive technologies used by people who are visually impaired to facilitate written and electronic communications as well as low tech solutions for producing large print and braille materials in house. providers who implement these communication techniques will be well equipped to serve visually impaired consumers and consumers will be more likely to avail themselves of these services when providers make them easily accessible.
inspec,train_778,access matters. discusses accessibility needs of people with disabilities both from the perspective of getting the information from i r programs including accessible web sites tty access braille and other mechanisms and from the perspective of being aware of accessibility needs when referring clients to resources. includes information on ada legislation requiring accessibility to public places and recommends several organizations and web sites for additional information.
inspec,train_779,domesticating computers and the internet. the people who use computers and the ways they use them have changed substantially over the past 25 years. in the beginning highly educated people mostly men in technical professions used computers for work but over time a much broader range of people are using computers for personal and domestic purposes. this trend is still continuing and over a shorter time scale has been replicated with the use of the internet. the paper uses data from four national surveys to document how personal computers and the internet have become increasingly domesticated since 1995 and to explore the mechanisms for this shift. now people log on more often from home than from places of employment and do so for pleasure and for personal purposes rather than for their jobs. analyses comparing veteran internet users to novices in 1998 and 2000 and analyses comparing the change in use within a single sample between 1995 and 1996 support two complementary explanations for how these technologies have become domesticated. women children and less well educated individuals are increasingly using computers and the internet and have a more personal set of motives than well educated men. in addition the widespread diffusion of the pc and the internet and the response of the computing industry to the diversity in consumers has led to a rich set of personal and domestic services.
inspec,train_78,applying genetic algorithms to solve the fuzzy optimal profit problem. this study investigated the application of genetic algorithms in solving a fuzzy optimization problem that arises in business and economics. in this problem a fuzzy price is determined using a linear or a quadratic fuzzy demand function as well as a linear cost function. the objective is to find the optimal fuzzy profit which is derived from the fuzzy price and fuzzy cost. traditional methods for solving this problem are 1 the extension principle and 2 using interval arithmetic and alpha cuts. however we argue that traditional methods for solving this problem are too restrictive to produce an optimal solution and that an alternative approach is possibly needed. we use genetic algorithms to obtain an approximate solution for this fuzzy optimal profit problem without using membership functions. we not only give empirical examples to show the effectiveness of this approach but also give theoretical proofs to validate correctness of the algorithm. we conclude that genetic algorithms can produce good approximate solutions when applied to solve fuzzy optimization problems.
inspec,train_780,failures and successes notes on the development of electronic cash. between 1997 and 2001 two mid sized communities in canada hosted north america s most comprehensive experiment to introduce electronic cash and in the process replace physical cash for casual low value payments. the technology used was mondex and its implementation was supported by all the country s major banks. it was launched with an extensive publicity campaign to promote mondex not only in the domestic but also in the global market for which the canadian implementation was to serve as a showcase. however soon after the start of the first field test it became apparent that the new technology did not work smoothly. on the contrary it created a host of controversies in areas as varied as computer security consumer privacy and monetary policy. in the following years few of these controversies could be resolved and mondex could not be established as a widely used payment mechanism. in 2001 the experiment was finally terminated. using the concepts developed in recent science and technology studies sts the article analyzes these controversies as resulting from the difficulties of fitting electronic cash a new sociotechnical system into the complex setting of the existing payment system. the story of mondex not only offers lessons on why technologies fail but also offers insight into how short term failures can contribute to long term transformations. this suggests the need to rethink the dichotomy of success and failure.
inspec,train_781,icann and internet governance leveraging technical coordination to realize global public policy. the internet corporation for assigned names and numbers icann was created in 1998 to perform technical coordination of the internet. icann also lays the foundations for governance creating capabilities for promulgating and enforcing global regulations on internet use. icann leverages the capabilities in the internet domain name system dns to implement four mechanisms of governance authority law sanctions and jurisdictions. these governance related features are embodied in seemingly technical features of icann s institutional design. recognition of icann s governance mechanisms allows us to better understand the internet s emerging regulatory regime.
inspec,train_782,community technology and democratic rationalization. the objective of the paper is to explore questions of human agency and democratic process in the technical sphere through the example of virtual community. the formation of relatively stable long term group associations community in the broad sense of the term is the scene on which a large share of human development occurs. as such it is a fundamental human value mobilizing diverse ideologies and sensitivities. the promise of realizing this value in a new domain naturally stirs up much excitement among optimistic observers of the internet. at the same time the eagerness to place hopes for community in a technical system flies in the face of an influential intellectual tradition of technology criticism. this eagerness seems even more naive in the light of the recent commercialization of so much internet activity. despite the widespread skepticism we believe the growth of virtual community is significant for an inquiry into the democratization of technology. we show that conflicting answers to the central question of the present theoretical debate is community possible on computer networks. epsilon neralize from particular features of systems and software prevalent at different stages in the development of computer networking. we conclude that research should focus instead on how to design computer networks to better support community activities and values.
inspec,train_783,the network society as seen from italy. italy was behind the european average in internet development for many years but a new trend which has brought considerable change emerged at the end of 1998 and showed its effects in 2000 and the following years. now italy is one of the top ten countries worldwide in internet hostcount and the fourth largest in europe. the density of internet activity in italy in proportion to the population is still below the average in the european union but is growing faster than germany the uk and france and faster than the worldwide or european average. from the point of view of media control there are several problems. italy has democratic institutions and freedom of speech but there is an alarming concentration in the control of mainstream media especially broadcast. there are no officially declared restrictions in the use of the internet but several legal and regulatory decisions reveal a desire to limit freedom of opinion and dialogue and or gain centralized control of the net.
inspec,train_784,where tech is cheap servers. talk consultancy support not tech is the expensive part of network installations. it s a good job that small scale servers can either be remotely managed or require little actual management.
inspec,train_785,networking without wires. several types of devices use radio transmitters to send data over thin air. are wlans wireless local area networks the end to all cables. will dalrymple weighs up the costs and benefits.
inspec,train_787,new kit on the block it upgrades. as time passes new hardware and software replace the old. the hows are straightforward it resellers and consultants can help with upgrade practicalities. will dalrymple examines the business issues and costs involved in it upgrades.
inspec,train_788,rise of the supercompany crm. all the thoughts conversations and notes of employees help the firm create a wider picture of business. customer relationship management crm feeds on data and it is hungry.
inspec,train_79,an efficient and stable ray tracing algorithm for parametric surfaces. in this paper we propose an efficient and stable algorithm for finding ray surface intersections. newton s method and bezier clipping are adapted to form the core of our algorithm. ray coherence is used to find starting points for newton iteration. we introduce an obstruction detection technique to verify whether an intersection point found using newton s method is the closest. when newton s method fails to achieve convergence we use bezier clipping substitution to find the intersection points. this combination achieves a significant improvement in tracing primary rays. a similar approach successfully improves the performance of tracing secondary rays.
inspec,train_790,data assimilation of local model error forecasts in a deterministic model. one of the most popular data assimilation techniques in use today are of the kalman filter type which provide an improved estimate of the state of a system up to the current time level based on actual measurements. from a forecasting viewpoint this corresponds to an updating of the initial conditions. the standard forecasting procedure is to then run the model uncorrected into the future driven by predicted boundary and forcing conditions. the problem with this methodology is that the updated initial conditions quickly wash out  thus after a certain forecast horizon the model predictions are no better than from an initially uncorrected model. this study demonstrates that through the assimilation of error forecasts in the present case made using so called local models entire model domains can be corrected for extended forecast horizons i e long after updated initial conditions have become washed out thus demonstrating significant improvements over the conventional methodology. some alternate uses of local models are also explored for the re distribution of error forecasts over the entire model domain which are then compared with more conventional kalman filter type schemes.
inspec,train_791,the rise and fall and rise again of customer care. taking care of customers has never gone out of style but as the recession fades interest is picking up in a significant retooling of the crm solutions banks have been using. the goal usable knowledge to help improve service.
inspec,train_792,remember e commerce. yeah well it s still here. sandy kemper the always outspoken ceo of successful e commerce company escout offers his views on the purported demise of commerce in e commerce and what opportunities lie ahead for those bankers bold enough to act in a market turned tentative by early excesses.
inspec,train_793,advancements during the past quarter century in on line monitoring of motor and generator winding insulation. electrical insulation plays a critical role in the operation of motor and generator rotor and stator windings. premature failure of the insulation can cost millions of dollars per day. with advancements in electronics sensors computers and software tremendous progress has been made in the past 25 yr which has transformed on line insulation monitoring from a rarely used and expensive tool to the point where 50 of large utility generators in north america are now equipped for such monitoring. this review paper outlines the motivation for online monitoring discusses the transition to today s technology and describes the variety of methods now in use for rotor winding and stator winding monitoring.
inspec,train_794,on the discretization of double bracket flows. this paper extends the method of magnus series to lie algebraic equations originating in double bracket flows. we show that the solution of the isospectral flow y  y n y y o y sub 0 in sym n can be represented in the form y t e sup omega t y sub 0 e sup omega 1  where the taylor expansion of omega can be constructed explicitly term by term identifying individual expansion terms with certain rooted trees with bicolor leaves. this approach is extended to other lie algebraic equations that can be appropriately expressed in terms of a finite alphabet.
inspec,train_795,approximation and complexity. ii. iterated integration. for pt. i see ibid no 1 p 289 95 2001. we introduce two classes of real analytic functions w contained in implied by u on an interval. starting with rational functions to construct functions in w we allow the application of three types of operations addition integration and multiplication by a polynomial with rational coefficients. in a similar way to construct functions in u we allow integration addition and multiplication of functions already constructed in u and multiplication by rational numbers. thus u is a subring of the ring of pfaffian functions. two lower bounds on the l sub infinity  norm are proved on a function f from w or from u respectively in terms of the complexity of constructing f.
inspec,train_796,quadratic newton iteration for systems with multiplicity. newton s iterator is one of the most popular components of polynomial equation system solvers either from the numeric or symbolic point of view. this iterator usually handles smooth situations only when the jacobian matrix associated to the system is invertible. this is often a restrictive factor. generalizing newton s iterator is still an open problem how to design an efficient iterator with a quadratic convergence even in degenerate cases. we propose an answer for an m adic topology when the ideal m can be chosen generic enough compared to a smooth case we prove quadratic convergence with a small overhead that grows with the square of the multiplicity of the root.
inspec,train_797,adaptive wavelet methods. ii. beyond the elliptic case. this paper is concerned with the design and analysis of adaptive wavelet methods for systems of operator equations. its main accomplishment is to extend the range of applicability of the adaptive wavelet based method developed previously for symmetric positive definite problems to indefinite or unsymmetric systems of operator equations. this is accomplished by first introducing techniques such as the least squares formulation developed previously that transform the original continuous problem into an equivalent infinite system of equations which is now well posed in the euclidean metric. it is then shown how to utilize adaptive techniques to solve the resulting infinite system of equations. it is shown that for a wide range of problems this new adaptive method performs with asymptotically optimal complexity i e it recovers an approximate solution with desired accuracy at a computational expense that stays proportional to the number of terms in a corresponding wavelet best n term approximation. an important advantage of this adaptive approach is that it automatically stabilizes the numerical procedure so that for instance compatibility constraints on the choice of trial spaces like the lbb condition no longer arise.
inspec,train_798,clioweb cliorequest and clio database enhancing patron and staff satisfaction. faced with increased demand from students and faculty for a speedier and more user friendly method of obtaining materials from other institutions the interlibrary loan ill department sought to implement a management system which would accomplish the task. students wanted remote interconnectivity to the system and staff wanted increased workflow efficiency reduced paper work and better data management. this paper focuses on washington college s experience in selecting and implementing an interlibrary loan system which would enhance student satisfaction as well as that of the library staff.
inspec,train_799,electronic reserves at university college london understanding the needs of academic departments. this article describes a recent project at university college london to explore the feasibility of providing a service to improve access to electronic course materials. funded by the higher education funding council for england hefce the project was not simply to set up an electronic reserve. by undertaking a needs analysis of academic departments the project was able to tailor the design of the new service appropriately. while new initiatives in libraries are often established using project funding this work was unique in being research led. it also involved collaboration between library and computing staff and learning technologists.
inspec,train_8,new investors get steal of a deal global crossing. hutchison telecommunications and singapore technologies take control of global crossing for a lot less money than they originally offered. the deal leaves the bankrupt carrier intact but does n t put it in the clear just yet.
inspec,train_80,evaluating the performance of a distributed database of repetitive elements in complete genomes. the original version of the repeat sequence database rsdb was created based on centralized database systems cdbss. rsdb presently includes an enormous amount of data with the amount of biological data increasing rapidly. distributed rsdb drsdb is developed to yield better performance. this study proposed many approaches to data distribution and experimentally determines the best approach to obtain good performance of our database. experimental results indicate that drsdb performs well for particular types of query.
inspec,train_800,a model for choosing an electronic reserves system a pre implementation study at the library of long island university s brooklyn campus. this study explores the nature of electronic reserves e reserves and investigates the possibilities of implementing the e reserves at the long island university brooklyn campus library liu bcl.
inspec,train_801,international customers suppliers and document delivery in a fee based information service. the purdue university libraries library fee based information service the technical information service tis works with both international customers and international suppliers to meet its customers needs for difficult and esoteric document requests. successful completion of these orders requires the ability to verify fragmentary citations ascertain documents availability obtain pricing information calculate inclusive cost quotes meet customers deadlines accept international payments and ship across borders. while international orders make tip a small percent of the total workload these challenging and rewarding orders meet customers needs and offer continuous improvement opportunities to the staff.
inspec,train_802,a brief history of electronic reserves. electronic reserves has existed as a library service for barely ten years yet its history however brief is important as an indicator of the direction being taken by the profession of librarianship as a whole. recent improvements in technology and a desire to provide better service to students and faculty have resulted in the implementation of e reserves by ever greater numbers of academic libraries. yet a great deal of confusion still surrounds the issue of copyright compliance. negotiation litigation and legislation in particular have framed the debate over the application of fair use to an e reserves environment and the question of whether or not permission fees should be paid to rights holders but as of yet no definitive answers or standards have emerged.
inspec,train_803,the mutual effects of grid and wind turbine voltage stability control. this note considers the results of wind turbine modelling and power system stability investigations. voltage stability of the power grid with grid connected wind turbines will be improved by using blade angle control for a temporary reduction of the wind turbine power during and shortly after a short circuit fault in the grid.
inspec,train_804,voltage control methods with grid connected wind turbines a tutorial review. within electricity grid networks it is conventional for large scale central generators to both provide power and control grid node voltage. therefore when wind turbines replace conventional power stations on a substantial scale they must not only generate power but also control grid node voltages. this paper reviews the basic principles of voltage control for tutorial benefit and then considers application of grid connected wind turbines for voltage control. the most widely used contemporary wind turbine types are considered and further detail is given for determining the range of variables that allow control.
inspec,train_805,active pitch control in larger scale fixed speed horizontal axis wind turbine systems. i linear controller design. this paper reviews and addresses the principles of linear controller design of the fixed speed wind turbine system in above rated wind speed using pitch angle control of the blades and applying modern control theory. first the nonlinear equations of the system are built in under some reasonable suppositions. then the nonlinear equations are linearised at set operating point and digital simulation results are shown in this paper. finally a linear quadratic optimal feedback controller is designed and the dynamics of the closed circle system are simulated with digital calculation. the advantages and disadvantages of the assumptions and design method are also discussed. because of the inherent characteristics of the linear system control theory the performance of the linear controller is not sufficient for operating wind turbines as is discussed.
inspec,train_806,flow measurement future directions. interest in the flow of liquids and its measurement can be traced back to early studies by the egyptians the chinese and the romans. since these early times the science of flow measurement has undergone a massive change but during the last 25 years or so 1977 2002 it has matured enormously. one of the principal reasons for this is that higher accuracies and reliabilities have been demanded by industry in the measurement of fiscal transfers and today there is vigorous interest in the subject from both the flowmeter manufacturer and user viewpoints. this interest is coupled with the development of advanced computer techniques in fluid mechanics together with the application of increasingly sophisticated electronics.
inspec,train_807,integrated optical metrology controls post etch cds. control of the transistor gate critical dimension cd on the order of a few nanometers is a top priority in many advanced ic fabs. each nanometer deviation from the target gate length translates directly into the operational speed of these devices. however using in line process control by linking the lithography and etch tools can improve cd performance beyond what each individual tool can achieve. the integration of optical cd metrology tools to etch mainframes can result in excellent etcher stability and better control of post etch cds.
inspec,train_808,a novel control logic for fast valving operations. this letter proposes new control logic for operating parallel valves in fast valving schemes in order to improve the transient stability performance of power systems. a fast valving scheme using parallel valves overcomes many of the limitations of the conventional scheme. the proposed control logic for operating these valves has been applied to a typical single machine infinite bus system. single as well as multiple stroke operations for controlling the turbine power output have been studied with the new control sequences. encouraging results have been shown over the conventional schemes of fast valving.
inspec,train_809,edison s direct current influenced broadway show lighting. during the early decades of the 20 th century midtown manhattan in new york city developed an extensive underground direct current dc power distribution system. this was a result of the original introduction of direct current by thomas edison s pioneering pearl street station in 1882. the availability of dc power in the theater district led to the perpetuation of an archaic form of stage lighting control through nearly three quarters of the 20 th century. this control device was known as a resistance dimmer. it was essentially a series connected rheostat but it was wound with a special resistance taper so as to provide a uniform change in the apparent light output of typical incandescent lamps throughout the travel of its manually operated arm. the development and use of dc powered stage lighting is discussed in this article.
inspec,train_81,a scalable and efficient systolic algorithm for the longest common subsequence problem. a longest common subsequence lcs of two strings is a common subsequence of two strings of maximal length. the lcs problem is that of finding an lcs of two given strings and the length of the lcs. this problem has been the subject of much research because its solution can be applied in many areas. in this paper a scalable and efficient systolic algorithm is presented. for two given strings of length m and n where m or n the algorithm can solve the lcs problem in m 2 r 1 respectively n 2 r 1 time steps with r n 2 respectively r m 2 processors. experimental results show that the algorithm can be faster on multicomputers than all the previous systolic algorithms for the same problem.
inspec,train_810,oracle s suite grows up. once a low cost web offering oracle s small business suite now carries a price tag to justify var interest.
inspec,train_811,integration the web are key this season tax. integration and the web are driving many of the enhancements planned by tax preparation software vendors for this coming season.
inspec,train_812,eleaders make the web work. some companies are making the most of back office web integration. here are some winners.
inspec,train_813,on generalized gaussian quadratures for exponentials and their applications. we introduce new families of gaussian type quadratures for weighted integrals of exponential functions and consider their applications to integration and interpolation of bandlimited functions. we use a generalization of a representation theorem due to caratheodory to derive these quadratures. for each positive measure the quadratures are parameterized by eigenvalues of the toeplitz matrix constructed from the trigonometric moments of the measure. for a given accuracy epsilon selecting an eigenvalue close to epsilon yields an approximate quadrature with that accuracy. to compute its weights and nodes we present a new fast algorithm. these new quadratures can be used to approximate and integrate bandlimited functions such as prolate spheroidal wave functions and essentially bandlimited functions such as bessel functions. we also develop for a given precision an interpolating basis for bandlimited functions on an interval.
inspec,train_814,a framework for image deblurring using wavelet packet bases. we show that the average over translations of an operator diagonal in a wavelet packet basis is a convolution. we also show that an operator diagonal in a wavelet packet basis can be decomposed into several operators of the same kind each of them being better conditioned. we investigate the possibility of using such a convolution to approximate a given convolution in practice an image blur. then we use these approximations to deblur images. first we show that this framework permits us to redefine existing deblurring methods. then we show that it permits us to define a new variational method which combines the wavelet packet and the total variation approaches. we argue and show by experiments that this permits us to avoid the drawbacks of both approaches which are respectively ringing and staircasing.
inspec,train_815,the canonical dual frame of a wavelet frame. we show that there exist wavelet frames that have nice dual wavelet frames but for which the canonical dual frame does not consist of wavelets i e can not be generated by the translates and dilates of a single function.
inspec,train_816,accelerating filtering techniques for numeric csps. search algorithms for solving numeric csps constraint satisfaction problems make an extensive use of filtering techniques. in this paper we show how those filtering techniques can be accelerated by discovering and exploiting some regularities during the filtering process. two kinds of regularities are discussed cyclic phenomena in the propagation queue and numeric regularities of the domains of the variables. we also present in this paper an attempt to unify numeric csps solving methods from two distinct communities that of csp in artificial intelligence and that of interval analysis.
inspec,train_817,summarization beyond sentence extraction a probabilistic approach to sentence compression. when humans produce summaries of documents they do not simply extract sentences and concatenate them. rather they create new sentences that are grammatical that cohere with one another and that capture the most salient pieces of information in the original document. given that large collections of text abstract pairs are available online it is now possible to envision algorithms that are trained to mimic this process. in this paper we focus on sentence compression a simpler version of this larger challenge. we aim to achieve two goals simultaneously our compressions should be grammatical and they should retain the most important pieces of information. these two goals can conflict. we devise both a noisy channel and a decision tree approach to the problem and we evaluate results against manual compressions and a simple baseline.
inspec,train_818,clausal resolution in a logic of rational agency. a resolution based proof system for a temporal logic of possible belief is presented. this logic is the combination of the branching time temporal logic ctl representing change over time with the modal logic kd45 representing belief. such combinations of temporal or dynamic logics and modal logics are useful for specifying complex properties of multi agent systems. proof methods are important for developing verification techniques for these complex multi modal logics. soundness completeness and termination of the proof method are shown and simple examples illustrating its use are given.
inspec,train_819,local search with constraint propagation and conflict based heuristics. search algorithms for solving csp constraint satisfaction problems usually fall into one of two main families local search algorithms and systematic algorithms. both families have their advantages. designing hybrid approaches seems promising since those advantages may be combined into a single approach. in this paper we present a new hybrid technique. it performs a local search over partial assignments instead of complete assignments and uses filtering techniques and conflict based techniques to efficiently guide the search. this new technique benefits from both classical approaches a priori pruning of the search space from filtering based search and possible repair of early mistakes from local search. we focus on a specific version of this technique tabu decision repair. experiments done on open shop scheduling problems show that our approach competes well with the best highly specialized algorithms.
inspec,train_82,bit serial ab sup 2 multiplier using modified inner product. this paper presents a new multiplication algorithm and based on this algorithm proposes a hardware architecture called modified inner product multiplier mipm which computes ab sup 2 multiplication based on a linear feedback shift register lfsr. the algorithm is based on the property of the irreducible all one polynomial aop over the finite field gf 2 sup m. the proposed architecture reduces the time and space complexity for computing ab sup 2. the proposed architecture has a potential application to implementing exponentiation architecture for a public key cryptosystem.
inspec,train_820,yet some more complexity results for default logic. we identify several new tractable subsets and several new intractable simple cases for reasoning in the propositional version of reiter s default logic. the majority of our findings are related to brave reasoning. by making some intuitive observations most classes that we identify can be derived quite easily from some subsets of default logic already known in the literature. some of the subsets we discuss are subclasses of the so called extended logic programs. all the tractable subsets presented in this paper can be recognized in linear time.
inspec,train_821,digital rights and wrongs. attempting to grasp the many conflicts and proposed safeguards for intellectual property is extremely difficult. legal political economic and cultural issues both domestic and international loom large almost dwarfing the daunting technological challenges. solutions devised by courts and legislatures and regulatory agencies are always late out of the blocks and fall ever farther behind. recently proposed legislation only illustrates the depth and complexity of the problem.
inspec,train_822,reinventing broadband. many believe that broadband providers need to change their whole approach. the future then is in reinventing broadband. that means tiered pricing to make broadband more competitive with dial up access and livelier more distinct content video on demand mp3 and other features exclusive to the fat pipe superhighway.
inspec,train_823,estimation of thermal coefficients of magneto optical media. previously we described a method for estimating the thermal conductivity of magneto optic recording media. the method relies on identifying the laser power that brings the maximum temperature of the tbfeco layer to as high as the curie temperature. we extensively use a similar method to estimate the heat capacity of a dielectric layer a tbfeco layer and an aluminum alloy layer of magneto optic recording media. measurements are conducted on static disks with a beam of light focused on a tbfeco layer. the method has the advantage of thermal diffusion depending on a multilayer structure and irradiation time.
inspec,train_824,the internet knowledge and the academy. as knowledge is released from the bounds of libraries as research becomes no longer confined to the academy and education certification is available any time any place the university and the faculty must redefine themselves. liberal studies once the core and currently eschewed in favor of science and technology will be reborn in those institutions that can rise above the mundane and embrace an emerging third culture.
inspec,train_825,genetic algorithm neural network estimation of cobb angle from torso asymmetry in scoliosis. scoliosis severity measured by the cobb angle was estimated by artificial neural network from indices of torso surface asymmetry using a genetic algorithm to select the optimal set of input torso indices. estimates of the cobb angle were accurate within 5 degrees in two thirds and within 10 degrees in six sevenths of a test set of 115 scans of 48 scoliosis patients showing promise for future longitudinal studies to detect scoliosis progression without use of x rays.
inspec,train_826,a round of cash a pound of flesh telecom. despite the upheaval across telecom venture capital firms are still investing in start ups. but while a promising idea and a catchy name were enough to guarantee millions in funding at the peak of the dotcom frenzy now start ups must prove their long term viability and be willing to concede control of their business to their vc suitors.
inspec,train_827,williams nears end of chapter 11 telecom. leucadia national corp comes through with a 330 million boost for williams communications which should keep the carrier afloat through the remainder of its bankruptcy.
inspec,train_828,verizon leapfrogs sprint pcs with q2 subscriber numbers. the wireless carrier industry s second quarter results showed a surprising shift in market share as sprint pcs fell from grace after a nearly four year lead in subscriber additions and verizon wireless added considerably more customers than analysts expected.
inspec,train_829,santera targets independents in major strategy overhaul telecom. with big carriers slashing capital expense budgets santera systems is broadening the reach of its next generation switching platform to include independent telcos. this week the vendor will announce that it has signed a deal with kerman calif based kerman telephone co. furthermore the company is angling for inclusion in the rural utilities service s approved equipment list hoping to sell its class 5 replacement boxes to the smallest carriers. the move is almost a complete reversal for the plano texas based vendor which previously focused solely on large carriers including the rbocs.
inspec,train_83,a distributed mobile agent framework for maintaining persistent distance education. mobile agent techniques involve distributed control if communication is required among different types of agents especially when mobile agents can migrate from station to station. this technique can be implemented in a distributed distance learning environment which allows students or instructors to login from anywhere to a central server in an education center while still retaining the look and feel of personal setups. in this research paper we propose a distributed agent framework along with its communication messages to facilitate mobile personal agents which serve three different groups of distance education users instructors students and system administrators. we propose an agent communication framework as well as agent evolution states of mobile agents. the communication architecture and message transmission protocols are illustrated. the system is implemented on the windows platform to support nomadic accessibility of remote distance learning users. personal data also migrate with the mobile agents allowing users to maintain accessibility to some extent even when the internet connection is temperately disconnected. using user friendly personal agents a distance education platform can include different tools to meet different needs for users.
inspec,train_830,the real story behind calpoint telecom. a former qwest executive sheds light on the carrier s controversial deal with calpoint. discusses why calpoint gets a monthly check from quest regardless of whether it provides services.
inspec,train_831,software vendors failure fuels consolidation theories telecom interconnection and billing. as independent software vendors like ap engines fall by the wayside as independent entities attrition could accelerate consolidation in the oss space.
inspec,train_832,senate to powell regulate more fcc. fcc chairman michael powell pitched a six step market based recovery plan to the senate last week but two members of the commerce committee told him telecom s revival requires more reliance on regulation.
inspec,train_833,packet promises past present ip switching. with the death of the competitive carrier market and the significant slashing of rboc capex budgets softswitch vendors have been forced to retrench. now instead of focusing primarily on limited internet off load applications packet based softswitches are set to gel around real user needs for services such as voice over ip and ip centrex.
inspec,train_834,commerce department plan eases 3g spectrum crunch. the federal government made its first move last week toward cleaning up a spectrum allocation system that was in shambles just a year ago and had some spectrum starved wireless carriers fearing they would n t be able to compete in third generation services. the move however is far from complete and leaves numerous details unsettled.
inspec,train_835,pioneering women in computer science. although their contributions are not well documented women have played an important role in the development of computer science. a survey of women pioneers demonstrates their influence in designing and programming the first electronic computers and languages while laying the groundwork for women s expanding involvement in science.
inspec,train_836,recruitment and retention of women graduate students in computer science and engineering results of a workshop organized by the computing research association. this document is the report of a workshop that convened a group of experts to discuss the recruitment and retention of women in computer science and engineering cse graduate programs. participants included long time members of the cse academic and research communities social scientists engaged in relevant research and directors of successful retention efforts. the report is a compendium of the experience and expertise of workshop participants rather than the result of a full scale scholarly study into the range of issues. its goal is to provide departments with practical advice on recruitment and retention in the form of a set of specific recommendations.
inspec,train_837,ten suggestions for a gender equitable cs classroom. though considerable attention has been paid to the creation of a nurturing environment for women in the field of computer science proposed solutions have primarily focused on activities outside of the classroom. this paper presents a list of suggestions for modifications to both the pedagogy and content of cs courses designed to make the cs classroom environment more inviting for women students.
inspec,train_838,pool halls chips and war games women in the culture of computing. computers are becoming ubiquitous in our society and they offer superb opportunities for people in jobs and everyday life. but there is a noticeable sex difference in use of computers among children. this article asks why computers are more attractive to boys than to girls and offers a cultural framework for explaining the apparent sex differences. although the data are fragmentary the world of computing seems to be more consistent with male adolescent culture than with feminine values and goals. furthermore both arcade and educational software is designed with boys in mind. these observations lead us to speculate that computing is neither inherently difficult nor uninteresting to girls but rather that computer games and other software might have to be designed differently for girls. programs to help teachers instill computer efficacy in all children also need to be developed.
inspec,train_839,women in computing what brings them to it what keeps them in it. career stereotyping and misperceptions about the nature of computing are substantive reasons for the under representation of women in professional computing careers. in this study 15 women who have work experience in several aspects of computing were asked about their reasons for entering computing what they liked about working in computing and what they disliked. while there are many common threads there are also individual differences. common reasons for choosing computing as a career included exposure to computing in a setting which enabled them to see the versatility of computers the influence of someone close to them personal abilities which they perceived to be appropriate for a career in computing and characteristics of such careers which appealed to them. generally women working in the field enjoy the work they are doing. dislikes arising from their work experiences are more likely to be associated with people and politics than with the work they do and they would like to have more female colleagues.
inspec,train_84,efficient cellular automata based versatile multiplier for gf 2 sup m. in this paper a low complexity programmable cellular automata pca based versatile modular multiplier in gf 2 sup m is presented. the proposed versatile multiplier increases flexibility by using the same multiplier in different security environments and it reduces the user s cost. moreover the multiplier can be easily extended to high order of m for more security and low cost serial implementation is feasible in restricted computing environments such as smart cards and wireless devices.
inspec,train_840,gender benders women in computing profession. as a minority in the upper levels of the computing profession women are sometimes mistreated through ignorance or malice. some women have learned to respond with wit and panache.
inspec,train_841,becoming a computer scientist. the focus of this report is pipeline shrinkage for women in computer science. we describe the situation for women at all stages of training in computer science from the precollege level through graduate school. because many of the problems discussed are related to the lack of role models for women who are in the process of becoming computer scientists we also concern ourselves with the status of women faculty members. we not only describe the problems but also make specific recommendations for change and encourage further study of those problems whose solutions are not yet well understood.
inspec,train_842,the incredible shrinking pipeline. we look at the harsh facts concerning the percentage of degrees awarded in cs to women. we study the trend of degrees awarded in cs since 1980 and compare the trend in cs to other science and engineering disciplines. we consider the relationship between the percentage of degrees awarded to women by a cs department and the college the cs department is within. we find that cs departments in engineering colleges graduate on average proportionately fewer women than cs departments in non engineering colleges. we request that the community respond to the facts and speculations presented in this article.
inspec,train_843,an acm w literature review on women in computing. the pipeline shrinkage problem for women in computer science is a well known and documented phenomenon where the ratio of women to men involved in computing shrinks dramatically from early student years to working years. during the last decade considerable research ensued to understand the reasons behind the existence of the shrinking pipeline and in some cases to take action to increase the numbers of women in computing. through the work of a national science foundation funded project acm s committee on women in computing acm w has taken a first step towards pulling this research together. a large number of articles was gathered and processed on the topic of women in computing and the shrinking pipeline. the committee created a publicly available online database to organize the references of this body of work by topic author and reference information. the database constantly being updated is accessible through acm w s website http www acm org women. a final report is also available via the acm w web site which covers current statistics on women in computing summaries of the literature in the database and a set of recommendations. the article is a brief synopsis of a subset of the literature review as of august 2001.
inspec,train_844,women in computing history. exciting inventions innovative technology human interaction and intriguing politics fill computing history. however the recorded history is mainly composed of male achievements and involvements even though women have played substantial roles. this situation is not unusual. most science fields are notorious for excluding undervaluing or overlooking the accomplishments of their female scientists. as lee points out it is up to the historians and others to remedy this imbalance. steps have been taken towards this goal through publishing biographies on women in technology and through honoring the pioneers with various awards such as the ghc 97 pioneering awards the witi hall of fame and the awc lovelace award. a few online sites contain biographies of women in technology. however even with these resources many women who have contributed significantly to computer science are still to be discovered.
inspec,train_845,gender software design and occupational equity. after reviewing the work on gender bias in software design a model of gender role influenced achievement choice taken from eccles 1994 is presented. the paper concludes that 1 though laudable reduction of gender bias in software design is not the most straightforward way to reduce gender inequity in the choice of computing as a career 2 the model itself makes more clear some of the ethical issues involved in attempting to achieve gender equity on computing and 3 efforts to reduce gender inequity in the choice of computing as a career need to be evaluated in the light of this model.
inspec,train_846,female computer science doctorates what does the survey of earned doctorates reveal. based on the national center for education statistics 2000 in the 1997 1998 academic year 26 7 of earned bachelors degrees 29 0 of earned masters degrees and 16 3 of earned doctorates degrees in computer science were awarded to women. as these percentages suggest women are underrepresented at all academic levels in computer science camp 1997. the most severe shortage occurs at the top level the doctorate in computer science. we know very little about the women who persist to the top level of academic achievement in computer science. this paper examines a subset of data collected through the survey of earned doctorates sed. the specific focus of this paper is to identify trends that have emerged from the sed with respect to females completing doctorates in computer science between the academic years 1990 1991 and 1999 2000. although computer science doctorates include doctorates in information science prior research camp 1997 suggests that the percentage of women completing doctorates in information science as compared to computer science is low. the specific research questions are 1. how does the percentage of women who complete doctorates in computer science compare to those that complete doctorates in other fields. 2. how does the length of time in school and the sources of funding differ for females as compared to males who complete doctorates in computer science. 3. where do women go after completing doctorates in computer science and what positions do they acquire. how do these experiences differ from their male peers.
inspec,train_847,a gendered view of computer professionals preliminary results of a survey. the under representation of women in the computing profession in many parts the western world has received our attention through numerous publications the noticeable low representation of women at computer science conferences and in the lecture halls. over the past two decades the situation had become worse. this paper seeks to add to the dialogue by presenting preliminary findings from a research project conducted in four countries. the aim of this research was to gain an insight into the perceptions future computer professionals hold on the category of employment loosely defined under the term of a computer professional. one goal was to get insight into whether or not there is a difference between female and mate students regarding their view of computer professionals. other goals were to determine if there was any difference between female and male students in different parts of the world as well as who or what most influences the students to undertake their courses in computing.
inspec,train_848,women in computing around the world. this paper describes the participation of women in computing in more than 30 countries by focussing on participation at undergraduate level. a brief discussion covers how societal and cultural factors may affect women s participation. statistics from many different sources are presented for comparison. generally participation is low most countries fall in the 10 40 range with a few below 10 and a few above 40.
inspec,train_849,ten years of strategies to increase participation of women in computing programs. the central queensland university experience 1999 2001. in the late eighties the participation rate of women in information technology courses in most australian universities was around 25. this low level of women s participation in computing courses occurs not only in australia but also overseas. more studies indicate that the participation rates have not improved and in fact may be even further in decline. participation rates in the workforce also appear to be in decline. concerned at the imbalance within australia the federal government directed all australian universities to increase the number of women in courses leading to a professional computing qualification i e information technology courses to 40 of students by 1995. this paper details one australian university s approach over a 10 year period 1991 2001 to redress this imbalance. we provide examples of intervention strategies developed and the outcomes for these strategies. we present the outcomes against a background frame of the australian higher education scene of that decade which was influenced by funding levels to universities in general and to equity programs in particular. we present data related to the participation of women in computing programs along with snapshots of the overall changing student demographics over this period.
inspec,train_85,strategic implementation of it is projects in construction a case study. the need for improved implementation of information technology it and information systems is has been emphasised in both empirical and prescriptive research studies. this problem is magnified in the construction industry which has been slow to embrace and utilise new technologies with negative consequences on productivity and innovation. this paper presents a strategic implementation framework for it is projects in construction. the framework builds upon recent published works and encompasses well documented predictors for effective it is implementation. a case study with a large multi national construction organisation is used to demonstrate the strategic implementation of a project management information system pmis used for the construction of a mobile phone telecommunications network in the south east of queensland australia.
inspec,train_850,encouraging women in computer science. at a cost to both their own opportunities and society s ability to produce people with much needed technical skills women continue to be underrepresented in computer science degree programs at both the undergraduate and graduate level. although some of the barriers that women face have their foundations in cultural expectations established well before the college level we believe that departments can take effective steps to increase recruitment and retention of women students. this paper describes several strategies we have adopted at stanford over the past decade.
inspec,train_851,unlocking the clubhouse the carnegie mellon experience. in the fall of 1995 just seven of 95 students entering the undergraduate program in computer science at carnegie mellon university were women. in 2000 54 of 130 or 42  were women. what happened. this article presents a brief history of the transformation at carnegie mellon s school of computer science and the research project that lay behind it.
inspec,train_852,building an effective computer science student organization the carnegie mellon women scs action plan. this paper aims to provide a practical guide for building a student organization and designing activities and events that can encourage and support a community of women in computer science. this guide is based on our experience in building women scs a community of women in the school of computer science scs at carnegie mellon university. rather than provide an abstract to do or must do list we present a sampling of concrete activities and events in the hope that these might suggest possibilities for a likeminded student organization. however since we have found it essential to have a core group of activist students at the helm we provide a to do list of features that we feel are essential for forming supporting and sustaining creative and effective student leadership.
inspec,train_853,virtual development center. the virtual development center of the institute for women and technology seeks to significantly enhance the impact of women on technology. it addresses this goal by increasing the number of women who have input on created technology enhancing the ways people teach and develop technology and developing need based technology that serves the community. through activities of the virtual development center a pattern is emerging regarding how computing technologies do or do not satisfy the needs of community groups particularly those communities serving women. this paper describes the virtual development center program and offers observations on the impact of computing technology on non technical communities.
inspec,train_854,a conference s impact on undergraduate female students. in september of 2000 the 3rd grace hopper celebration of women in computing was held in cape cod massachusetts. along with a colleague from a nearby university we accompanied seven of our female undergraduate students to this conference. this paper reports on how the conference experience immediately affected these students what impressed them what scared them what it clarified for them. it also reports on how the context in which these students currently evaluate their ability potential and opportunity in computer science is different now from what it was before the conference. hopefully by understanding their experience we can gain some insight into things we can do for all of our undergraduate female students to better support their computer science and engineering education.
inspec,train_855,support communities for women in computing. this article highlights the many activities provided by the support communities available for women in computing. thousands of women actively participate in these programs and they receive many benefits including networking and professional support. in addition the organizations and associations help promote the accomplishments of women computer scientists and disseminate valuable information. this article surveys some of these organizations and concludes with a list of suggestions for how faculty members can incorporate the benefits of these organizations in their own institutions.
inspec,train_856,people who make a difference mentors and role models. the literature of gender issues in computing steadfastly and uniformly has advocated the use of mentors and role models m rm for recruiting and retaining women in computer science. this paper therefore accepts the results of research studies and avoids reiterating details of the projects but offers instead a practical guide for using m rm to recruit and retain women in computer science. the guide provides pragmatic advice describing several different facets of the m rm concept.
inspec,train_857,leveraging an alternative source of computer scientists reentry programs. much has been written about the leaky pipeline of women in computer science cs with the percentage of women decreasing as one moves from lower levels such as college to higher levels culminating in full professorship. while significant attention focused on keeping women from leaving the pipeline there is also an opportunity to bring women into the pipeline through non traditional programs instead of requiring that everyone enter at the undergraduate level. both mills college a small liberal arts institution for women and uc berkeley a large research university established programs in the 80 s to increase the number of women in computer science by tapping non traditional students. both programs share the core value of accommodating older students lacking technical backgrounds. the two programs have produced similar results graduate degrees earned in computer science by students who would not have qualified without these programs professional employment in the computer science field by women and minorities and a recognition that this population represents a rich source of talent for our nation.
inspec,train_858,recruiting and retaining women in undergraduate computing majors. this paper recommends methods for increasing female participation in undergraduate computer science. the recommendations are based on recent and on going research into the gender gap in computer science and related disciplines. they are intended to work in tandem with the computing research association s recommendations for graduate programs to promote a general increase in women s participation in computing professions. most of the suggestions offered could improve the educational environment for both male and female students. however general improvements are likely to be of particular benefit to women because women in our society do not generally receive the same level of support that men receive for entering and persisting in this field.
inspec,train_859,developing a hardware and programming curriculum for middle school girls. techbridge provides experiences and resources that would teach girls technology skills as well as excite their curiosity and build their confidence. funded by the national science foundation and sponsored by chabot space and science center in oakland california techbridge is a three year program that serves approximately 200 girls annually. techbridge is hosted at 8 middle and high schools in oakland and at the california school for the blind in fremont california generally as an after school program meeting once a week. techbridge comes at a critical time in girls development when girls have many important decisions to make regarding classes and careers but often lack the confidence and guidance to make the best choices. techbridge helps girls plan for the next steps to high school and college with its role models and guidance. techbridge also provides training and resources for teachers counselors and families.
inspec,train_86,laser based internal profile measurement system. an automatic laser based system to measure the internal profiles of various structures has been developed. the system uses a point laser source through a rotating optical device fixed on to a laser measurement meter. a notebook computer with custom software is used to control the laser meter and rotating device to estimate the scanned profile shape and to determine the resulting cross section area. the information provided by this system is essential to construction industry including window and door builders the glass panel board and floor tile manufacturers carpet venders and building contractors for cost estimation and production control. as a result the lead time for delivering the customized windowpanes woodwork floor tiles and ceilings can be reduced. applications of this system for measuring the shapes of window frames and floor plans are described and demonstrated. the measurement accuracy is evaluated and analyzed. results have indicated that the measurement accuracy can be achieved within 4 of the measurement distance for typical window designs and floor patterns required by major window manufacturers. recommendations to improve the system are also included.
inspec,train_860, virtual family  an approach to introducing java programming. this paper introduces and discusses virtual family vf a gender neutral game based software that introduces java programming. vf provides a completely functioning game that students extend and enhance via programming. we discuss the background and context within which virtual family was developed and other available multimedia resources for teaching programming. the paper then goes on to describe virtual family s concept and design. finally feedback received from virtual family teaching workshops is related as well as preliminary results from using vf in high school teaching units. virtual family is under development in a research lab at the university of british columbia and is an initiative of supporting women in information technology swift. swift is a five year research action and implementation project to increase the participation of women in information technology.
inspec,train_861,the decision procedure for profitability of investment projects using the internal rate of return of single period projects. the internal rate of return irr criterion is often used to evaluate profitability of investment projects. in this paper we focus on a single period project which consists of two types of cash flows an investment at one period and a return at a succeeding period and a financing at one period and a repayment at a succeeding period. we decompose the given investment project into a series of the single period projects. from the viewpoint of the single period project we point out the applicability issue of the irr criterion namely the irr criterion can not be applied in which a project is composed of both investment type and financing type. investigating the properties of a series of the single period projects we resolve the applicability issue of the irr criterion and propose the decision procedure for profitability judgment toward any type of investment project based on the comparison between the irr and the capital cost. we develop a new algorithm to obtain the value of the project investment rate pir for the given project which is a function of the capital cost only using the standard irr computing routine. this outcome is a theoretical breakthrough to widen the utilization of irr in practical applications.
inspec,train_862,two efficient algorithms for the generalized maximum balanced flow problem. minoux 1976 considered the maximum balanced flow problem i e the problem of finding a maximum flow in a two terminal network n v a with source s and sink t satisfying the constraint that any arc flow of n is bounded by a fixed proportion of the total flow value from s to t where v is vertex set and a is arc set. as a generalization we focus on the problem of maximizing the total flow value of a generalized flow in n with gains gamma a 0 a in a where any arc flow is bounded by a fixed proportion of the total flow value where gamma a f a units arrive at the vertex w for each arc flow f a a identical to upsilon w in a entering vertex upsilon in a generalized flow. our main results are to propose two polynomial algorithms for this problem. the first algorithm runs in o mm n m b log b time where b is the maximum absolute value among integral values used by an instance of the problem and m n m b denotes the complexity of solving a generalized maximum flow problem in a network with n vertices and m arcs and a rational instance expressed with integers between 1 and b. in the second algorithm using a parameterized technique runs in o m n m b  sup 2 time.
inspec,train_863,a scanline based algorithm for the 2d free form bin packing problem. this paper describes a heuristic algorithm for the 2d free form bin packing 2d fbp problem. given a set of 2d free form bins and a set of 2d free form items the 2d fbp problem is to lay out items inside one or more bins in such a way that the number of bins used is minimized and for each bin the yield is maximized. the proposed algorithm handles the problem as a variant of the 1d problem i e items and bins are approximated as sets of scanlines and scanlines are packed. the details of the algorithm are given and its application to a nesting problem in a shipbuilding company is reported. the proposed algorithm consists of the basic and the group placement algorithms. the basic placement algorithm is a variant of the first fit decreasing algorithm which is simply extended from the 1d case to the 2d case by a novel scanline approximation. a numerical study with real instances shows that the basic placement algorithm has sufficient performance for most of the instances however the group placement algorithm is required when items must be aligned in columns. the qualities of the resulting layouts are good enough for practical use and the processing times are good.
inspec,train_864,valuing corporate debt the effect of cross holdings of stock and debt. we have developed a simple approach to valuing risky corporate debt when corporations own securities issued by other corporations. we assume that corporate debt can be valued as an option on corporate business asset value and derive payoff functions when there exist cross holdings of stock or debt between two firms. next we show that payoff functions with multiple cross holdings can be solved by the contraction principle. the payoff functions which we derive provide a number of insights about the risk structure of company cross holdings. first the modigliani miller theorem can obtain when there exist cross holdings between firms. second by establishing cross shareholdings each of stock holders distributes a part of its payoff values to the bond holder of the other s firm so that both firms can decrease credit risks by cross shareholdings. in the numerical examples we show that the correlation in firms can be a critical condition for reducing credit risk by cross holdings of stock using monte carlo simulation. moreover we show we can calculate the default spread easily when complicated cross holdings exist and find which shares are beneficial or disadvantageous.
inspec,train_865,setup cost and lead time reductions on stochastic inventory models with a service level constraint. the stochastic inventory models analyzed in this paper explore the problem of lead time associated with setup cost reductions for the continuous review and periodic review inventory models. for these two models with a mixture of backorders and lost sales we respectively assume that their mean and variance of the lead time demand and protection interval i e lead time plus review period demand are known but their probability distributions are unknown. we develop a minimax distribution free procedure to find the optimal solution for each case.
inspec,train_866,adjoint based optimization of steady suction for disturbance control in incompressible flows. the optimal distribution of steady suction needed to control the growth of single or multiple disturbances in quasi three dimensional incompressible boundary layers on a flat plate is investigated. the evolution of disturbances is analysed in the framework of the parabolized stability equations pse. a gradient based optimization procedure is used and the gradients are evaluated using the adjoint of the parabolized stability equations apse and the adjoint of the boundary layer equations able. the accuracy of the gradient is increased by introducing a stabilization procedure for the pse. results show that a suction peak appears in the upstream part of the suction region for optimal control of tollmien schlichting t s waves steady streamwise streaks in a two dimensional boundary layer and oblique waves in a quasi three dimensional boundary layer subject to an adverse pressure gradient. the mean flow modifications due to suction are shown to have a stabilizing effect similar to that of a favourable pressure gradient. it is also shown that the optimal suction distribution for the disturbance of interest reduces the growth rate of other perturbations. results for control of a steady cross flow mode in a three dimensional boundary layer subject to a favourable pressure gradient show that not even large amounts of suction can completely stabilize the disturbance.
inspec,train_867,tracking control of the flexible slider crank mechanism system under impact. the variable structure control vsc and the stabilizer design by using the pole placement technique are applied to the tracking control of the flexible slider crank mechanism under impact. the vsc strategy is employed to track the crank angular position and speed while the stabilizer design is involved to suppress the flexible vibrations simultaneously. from the theoretical impact consideration three approaches including the generalized momentum balance gmb the continuous force model cfm and the cfm associated with the effective mass compensation emc are adopted and are derived on the basis of the energy and impulse momentum conservations. simulation results are provided to demonstrate the performance of the motor controller flexible slider crank mechanism not only accomplishing good tracking trajectory of the crank angle but also eliminating vibrations of the flexible connecting rod.
inspec,train_868,two quantum analogues of fisher information from a large deviation viewpoint of quantum estimation. we discuss two quantum analogues of the fisher information the symmetric logarithmic derivative fisher information and kubo mori bogoljubov fisher information from a large deviation viewpoint of quantum estimation and prove that the former gives the true bound and the latter gives the bound of consistent superefficient estimators. as another comparison it is shown that the difference between them is characterized by the change of the order of limits.
inspec,train_869,an exactly solvable random satisfiability problem. we introduce a new model for the generation of random satisfiability problems. it is an extension of the hyper sat model of ricci tersenghi weigt and zecchina 2001 which is a variant of the famous k sat model it is extended to q state variables and relates to a different choice of the statistical ensemble. the model has an exactly solvable statistic the critical exponents and scaling functions of the sat unsat transition are calculable at zero temperature with no need of replicas also with exact finite size corrections. we also introduce an exact duality of the model and show an analogy of thermodynamic properties with the random energy model of disordered spin system theory. relations with error correcting codes are also discussed.
inspec,train_87,positional control of pneumatic manipulators for construction tasks. this paper describes solutions that can be applied to pneumatic manipulator problems in positioning both for angle trajectories and for long linear trajectories used in construction tasks. optimal positioning of a pneumatic manipulator along angle trajectories with minimum control energy consumption is given. the implementation of the control system is presented. control algorithms for a long linear trajectory manipulator based on two phase and three phase motion modes of the end effector are investigated. conventional and fuzzy logic controls of a pneumatic manipulator were applied and experimental testing was carried out. the obtained results allow widening the application range of pneumatic manipulators in construction particularly in gantry type machines.
inspec,train_870,speaker identification from voice using neural networks. the paper provides three different schemes for speaker identification of personnel from their voice using artificial neural networks. the first scheme recognizes speakers by employing the classical backpropagation algorithm pre trained with known voice samples of the persons. the second scheme provides a framework for classifying the known training samples of the voice features using a hierarchical architecture realized with a self organizing feature map neural net. the first scheme is highly robust as it is capable of identifying the personnel from their noisy voice samples but because of its excessive training time it has limited applications for a large voice database. the second scheme though not so robust as the former however can classify an unknown voice sample to its nearest class. the time needed for classification by the first scheme is always unique irrespective of the voice sample. it is proportional to the number of feedforward layers in the network. the time requirement of the second classification scheme however is not free from the voice features and is proportional to the number of 2d arrays traversed by the algorithm on the hierarchical structure. the third scheme is highly robust and mis classification is as low as 0 2 per cent. the third scheme combines the composite benefits of a radial basis function neural net and backpropagation trained neural net.
inspec,train_871,priming the pipeline women in computer science careers. in 1997 the backyard project a pilot program of the garnett foundation was instituted to encourage high school girls to explore careers in the computer industry. at that time the garnett foundation commissioned the global strategy group to execute a survey of 652 college bound high school students grades 9 through 12 to help discover directions that the backyard project might take to try to move toward the mission of the pilot program. it conducted the study by telephone between march 25 and april 8 1997 in the silicon valley boston and austin metropolitan areas. it conducted all interviews using a random digit dialing methodology derived from a file of american households with high incidences of adolescent children. the top six answers from girls to the survey question why are girls less likely to pursue computer science careers. in order of perceived importance by the girls were not enough role models women have other interests did n t know about the industry limited opportunity negative media and too nerdy. these responses are discussed.
inspec,train_872,shortchanging the future of information technology the untapped resource. building on ideas from a virtual workshop and additional input from the scientific community the cise directorate at the national science foundation established the information technology workforce program itwf in march 2000 to support a broad set of scientific research studies focused on the under representation of women and minorities in the information technology workforce. in this paper we explore various approaches that the funded researchers are taking to address the problem of women in information technology. we begin with a brief history of the itwf and then focus on some of the research projects in terms of their goals approaches and expected outcomes.
inspec,train_873,programmatic efforts encouraging women to enter the information technology workforce. for over a decade the national science foundation nsf has been supporting projects designed to improve opportunities for women in computing. from an initial emphasis on increasing the number of women in graduate school studying computer science and engineering nsf s current emphasis has broadened to include research studies examining the underlying reasons why women are underrepresented in the information technology it workforce. this paper describes the recent history of nsf s activities in this area and the subsequent emergence of a research portfolio addressing the underrepresentation issue.
inspec,train_874,the curious ways of professional cultures and the two body opportunity. when two professionals are a couple we sometimes refer to them as having a two body problem. however when each partner of a couple exists in the same cultures they also have an opportunity for deeply shared understanding and empathy simply because each understands at a deep level the culture in which the other works. i explore this notion. a couple has what we call the two body problem when both are professionals who are qualified for a kind of position that is relatively rare and who are very selective about the positions that they accept. for example there are relatively scant numbers of jobs as a computer science professor at any level. an individual considering an academic job may only be interested in research universities or in teaching universities restricting the choice of open positions substantially. the classic two body problem arises when one partner wants to accept a new position that requires geographical relocation. then the other partner also needs to find a new position. moreover it can be very difficult to find a suitable position when they are naturally scarce.
inspec,train_875,women of color in computing. it is well known that there is a need to increase the number of women in the area of computing that is in computer science and computer engineering. if we consider women of color that is women of under represented ethnicities we find the numbers are very dismal. the goal of this article is to bring to light the unique issues of women of color based upon the personal experience of one african american woman who has been in the field of computing for over 20 years including the years of higher education.
inspec,train_876,perspectives on academic vs industry environments for women in computer science. the authors were tenure track faculty members at the colorado school of mines and later moved into senior positions at software companies. both are part of two career couples as well and both have two children. in this article they discuss their impressions and share anecdotes regarding the differing experiences of women and families in these two environments.
inspec,train_877,what do you say. open letters to women considering a computer science major. in the last decade we have both monitored with great interest the ratio of female to male computer science majors at our respective institutions. with each entering class we think  surely now is the time when the numbers will become more balanced. logic tells us that this must eventually happen because the opportunities in computing are simply too attractive for an entire segment of our population to routinely pass up. but each year we are again disappointed in the number of women students as they continue to be woefully under represented among computer science majors. so what do you say to a young woman who is considering a college choice and a choice of major in order to make computer science a more attractive option. we have organized some thoughts on that subject into open letters.
inspec,train_878,girls boys and computers. today north american girls boys teachers and parents frequently regard computer science and programming as something boys are better at. the author considers how many of the factors that contribute to the low participation of women in computing occur first and perhaps most forcefully in childhood. she presents four recommendations to address the situation.
inspec,train_879,well behaved women rarely make history. the author considers women in the history of computer science. prior to the eniac women were extremely important to the computing business as computers. just as women had taken over the tasks as secretaries in the late 1800s with the advent of the typewriter and in the early 1900s staffing telephone exchanges so computing relied on women as the workhorses of the business.
inspec,train_88,planning linear construction projects automated method for the generation of earthwork activities. earthworks planning for road construction projects is a complex operation and the planning rules used are usually intuitive and not well defined. an approach to automate the earthworks planning process is described and the basic techniques that are used are outlined. a computer based system has been developed initially to help planners use existing techniques more efficiently. with their input the system has been extended to incorporate a knowledge base and a simulation of the earthworks processes. as well as creating activity sets in a much shorter time the system has shown that for a real project the model is able to generate activity sets that are comparable to those generated by a project planner.
inspec,train_880,computing 2002 democracy education and the future. computer scientists computer engineers information technologists and their collective products have grown and changed in quantity quality and nature. in the first decade of this new century it should become apparent to everyone that the computing and information fields broadly defined will have a profound impact on every element of every person s life. the author considers how women and girls of the world have been neither educated for computing nor served by computing. globally women s participation in computer science grew for a while then dropped precipitously. computing science engineering and society will suffer if this decline continues because women have different perspectives on technology what it is important for how it should be built which projects should be funded and so on. to create a positive future to assure that women equally influence the future computing education must change.
inspec,train_881,is diversity in computing a moral matter. we have presented an ethical argument that takes into consideration the subtleties of the issue surrounding under representation in computing. we should emphasize that there is nothing subtle about overt unfair discrimination. where such injustice occurs we condemn it. our concern is that discrimination need not be explicit or overt. it need not be individual to individual. rather it can be subtly built into social practices and social institutions. our analysis raises ethical questions about aspects of computing that drive women away aspects that can be changed in ways that improve the profession and access to the profession. we hope that computing will move towards these improvements.
inspec,train_882,on m d 1 queue with deterministic server vacations. we study a single server vacation queue with poisson arrivals deterministic service of constant duration b 0 and deterministic vacations of constant duration d 0 and designate this model as m d d 1. after completion of each service the server may take a vacation with probability p or may continue working in the system with probability 1 p. we obtain time dependent as well as steady state probability generation functions for the number in the system. for the steady state we obtain explicitly the mean number and the mean waiting time for the system and for the queue. all known results of the m d 1 queue are derived as a special case. finally a numerical illustration is discussed.
inspec,train_883,on conflict free executions of elementary nets. deals with analysis of elementary petri nets with respect to possibilities of avoiding conflicts during their executions. there are two main aims of the paper. the first is to find a method of checking if a net is conflict avoidable i e if it possesses a conflict free fair run. the second is to find a method of rebuilding any net to a totally conflict avoidable net i e a net possessing a conflict free fair run in every one process with the same behaviour. the main results are the following 1. the proof of decidability for elementary nets of the problem of existence of a conflict avoidable fair process and an algorithm producing all fair runs. 2. construction for an arbitrary given elementary net of a totally conflict avoidable net with the same behaviour. the net completed this way has the same behaviour as the original one. moreover it is totally conflict avoidable and its execution may be supervised in order to ensure conflict freeness by the reduced case graph built by the algorithm of the former section.
inspec,train_884,a hybrid neural network and population learning algorithm approach to solving reliability optimization problem. proposes a hybrid approach integrating a dedicated artificial neural network and population learning algorithm applied to maximising system reliability under cost and technical feasibility constraints. the paper includes a formulation of the system reliability optimisation sro problem and a description of the dedicated neural network trained by applying the population learning algorithm. a solution to the example sro problem is shown and results of the computational experiment are presented and discussed.
inspec,train_885,assignment of periods and priorities of messages and tasks in distributed control systems. presents a task and message based scheduling method to guarantee the given end to end constraints including precedence constraints time constraints and period and priority of task and message. the method is an integrated one considering both tasks executed in each node and messages transmitted via the network and is designed to apply to a general distributed control system that has multiple loops and a single loop has sensor nodes with multiple sensors actuator nodes with multiple actuators controller nodes with multiple tasks and several types of constraints. the assigning method of the optimal period and priority of task and message is proposed using the presented task and message based scheduling method.
inspec,train_886,a fractional flow model of serial manufacturing systems with rework and its reachability and controllability properties. a dynamic fractional flow model of a serial manufacturing system incorporating rework is considered. using some results on reachability and controllability of positive linear systems the ability of serial manufacturing systems with rework to move in space  that is their reachability and controllability properties are studied. these properties are important not only for optimising the performance of the manufacturing system possibly off line but also to improve its functioning by using feedback control online.
inspec,train_887,towards strong stability of concurrent repetitive processes sharing resources. the paper presents a method for design of stability conditions of concurrent repetitive processes sharing common resources. steady state behaviour of the system with m cyclic processes utilising a resource with the mutual exclusion is considered. based on a recurrent equations framework necessary and sufficient conditions for the existence of maximal performance steady state are presented. it was shown that if the conditions hold then the m process system is marginally stable i e a steady state of the system depends on the perturbations. the problem of finding the relative positions of the processes leading to waiting free maximal efficiency steady states of the system is formulated as a constraint logic programming problem. an example illustrating the solving of the problem for a 3 process system using object oriented constraint logic programming language oz is presented. a condition sufficient for strong stability of the m process system is given. when the condition holds then for any initial phases of the processes a waiting free steady state will be reached.
inspec,train_888,storage functionals and lyapunov functions for passive dynamical systems. for nonlinear time invariant input output dynamical systems the passivity conditions are obtained under some restrictions. the conditions imply storage functions satisfying a dissipation inequality. a class of storage functions allowing unique reconstruction of a passive dynamical system is defined. these results are illustrated by an example of a linear system with fading memory. an important for practical application class of the linear relaxation systems without direct input output interaction is considered. a necessary condition for dynamical systems to be of the relaxation type is obtained for this class. the condition is connected with the existence of a unique quadratic lyapunov function satisfying the complete monotonicity condition. this unique lyapunov function corresponds to a standard thermodynamic potential in a compact family of potentials in the nonequilibrium thermodynamics. the results obtained can be useful in automatic control mechanics of viscoelastic materials and various applications in physics and the system theory.
inspec,train_889,synthesis of the control systems via reflection onto auxiliary surfaces. an approach to robust control systems synthesis both linear and nonlinear and nonstationary is offered. the control is carried out providing the given phase constraints varied in acceptable limits in view of constraints on its value and incompleteness of the information about functioning disturbances. the approach is based on the introduction of auxiliary integral surfaces on which the initial moving is projected. as a result the reduced equivalent moving is formed being described by the scalar equation which in many important cases can be integrated directly. on the basis of the equation obtained solving a synthesis task is carried out and can be reduced to algebraic or integral inequalities. the final relations defined for linear equivalent moving are presented.
inspec,train_89,a framework for rapid local area modeling for construction automation. rapid 3d positioning and modeling in construction can be used to more effectively plan visualize and communicate operations before execution. it can also help to optimize equipment operations significantly improve safety and enhance a remote operator s spatial perception of the workspace. a new framework for rapid local area sensing and 3d modeling for better planning and control of construction equipment operation is described and demonstrated. by combining human assisted graphical workspace modeling with pre stored computer aided design cad models and simple sensors such as single axis laser rangefinders and remote video cameras modeling time can be significantly reduced while potentially increasing modeling accuracy.
inspec,train_890,multiple criteria decision making without optimization. we present a development intended to make interactive decision making schemes accessible for a wider spectrum of decision makers. to this aim we propose to eliminate the need to solve optimization problems at successive iterations of interactive decision processes. we show that the need for optimization can be eliminated by the ability of establishing sufficiently tight bounds on criteria values for efficient decisions prior to explicit identification of such decisions. we present a technique fully operational and numerically simple for establishing such bounds. bounds are dynamic i e they become stronger with the growing number of decisions explicitly identified. they are also parametric with respect to weighting coefficients. we also point out how this technique can enhance the existing interactive decision making methods.
inspec,train_891,establishing the discipline of physics based cmp modeling. for the past decade a physically based comprehensive process model for chemical mechanical polishing has eluded the semiconductor industry. however a long term collaborative effort has now resulted in a workable version of that approach. the highly fundamental model is based on advanced finite element analysis and is beginning to show promise in cmp process development.
inspec,train_892,dementing disorders volumetric measurement of cerebrospinal fluid to distinguish normal from pathologic finding feasibility study. we have demonstrated that automated methods to describe the severity and distribution of cerebral atrophy are capable of providing diagnostic information in the classification of neurodegenerative diseases.
inspec,train_893,use of natural language processing to translate clinical information from a database of 889 921 chest radiographic reports. the aim was to evaluate translation of chest radiographic reports using natural language processing and to compare the findings with those in the literature. a natural language processor coded 10 years of narrative chest radiographic reports from an urban academic medical center. coding for 150 reports was compared with manual coding. frequencies and cooccurrences of 24 clinical conditions diseases abnormalities and clinical states were estimated. the ratio of right to left lung mass association of pleural effusion with other conditions and frequency of bullet and stab wounds were compared with independent observations. the sensitivity and specificity of the system s pneumothorax coding were compared with those of manual financial coding. internal and external validation in this study confirmed the accuracy of natural language processing for translating chest radiographic narrative reports into a large database of information.
inspec,train_894,improved detection of lung nodules by using a temporal subtraction technique. the authors evaluated the effect of a temporal subtraction technique for digital chest radiography with regard to the accuracy of detection of lung nodules. twenty solitary lung nodules smaller than 30 mm in diameter including 10 lung cancers and 10 benign nodules were used. the nodules were grouped subjectively according to their subtlety. for nonnodular cases 20 nodules without perceptible interval changes were selected. all chest radiographs were obtained by using a computed radiographic system and temporal subtraction images were produced by using a program developed at the university of chicago. the effect of the temporal subtraction image was evaluated by using an observer performance study with use of receiver operating characteristic analysis. observer performance with temporal subtraction images was substantially improved a sub z  0 980 and 0 958 as compared with that without temporal subtraction images a sub z  0 920 and 0 825 for the certified radiologists and radiology residents respectively. the temporal subtraction technique clearly improved diagnostic accuracy for detecting lung nodules especially subtle cases. in conclusion the temporal subtraction technique is useful for improving detection accuracy for peripheral lung nodules on digital chest radiographs.
inspec,train_895,algorithms for improving the quality of r trees. a novel approach to operation with a structure for spatial indexing of extended objects shaped as r trees is considered. it consists of the initial global construction of an efficient r tree structure and the subsequent operation with it using conventional dynamic algorithms. a global strategy for constructing an r tree reduced to a problem of dividing a set of rectangular objects into k parts with minimum mutual overlay is suggested. base box and divide and conquer algorithms are suggested. the results of experimental modeling of the execution of various algorithms are discussed.
inspec,train_896,calculation of the probability of survival of an insurance company with allowance for the rate of return for a poisson stream of premiums. the probability of survival of an insurance company with the working capital is calculated for a poisson stream of premiums.
inspec,train_897,optimization of advertising expenses in the functioning of an insurance company. with the use of pontryagin s maximum principle a problem of optimal time distribution of advertising expenses in the functioning of an insurance company is solved.
inspec,train_898,influence of advertising expenses on the characteristics of functioning of an insurance company. the basic characteristics of the functioning of an insurance company including the average capital ruin and survival probabilities and the conditional time before ruin are examined with allowance for advertising expenses.
inspec,train_899,mathematical model of functioning of an insurance company with allowance for advertising expenses. a mathematical model of the functioning of an insurance company with allowance for advertising expenses is suggested. the basic characteristics of the capital of the company and the advertising efficiency are examined in the case in which the advertising expenses are proportional to the capital.
inspec,train_9,achieving competitive capabilities in e services. what implications does the internet have for service operations strategy. how can business performance of e service companies be improved in today s knowledge based economy. these research questions are the subject of the paper. we propose a model that links the e service company s knowledge based competencies with their competitive capabilities. drawing from the current literature our analysis suggests that services that strategically build a portfolio of knowledge based competencies namely human capital structural capital and absorptive capacity have more operations based options than their counterparts who are less apt to invest. we assume that the combinative capabilities of service quality delivery flexibility and cost are determined by the investment in intellectual capital. arguably with the advent of the internet different operating models e g bricks and mortar clicks and mortar or pure dot com have different strategic imperatives in terms of knowledge based competencies. thus the new e operations paradigm can be viewed as a configuration of knowledge based competencies and capabilities.
inspec,train_90,lan based building maintenance and surveillance robot. the building and construction industry is the major industry of hong kong as in many developed countries around the world. after the commissioning of a high rise building or a large estate substantial manpower both inside the management centre under a standby manner as well as surveillance for security purposes around the whole building is required for daily operation to ensure a quality environment for the occupants. if the surveillance job can be done by robots the efficiency can be highly enhanced resulting in a great saving of manpower and the improved safety of the management staff as a by product. furthermore if the robot can retrieve commands from the building management system via a local area network lan further savings in manpower can be achieved in terms of first line fault attendance by human management staff. this paper describes the development of a robot prototype here in hong kong which can handle some daily routine maintenance works and surveillance responsibilities. the hardware structure of the robot and its on board devices are described. real time images captured by a camera on the robot with pan tilt zoom functions can be transmitted back to the central management office via a local area network. the interface between the robot and the building automation system bas of the building is discussed. this is the first key achievement of this project with a strong implication on reducing the number of human staff to manage a modem building. teleoperation of the robot via the internet or intranet is also possible which is the second achievement of this project. finally the robot can identify its physical position inside the building by a landmark recognition method based on standard cad drawings which is the third achievement of this project. the main goal of this paper is not the description of some groundbreaking technology in robotic development. it is mainly intended to convince building designers and managers to incorporate robotic systems when they are managing modem buildings to save manpower and improve efficiency.
inspec,train_900,mathematical models of functioning of an insurance company with allowance for the rate of return. models of the functioning of insurance companies are suggested when the free capital increases from interest at a certain rate. the basic characteristics of the capital of a company are studied in the stationary regime.
inspec,train_901,estimation of the poisson stream intensity in a multilinear queue with an exponential job queue decay. times the busy queue periods start are found for a multilinear queue with an exponential job queue decay and uniform resource allocation to individual servers. the stream intensity and the average job are estimated from observations of the times the queue busy periods start.
inspec,train_902,tcp explicit congestion notification over atm ubr a simulation study. the enhancement of transmission control protocol s tcp s congestion control mechanisms using explicit congestion notification ecn over asynchronous transfer mode atm networks is overviewed. tcp s congestion control is enhanced so that congestion is indicated by not only packet losses as is currently the case but an agent implemented at the atm network s edge as well. the novel idea uses efci explicit forward congestion indication bits available in every atm cell header to generalize the ecn response to the ubr unspecified bit rate service notify congestion and adjust the credit based window size of the tcr. the authors simulation experiments show that tcp ecn achieves significantly lower cell loss packet retransmissions and buffer utilization and exhibits better throughput than non ecn tcp reno.
inspec,train_903,modeling and simulation of an abr flow control algorithm using a virtual source virtual destination switch. the available bit rate abr service class of asynchronous transfer mode networks uses a feedback control mechanism to adapt to varying link capacities. the virtual source virtual destination vs vd technique offers the possibility of segmenting the otherwise end to end abr control loop into separate loops. the improved feedback delay and control of abr traffic inside closed segments provide a better performance for abr connections. this article presents the use of classical linear control theory to model and develop an abr vs vd flow control algorithm. discrete event simulations are used to analyze the behavior of the algorithm with respect to transient behavior and correctness of the control model. linear control theory offers the means to derive correct choices of parameters and to assess performance issues such as stability of the system during the design phase. the performance goals are high link utilization fair bandwidth distribution and robust operation in various environments which are verified by discrete event simulations. the major contribution of this work is the use of analytic methods linear control theory to model and design an abr flow control algorithm tailored for the special layout of a vs vd switch and the use of simulation techniques to verify the result.
inspec,train_904,modeling and simulation of adaptive available bit rate voice over asynchronous transfer mode networks. this article presents a modeling and simulation methodology to analyze the performance of voice quality when sent over the available bit rate service in asynchronous transfer mode networks. sources can modify the rate at which they send traffic to the network based on the feedback carried in the resource management cells. this is achieved by changing the encoding level. as the contention increases to network resources bandwidth in this case sources start reducing the rate at which they generate and send traffic. the efficiency of the scheme under different scheduling drop policies and other operating conditions and environments is evaluated using simulation modeling. furthermore sensitivity analysis is applied to different parameters such as queue size and averaging interval length to investigate their impact on the performance metrics. results show that limiting the load to 41 of the link capacity results in an acceptable quality.
inspec,train_905,ultra high speed positioning control of a gravure engraving unit using a discrete time two degree of freedom h sub infinity control. the piezoelectric actuator has high speed response in comparison with the electro magnetic actuator. however it is not easy to achieve both high speed and high precision response by feedforward control only because the piezoelectric element has nonlinear properties such as the hysteresis effect. thus feedback control is required to achieve good performance. we develop a control design method to achieve both high speed and high precision response for piezoelectric actuators using the discrete time h sub infinity control method and the two degree of freedom control scheme. the effectiveness of our proposed method has been shown by simulation and experimental results. the most important contribution of our study is that our method can be directly applied to commercial machines.
inspec,train_906,high performance servo systems based on multirate sampling control. in this paper novel multirate two degree of freedom controllers are proposed for digital control systems in which the sampling period of plant output is restricted to be relatively longer than the control period of plant input. the proposed feedforward controller assures perfect tracking at m inter sampling points. on the other hand the proposed feedback controller assures perfect disturbance rejection at m inter sample points in the steady state. illustrative examples of position control for hard disk drive are presented and advantages of these approaches are demonstrated.
inspec,train_907,development of an integrated and open architecture precision motion control system. in this paper the development of an integrated and open architecture precision motion control system is presented. the control system is generally applicable but it is developed with a particular focus on direct drive servo systems based on linear motors. the overall control system is comprehensive comprising of various selected control and instrumentation components integrated within a configuration of hardware architecture centred around a dspace ds1004 dsp processor board. these components include a precision composite controller comprising of feedforward and feedback control a disturbance observer an adaptive notch filter and a geometrical error compensator. the hardware architecture software development platform user interface and all constituent control components are described.
inspec,train_908,multivariable h sub infinity  mu feedback control design for high precision wafer stage motion. conventional pid like siso controllers are still the most common in industry but with performance requirements becoming tighter there is a growing need for advanced controllers. for the positioning devices in ic manufacturing plant interaction is a major performance limiting factor. mimo control can be invoked to tackle this problem. a practically feasible procedure is presented to design mimo feedback controllers for electromechanical positioning devices using h sub infinity  mu techniques. weighting filters are proposed to straightforwardly and effectively impose performance and uncertainty specifications. experiments show that mimo control can considerably improve upon the performance with multiloop siso control. some problems are highlighted that are important for industrial practice but lacking a workable solution.
inspec,train_909,influence of the process design on the control strategy application in electropneumatic field. this article proposes an example of electropneumatic system where the architecture of the process is modified with respect to both the specifications for position and velocity tracking and a criterion concerning the energy consumption. experimental results are compared and analyzed using an industrial bench test. for this a complete model of the system is presented and two kinds of nonlinear control laws are developed a monovariable and multivariable type based on the flatness theory.
inspec,train_91,it challenge cross selling finance. like most financial institutions fleetboston fidelity and berkshire group of companies are being charged with developing a strong technology platform that will allow them to cross sell their products and services. they discuss their solutions advice and technology choices.
inspec,train_910,control of a heavy duty robotic excavator using time delay control with integral sliding surface. the control of a robotic excavator is difficult from the standpoint of the following problems parameter variations in mechanical structures various nonlinearities in hydraulic actuators and disturbance due to the contact with the ground. in addition the more the size of robotic excavators increases the more the length and mass of the excavator links the more the parameters of a heavy duty excavator vary. a time delay control with switching action tdcsa using an integral sliding surface is proposed in this paper for the control of a 21 ton robotic excavator. through analysis and experiments we show that using an integral sliding surface for the switching action of tdcsa is better than using a pd type sliding surface. the proposed controller is applied to straight line motions of a 21 ton robotic excavator with a speed level at which skillful operators work. experiments which were designed for surfaces with various inclinations and over broad ranges of joint motions show that the proposed controller exhibits good performance.
inspec,train_911,scheduling schemes for an integrated flight and propulsion control system. we describe two schemes for scheduling an integrated flight and propulsion control system for an experimental vertical short take off and landing v stol aircraft concept in the acceleration from hover 0 120 kn flight phase. multivariable integrated flight and propulsion controllers are designed at several points over the v stol envelope and implemented as exact plant observers with state feedback. in the first scheduling scheme the values of the state feedback and observer gain matrices are interpolated between the fixed point designs as a function of aircraft speed. in the second approach the control signals produced by the different fixed point controllers are blended allowing a significant reduction in the order of the scheduled controllers. both scheduling schemes are shown in nonlinear simulation to provide excellent handling qualities as the aircraft accelerates from the hover.
inspec,train_912,grey box model identification via evolutionary computing. this paper presents an evolutionary grey box model identification methodology that makes the best use of a priori knowledge on a clear box model with a global structural representation of the physical system under study whilst incorporating accurate blackbox models for immeasurable and local nonlinearities of a practical system. the evolutionary technique is applied to building dominant structural identification with local parametric tuning without the need of a differentiable performance index in the presence of noisy data. it is shown that the evolutionary technique provides an excellent fitting performance and is capable of accommodating multiple objectives such as to examine the relationships between model complexity and fitting accuracy during the model building process. validation results show that the proposed method offers robust uncluttered and accurate models for two practical systems. it is expected that this type of grey box models will accommodate many practical engineering systems for a better modelling accuracy.
inspec,train_913,control of a coupled map lattice model for vortex shedding in the wake of a cylinder. the flow behind a vibrating flexible cable at low reynolds numbers can exhibit complex wake structures such as lace like patterns vortex dislocations and frequency cells. these structures have been observed in experiments and numerical simulations and are predicted by a previously developed low order coupled map lattice cml. the discrete in time and space cml models consist of a series of diffusively coupled circle map oscillators along the cable span. motivated by a desire to modify the complex wake patterns behind flexible vibrating cables we have studied the addition of control terms into the highly efficient cml models and explored the resulting dynamics. proportional adaptive proportional and discontinuous non linear dnl control methods were used to derive the control laws. the first method employed occasional proportional feedback. the adaptive method used spatio temporal feedback control. the dnl method used a discontinuous feedback linearization procedure and the controller was designed for the resulting linearized system using eigenvalue assignment. these techniques were applied to a modeled vortex dislocation structure in the wake of a vibrating cable in uniform freestream flow. parallel shedding patterns were achieved for a range of forcing frequency forcing amplitude combinations studied to validate the control theory. the adaptive proportional and dnl methods were found to be more effective than the proportional control method due to the incorporation of a spatially varying feedback gain across the cylinder span. the dnl method was found to be the most efficient controller of the low order cml model. the required control level across the cable span was correlated to the 1 1 lock on behavior of the temporal circle map.
inspec,train_914,a knowledge management framework for the support of decision making in humanitarian assistance disaster relief. the major challenge in current humanitarian assistance disaster relief ha dr efforts is that diverse information and knowledge are widely distributed and owned by different organizations. these resources are not efficiently organized and utilized during ha dr operations. we present a knowledge management framework that integrates multiple information technologies to collect analyze and manage information and knowledge for supporting decision making in ha dr. the framework will help identify the information needs be aware of a disaster situation and provide decision makers with useful relief recommendations based on past experience. a comprehensive consistent and authoritative knowledge base within the framework will facilitate knowledge sharing and reuse. this framework can also be applied to other similar real time decision making environments such as crisis management and emergency medical assistance.
inspec,train_915,a meteorological fuzzy expert system incorporating subjective user input. we present a fuzzy expert system medex for forecasting gale force winds in the mediterranean basin. the most successful local wind forecasting in this region is achieved by an expert human forecaster with access to numerical weather prediction products. that forecaster s knowledge is expressed as a set of rules of thumb. fuzzy set methodologies have proved well suited for encoding the forecaster s knowledge and for accommodating the uncertainty inherent in the specification of rules as well as in subjective and objective input. medex uses fuzzy set theory in two ways as a fuzzy rule base in the expert system and for fuzzy pattern matching to select dominant wind circulation patterns as one input to the expert system. the system was developed tuned and verified over a two year period during which the weather conditions from 539 days were individually analyzed. evaluations of medex performance for both the onset and cessation of winter and summer winds are presented and demonstrate that medex has forecasting skill competitive with the us navy s regional forecasting center in rota spain.
inspec,train_916,attribute generation based on association rules. a decision tree is considered to be appropriate 1 if the tree can classify the unseen data accurately and 2 if the size of the tree is small. one of the approaches to induce such a good decision tree is to add new attributes and their values to enhance the expressiveness of the training data at the data pre processing stage. there are many existing methods for attribute extraction and construction but constructing new attributes is still an art. these methods are very time consuming and some of them need a priori knowledge of the data domain. they are not suitable for data mining dealing with large volumes of data. we propose a novel approach that the knowledge on attributes relevant to the class is extracted as association rules from the training data. the new attributes and the values are generated from the association rules among the originally given attributes. we elaborate on the method and investigate its feature. the effectiveness of our approach is demonstrated through some experiments.
inspec,train_917,efficient transitive closure reasoning in a combined class part containment hierarchy. class hierarchies form the backbone of many implemented knowledge representation and reasoning systems. they are used for inheritance classification and transitive closure reasoning. part hierarchies are also important in artificial intelligence. other hierarchies e g containment hierarchies have received less attention in artificial intelligence. this paper presents an architecture and an implementation of a hierarchy reasoner that integrates a class hierarchy a part hierarchy and a containment hierarchy into one structure. in order to make an implemented reasoner useful it needs to operate at least at speeds comparable to human reasoning. as real world hierarchies are always large special techniques need to be used to achieve this. we have developed a set of parallel algorithms and a data representation called maximally reduced tree cover for that purpose. the maximally reduced tree cover is an improvement of a materialized transitive closure representation which has appeared in the literature. our experiments with a medical vocabulary show that transitive closure reasoning for combined class part containment hierarchies in near constant time is possible for a fixed hardware configuration.
inspec,train_918,schema evolution in data warehouses. we address the issues related to the evolution and maintenance of data warehousing systems when underlying data sources change their schema capabilities. these changes can invalidate views at the data warehousing system. we present an approach for dynamically adapting views according to schema changes arising on source relations. this type of maintenance concerns both the schema and the data of the data warehouse. the main issue is to avoid the view recomputation from scratch especially when views are defined from multiple sources. the data of the data warehouse is used primarily in organizational decision making and may be strategic. therefore the schema of the data warehouse can evolve for modeling new requirements resulting from analysis or data mining processing. our approach provides means to support schema evolution of the data warehouse independently of the data sources.
inspec,train_919,agents in e commerce state of the art. this paper surveys the state of the art of agent mediated electronic commerce e commerce especially in business to consumer b2c e commerce and business to business b2b e commerce. from the consumer buying behaviour perspective the roles of agents in b2c e commerce are product brokering merchant brokering and negotiation. the applications of agents in b2b e commerce are mainly in supply chain management. mobile agents evolutionary agents and data mining agents are some special techniques which can be applied in agent mediated e commerce. in addition some technologies for implementation are briefly reviewed. finally we conclude this paper by discussions on the future directions of agent mediated e commerce.
inspec,train_92,wireless retail financial services adoption ca n t justify the cost. slow adoption by retail investors costly services and bankrupt vendors has prompted banks and brokerage firms to turn off their wireless applications.
inspec,train_920,three dimensional periodic voronoi grain models and micromechanical fe simulations of a two phase steel. a three dimensional model is proposed for modeling of microstructures. the model is based on the finite element method with periodic boundary conditions. the voronoi algorithm is used to generate the geometrical model which has a periodic grain structure that follows the original boundaries of the voronoi cells. as an application the model is used to model a two phase ferrite pearlite steel. it is shown that periodic cells with only five grains generate representative stress strain curves.
inspec,train_921,processing of complexly shaped multiply connected domains in finite element mesh generation. large number of finite element models in modern materials science and engineering is defined on complexly shaped domains quite often multiply connected. generation of quality finite element meshes on such domains especially in cases when the mesh must be 100 quadrilateral is highly problematic. this paper describes mathematical fundamentals and practical implementation of a powerful method and algorithm allowing transformation of multiply connected domains of arbitrary geometrical complexity into a set of simple domains the latter can then be processed by broadly available finite element mesh generators. the developed method was applied to a number of complex geometries including those arising in analysis of parasitic inductances and capacitances in printed circuit boards. the quality of practical results produced by the method and its programming implementation provide evidence that the algorithm can be applied to other finite element models with various physical backgrounds.
inspec,train_922,smart collision information processing sensors for fast moving objects. in this technical note we survey the area of smart collision information processing sensors. we review the existing technologies to detect collision or overlap between fast moving physical objects or objects in virtual environments physical environments or a combination of physical and virtual objects. we report developments in the collision detection of fast moving objects at discrete time steps such as two consecutive time frames as well as continuous time intervals such as in an interframe collision detection system. our discussion of computational techniques in this paper is limited to convex objects. techniques exist however to efficiently decompose non convex objects into convex objects. we also discuss the tracking technologies for objects from the standpoint of collision detection or avoidance.
inspec,train_923,design and manufacture of a lightweight piezo composite curved actuator. in this paper we are concerned with the design manufacture and performance test of a lightweight piezo composite curved actuator called lipca using a top carbon fiber composite layer with near zero coefficient of thermal expansion cte a middle pzt ceramic wafer and a bottom glass epoxy layer with a high cte. the main point of the design for lipca is to replace the heavy metal layers of thunder tm by lightweight fiber reinforced plastic layers without losing the capabilities for generating high force and large displacement. it is possible to save up to about 40 of the weight if we replace the metallic backing material by the light fiber composite layer. we can also have design flexibility by selecting the fiber direction and the size of prepreg layers. in addition to the lightweight advantage and design flexibility the proposed device can be manufactured without adhesive layers when we use an epoxy resin prepreg system. glass epoxy prepregs a ceramic wafer with electrode surfaces and a carbon prepreg were simply stacked and cured at an elevated temperature 177 degrees c after following an autoclave bagging process. we found that the manufactured composite laminate device had a sufficient curvature after being detached from a flat mould. an analysis method using the classical lamination theory is presented to predict the curvature of lipca after curing at an elevated temperature. the predicted curvatures are in quite good agreement with the experimental values. in order to investigate the merits of lipca performance tests of both lipca and thunder tm have been conducted under the same boundary conditions. from the experimental actuation tests it was observed that the developed actuator could generate larger actuation displacement than thunder tm.
inspec,train_924,dynamic testing of inflatable structures using smart materials. in this paper we present experimental investigations of the vibration testing of an inflated thin film torus using smart materials. lightweight inflatable structures are very attractive in satellite applications. however the lightweight flexible and highly damped nature of inflated structures poses difficulties in ground vibration testing. in this study we show that polyvinylidene fluoride pvdf patches and recently developed macro fiber composite actuators may be used as sensors and actuators in identifying modal parameters. both smart materials can be integrated unobtrusively into the skin of a torus or space device forming an attractive testing arrangement. the addition of actuators and pvdf sensors to the torus does not significantly interfere with the suspension modes of a free free boundary condition and can be considered an integral part of the inflated structure. the results indicate the potential of using smart materials to measure and control the dynamic response of inflated structures.
inspec,train_925,a fundamental investigation into large strain recovery of one way shape memory alloy wires embedded in flexible polyurethanes. shape memory alloys smas are being embedded in or externally attached to smart structures because of the large amount of actuation deformation and force that these materials are capable of producing when they are heated. previous investigations have focused primarily on using single or opposing sma wires exhibiting the two way shape memory effect sme because of the simplicity with which the repeatable actuation behavior of the structure can be predicted. this repeatable actuation behavior is achieved at the expense of reduced levels of recoverable deformation. alternatively many potential smart structure applications will employ multiple sma wires exhibiting a permanent one way sme to simplify fabrication and increase the recoverable strains in the structure. to employ the one way wires it is necessary to investigate how they affect the recovery of large strains when they are embedded in a structure. in this investigation the large strain recovery of a one way sma wire embedded in a flexible polyurethane is characterized using the novel deformation measurement technique known as digital image correlation. these results are compared with a simple actuation model and a three dimensional finite element analysis of the structure using the brinson model for describing the thermomechanical behavior of the sma. results indicate that the level of actuation strain in the structure is substantially reduced by the inelastic behavior of the one way sma wires and there are significant differences between the deformations of the matrix material adjacent to the sma wires and in the region surrounding it. the transformation behavior of the sma wires was also determined to be volume preserving which had a significant effect on the transverse strain fields.
inspec,train_926,experimental investigation of active vibration control using neural networks and piezoelectric actuators. the use of neural networks for identification and control of smart structures is investigated experimentally. piezoelectric actuators are employed to suppress the vibrations of a cantilevered plate subject to impulse sine wave and band limited white noise disturbances. the neural networks used are multilayer perceptrons trained with error backpropagation. validation studies show that the identifier predicts the system dynamics accurately. the controller is trained adaptively with the help of the neural identifier. experimental results demonstrate excellent closed loop performance and robustness of the neurocontroller.
inspec,train_927,autonomous detection of crack initiation using surface mounted piezotransducers. in this paper we report on the application of an in situ health monitoring system comprising an array of piezoceramic wafer elements to the detection of fatigue degradation in metallic specimens exposed to cyclic loading. lamb waves transmitted through a beam test coupon are sensed using small surface mounted piezotransducer elements and the signals are then autonomously analysed for indications relating to the onset of structural degradation. the experimental results confirm the efficacy of the approach and provide a demonstration of good robustness under realistic loading conditions emphasizing the great potential for developing an automated in situ structural health monitoring system for application to fatigue prone operational structures such as aircraft.
inspec,train_928,weighted energy linear quadratic regulator vibration control of piezoelectric composite plates. in this paper on finite element linear quadratic regulator lqr vibration control of smart piezoelectric composite plates we propose the use of the total weighted energy method to select the weighting matrices. by constructing the optimal performance function as a relative measure of the total kinetic energy strain energy and input energy of the system only three design variables need to be considered to achieve a balance between the desired higher damping effect and lower input cost. modal control analysis is used to interpret the effects of three energy weight factors on the damping ratios and modal voltages and it is shown that the modal damping effect will increase with the kinetic energy weight factor approaching square root 2 2 as the strain energy weight factor increases and decrease with the input energy weight factor. numerical results agree well with those from the modal control analysis. since the control problem is simplified to three design variables only the computational cost will be greatly reduced and a more accurate structural control analysis becomes more attractive for large systems.
inspec,train_929,closed loop finite element modeling of active constrained layer damping in the time domain analysis. a three dimensional finite element closed loop model has been developed to predict the effects of active passive damping on a vibrating structure. the golla hughes mctavish method is employed to capture the viscoelastic material behavior in a time domain analysis. the parametric study includes the different control gains as well as geometric parameters related to the active constrained layer damping acld treatment. comparisons are made among several acld models the passive constrained model and the active damping model. the results obtained here reiterate that acld is somewhat better for vibration suppression than either the purely passive or the active system and provides higher structural damping with less control gain when compared to the purely active system. since the acld performance can be reduced by the viscoelastic layer the design of the acld model must be given a careful consideration in order to optimize the effect of passive damping.
inspec,train_93,help desk support is key to wireless success finance. a well thought out help desk can make or break an institution s mobile play. schwab ameritrade and rbc are taking their support function seriously.
inspec,train_930,narx based technique for the modelling of magneto rheological damping devices. this paper presents a methodology for identifying variable structure nonlinear models of magneto rheological dampers mrd and similar devices. its peculiarity with respect to the mainstream literature is to be especially conceived for obtaining models that are structurally simple easy to estimate and well suited for model based control. this goal is pursued by adopting linear in the parameters narx models for which an identification method is developed based on the minimization of the simulation error. this method is capable of selecting the model structure together with the parameters thus it does not require a priori structural information. a set of validation tests is reported with the aim of demonstrating the technique s efficiency by comparing it to a widely accepted mrd modelling approach.
inspec,train_931,active vibration control of composite sandwich beams with piezoelectric extension bending and shear actuators. we have used quasi static equations of piezoelectricity to derive a finite element formulation capable of modelling two different kinds of piezoelastically induced actuation in an adaptive composite sandwich beam. this formulation is made to couple certain piezoelectric constants to a transverse electric field to develop extension bending actuation and shear induced actuation. as an illustration we present a sandwich model of three sublaminates face core face. we develop a control scheme based on the linear quadratic regulator independent modal space control lqr imsc method and use this to estimate the active stiffness and the active damping introduced by shear and extension bending actuators. to assess the performance of each type of actuator a dynamic response study is carried out in the modal domain. we observe that the shear actuator is more efficient in actively controlling the vibration than the extension bending actuator for the same control effort.
inspec,train_932,modeling of torsional vibration induced by extension twisting coupling of anisotropic composite laminates with piezoelectric actuators. in this paper we present a dynamic analytical model for the torsional vibration of an anisotropic piezoelectric laminate induced by the extension twisting coupling effect. in the present approach we use the hamilton principle and a reduced bending stiffness method for the derivation of equations of motion. as a result the in plane displacements are not involved and the out of plane displacement of the laminate is the only quantity to be calculated. therefore the proposed method turns the twisting of a laminate with structural coupling into a simplified problem without losing its features. we give analytical solutions of the present model with harmonic excitation. a parametric study is performed to demonstrate the present approach.
inspec,train_933,real time estimations of multi modal frequencies for smart structures. in this paper various methods for the real time estimation of multi modal frequencies are realized in real time and compared through numerical and experimental tests. these parameter based frequency estimation methods can be applied to various engineering fields such as communications radar and adaptive vibration and noise control. well known frequency estimation methods are introduced and explained. the bairstow method is introduced to find the roots of a characteristic equation for estimations of multi modal frequencies and the computational efficiency of the bairstow method is shown quantitatively. for a simple numerical test we consider two sinusoids of the same amplitudes mixed with various amounts of white noise. the test results show that the auto regressive ar and auto regressive and moving average arma methods are unsuitable in noisy environments. the other methods apart from the ar method have fast tracking capability. from the point of view of computational efficiency the results reveal that the arma method is inefficient while the cascade notch filter method is very effective. the linearized adaptive notch filter and recursive maximum likelihood methods have average performances. experimental tests are devised to confirm the feasibility of real time computations and to impose the severe conditions of drastically different amplitudes and of considerable changes of natural frequencies. we have performed experiments to extract the natural frequencies from the vibration signal of wing like composite plates in real time. the natural frequencies of the specimen are changed by added masses. especially the ar method exhibits a remarkable performance in spite of the severe conditions. this study will be helpful to anyone who needs a frequency estimation algorithm for real time applications.
inspec,train_934,induced shear piezoelectric actuators for rotor blade trailing edge flaps. much of the current rotorcraft research is focused on improving performance by reducing unwanted helicopter noise and vibration. one of the most promising active rotorcraft vibration control systems is an active trailing edge flap. in this paper an induced shear piezoelectric tube actuator is used in conjunction with a simple lever cusp hinge amplification device to generate a useful combination of trailing edge flap deflections and hinge moments. a finite element model of the actuator tube and trailing edge flap including aerodynamic and inertial loading was used to guide the design of the actuator flap system. a full scale induced shear tube actuator flap system was fabricated and bench top testing was conducted to validate the analysis. hinge moments corresponding to various rotor speeds were applied to the actuator using mechanical springs. the testing demonstrated that for an applied electric field of 3 kv cm sup 1 the tube actuator deflected a representative full scale 12 inch flap or 2 8 degrees at 0 rpm and or 1 4 degrees for a hinge moment simulating a 400 rpm condition. the per cent error between the predicted and experimental full scale flap deflections ranged from 4 low rpm to 12 5 large rpm. increasing the electric field to 4 kv cm sup 1 results in or 2 5 degrees flap deflection at a rotation speed of 400 rpm according to the design analysis. a trade study was conducted to compare the performance of the piezoelectric tube actuator to the state of the art in trailing edge flap actuators and indicated that the induced shear tube actuator shows promise as a trailing edge flap actuator.
inspec,train_935,experimental feedforward and feedback control of a one dimensional sma composite. the control of embedded shape memory alloy sma actuators has recently become a topic of interest in the field of smart structures. the inherent difficulties associated with sma actuators has resulted in a variety of approaches. homogenization provides a simplified yet mathematically rigorous method of determining average stress and strain fields in a composite. a modified constitutive model is presented based on experimental results demonstrating the inability of most simple phenomenological models to capture the effective behavior of smas during thermal activation. a feedforward controller is presented for a sma composite based on the homogenization of a modified phenomenological model for smas in a linear matrix.
inspec,train_936,resonant controllers for smart structures. in this paper we propose a special type of colocated feedback controller for smart structures. the controller is a parallel combination of high q resonant circuits. each of the resonant circuits is tuned to a pole or the resonant frequency of the smart structure. it is proven that the parallel combination of resonant controllers is stable with an infinite gain margin. only one set of actuator sensor can damp multiple resonant modes with the resonant controllers. experimental results are presented to show the robustness of the proposed controller in damping multimode resonances.
inspec,train_937,use of neural networks in the analysis of particle size distribution by laser diffraction tests with different particle systems. the application of forward light scattering methods for estimating the particle size distribution psd is usually limited by the occurrence of multiple scattering which affects the angular distribution of light in highly concentrated suspensions thus resulting in false calculations by the conventionally adopted algorithms. in this paper a previously proposed neural network based method is tested with different particle systems in order to evaluate its applicability. in the first step of the study experiments were carried out with solid liquid suspensions having different characteristics of particle shape and size distribution under varying solid concentrations. the experimental results consisting of the angular distribution of light intensity particle shape and suspension concentration were used as input data in the fitting of neural network models nn that replaced the optical model to provide the psd. the reference values of particle shape and psd for the nn fitting were based on image analysis. comparisons between the psd values computed by the nn model and the reference values indicate that the method can be used in monitoring the psd of particles with different shapes in highly concentrated suspensions thus extending the range of application of forward laser diffraction to a number of systems with industrial interest.
inspec,train_938,fast accurate meg source localization using a multilayer perceptron trained with real brain noise. iterative gradient methods such as levenberg marquardt lm are in widespread use for source localization from electroencephalographic eeg and magnetoencephalographic meg signals. unfortunately lm depends sensitively on the initial guess necessitating repeated runs. this combined with lm s high per step cost makes its computational burden quite high. to reduce this burden we trained a multilayer perceptron mlp as a realtime localizer. we used an analytical model of quasistatic electromagnetic propagation through a spherical head to map randomly chosen dipoles to sensor activities according to the sensor geometry of a 4d neuroimaging neuromag 122 meg system and trained a mlp to invert this mapping in the absence of noise or in the presence of various sorts of noise such as white gaussian noise correlated noise or real brain noise. a mlp structure was chosen to trade off computation and accuracy. this mlp was trained four times with each type of noise. we measured the effects of initial guesses on lm performance which motivated a hybrid mlp start lm method in which the trained mlp initializes lm. we also compared the localization performance of lm mlps and hybrid mlp start lms for realistic brain signals. trained mlps are much faster than other methods while the hybrid mlp start lms are faster and more accurate than fixed 4 start lm. in particular the hybrid mlp start lm initialized by a mlp trained with the real brain noise dataset is 60 times faster and is comparable in accuracy to random 20 start lm and this hybrid system localization error 0 28 cm computation time 36 ms shows almost as good performance as optimal 1 start lm localization error 0 23 cm computation time 22 ms which initializes lm with the correct dipole location. mlps trained with noise perform better than the mlp trained without noise and the mlp trained with real brain noise is almost as good an initial guesser for lm as the correct dipole location.
inspec,train_939,image reconstruction from fan beam projections on less than a short scan. this work is concerned with 2d image reconstruction from fan beam projections. it is shown that exact and stable reconstruction of a given region of interest in the object does not require all lines passing through the object to be measured. complete non truncated fan beam projections provide sufficient information for reconstruction when every line passing through the region of interest intersects the vertex path in a non tangential way. the practical implications of this condition are discussed and a new filtered backprojection algorithm is derived for reconstruction. experiments with computer simulated data are performed to support the mathematical results.
inspec,train_94,gearing up for cls bank. continuous linked settlement a dream of the foreign exchange community for years may finally become a reality by the end of 2002.
inspec,train_940,tools for the analysis of dose optimization. i effect volume histogram. with the advent of dose optimization algorithms predominantly for intensity modulated radiotherapy imrt computer software has progressed beyond the point of being merely a tool at the hands of an expert and has become an active independent mediator of the dosimetric conflicts between treatment goals and risks. to understand and control the internal decision finding as well as to provide means to influence it a tool for the analysis of the dose distribution is presented which reveals the decision making process performed by the algorithm. the internal trade offs between partial volumes receiving high or low doses are driven by functions which attribute a weight to each volume element. the statistics of the distribution of these weights is cast into an effect volume histogram evh in analogy to dose volume histograms. the analysis of the evh reveals which traits of the optimum dose distribution result from the defined objectives and which are a random consequence of under or misspecification of treatment goals. the evh can further assist in the process of finding suitable objectives and balancing conflicting objectives. if biologically inspired objectives are used the evh shows the distribution of local dose effect relative to the prescribed level.
inspec,train_941,option pricing formulas based on a non gaussian stock price model. options are financial instruments that depend on the underlying stock. we explain their non gaussian fluctuations using the nonextensive thermodynamics parameter q. a generalized form of the black scholes bs partial differential equation 1973 and some closed form solutions are obtained. the standard bs equation q 1 which is used by economists to calculate option prices requires multiple values of the stock volatility known as the volatility smile. using q 1 5 which well models the empirical distribution of returns we get a good description of option prices using a single volatility.
inspec,train_942,micro optical realization of arrays of selectively addressable dipole traps a scalable configuration for quantum computation with atomic qubits. we experimentally demonstrate novel structures for the realization of registers of atomic qubits we trap neutral atoms in one and two dimensional arrays of far detuned dipole traps obtained by focusing a red detuned laser beam with a microfabricated array of microlenses. we are able to selectively address individual trap sites due to their large lateral separation of 125 mu m. we initialize and read out different internal states for the individual sites. we also create two interleaved sets of trap arrays with adjustable separation as required for many proposed implementations of quantum gate operations.
inspec,train_943,implementation of universal quantum gates based on nonadiabatic geometric phases. we propose an experimentally feasible scheme to achieve quantum computation based on nonadiabatic geometric phase shifts in which a cyclic geometric phase is used to realize a set of universal quantum gates. physical implementation of this set of gates is designed for josephson junctions and for nmr systems. interestingly we find that the nonadiabatic phase shift may be independent of the operation time under appropriate controllable conditions. a remarkable feature of the present nonadiabatic geometric gates is that there is no intrinsic limitation on the operation time.
inspec,train_944,conditions for the local manipulation of gaussian states. we present a general necessary and sufficient criterion for the possibility of a state transformation from one mixed gaussian state to another of a bipartite continuous variable system with two modes. the class of operations that will be considered is the set of local gaussian completely positive trace preserving maps.
inspec,train_945,testing statistical bounds on entanglement using quantum chaos. previous results indicate that while chaos can lead to substantial entropy production thereby maximizing dynamical entanglement this still falls short of maximality. random matrix theory modeling of composite quantum systems investigated recently entails a universal distribution of the eigenvalues of the reduced density matrices. we demonstrate that these distributions are realized in quantized chaotic systems by using a model of two coupled and kicked tops. we derive an explicit statistical universal bound on entanglement which is also valid for the case of unequal dimensionality of the hilbert spaces involved and show that this describes well the bounds observed using composite quantized chaotic systems such as coupled tops.
inspec,train_946,entanglement measures with asymptotic weak monotonicity as lower upper bound for the entanglement of cost distillation. we propose entanglement measures with asymptotic weak monotonicity. we show that a normalized form of entanglement measures with the asymptotic weak monotonicity are lower upper bound for the entanglement of cost distillation.
inspec,train_947,the fully entangled fraction as an inclusive measure of entanglement applications. characterizing entanglement in all but the simplest case of a two qubit pure state is a hard problem even understanding the relevant experimental quantities that are related to entanglement is difficult. it may not be necessary however to quantify the entanglement of a state in order to quantify the quantum information processing significance of a state. it is known that the fully entangled fraction has a direct relationship to the fidelity of teleportation maximized under the actions of local unitary operations. in the case of two qubits we point out that the fully entangled fraction can also be related to the fidelities maximized under the actions of local unitary operations of other important quantum information tasks such as dense coding entanglement swapping and quantum cryptography in such a way as to provide an inclusive measure of these entanglement applications. for two qubit systems the fully entangled fraction has a simple known closed form expression and we establish lower and upper bounds of this quantity with the concurrence. this approach is readily extendable to more complicated systems.
inspec,train_948,pairwise thermal entanglement in the n qubit n or 5 heisenberg xx chain. we have calculated the concurrence of the pairwise thermal entanglement for the four qubit and five qubit heisenberg xx chain. it is found that there is a great difference between the even qubit and the odd qubit chain in the aspect of the critical temperature and of the existence of the entanglement for the case of the qubit number n no more than 5.
inspec,train_949,reply to comment on teleportation of an unknown state by w state phys. lett. a 300 2002 324. in our letter see ibid vol. 296 p 161 2002 the main question we consider is whether a general three particle w state can be used to realize the teleportation of an unknown qubit state. we give the positive answer to this question in our letter and show that w state can be used to realize to do that probabilistically. we also discuss how to do it in detail in our letter. in the previous comment see ibid vol. 300 p 324 2002 authors check carefully the mathematics calculation of our letter find and point out a simple mathematics error about normalization coefficient of eq. 1. this mathematics error induces the incorrect probability calculation of eq. 6 and also an incorrect claim in first part of our letter.
inspec,train_95,sia shelves t 1 decision till 2004. the securities industry association has decided that a move to t 1 is more than the industry can handle right now. stp however will remain a focus.
inspec,train_950,quantum sensitive dependence. wave functions of bounded quantum systems with time independent potentials being almost periodic functions can not have time asymptotics as in classical chaos. however bounded quantum systems with time dependent interactions as used in quantum control may have continuous spectrum and the rate of growth of observables is an issue of both theoretical and practical concern. rates of growth in quantum mechanics are discussed by constructing quantities with the same physical meaning as those involved in the classical lyapunov exponent. a generalized notion of quantum sensitive dependence is introduced and the mathematical structure of the operator matrix elements that correspond to different types of growth is characterized.
inspec,train_951,how to drive strategic innovation law firms. innovation. it has everything to do with organization and attitude. marginal improvement is n t enough anymore. convert your problem solving skills into a new value for the entire firm. 10 initiatives.
inspec,train_953,take it to the next level law firm innovation. it s called innovating. our clients do it. our culture worships it. our future hinges on it. why is it so difficult in law firms. how can we make it easier. viva la difference.
inspec,train_954,caring for your new lawyers. in any given year a striking number of lawyers are in a state of flux from newly minted law school graduates looking for their first job to senior litigators migrating to new challenges with new firms. the one certainty is that lawyers new to any firm need care and feeding in myriad ways. all of them need to know and understand three things 1 the firm s culture 2 the resources available to help them develop their practices and 3 where to get help and guidance for research and practice purposes. obtaining a thorough understanding of a new firm s workings may be the greatest research project lawyers face. how can a firm help its new lawyers learn what they need to know. to offer an example here are programs in place at my firm.
inspec,train_955,from the dos dog days to e filing law firms. the poster child for a successful e filing venture is the case management and electronic case file system now rolling through the district and bankruptcy courts. a project of the administrative office of the united states courts cm ecf is a loud proponent of the benefits of the pdf approach and it has a full head of steam. present plans are for all federal courts to implement cm ecf by 2005. that means a radical shift in methodology and tools for a lot of lawyers. it also means that you should get cozy with acrobat real soon.
inspec,train_956,do you see what i see. visual technology in law firms. think of how well done computer presentations can aid in the learning experience. they are however less common in client meetings settlement conferences and the courtroom. and you have to wonder why when the same benefits of attention focus and visual learning apply in those legal communication settings. the software and hardware components are easy to use and they re increasingly affordable to boot. the next time you need to convey a point to an audience be it one person or many think of how you might benefit from the visual impact available through presentation software like powerpoint. anyone will understand you more easily when assisted by visual input and it may make all the difference in reaching visual focused learners.
inspec,train_957,a blog in every law firm. you do n t know today what you ll want to know next year. rather than trying to solve that problem focus on providing simple tools to users that create valuable content across the firm. individual contributions will be more visible and you will have a searchable archive of your institutional memory and a simplified process for ensuring everyone is up to speed. whether you embrace weblogs for their individual or institutional benefits one thing is certain they will become powerful tools for those who seek ways to more efficiently and intelligently manage information.
inspec,train_958,efficient combinational verification using overlapping local bdds and a hash table. we propose a novel methodology that combines local bdds binary decision diagrams with a hash table for very efficient verification of combinational circuits. the main purpose of this technique is to remove the considerable overhead associated with case by case verification of internal node pairs in typical internal correspondence based verification methods. two heuristics based on the number of structural levels of circuitry looked at and the total number of nodes in the bdd manager are used to control the bdd sizes and introduce new cutsets based on already found equivalent nodes. we verify the iscas85 benchmark circuits and demonstrate significant speedup over existing methods. we also verify several hard industrial circuits and show our superiority in extracting internal equivalences.
inspec,train_959,silicon debug of a powerpc tm microprocessor using model checking. when silicon is available newly designed microprocessors are tested in specially equipped hardware laboratories where real applications can be run at hardware speeds. however the large volumes of code being run plus the limited access to the internal nodes of the chip make it very difficult to characterize the nature of any failures that occur. we describe how temporal logic model checking was used to quickly characterize a design error exhibited during hardware testing of a powerpc microprocessor. we outline the conditions under which model checking can efficiently characterize such failures and show how the particular error we detected could have been revealed early in the design cycle by model checking a short and simple correctness specification. we discuss the implications of this for verification methodologies over the full design cycle.
inspec,train_96,oms battle heating up as chicago equity ousts longview for macgregor. chicago equity partners llc has gone into full production with macgregor s financial trading platform. this marks a concentrated effort to achieve straight through processing.
inspec,train_960,bisimulation minimization and symbolic model checking. state space minimization techniques are crucial for combating state explosion. a variety of explicit state verification tools use bisimulation minimization to check equivalence between systems to minimize components before composition or to reduce a state space prior to model checking. experimental results on bisimulation minimization in symbolic model checking contexts however are mixed. we explore bisimulation minimization as an optimization in symbolic model checking of invariance properties. we consider three bisimulation minimization algorithms. from each we produce a bdd based model checker for invariant properties and compare this model checker to a conventional one based on backwards reachability. our comparisons both theoretical and experimental suggest that bisimulation minimization is not viable in the context of invariance verification because performing the minimization requires as many if not more computational resources as model checking the unminimized system through backwards reachability.
inspec,train_961,modular and visual specification of hybrid systems an introduction to hycharts. visual description techniques are particularly important for the design of hybrid systems because specifications of such systems usually have to be discussed between engineers from a number of different disciplines. modularity is vital for hybrid systems not only because it allows to handle large systems but also because it permits to think in terms of components which is familiar to engineers. based on two different interpretations for hierarchic graphs and on a clear hybrid computation model we develop hycharts. hycharts consist of two modular visual formalisms one for the specification of the architecture and one for the specification of the behavior of hybrid systems. the operators on hierarchic graphs enable us to give a surprisingly simple denotational semantics for many concepts known from statechart like formalisms. due to a very general composition operator hycharts can easily be composed with description techniques from other engineering disciplines. such heterogeneous system specifications seem to be particularly appropriate for hybrid systems because of their interdisciplinary character.
inspec,train_962,optimal control using the transport equation the liouville machine. transport theory describes the scattering behavior of physical particles such as photons. here we show how to connect this theory to optimal control theory and to adaptive behavior of agents embedded in an environment. environments and tasks are defined by physical boundary conditions. given some task we compute a set of probability densities on continuous state and action and time. from these densities we derive an optimal policy such that for all states the most likely action maximizes the probability of reaching a predefined goal state. liouville s conservation theorem tells us that the conditional density at time t state s and action a must equal the density at t dt s ds a da. discretization yields a linear system that can be solved directly and whose solution corresponds to an optimal policy. discounted reward schemes are incorporated naturally by taking the laplace transform of the equations. the liouville machine quickly solves rather complex maze problems.
inspec,train_963,a computational model of learned avoidance behavior in a one way avoidance experiment. we present a computational model of learned avoidance behavior in a one way avoidance experiment. our model employs the reinforcement learning paradigm and a temporal difference algorithm to implement both classically conditioned and instrumentally conditioned components. the role of the classically conditioned component is to develop an expectation of future benefit that is a function of the learning system s state and action. competition among the instrumentally conditioned components determines the overt behavior generated by the learning system. our model displays in simulation the reduced latency of the avoidance behavior during learning with continuing trials and the resistance to extinction of the avoidance response. these results are consistent with experimentally observed animal behavior. our model extends the traditional two process learning mechanism of mowrer 1947 by explicitly defining the mechanisms of proprioceptive feedback an internal clock and generalization over the action space.
inspec,train_964,modeling group foraging individual suboptimality interference and a kind of matching. a series of agent based models support the hypothesis that behaviors adapted to a group situation may be suboptimal or irrational when expressed by an isolated individual. these models focus on two areas of current concern in behavioral ecology and experimental psychology the interference function which relates the intake rate of a focal forager to the density of conspecifics and the matching law which formalizes the observation that many animals match the frequency of their response to different stimuli in proportion to the reward obtained from each stimulus type. each model employs genetic algorithms to evolve foraging behaviors for multiple agents in spatially explicit environments structured at the level of situated perception and action. a second concern of the article is to extend the understanding of both matching and interference per se by modeling at this level.
inspec,train_965,sliding mode control of chaos in the cubic chua s circuit system. in this paper a sliding mode controller is applied to control the cubic chua s circuit system. the sliding surface of this paper used is one dimension higher than the traditional surface and guarantees its passage through the initial states of the controlled system. therefore using the characteristic of this sliding mode we aim to design a controller that can meet the desired specification and use less control energy by comparing with the result in the current existing literature. the results show that the proposed controller can steer chua s circuit system to the desired state without the chattering phenomenon and abrupt state change.
inspec,train_966,controlling in between the lorenz and the chen systems. this letter investigates a new chaotic system and its role as a joint function between two complex chaotic systems the lorenz and the chen systems using a simple variable constant controller. with the gradual tuning of the controller the controlled system evolves from the canonical lorenz attractor to the chen attractor through the new transition chaotic attractor. this evolving procedure reveals the forming mechanisms of all similar and closely related chaotic systems and demonstrates that a simple control technique can be very useful in generating and analyzing some complex chaotic dynamical phenomena.
inspec,train_967,on the relationship between parametric variation and state feedback in chaos control. in this letter we study the popular parametric variation chaos control and state feedback methodologies in chaos control and point out for the first time that they are actually equivalent in the sense that there exist diffeomorphisms that can convert one to the other for most smooth chaotic systems. detailed conversions are worked out for typical discrete chaotic maps logistic henon and continuous flows rossler lorenz for illustration. this unifies the two seemingly different approaches from the physics and the engineering communities on chaos control. this new perspective reveals some new potential applications such as chaos synchronization and normal form analysis from a unified mathematical point of view.
inspec,train_968,stabilization of global invariant sets for chaotic systems an energy based control approach. this paper presents a new control approach for steering trajectories of three dimensional nonlinear chaotic systems towards stable stationary states or time periodic orbits. the proposed method mainly consists in a sliding mode based control design that is extended by an explicit consideration of system energy as basis for both controller design and system stabilization. the control objective is then to regulate the energy with respect to a shaped nominal representation implicitly related to system trajectories. in this paper we establish some theoretical results to introduce the control design approach referred to as energy based sliding mode control. then some capabilities of the proposed approach are illustrated through examples related to the chaotic circuit of chua.
inspec,train_969,controlled projective synchronization in nonpartially linear chaotic systems. projective synchronization ps in which the state vectors synchronize up to a scaling factor is usually observable only in partially linear systems. we show that ps could by means of control be extended to general classes of chaotic systems with nonpartial linearity. performance of ps may also be manipulated by controlling the scaling factor to any desired value. in numerical experiments we illustrate the applications to a rossler system and a chua s circuit. the feasibility of the control for high dimensional systems is demonstrated in a hyperchaotic system.
inspec,train_97,philadelphia stock exchange taps timesten for database technology. phlx rolls out equity options autoquote system to traders as the first application to leverage its enhanced data architecture.
inspec,train_970,complex dynamics in nearly symmetric three cell cellular neural networks. the paper introduces a class of third order nonsymmetric cellular neural networks cnns and shows through computer simulations that they undergo a cascade of period doubling bifurcations which leads to the birth of a large size complex attractor. a major point is that these bifurcations and complex dynamics happen in a small neighborhood of a particular cnn with a symmetric interconnection matrix.
inspec,train_971,homogenization in l sup infinity. homogenization of deterministic control problems with l sup infinity running cost is studied by viscosity solutions techniques. it is proved that the value function of an l sup infinity problem in a medium with a periodic micro structure converges uniformly on the compact sets to the value function of the homogenized problem as the period shrinks to 0. our main convergence result extends that of ishii stochastic analysis control optimization and applications pp 305 324 birkhauser boston boston ma 1999. to the case of a discontinuous hamiltonian. the cell problem is solved but as nonuniqueness occurs the effective hamiltonian must be selected in a careful way. the paper also provides a representation formula for the effective hamiltonian and gives illustrations to calculus of variations averaging and one dimensional problems.
inspec,train_972,voip leveraging existing cable architecture. as operators prepare to enter the voice over ip fray they are searching for ways to leverage their existing two way interactive infrastructure. there are several approaches for supporting voip on top of the core ip transport network. the one garnering the most interest especially in the united states is based on the packetcable 1 x architecture. this article discusses the packetcable based approach.
inspec,train_973,time integration of multiphase chemistry in size resolved cloud models. the existence of cloud drops leads to a transfer of chemical species between the gas and aqueous phases. species concentrations in both phases are modified by chemical reactions and by this phase transfer. the model equations resulting from such multiphase chemical systems are nonlinear highly coupled and extremely stiff. in the paper we investigate several numerical approaches for treating such processes. the droplets are subdivided into several classes. this decomposition of the droplet spectrum into classes is based on their droplet size and the amount of scavenged material inside the drops respectively. the very fast dissociations in the aqueous phase chemistry are treated as forward and backward reactions. the aqueous phase and gas phase chemistry the mass transfer between the different droplet classes among themselves and with the gas phase are integrated in an implicit and coupled manner by the second order bdf method. for this part we apply a modification of the code lsode with special linear system solvers. these direct sparse techniques exploit the special block structure of the corresponding jacobian. furthermore we investigate an approximate matrix factorization which is related to operator splitting at the linear algebra level. the sparse jacobians are generated explicitly and stored in a sparse form. the efficiency and accuracy of our time integration schemes is discussed for four multiphase chemistry systems of different complexity and for a different number of droplet classes.
inspec,train_974,extrapolation in lie groups with approximated bch formula. we present an extrapolation algorithm for the integration of differential equations in lie groups which is a suitable generalization of the well known gbs algorithm for odes. sufficiently accurate approximations to the bch formula are required to reach a given order. we give such approximations with a minimized number of commutators.
inspec,train_975,algebraic conditions for high order convergent deferred correction schemes based on runge kutta nystrom methods for second order boundary value problems. in t van hecke m van daele j comp. appl. math vol. 132 p 107 125 2001 the investigation of high order convergence of deferred correction schemes for the numerical solution of second order nonlinear two point boundary value problems not containing the first derivative is made. the derivation of the algebraic conditions to raise the increase of order by the deferred correction scheme was based on taylor series expansions. in this paper we describe a more elegant way by means of p series to obtain this necessary conditions and generalize this idea to equations of the form y  f t y y.
inspec,train_976,completion to involution and semidiscretisations. we discuss the relation between the completion to involution of linear over determined systems of partial differential equations with constant coefficients and the properties of differential algebraic equations obtained by their semidiscretisation. for a certain class of weakly over determined systems we show that the differential algebraic equations do not contain hidden constraints if and only if the original partial differential system is involutive. we also demonstrate how the formal theory can be used to obtain an existence and uniqueness theorem for smooth solutions of strongly hyperbolic systems and to estimate the drift off the constraints if an underlying equation is numerically solved. finally we show for general linear systems how the index of differential algebraic equations obtained by semidiscretisations can be predicted from the result of a completion of the partial differential system.
inspec,train_977,behavior of runge kutta discretizations near equilibria of index 2 differential algebraic systems. we analyze runge kutta discretizations applied to index 2 differential algebraic equations dae s near equilibria. we compare the geometric properties of the numerical and the exact solutions. it is shown that projected and half explicit runge kutta methods reproduce the qualitative features of the continuous system in the vicinity of an equilibrium correctly. the proof combines cut off and scaling techniques for index 2 differential algebraic equations with some invariant manifold results of schropp geometric properties of runge kutta discretizations for index 2 differential algebraic equations konstanzer schriften in mathematik und informatik 128 and classical results for discretized ordinary differential equations.
inspec,train_978,on implicit euler for high order high index daes. the implicit euler method is seldom used to solve differential algebraic equations daes of differential index r or 3 since the method in general fails to converge in the first r 2 steps after a change of stepsize. however if the differential equation is of order d r 1 or 1 an alternative variable step version of the euler method can be shown uniformly convergent. for d r 1 this variable step method is equivalent to the implicit euler except for the first r 2 steps after a change of stepsize. generalization to daes with differential equations of order d r 1 or 1 and to variable order formulas is discussed.
inspec,train_979,design analysis and testing of some parallel two step w methods for stiff systems. parallel two step w methods are linearly implicit integration methods where the s stage values can be computed in parallel. we construct methods of stage order q s and order p s with favourable stability properties. generalizations for the concepts of a and l stability are proposed and conditions for stiff accuracy are given. numerical comparisons on a shared memory computer show the efficiency of the methods especially in combination with krylov techniques for large stiff systems.
inspec,train_98,automating the compliance and supervision process. new technology enables large broker dealers to supervise and ensure compliance across multiple branches and managers.
inspec,train_980,convergence of runge kutta methods for nonlinear parabolic equations. we study time discretizations of fully nonlinear parabolic differential equations. our analysis uses the fact that the linearization along the exact solution is a uniformly sectorial operator. we derive smooth and nonsmooth data error estimates for the backward euler method and we prove convergence for strongly a v stable runge kutta methods. for the latter the order of convergence for smooth solutions is essentially determined by the stage order of the method. numerical examples illustrating the convergence estimates are presented.
inspec,train_981,basin configuration of a six dimensional model of an electric power system. as part of an ongoing project on the stability of massively complex electrical power systems we discuss the global geometric structure of contacts among the basins of attraction of a six dimensional dynamical system. this system represents a simple model of an electrical power system involving three machines and an infinite bus. apart from the possible occurrence of attractors representing pathological states the contacts between the basins have a practical importance from the point of view of the operation of a real electrical power system. with the aid of a global map of basins one could hope to design an intervention strategy to boot the power system back into its normal state. our method involves taking two dimensional sections of the six dimensional state space and then determining the basins directly by numerical simulation from a dense grid of initial conditions. the relations among all the basins are given for a specific numerical example that is choosing particular values for the parameters in our model.
inspec,train_982,abundance of mosaic patterns for cnn with spatially variant templates. this work investigates the complexity of one dimensional cellular neural network mosaic patterns with spatially variant templates on finite and infinite lattices. various boundary conditions are considered for finite lattices and the exact number of mosaic patterns is computed precisely. the entropy of mosaic patterns with periodic templates can also be calculated for infinite lattices. furthermore we show the abundance of mosaic patterns with respect to template periods and which differ greatly from cases with spatially invariant templates.
inspec,train_983,limitations of delayed state feedback a numerical study. stabilization of a class of linear time delay systems can be achieved by a numerical procedure called the continuous pole placement method michiels et al 2000. this method can be seen as an extension of the classical pole placement algorithm for ordinary differential equations to a class of delay differential equations. in michiels et al 2000 it was applied to the stabilization of a linear time invariant system with an input delay using static state feedback. in this paper we study the limitations of such delayed state feedback laws. more precisely we completely characterize the class of stabilizable plants in the 2d case. for that purpose we make use of numerical continuation techniques. the use of delayed state feedback in various control applications and the effect of its limitations are briefly discussed.
inspec,train_984,bistability of harmonically forced relaxation oscillations. relaxation oscillations appear in processes which involve transitions between two states characterized by fast and slow time scales. when a relaxation oscillator is coupled to an external periodic force its entrainment by the force results in a response which can include multiple periodicities and bistability. the prototype of these behaviors is the harmonically driven van der pol equation which displays regions in the parameter space of the driving force amplitude where stable orbits of periods 2n or 1 coexist flanked by regions of periods 2n 1 and 2n 1. the parameter regions of such bistable orbits are derived analytically for the closely related harmonically driven stoker haag piecewise discontinuous equation. the results are valid over most of the control parameter space of the system. also considered are the reasons for the more complicated dynamics featuring regions of high multiple periodicity which appear like noise between ordered periodic regions. since this system mimics in detail the less analytically tractable forced van der pol equation the results suggest extensions to situations where forced relaxation oscillations are a component of the operating mechanisms.
inspec,train_985,local activity criteria for discrete map cnn. discrete time cnn systems are studied in this paper by the application of chua s local activity principle. these systems are locally active everywhere except for one isolated parameter value. as a result nonhomogeneous spatiotemporal patterns may be induced by any initial setting of the cnn system when the strength of the system diffusion coupling exceeds a critical threshold. the critical coupling coefficient can be derived from the loaded cell impedance of the cnn system. three well known 1d map cnn s namely the logistic map cnn the magnetic vortex pinning map cnn and the spiral wave reproducing map cnn are introduced to illustrate the applications of the local activity principle. in addition we use the cell impedance to demonstrate the period doubling scenario in the logistic and the magnetic vortex pinning maps.
inspec,train_986,wavelet based level of detail representation of 3d objects. in this paper we propose a 3d object lod level of detail modeling system that constructs a mesh from range images and generates the mesh of various lod using the wavelet transform. in the initial mesh generation we use the marching cube algorithm. we modify the original algorithm to apply it to construct the mesh from multiple range images efficiently. to get the base mesh we use the decimation algorithm which simplifies a mesh with preserving the topology. finally when reconstructing new mesh which is similar to initial mesh we calculate the wavelet coefficients by using the wavelet transform. we solve the critical problem of wavelet based methods the surface crease problem by using the mesh simplification as the base mesh generation method.
inspec,train_987,proof that the election problem belongs to nf completeness problems in asynchronous distributed systems. this paper is about the hardness of the election problem in asynchronous distributed systems in which processes can crash but links are reliable. the hardness of the problem is defined with respect to the difficulty to solve it despite failures. it is shown that problems encountered in the system are classified as three classes of problems f fault tolerant nf not fault tolerant and nfc nf completeness. among those the class nfc are the hardest problems to solve. in this paper we prove that the election problem is the most difficult problem which belongs to the class nfc.
inspec,train_988,a new merging algorithm for constructing suffix trees for integer alphabets. a new approach for constructing a suffix tree t sub s for a given string s is to construct recursively a suffix tree t sub o for odd positions construct a suffix tree t sub e for even positions from t sub o and then merge t sub o and t sub e into t sub s. to construct suffix trees for integer alphabets in linear time had been a major open problem on index data structures. farach used this approach and gave the first linear time algorithm for integer alphabets. the hardest part of farach s algorithm is the merging step. in this paper we present a new and simpler merging algorithm based on a coupled bfs breadth first search. our merging algorithm is more intuitive than farach s coupled dfs depth first search merging and thus it can be easily extended to other applications.
inspec,train_989,a dynamic checkpoint scheduling scheme for fault tolerant distributed computing systems. the selection of the optimal checkpointing interval has been a very critical issue in implementing checkpointing recovery schemes for fault tolerant distributed systems. this paper presents a new scheme that allows a process to select the proper checkpointing interval dynamically. a process in the system evaluates the cost of checkpointing and possible rollback for each checkpointing interval and selects the proper time interval for the next checkpointing. unlike the other schemes the overhead incurred by both the checkpointing and rollback activities are considered for the cost evaluation and the current communication pattern is reflected in the selection of the checkpointing interval. moreover the proposed scheme requires no extra message communication for the checkpointing interval selection and can easily be incorporated into the existing checkpointing coordination schemes.
inspec,train_99,radianz and savvis look to expand service in wake of telecom scandals finance. with confidence in network providers waning radianz and savvis try to prove their stability. savvis and radianz which both specialize in providing the data extranet components of telecommunication infrastructures may see more networking doors open at investment banks brokerage houses exchanges and alternative trading systems.
inspec,train_990,pipelined broadcast with enhanced wormhole routers. this paper proposes a pipelined broadcast that broadcasts a message of size m in o m n 1 time in an n dimensional hypercube. it is based on the replication tree which is derived from reachable sets. it has greatly improved performance compared to ho kao s 1995 algorithm with the time of o m n log n 1. the communication in the broadcast uses an all port wormhole router with message replication capability. this paper includes the algorithm together with performance comparisons to previous schemes in a practical implementation.
inspec,train_991,estimation of blocking probabilities in cellular networks with dynamic channel assignment. blocking probabilities in cellular mobile communication networks using dynamic channel assignment are hard to compute for realistic sized systems. this computational difficulty is due to the structure of the state space which imposes strong coupling constraints amongst components of the occupancy vector. approximate tractable models have been proposed which have product form stationary state distributions. however for real channel assignment schemes the product form is a poor approximation and it is necessary to simulate the actual occupancy process in order to estimate the blocking probabilities. meaningful estimates of the blocking probability typically require an enormous amount of cpu time for simulation since blocking events are usually rare. advanced simulation approaches use importance sampling is to overcome this problem. we study two regimes under which blocking is a rare event low load and high cell capacity. our simulations use the standard clock sc method. for low load we propose a change of measure that we call static issc which has bounded relative error. for high capacity we use a change of measure that depends on the current state of the network occupancy. this is the dynamic issc method. we prove that this method yields zero variance estimators for single clique models and we empirically show the advantages of this method over naive simulation for networks of moderate size and traffic loads.
inspec,train_992,cross entropy and rare events for maximal cut and partition problems. we show how to solve the maximal cut and partition problems using a randomized algorithm based on the cross entropy method. for the maximal cut problem the proposed algorithm employs an auxiliary bernoulli distribution which transforms the original deterministic network into an associated stochastic one called the associated stochastic network asn. each iteration of the randomized algorithm for the asn involves the following two phases 1 generation of random cuts using a multidimensional ber p distribution and calculation of the associated cut lengths objective functions and some related quantities such as rare event probabilities 2 updating the parameter vector p on the basis of the data collected in the first phase. we show that the ber p distribution converges in distribution to a degenerated one ber p sub d  p sub d  p sub d  sub 1  p sub d n in the sense that some elements of p sub d  will be unities and the rest zeros. the unity elements of p sub d  uniquely define a cut which will be taken as the estimate of the maximal cut. a similar approach is used for the partition problem. supporting numerical results are given as well. our numerical studies suggest that for the maximal cut and partition problems the proposed algorithm typically has polynomial complexity in the size of the network.
inspec,train_993,a large deviations analysis of the transient of a queue with many markov fluid inputs approximations and fast simulation. this article analyzes the transient buffer content distribution of a queue fed by a large number of markov fluid sources. we characterize the probability of overflow at time t given the current buffer level and the number of sources in the on state. after scaling buffer and bandwidth resources by the number of sources n we can apply large deviations techniques. the transient overflow probability decays exponentially in n. in the case of exponential on off sources we derive an expression for the decay rate of the rare event probability under consideration. for general markov fluid sources we present a plausible conjecture. we also provide the most likely path from the initial state to overflow at time t. knowledge of the decay rate and the most likely path to overflow leads to i approximations of the transient overflow probability and ii efficient simulation methods of the rare event of buffer overflow. the simulation methods based on importance sampling give a huge speed up compared to straightforward simulations. the approximations are of low computational complexity and are accurate as verified by means of simulation experiments.
inspec,train_994,design and implementation of a flexible manufacturing control system using neural network. design and implementation of a sequential controller based on the concept of artificial neural networks for a flexible manufacturing system are presented. the recurrent neural network rnn type is used for such a purpose. contrary to the programmable controller an rnn based sequential controller is based on a definite mathematical model rather than depending on the experience and trial and error techniques. the proposed controller is also more flexible because it is not limited by the restrictions of the finite state automata theory. adequate guidelines of how to construct an rnn based sequential controller are presented. these guidelines are applied to different case studies. the proposed controller is tested by simulations and real time experiments. these tests prove the successfulness of the proposed controller performances. theoretical as well as experimental results are presented and discussed indicating that the proposed design procedure using elman s rnn can be effective in designing a sequential controller for event based type manufacturing systems. in addition the simulation results assure the effectiveness of the proposed controller to overcome the effect of noisy inputs.
inspec,train_995,vehicle travel time models for agv systems under various dispatching rules. the design and evaluation of agv based material handling systems are highly complex because of the randomness and the large number of variables involved. vehicle travel time is a fundamental parameter for solving various flexible manufacturing system fms design problems. this article presents stochastic vehicle travel time models for agv based material handling systems with emphasis on the empty travel times of vehicles. various vehicle dispatching rules examined here include the nearest vehicle selection rule and longest idle vehicle selection rule. a simulation experiment is used to evaluate and demonstrate the presented models.
inspec,train_996,flexible air jet tooling for vibratory bowl feeder systems. vibratory bowl feeders vbfs are machines that feed various small parts in large volume automatic assembly systems. their shortcomings like inflexibility and the propensity to jam stem from the use of mechanical orienting devices. air jet based orienting devices can be implemented to overcome these limitations. applications of passive and active air jet based orienting devices that replace conventional devices for the vbf are discussed. passive devices which reject incorrectly oriented parts are discussed first. active air jet based orienting devices are then introduced to further improve the flexibility of vbfs. since active devices reorient parts into a desired orientation the part motion under their influence is analyzed. a number of tests demonstrate the feasibility and advantages of these new orienting devices.
inspec,train_997,production capacity of flexible manufacturing systems with fixed production ratios. determining the production capacity of flexible manufacturing systems is a very important issue in the design of such systems. we propose an approach for determining the production capacity i e the maximum production rate of a flexible manufacturing system with several part types dedicated pallets and fixed production ratios among the different part types. we show that the problem reduces to the determination of a single parameter for which we propose an iterative procedure. simulation or approximate analytical techniques can be used as the building block performance evaluation technique in the iterative procedure.
inspec,train_998,discreteness and relevance a reply to roman poznanski. in reply to poznanski see ibid p 435 2002 on discreteness and relevance eliasmith claims that all of the concerns voiced by poznanski in his reply fail to offer a serious challenge to the idea that continuity is irrelevant to a good understanding of cognitive systems. eliasmith hopes that it is evident that he does not claim that the process in neural systems is discrete but rather that a complete characterization of the process can be discrete these of course are significantly different claims.
inspec,train_999,the importance of continuity a reply to chris eliasmith. in his reply to eliasmith see ibid vol 11 p 417 26 2001 poznanski considers how the notion of continuity of dynamic representations serves as a beacon for an integrative neuroscience to emerge. he considers how the importance of continuity has come under attack from eliasmith 2001 who claims i continuous nature of neurons is not relevant to the information they process and ii continuity is not important for understanding cognition because the various sources of noise introduce uncertainty into spike arrival times so encoding and decoding spike trains must be discrete at some level.
inspec,test_193,twenty years of the literature on acquiring out of print materials. this article reviews the last two and a half decades of literature on acquiring out of print materials to assess recurring issues and identify changing practices. the out of print literature is uniform in its assertion that libraries need to acquire o p materials to replace worn or damaged copies to replace missing copies to duplicate copies of heavily used materials to fill gaps in collections to strengthen weak collections to continue to develop strong collections and to provide materials for new courses new programs and even entire new libraries.
inspec,test_1930,a new method of systemological analysis coordinated with the procedure of object oriented design. ii. for pt i. see vestn. khgpu no 81 p 15 18 2000. the paper presents the results of development of an object oriented systemological method used to design complex systems. a formal system representation as well as an axiomatics of the calculus of systems as functional flow type objects based on a node function object class hierarchy are proposed. a formalized nfo ufo analysis algorithm and case tools used to support it are considered.
inspec,test_1931,mathematical fundamentals of constructing fuzzy bayesian inference techniques. problems and an associated technique for developing a bayesian approach to decision making in the case of fuzzy data are presented. the concept of fuzzy and pseudofuzzy quantities is introduced and main operations with pseudofuzzy quantities are considered. the basic relationships and the principal concepts of the bayesian decision procedure based on the modus ponens rule are proposed. some problems concerned with the practical realization of the fuzzy bayesian method are considered.
inspec,test_1932,solution of the safe problem on 0 1 matrices. a safe problem with mn locks is studied. it is reduced to a system of linear equations in the modulo 2 residue class. there are three possible variants defined by the numbers m and n evenness with only one of them having a solution. in two other cases correction of the initial state of the safe insuring a solution is proposed.
inspec,test_1933,accelerated simulation of the steady state availability of non markovian systems. a general accelerated simulation method for evaluation of the steady state availability of non markovian systems is proposed. it is applied to the investigation of a class of systems with repair. numerical examples are given.
inspec,test_1934,computational finite element schemes for optimal control of an elliptic system with conjugation conditions. new optimal control problems are considered for distributed systems described by elliptic equations with conjugate conditions and a quadratic minimized function. highly accurate computational discretization schemes are constructed for the case where a feasible control set u sub delta coincides with the full hilbert space u of controls.
inspec,test_1935,identification of states of complex systems with estimation of admissible measurement errors on the basis of fuzzy information. the problem of identification of states of complex systems on the basis of fuzzy values of informative attributes is considered. some estimates of a maximally admissible degree of measurement error are obtained that make it possible using the apparatus of fuzzy set theory to correctly identify the current state of a system.
inspec,test_1936,a new approach to the decomposition of boolean functions by the method of q partitions. ii. repeated decomposition. for pt i. see upr. sist. mash no 6 p 29 42 1999. a new approach to the decomposition of boolean functions that depend on n variables and are represented in various forms is considered. the approach is based on the method of q partitioning of minterms and on the introduced concept of a decomposition clone. the theorem on simple disjunctive decomposition of full and partial functions is formulated. the approach proposed is illustrated by examples.
inspec,test_1937,nonlinear extrapolation algorithm for realization of a scalar random process. a method of construction of a nonlinear extrapolation algorithm is proposed. this method makes it possible to take into account any nonlinear random dependences that exist in an investigated process and are described by mixed central moment functions. the method is based on the v s pugachev canonical decomposition apparatus. as an example the problem of nonlinear extrapolation is solved for a moment function of third order.
inspec,test_1938,a method for solution of systems of linear algebraic equations with m dimensional lambda matrices. a system of linear algebraic equations with m dimensional lambda matrices is considered. the proposed method of searching for the solution of this system lies in reducing it to a numerical system of a special kind.
inspec,test_1939,compatibility of systems of linear constraints over the set of natural numbers. criteria of compatibility of a system of linear diophantine equations strict inequations and nonstrict inequations are considered. upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. these criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types of systems and systems of mixed types.
inspec,test_194,books on demand just in time acquisitions. the purdue university libraries interlibrary loan unit proposed a pilot project to purchase patrons loan requests from amazon. com lend them to the patrons and then add the titles to the collection. staff analyzed previous monograph loans developed ordering criteria implemented the proposal as a pilot project for six months and evaluated the resulting patron comments statistics and staff perceptions. as a result of enthusiastic patron comments and a review of the project statistics the program was extended.
inspec,test_1940,new lower bounds of the size of error correcting codes for the z channel. optimization problems on graphs are formulated to obtain new lower bounds of the size of error correcting codes for the z channel.
inspec,test_1941,descriptological foundations of programming. descriptological foundations of programming are constructed. an explication of the concept of a descriptive process is given. the operations of introduction and elimination of abstraction at the level of processes are refined. an intensional concept of a bipolar function is introduced. an explication of the concept of introduction and extraction of abstraction at the bipole level is given. on this basis a complete set of descriptological operations is constructed.
inspec,test_1942,precoded ofdm with adaptive vector channel allocation for scalable video transmission over frequency selective fading channels. orthogonal frequency division multiplexing ofdm has been applied in broadband wireline and wireless systems for high data rate transmission where severe intersymbol interference isi always occurs. the conventional ofdm system provides advantages through conversion of an isi channel into isi free subchannels at multiple frequency bands. however it may suffer from channel spectral nulls and heavy data rate overhead due to cyclic prefix insertion. previously a new ofdm framework the precoded ofdm has been proposed to mitigate the above two problems through precoding and conversion of an isi channel into isi free vector channels. in this paper we consider the application of the precoded ofdm system to efficient scalable video transmission. we propose to enhance the precoded ofdm system with adaptive vector channel allocation to provide stronger protection against errors to more important layers in the layered bit stream structure of scalable video. the more critical layers or equivalently the lower layers are allocated vector channels of higher transmission quality. the channel quality is characterized by frobenius norm metrics based on channel estimation at the receiver. the channel allocation information is fed back periodically to the transmitter through a control channel. simulation results have demonstrated the robustness of the proposed scheme to noise and fading inherent in wireless channels.
inspec,test_1943,i wap an intelligent wap site management system. the popularity regarding wireless communications is such that more and more wap sites have been developed with wireless markup language wml. meanwhile to translate hypertext markup language html pages into proper wml ones becomes imperative since it is difficult for wap users to read most contents designed for pc users via their mobile phone screens. however for those sites that have been maintained with hypertext markup language html considerable time and manpower costs will be incurred to rebuild them with wml. in this paper we propose an intelligent wap site management system to cope with these problems. with the help of the intelligent management system the original contents of html web sites can be automatically translated to proper wap content in an efficient way. as a consequence the costs associated with maintaining wap sites could be significantly reduced. the management system also allows the system manager to define the relevance of numerals and keywords for removing unimportant or meaningless contents. the original contents will be reduced and reorganized to fit the size of mobile phone screens thus reducing the communication cost and enhancing readability. numerical results gained through various experiments have evinced the effective performance of the wap management system.
inspec,test_1944,a framework of electronic tendering for government procurement a lesson learned in taiwan. to render government procurement efficient transparent nondiscriminating and accountable an electronic government procurement system is required. accordingly taiwan government procurement law tgpl states that suppliers may employ electronic devices to forward a tender. this investigation demonstrates how the electronic government procurement system functions and reengineers internal procurement processes which in turn benefits both government bodies and vendors. the system features explored herein include posting receiving bids via the internet vendor registration certificate authorization contract development tools bid request for proposal rfp development online bidding and online payment all of which can be integrated easily within most existing information infrastructures.
inspec,test_1945,the development of a mobile manipulator imaging system for bridge crack inspection. a mobile manipulator imaging system is developed for the automation of bridge crack inspection. during bridge safety inspections an eyesight inspection is made for preliminary evaluation and screening before a more precise inspection. the inspection for cracks is an important part of the preliminary evaluation. currently the inspectors must stand on the platform of a bridge inspection vehicle or a temporarily erected scaffolding to examine the underside of a bridge. however such a procedure is risky. to help automate the bridge crack inspection process we installed two ccd cameras and a four axis manipulator system on a mobile vehicle. the parallel cameras are used to detect cracks. the manipulator system is equipped with binocular charge coupled devices ccd for examining structures that may not be accessible to the eye. the system also reduces the danger of accidents to the human inspectors. the manipulator system consists of four arms. balance weights are placed at the ends of arms 2 and 4 respectively to maintain the center of gravity during operation. mechanically arms 2 and 4 can revolve smoothly. experiments indicated that the system could be useful for bridge crack inspections.
inspec,test_1946,integrating building management system and facilities management on the internet. recently it is of great interest to adopt the internet intranet to develop building management systems bms and facilities management systems fms. this paper addresses two technical issues the web based access including database integration and the integration of bms and fms. these should be addressed for accessing bms remotely via the internet integrating control networks using the internet protocols and infrastructures and using internet intranet for building facilities management. an experimental internet enabled system that integrates building and facilities management systems has been developed and tested. this system integrated open control networks with the internet and is developed utilizing the embedded web server the pc web server and the distributed component object model dcom software development technology on the platform of an open control network. three strategies for interconnecting bms local networks via internet intranet are presented and analyzed.
inspec,test_1947,modelling user acceptance of building management systems. this study examines user acceptance of building management systems bms using a questionnaire survey. these systems are crucial for optimising building performance and yet it has been widely reported that users are not making full use of their systems facilities. established models of technology acceptance have been employed in this research and the positive influence of user perceptions of ease of use and compatibility has been demonstrated. previous research has indicated differing levels of importance of perceived ease of use relative to other factors. here perceived ease of use is shown generally to be more important though the balance between this and compatibility is moderated by the user perceptions of voluntariness.
inspec,test_1948,estimating populations for collective dose calculations. the collective dose provides an estimate of the effects of facility operations on the public based on an estimate of the population in the area. geographic information system software electronic population data resources and a personal computer were used to develop estimates of population within 80 km radii of two sites.
inspec,test_1949,a new graphical user interface for fast construction of computation phantoms and mcnp calculations application to calibration of in vivo measurement systems. reports on a new utility for development of computational phantoms for monte carlo calculations and data analysis for in vivo measurements of radionuclides deposited in tissues. the individual properties of each worker can be acquired for a rather precise geometric representation of his her anatomy which is particularly important for low energy gamma ray emitting sources such as thorium uranium plutonium and other actinides. the software enables automatic creation of an mcnp input data file based on scanning data. the utility includes segmentation of images obtained with either computed tomography or magnetic resonance imaging by distinguishing tissues according to their signal brightness and specification of the source and detector. in addition a coupling of individual voxels within the tissue is used to reduce the memory demand and to increase the calculational speed. the utility was tested for low energy emitters in plastic and biological tissues as well as for computed tomography and magnetic resonance imaging scanning information.
inspec,test_195,the acquisition of out of print music. non specialist librarians are alerted to factors important in the successful acquisition of out of print music both scholarly editions and performance editions. the appropriate technical music vocabulary the music publishing industry specialized publishers and vendors and methods of acquisition of out of print printed music are introduced and the need for familiarity with them is emphasized.
inspec,test_1950,general solution of a density functionally gradient piezoelectric cantilever and its applications. we have used the plane strain theory of transversely isotropic bodies to study a piezoelectric cantilever. in order to find the general solution of a density functionally gradient piezoelectric cantilever we have used the inverse method i e the airy stress function method. we have obtained the stress and induction functions in the form of polynomials as well as the general solution of the beam. based on this general solution we have deduced the solutions of the cantilever under different loading conditions. furthermore as applications of this general solution in engineering we have studied the tip deflection and blocking force of a piezoelectric cantilever actuator. finally we have addressed a method to determine the density distribution profile for a given piezoelectric material.
inspec,test_1951,recording quantum properties of light in a long lived atomic spin state towards quantum memory. we report an experiment on mapping a quantum state of light onto the ground state spin of an ensemble of cs atoms with the lifetime of 2 ms recording of one of the two quadrature phase operators of light is demonstrated with vacuum and squeezed states of light. the sensitivity of the mapping procedure at the level of approximately 1 photon sec per hz is shown. the results pave the road towards complete storing both quadrature phase observables quantum memory for gaussian states of light. the experiment also sheds new light on fundamental limits of sensitivity of the magneto optical resonance method.
inspec,test_1952,comprehensive encoding and decoupling solution to problems of decoherence and design in solid state quantum computing. proposals for scalable quantum computing devices suffer not only from decoherence due to the interaction with their environment but also from severe engineering constraints. here we introduce a practical solution to these major concerns addressing solid state proposals in particular. decoherence is first reduced by encoding a logical qubit into two qubits then completely eliminated by an efficient set of decoupling pulse sequences. the same encoding removes the need for single qubit operations which pose a difficult design constraint. we further show how the dominant decoherence processes can be identified empirically in order to optimize the decoupling pulses.
inspec,test_1953,social percolation and the influence of mass media. in the marketing model of solomon and weisbuch people buy a product only if their neighbours tell them of its quality and if this quality is higher than their own quality expectations. now we introduce additional information from the mass media which is analogous to the ghost field in percolation theory. the mass media shift the percolative phase transition observed in the model and decrease the time after which the stationary state is reached.
inspec,test_1954,estimating long range dependence finite sample properties and confidence intervals. a major issue in financial economics is the behavior of asset returns over long horizons. various estimators of long range dependence have been proposed. even though some have known asymptotic properties it is important to test their accuracy by using simulated series of different lengths. we test r s analysis detrended fluctuation analysis and periodogram regression methods on samples drawn from gaussian white noise. the dfa statistics turns out to be the unanimous winner. unfortunately no asymptotic distribution theory has been derived for this statistics so far. we were able however to construct empirical i e approximate confidence intervals for all three methods. the obtained values differ largely from heuristic values proposed by some authors for the r s statistics and are very close to asymptotic values for the periodogram regression method.
inspec,test_1955,simulation of evacuation processes using a bionics inspired cellular automaton model for pedestrian dynamics. we present simulations of evacuation processes using a recently introduced cellular automaton model for pedestrian dynamics. this model applies a bionics approach to describe the interaction between the pedestrians using ideas from chemotaxis. here we study a rather simple situation namely the evacuation from a large room with one or two doors. it is shown that the variation of the model parameters allows to describe different types of behaviour from regular to panic. we find a non monotonic dependence of the evacuation times on the coupling constants. these times depend on the strength of the herding behaviour with minimal evacuation times for some intermediate values of the couplings i e a proper combination of herding and use of knowledge about the shortest way to the exit.
inspec,test_1956,dynamical transition to periodic motions of a recurrent bus induced by nonstops. we study the dynamical behavior of a recurrent bus on a circular route with many bus stops when the recurrent bus passes some bus stops without stopping. the recurrent time one period is described in terms of a nonlinear map. it is shown that the recurrent bus exhibits the complex periodic behaviors. the dynamical transitions to periodic motions occur by increasing nonstops. the periodic motions depend on the property of an attractor of the nonlinear map. the period n of the attractor varies sensitively with the number of nonstops.
inspec,test_1957,the two populations cellular automata model with predation based on the penna model. in penna s 1995 single species asexual bit string model of biological ageing the verhulst factor has too strong a restraining effect on the development of the population. danuta makowiec gave an improved model based on the lattice where the restraining factor of the four neighbours take the place of the verhulst factor. here we discuss the two populations penna model with predation on the planar lattice of two dimensions. a cellular automata model containing movable wolves and sheep has been built. the results show that both the quantity of the wolves and the sheep fluctuate in accordance with the law that one quantity increases while the other one decreases.
inspec,test_1958,option pricing from path integral for non gaussian fluctuations. natural martingale and application to truncated levy distributions. within a path integral formalism for non gaussian price fluctuations we set up a simple stochastic calculus and derive a natural martingale for option pricing from the wealth balance of options stocks and bonds. the resulting formula is evaluated for truncated levy distributions.
inspec,test_1959,quantum market games. we propose a quantum like description of markets and economics. the approach has roots in the recently developed quantum game theory.
inspec,test_196,on the emergence of rules in neural networks. a simple associationist neural network learns to factor abstract rules i e grammars from sequences of arbitrary input symbols by inventing abstract representations that accommodate unseen symbol sets as well as unseen but similar grammars. the neural network is shown to have the ability to transfer grammatical knowledge to both new symbol vocabularies and new grammars. analysis of the state space shows that the network learns generalized abstract structures of the input and is not simply memorizing the input strings. these representations are context sensitive hierarchical and based on the state variable of the finite state machines that the neural network has learned. generalization to new symbol sets or grammars arises from the spatial nature of the internal representations used by the network allowing new symbol sets to be encoded close to symbol sets that have already been learned in the hidden unit space of the network. the results are counter to the arguments that learning algorithms based on weight adaptation after each exemplar presentation such as the long term potentiation found in the mammalian nervous system can not in principle extract symbolic knowledge from positive examples as prescribed by prevailing human linguistic theory and evolutionary psychology.
inspec,test_1960,streaming disruptive interference and power law behavior in the exit dynamics of confined pedestrians. we analyze the exit dynamics of pedestrians who are initially confined in a room. pedestrians are modeled as cellular automata and compete to escape via a known exit at the soonest possible time. a pedestrian could move forward backward left or right within each iteration time depending on adjacent cell vacancy and in accordance with simple rules that determine the compulsion to move and physical capability relative to his neighbors. the arching signatures of jamming were observed and the pedestrians exited in bursts of various sizes. power law behavior is found in the burst size frequency distribution for exit widths w greater than one cell dimension w 1. the slope of the power law curve varies with w from 1 3092 w 2 to 1 0720 w 20. streaming which is a diffusive behavior arises in large burst sizes and is more likely in a single exit room with w 1 and leads to a counterintuitive result wherein an average exit throughput q is obtained that is higher than with w 2 3 or 4. for a two exit room w 1 q is not greater than twice the yield of a single exit room. if the doors are not separated far enough 4w q becomes even significantly less due to a collective slow down that emerges among pedestrians crossing in each other s path disruptive interference effect. for the same w and door number q is also higher with relaxed pedestrians than with anxious ones.
inspec,test_1961,the influence of tollbooths on highway traffic. we study the effects of tollbooths on the traffic flow. the highway traffic is simulated by the nagel schreckenberg model. various types of toll collection are examined which can be characterized either by a waiting time or a reduced speed. a first order phase transition is observed. the phase separation results a saturated flow which is observed as a plateau region in the fundamental diagram. the effects of lane expansion near the tollbooth are examined. the full capacity of a highway can be restored. the emergence of vehicle queuing is studied. besides the numerical results we also obtain analytical expressions for various quantities. the numerical simulations can be well described by the analytical formulas. we also discuss the influence on the travel time and its variance. the tollbooth increases the travel time but decreases its variance. the differences between long and short distance travelers are also discussed.
inspec,test_1962,the bagsik oscillator without complex numbers. we argue that the analysis of the so called bagsik oscillator recently published by piotrowski and sladkowski 2001 is erroneous due to 1 the incorrect banking data used and 2 the application of statistical mechanism apparatus to processes that are totally deterministic.
inspec,test_1963,the variance of firm growth rates the scaling puzzle. recent evidence suggests that a power law relationship exists between a firm s size and the variance of its growth rate. the flatness of the relation is regarded as puzzling in that it suggests that large firms are not much more stable than small firms. it has been suggested that the powerlaw nature of the relationship reflects the presence of some form of correlation of growth rates across the firm s constituent businesses. here it is shown that a model of independent businesses which allows for the fact that these businesses vary in size as modelled by a simple partitions of integers model provides a good representation of what is observed empirically.
inspec,test_1964,antipersistent markov behavior in foreign exchange markets. a quantitative check of efficiency in us dollar deutsche mark exchange rates is developed using high frequency tick by tick data. the antipersistent markov behavior of log price fluctuations of given size implies in principle the possibility of a statistical forecast. we introduce and measure the available information of the quote sequence and we show how it can be profitable following a particular trading rule.
inspec,test_1965,stock market dynamics. we elucidate on several empirical statistical observations of stock market returns. moreover we find that these properties are recurrent and are also present in invariant measures of low dimensional dynamical systems. thus we propose that the returns are modeled by the first poincare return time of a low dimensional chaotic trajectory. this modeling which captures the recurrent properties of the return fluctuations is able to predict well the evolution of the observed statistical quantities. in addition it explains the reason for which stocks present simultaneously dynamical properties and high uncertainties. in our analysis we use data from the s p 500 index and the brazilian stock telebras.
inspec,test_1966,application of nonlinear time series analysis techniques to high frequency currency exchange data. in this work we have applied nonlinear time series analysis to high frequency currency exchange data. the time series studied are the exchange rates between the us dollar and 18 other foreign currencies from within and without the euro zone. our goal was to determine if their dynamical behaviours were in some way correlated. the nonexistence of stationarity called for the application of recurrence quantification analysis as a tool for this analysis and is based on the definition of several parameters that allow for the quantification of recurrence plots. the method was checked using the european monetary system currency exchanges. the results show as expected the high correlation between the currencies that are part of the euro but also a strong correlation between the japanese yen the canadian dollar and the british pound. singularities of the series are also demonstrated taking into account historical events in 1996 in the euro zone.
inspec,test_1967,modeling daily realized futures volatility with singular spectrum analysis. using singular spectrum analysis ssa we model the realized volatility and logarithmic standard deviations of two important futures return series. the realized volatility and logarithmic standard deviations are constructed following the methodology of andersen et al j am. stat. ass. 96 2001 42 55 using intra day transaction data. we find that ssa decomposes the volatility series quite well and effectively captures both the market trend accounting for about 34 38 of the total variance in the series and more importantly a number of underlying market periodicities. reliable identification of any periodicities is extremely important for options pricing and risk management and we believe that ssa can be a useful addition to the financial practitioners toolbox.
inspec,test_1968,phase control of higher order squeezing of a quantum field. in a recent experiment phys. rev lett. 88 2002 023601 phase dependent photon statistics in a c w system has been observed in the mixing of a coherent field with a two photon source. their system has the advantage over other atomic transition based fluorescent systems. in this paper we examine further the squeezing properties of higher order quantum fluctuations in one of the quadrature components of the combined field in this system. we demonstrate that efficient and lasting higher order squeezing effects could be observed with proper choice of the relative phase between the pump and coherent fields. this nonclassical feature is attributed to a constructive two photon interference. relationship between the second and higher order squeezing of the field is discussed.
inspec,test_1969,modeling self consistent multi class dynamic traffic flow. in this study we present a systematic self consistent multiclass multilane traffic model derived from the vehicular boltzmann equation and the traffic dispersion model. the multilane domain is considered as a two dimensional space and the interaction among vehicles in the domain is described by a dispersion model. the reason we consider a multilane domain as a two dimensional space is that the driving behavior of road users may not be restricted by lanes especially motorcyclists. the dispersion model which is a nonlinear poisson equation is derived from the car following theory and the equilibrium assumption. under the concept that all kinds of users share the finite section the density is distributed on a road by the dispersion model. in addition the dynamic evolution of the traffic flow is determined by the systematic gas kinetic model derived from the boltzmann equation. multiplying boltzmann equation by the zeroth first and second order moment functions integrating both side of the equation and using chain rules we can derive continuity motion and variance equation respectively. however the second order moment function which is the square of the individual velocity is employed by previous researches does not have physical meaning in traffic flow.
inspec,test_197,mixture of experts classification using a hierarchical mixture model. a three level hierarchical mixture model for classification is presented that models the following data generation process 1 the data are generated by a finite number of sources clusters and 2 the generation mechanism of each source assumes the existence of individual internal class labeled sources subclusters of the external cluster. the model estimates the posterior probability of class membership similar to a mixture of experts classifier. in order to learn the parameters of the model we have developed a general training approach based on maximum likelihood that results in two efficient training algorithms. compared to other classification mixture models the proposed hierarchical model exhibits several advantages and provides improved classification performance as indicated by the experimental results.
inspec,test_1970,emarketing restaurant web sites that click. a number of global companies have adopted electronic commerce as a means of reducing transaction related expenditures connecting with current and potential customers and enhancing revenues and profitability. if a restaurant is to have an internet presence what aspects of the business should be highlighted. food service companies that have successfully ventured onto the web have employed assorted web based technologies to create a powerful marketing tool of unparalleled strength. historically it has been difficult to create a set of criteria against which to evaluate website effectiveness. as practitioners consider additional resources for website development the effectiveness of e marketing investment becomes increasingly important. care must be exercised to ensure that the quality of the site adheres to high standards and incorporates evolving technology as appropriate. developing a coherent website strategy including an effective website design are proving critical to an effective web presence.
inspec,test_1971,exploring developments in web based relationship marketing within the hotel industry. this paper provides a content analysis study of the application of world wide web marketing by the hotel industry. there is a lack of historical perspective on industry related web marketing applications and this paper attempts to resolve this with a two year follow up case study of the changing use of the web to develop different types of relationships. specifically the aims are 1 to identify key changes in the way hotels are using the web 2 to look for evidence of the adoption of a relationship marketing rm model as a strategy for the development of hotel web sites and the use of new technologies and 3 to investigate the use of multimedia in hotel web sites. the development and strategic exploitation of the internet has transformed the basis of marketing. using the evidence from a web content survey this study reveals the way relationships are being created and managed within the hotel industry by its use of the web as a marketing tool. the authors have collected evidence by means of a descriptive study on the way hotels build and create relationships with their web presence delivering multimedia information as well as channel and interactive means of communication. in addition a strategic framework is offered as the means to describe the mechanism and orientation of web based marketing by hotels. the study utilizes a model by gilbert 1996 as a means of developing a measurement instrument to allow a content analysis of the current approach by hotels to the development of web sites. the results indicate hotels are aware of the new uses of web technology and are promoting hotel products in the global electronic market in new and sophisticated ways.
inspec,test_1972,online auctions dynamic pricing and the lodging industry. the traditional channels of distribution for overnight accommodation are rapidly being displaced by web site scripting online intermediaries and specialty brokers. businesses that pioneered internet usage relied on it as a sales and marketing alternative to predecessor product distribution channels. as such web sites replace the traditional trading model to the internet. web enabled companies are popular because the medium renders the process faster less costly highly reliable and secure. auction based models impact business models by converting the price setting mechanism from supplier centric to market centric and transforming the trading model from one to many to many to many. historically pricing was based on the cost of production plus a margin of profit. traditionally as products and services move through the supply chain from the producer to the consumer various intermediaries added their share of profit to the price. as internet based mediums of distribution become more prevalent traditional pricing models are being supplanted with dynamic pricing. a dynamic pricing model represents a flexible system that changes prices not only from product to product but also from customer to customer and transaction to transaction. many industry leaders are skeptical of the long run impact of online auctions on lodging industry profit margins despite the fact pricing theory suggests that an increase in the flow of information results in efficient market pricing. the future of such endeavors remains promising but controversial.
inspec,test_1973,affine invariants of convex polygons. in this correspondence we prove that the affine invariants for image registration and object recognition proposed recently by yang and cohen see ibid vol 8 no 7 p 934 46 july 1999 are algebraically dependent. we show how to select an independent and complete set of the invariants. the use of this new set leads to a significant reduction of the computing complexity without decreasing the discrimination power.
inspec,test_1974,real time implementation of a new low memory spiht image coding algorithm using dsp chip. among all algorithms based on wavelet transform and zerotree quantization said and pearlman s 1996 set partitioning in hierarchical trees spiht algorithm is well known for its simplicity and efficiency. this paper deals with the real time implementation of spiht algorithm using dsp chip. in order to facilitate the implementation and improve the codec s performance some relative issues are thoroughly discussed such as the optimization of program structure to speed up the wavelet decomposition. spiht s high memory requirement is a major drawback for hardware implementation. in this paper we modify the original spiht algorithm by presenting two new concepts number of error bits and absolute zerotree. consequently the memory cost is significantly reduced. we also introduce a new method to control the coding process by number of error bits. our experimental results show that the implementation meets common requirement of real time video coding and is proven to be a practical and efficient dsp solution.
inspec,test_1975,efficient computation of local geometric moments. local moments have attracted attention as local features in applications such as edge detection and texture segmentation. the main reason for this is that they are inherently integral based features so that their use reduces the effect of uncorrelated noise. the computation of local moments when viewed as a neighborhood operation can be interpreted as a convolution of the image with a set of masks. nevertheless moments computed inside overlapping windows are not independent and convolution does not take this fact into account. by introducing a matrix formulation and the concept of accumulation moments this paper presents an algorithm which is computationally much more efficient than convolving and yet as simple.
inspec,test_1976,adaptive image denoising using scale and space consistency. this paper proposes a new method for image denoising with edge preservation based on image multiresolution decomposition by a redundant wavelet transform. in our approach edges are implicitly located and preserved in the wavelet domain whilst image noise is filtered out. at each resolution level the image edges are estimated by gradient magnitudes obtained from the wavelet coefficients which are modeled probabilistically and a shrinkage function is assembled based on the model obtained. joint use of space and scale consistency is applied for better preservation of edges. the shrinkage functions are combined to preserve edges that appear simultaneously at several resolutions and geometric constraints are applied to preserve edges that are not isolated. the proposed technique produces a filtered version of the original image where homogeneous regions appear separated by well defined edges. possible applications include image presegmentation and image denoising.
inspec,test_1977,tracking nonparameterized object contours in video. we propose a new method for contour tracking in video. the inverted distance transform of the edge map is used as an edge indicator function for contour detection. using the concept of topographical distance the watershed segmentation can be formulated as a minimization. this new viewpoint gives a way to combine the results of the watershed algorithm on different surfaces. in particular our algorithm determines the contour as a combination of the current edge map and the contour predicted from the tracking result in the previous frame. we also show that the problem of background clutter can be relaxed by taking the object motion into account. the compensation with object motion allows to detect and remove spurious edges in background. the experimental results confirm the expected advantages of the proposed method over the existing approaches.
inspec,test_1978,multilayered image representation application to image compression. the main contribution of this work is a new paradigm for image representation and image compression. we describe a new multilayered representation technique for images. an image is parsed into a superposition of coherent layers piecewise smooth regions layer textures layer etc. the multilayered decomposition algorithm consists in a cascade of compressions applied successively to the image itself and to the residuals that resulted from the previous compressions. during each iteration of the algorithm we code the residual part in a lossy way we only retain the most significant structures of the residual part which results in a sparse representation. each layer is encoded independently with a different transform or basis at a different bitrate and the combination of the compressed layers can always be reconstructed in a meaningful way. the strength of the multilayer approach comes from the fact that different sets of basis functions complement each others some of the basis functions will give reasonable account of the large trend of the data while others will catch the local transients or the oscillatory patterns. this multilayered representation has a lot of beautiful applications in image understanding and image and video coding. we have implemented the algorithm and we have studied its capabilities.
inspec,test_1979,combining spatial and scale space techniques for edge detection to provide a spatially adaptive wavelet based noise filtering algorithm. new methods for detecting edges in an image using spatial and scale space domains are proposed. a priori knowledge about geometrical characteristics of edges is used to assign a probability factor to the chance of any pixel being on an edge. an improved double thresholding technique is introduced for spatial domain filtering. probabilities that pixels belong to a given edge are assigned based on pixel similarity across gradient amplitudes gradient phases and edge connectivity. the scale space approach uses dynamic range compression to allow wavelet correlation over a wider range of scales. a probabilistic formulation is used to combine the results obtained from filtering in each domain to provide a final edge probability image which has the advantages of both spatial and scale space domain methods. decomposing this edge probability image with the same wavelet as the original image permits the generation of adaptive filters that can recognize the characteristics of the edges in all wavelet detail and approximation images regardless of scale. these matched filters permit significant reduction in image noise without contributing to edge distortion. the spatially adaptive wavelet noise filtering algorithm is qualitatively and quantitatively compared to a frequency domain and two wavelet based noise suppression algorithms using both natural and computer generated noisy images.
inspec,test_198,computational capacity of an odorant discriminator the linear separability of curves. we introduce and study an artificial neural network inspired by the probabilistic receptor affinity distribution model of olfaction. our system consists of n sensory neurons whose outputs converge on a single processing linear threshold element. the system s aim is to model discrimination of a single target odorant from a large number p of background odorants within a range of odorant concentrations. we show that this is possible provided p does not exceed a critical value p sub c and calculate the critical capacity alpha c p sub c  n. the critical capacity depends on the range of concentrations in which the discrimination is to be accomplished. if the olfactory bulb may be thought of as a collection of such processing elements each responsible for the discrimination of a single odorant our study provides a quantitative analysis of the potential computational properties of the olfactory bulb. the mathematical formulation of the problem we consider is one of determining the capacity for linear separability of continuous curves embedded in a large dimensional space. this is accomplished here by a numerical study using a method that signals whether the discrimination task is realizable together with a finite size scaling analysis.
inspec,test_1980,lossy to lossless object based coding of 3 d mri data. we propose a fully three dimensional 3 d object based coding system exploiting the diagnostic relevance of the different regions of the volumetric data for rate allocation. the data are first decorrelated via a 3 d discrete wavelet transform. the implementation via the lifting steps scheme allows to map integer to integer values enabling lossless coding and facilitates the definition of the object based inverse transform. the coding process assigns disjoint segments of the bitstream to the different objects which can be independently accessed and reconstructed at any up to lossless quality. two fully 3 d coding strategies are considered embedded zerotree coding ezw 3d and multidimensional layered zero coding mlzc both generalized for region of interest roi based processing. in order to avoid artifacts along region boundaries some extra coefficients must be encoded for each object. this gives rise to an overheading of the bitstream with respect to the case where the volume is encoded as a whole. the amount of such extra information depends on both the filter length and the decomposition depth. the system is characterized on a set of head magnetic resonance images. results show that mlzc and ezw 3d have competitive performances. in particular the best mlzc mode outperforms the others state of the art techniques on one of the datasets for which results are available in the literature.
inspec,test_1981,optimal linear control in stabilizer design. the most common method of improving stability of the power system is the synthesis of the turbine and generator control systems because of the high effectiveness and relatively low cost of these elements. the synthesis and construction of the effective synchronous generator and turbine controller is a very difficult task. this paper describes the seven step mu synthesis approach to pss design enabling the synchronous generator to remain stable over a wide range of system operating conditions.
inspec,test_1982,verifying resonant grounding in distribution systems. the authors describe resfal a software tool that can check on the behavior of distribution network resonant grounding systems with regard to compensation coil tuning and to fault detection.
inspec,test_1983,power electronics spark new simulation challenges. this article discusses some of the changes that have taken place in power systems and explores some of the inherent requirements for simulation technologies in order to keep up with this rapidly changing environment. the authors describe how energy utilities are realizing that with the appropriate tools they can train and sustain engineers who can maintain a great insight into system dynamics.
inspec,test_1984,deriving model parameters from field test measurements generator control simulation. a major component of any power system simulation is the generating plant. the purpose of deriveassist is to speed up the parameter derivation process and to allow engineers less versed in parameter matching and identification to get involved in the process of power plant electric generator modelling.
inspec,test_1985,prospective on computer applications in power. the so called deregulation and restructuring of the electric power industry have made it very difficult to keep up with industry changes and have made it much more difficult to envision the future. in this article current key issues and major developments of the past few years are reviewed to provide perspective and prospects for future computer applications in power are suggested. technology changes are occurring at an exponential rate. the interconnected bulk electric systems are becoming integrated with vast networked information systems. this article discusses the skills that will be needed by future power engineers to keep pace with these developments and trends.
inspec,test_1986,control centers are here to stay. despite changes with different structures market rules and uncertainties a control center must always be in place to maintain the security reliability and quality of electric service. this article focuses on the energy management system ems control center identifying the major functions that have become standard components of every application software package. the two most important control center functions security control and load following control guarantee the continuity of electric service which after all is the end product of the utility business. new technology trends in the design of control center infrastructures are emerging in the liberalized environment of the energy market. an example of a control center infrastructure is described. the article ends with a concern for the security of the control center itself.
inspec,test_1987,virus hunting. we all appreciate the need for and hopefully we have all deployed anti virus software. the good news is that av software has come a long way fast. four or so years ago it was true to write that av software could not detect trojan horses and similar intrusion attempts. now it can and does. mcafee s virusscan for example goes one further it detects viruses worms and trojan horses and deploys itself as a firewall to filter data packets control access to internet resources activate rule sets for specific applications in general to protect against hackers. but like so much software we use it with little thought as to how it came to do its job. behind the scenes there is an army of top notch programmers trying to stay ahead of the baddies who at the last count had produced some 60 000 viruses.
inspec,test_1988,integration is key an introduction to enterprise application integration eai technology. over the past few years numerous organisations have invested in the latest software applications to drive their business forward. but many are now finding that these systems are becoming redundant on their own. the key to staying ahead of the competition in today s current climate is now to integrate all of these systems says justin opie portfolio director at imark communications.
inspec,test_1989,managing system risk. companies are increasingly required to provide assurance that their systems are secure and conform to commercial security standards. senior business managers are ultimately responsible for the security of their corporate systems and for the implications in the event of a failure. businesses will be exposed to unquantified security risks unless they have a formal risk management framework in place to enable risks to be identified evaluated and managed. failure to assess and manage risks can lead to a business suffering serious financial impacts commercial embarrassment and fines or sanctions from regulators. this is both a key responsibility and opportunity for management services practitioners.
inspec,test_199,on optimality in auditory information processing. we study limits for the detection and estimation of weak sinusoidal signals in the primary part of the mammalian auditory system using a stochastic fitzhugh nagumo model and an action recovery model for synaptic depression. our overall model covers the chain from a hair cell to a point just after the synaptic connection with a cell in the cochlear nucleus. the information processing performance of the system is evaluated using so called phi divergences from statistics that quantify dissimilarity between probability measures and are intimately related to a number of fundamental limits in statistics and information theory it. we show that there exists a set of parameters that can optimize several important phi divergences simultaneously and that this set corresponds to a constant quiescent firing rate qfr of the spiral ganglion neuron. the optimal value of the qfr is frequency dependent but is essentially independent of the amplitude of the signal for small amplitudes. consequently optimal processing according to several standard it criteria can be accomplished for this model if and only if the parameters are tuned to values that correspond to one and the same qfr. this offers a new explanation for the qfr and can provide new insight into the role played by several other parameters of the peripheral auditory system.
inspec,test_1990,electrical facility construction work for information network structuring by the use of sewage conduits. to confront the advent of the advanced information society there has been a pressing demand for the adjustment of the communications infrastructure and the structuring of the information network by utilizing the sewage conduits. the city of tokyo is promoting a project by the name of the sewer optical fiber teleway soft network plan. according to this plan the total distance of the optical fiber network laid in the sewer conduits is scheduled to reach about 470 km by the end of march 2000. at the final stage this distance will reach 800 km as a whole. we completed the construction work for the information control facilities scattered in 11 places inclusive of the treatment site s with the intention to adjust and extend the information transmission network laid through the above mentioned optical fiber network to be used exclusively by the bureau of sewerage. this construction work is described in the paper.
inspec,test_1991,a framework for evaluating the data hiding capacity of image sources. an information theoretic model for image watermarking and data hiding is presented in this paper. previous theoretical results are used to characterize the fundamental capacity limits of image watermarking and data hiding systems. capacity is determined by the statistical model used for the host image by the distortion constraints on the data hider and the attacker and by the information available to the data hider to the attacker and to the decoder. we consider autoregressive block dct and wavelet statistical models for images and compute data hiding capacity for compressed and uncompressed host image sources. closed form expressions are obtained under sparse model approximations. models for geometric attacks and distortion measures that are invariant to such attacks are considered.
inspec,test_1992,geometrically invariant watermarking using feature points. this paper presents a new approach for watermarking of digital images providing robustness to geometrical distortions. the weaknesses of classical watermarking methods to geometrical distortions are outlined first. geometrical distortions can be decomposed into two classes global transformations such as rotations and translations and local transformations such as the stirmark attack. an overview of existing self synchronizing schemes is then presented. theses schemes can use periodical properties of the mark invariant properties of transforms template insertion or information provided by the original image to counter geometrical distortions. thereafter a new class of watermarking schemes using the image content is presented. we propose an embedding and detection scheme where the mark is bound with a content descriptor defined by salient points. three different types of feature points are studied and their robustness to geometrical transformations is evaluated to develop an enhanced detector. the embedding of the signature is done by extracting feature points of the image and performing a delaunay tessellation on the set of points. the mark is embedded using a classical additive scheme inside each triangle of the tessellation. the detection is done using correlation properties on the different triangles. the performance of the presented scheme is evaluated after jpeg compression geometrical attack and transformations. results show that the fact that the scheme is robust to these different manipulations. finally in our concluding remarks we analyze the different perspectives of such content based watermarking scheme.
inspec,test_1993,color plane interpolation using alternating projections. most commercial digital cameras use color filter arrays to sample red green and blue colors according to a specific pattern. at the location of each pixel only one color sample is taken and the values of the other colors must be interpolated using neighboring samples. this color plane interpolation is known as demosaicing it is one of the important tasks in a digital camera pipeline. if demosaicing is not performed appropriately images suffer from highly visible color artifacts. in this paper we present a new demosaicing technique that uses inter channel correlation effectively in an alternating projections scheme. we have compared this technique with six state of the art demosaicing techniques and it outperforms all of them both visually and in terms of mean square error.
inspec,test_1994,a comparison of computational color constancy algorithms. ii. experiments with image data. for pt i see ibid vol. 11 no 9 p 972 84 2002. we test a number of the leading computational color constancy algorithms using a comprehensive set of images. these were of 33 different scenes under 11 different sources representative of common illumination conditions. the algorithms studied include two gray world methods a version of the retinex method several variants of forsyth s 1990 gamut mapping method cardei et al s 2000 neural net method and finlayson et al s color by correlation method finlayson et al 1997 2001 hubel and finlayson 2000. we discuss a number of issues in applying color constancy ideas to image data and study in depth the effect of different preprocessing strategies. we compare the performance of the algorithms on image data with their performance on synthesized data. all data used for this study are available online at http www cs sfu ca color data and implementations for most of the algorithms are also available http www cs sfu ca color code. experiments with synthesized data part one of this paper suggested that the methods which emphasize the use of the input data statistics specifically color by correlation and the neural net algorithm are potentially the most effective at estimating the chromaticity of the scene illuminant. unfortunately we were unable to realize comparable performance on real images. here exploiting pixel intensity proved to be more beneficial than exploiting the details of image chromaticity statistics and the three dimensional 3 d gamut mapping algorithms gave the best performance.
inspec,test_1995,a comparison of computational color constancy algorithms. i methodology and experiments with synthesized data. we introduce a context for testing computational color constancy specify our approach to the implementation of a number of the leading algorithms and report the results of three experiments using synthesized data. experiments using synthesized data are important because the ground truth is known possible confounds due to camera characterization and pre processing are absent and various factors affecting color constancy can be efficiently investigated because they can be manipulated individually and precisely. the algorithms chosen for close study include two gray world methods a limiting case of a version of the retinex method a number of variants of forsyth s 1990 gamut mapping method cardei et al s 2000 neural net method and finlayson et al s color by correlation method finlayson et al 1997 2001 hubel and finlayson 2000. we investigate the ability of these algorithms to make estimates of three different color constancy quantities the chromaticity of the scene illuminant the overall magnitude of that illuminant and a corrected illumination invariant image. we consider algorithm performance as a function of the number of surfaces in scenes generated from reflectance spectra the relative effect on the algorithms of added specularities and the effect of subsequent clipping of the data. all data is available on line at http www cs sfu ca color data and implementations for most of the algorithms are also available http www cs sfu ca color code.
inspec,test_1996,quality image metrics for synthetic images based on perceptual color differences. due to the improvement of image rendering processes and the increasing importance of quantitative comparisons among synthetic color images it is essential to define perceptually based metrics which enable to objectively assess the visual quality of digital simulations. in response to this need this paper proposes a new methodology for the determination of an objective image quality metric and gives an answer to this problem through three metrics. this methodology is based on the llab color space for perception of color in complex images a modification of the cielab1976 color space. the first metric proposed is a pixel by pixel metric which introduces a local distance map between two images. the second metric associates to a pair of images a global value. finally the third metric uses a recursive subdivision of the images to obtain an adaptative distance map rougher but less expensive to compute than the first method.
inspec,test_1997,exact controllability of shells in minimal time. we prove an exact controllability result for thin cups using the fourier method and recent improvements of ingham 1936 type theorems.
inspec,test_1998,a friction compensator for pneumatic control valves. a procedure that compensates for static friction stiction in pneumatic control valves is presented. the compensation is obtained by adding pulses to the control signal. the characteristics of the pulses are determined from the control action. the compensator is implemented in industrial controllers and control systems and the industrial experiences show that the procedure reduces the control error during stick slip motion significantly compared to standard control without stiction compensation.
inspec,test_1999,performance comparison between pid and dead time compensating controllers. this paper is intended to answer the question  when can a simple dead time compensator be expected to perform better than a pid.. the performance criterion used is the integrated absolute error iae. it is compared for pi and pid controllers and a simple dead time compensator dtc when a step load disturbance is applied at the plant input. both stable and integrating processes are considered. for a fair comparison the controllers should provide equal robustness in some sense. here as a measure of robustness the h sub infinity norm of the sum of the absolute values of the sensitivity function and the complementary sensitivity function is used. performance of the dtc s is given also as a function of dead time margin d sub m.
inspec,test_2,waiting for the wave to crest wavelength services. wavelength services have been hyped ad nauseam for years. but despite their quick turn up time and impressive margins such services have yet to live up to the industry s expectations. the reasons for this lukewarm reception are many not the least of which is the confusion that still surrounds the technology but most industry observers are still convinced that wavelength services with ultimately flourish.
inspec,test_20,adaptive state feedback control for a class of linear systems with unknown bounds of uncertainties. the problem of adaptive robust stabilization for a class of linear time varying systems with disturbance and nonlinear uncertainties is considered. the bounds of the disturbance and uncertainties are assumed to be unknown being even arbitrary. for such uncertain dynamical systems the adaptive robust state feedback controller is obtained. and the resulting closed loop systems are asymptotically stable in theory. moreover an adaptive robust state feedback control scheme is given. the scheme ensures the closed loop systems exponentially practically stable and can be used in practical engineering. finally simulations show that the control scheme is effective.
inspec,test_200,preintegration lateral inhibition enhances unsupervised learning. a large and influential class of neural network architectures uses postintegration lateral inhibition as a mechanism for competition. we argue that these algorithms are computationally deficient in that they fail to generate or learn appropriate perceptual representations under certain circumstances. an alternative neural network architecture is presented here in which nodes compete for the right to receive inputs rather than for the right to generate outputs. this form of competition implemented through preintegration lateral inhibition does provide appropriate coding properties and can be used to learn such representations efficiently. furthermore this architecture is consistent with both neuroanatomical and neuropsychological data. we thus argue that preintegration lateral inhibition has computational advantages over conventional neural network architectures while remaining equally biologically plausible.
inspec,test_2000,generalized predictive control for non uniformly sampled systems. in this paper we study digital control systems with non uniform updating and sampling patterns which include multirate sampled data systems as special cases. we derive lifted models in the state space domain. the main obstacle for generalized predictive control gpc design using the lifted models is the so called causality constraint. taking into account this design constraint we propose a new gpc algorithm which results in optimal causal control laws for the non uniformly sampled systems. the solution applies immediately to multirate sampled data systems where rates are integer multiples of some base period.
inspec,test_2001,a simple graphic approach for observer decomposition. based upon the proposition that the roles of inputs and outputs in a physical system and those in the corresponding output injection observer do not really have to be consistent a systematic procedure is developed in this work to properly divide a set of sparse system models and measurement models into a number of independent subsets with the help of a visual aid. several smaller sub observers can then be constructed accordingly to replace the original one. the size of each sub observer may be further reduced by strategically selecting one or more appended states. these techniques are shown to be quite effective in relieving on line computation load of the output injection observers and also in identifying detectable sub systems.
inspec,test_2002,a new subspace identification approach based on principal component analysis. principal component analysis pca has been widely used for monitoring complex industrial processes with multiple variables and diagnosing process and sensor faults. the objective of this paper is to develop a new subspace identification algorithm that gives consistent model estimates under the errors in variables eiv situation. in this paper we propose a new subspace identification approach using principal component analysis. pca naturally falls into the category of eiv formulation which resembles total least squares and allows for errors in both process input and output. we propose to use pca to determine the system observability subspace the matrices and the system order for an eiv formulation. standard pca is modified with instrumental variables in order to achieve consistent estimates of the system matrices. the proposed subspace identification method is demonstrated using a simulated process and a real industrial process for model identification and order determination. for comparison the moesp algorithm and n4sid algorithm are used as benchmarks to demonstrate the advantages of the proposed pca based subspace model identification smi algorithm.
inspec,test_2003,nonlinear modeling and adaptive fuzzy control of mcfc stack. to improve availability and performance of fuel cells the operating temperature of the molten carbonate fuel cells mcfc stack should be controlled within a specified range. however most existing models of mcfc are not ready to be applied in synthesis. in the paper a radial basis function neural networks identification model of a mcfc stack is developed based on the input output sampled data. an adaptive fuzzy control procedure for the temperature of the mcfc stack is also developed. the parameters of the fuzzy control system are regulated by back propagation algorithm and the rule database of the fuzzy system is also adaptively adjusted by the nearest neighbor clustering algorithm. finally using the neural networks model of mcfc stack the simulation results of the control algorithm are presented. the results show the effectiveness of the proposed modeling and design procedures for the mcfc stack based on neural networks identification and the novel adaptive fuzzy control.
inspec,test_2004,new paradigms for interactive 3d volume segmentation. we present a new virtual reality based interaction metaphor for semi automatic segmentation of medical 3d volume data. the mouse based manual initialization of deformable surfaces in 3d represents a major bottleneck in interactive segmentation. in our multi modal system we enhance this process with additional sensory feedback. a 3d haptic device is used to extract the centreline of a tubular structure. based on the obtained path a cylinder with varying diameter is generated which in turn is used as the initial guess for a deformable surface.
inspec,test_2005,state of the art in orthopaedic surgical navigation with a focus on medical image modalities. this paper presents a review of surgical navigation systems in orthopaedics and categorizes these systems according to the image modalities that are used for the visualization of surgical action. medical images used to be an essential part of surgical education and documentation as well as diagnosis and operation planning over many years. with the recent introduction of navigation techniques in orthopaedic surgery a new field of application has been opened. today surgical navigation systems also known as image guided surgery systems are available for various applications in orthopaedic surgery. they visualize the position and orientation of surgical instruments as graphical overlays onto a medical image of the operated anatomy on a computer monitor. preoperative image data such as computed tomography scans or intra operatively generated images for example ultrasonic endoscopic or fluoroscopic images are suitable for this purpose. a new category of medical images termed surgeon defined anatomy has been developed that exclusively relies upon the usage of navigation technology. points on the anatomy are digitized interactively by the surgeon and are used to build up an abstract geometrical model of the bony structures to be operated on. this technique may be used when no other image data is available or appropriate for a given application.
inspec,test_2006,lung metastasis detection and visualization on ct images a knowledge based method. a solution to the problem of lung metastasis detection on computed tomography ct scans of the thorax is presented. a knowledge based top down approach for image interpretation is used. the method is inspired by the manner in which a radiologist and radiotherapist interpret ct images before radiotherapy is planned. a two dimensional followed by a three dimensional analysis is performed. the algorithm first detects the thorax contour the lungs and the ribs which further help the detection of metastases. thus two types of tumors are detected nodules and metastases located at the lung extremities. a method to visualize the anatomical structures segmented is also presented. the system was tested on 20 patients 988 total images from the oncology department of la chaux de fonds hospital and the results show that the method is reliable as a computer aided diagnostic tool for clinical purpose in an oncology department.
inspec,test_2007,the creation of a high fidelity finite element model of the kidney for use in trauma research. a detailed finite element model of the human kidney for trauma research has been created directly from the national library of medicine visible human female vhf project data set. an image segmentation and organ reconstruction software package has been developed and employed to transform the 2d vhf images into a 3d polygonal representation. nonuniform rational b spline nurbs surfaces were then mapped to the polygonal surfaces and were finally utilized to create a robust 3d hexahedral finite element mesh within a commercially available meshing software. the model employs a combined viscoelastic and hyperelastic material model to successfully simulate the behaviour of biological soft tissues. the finite element model was then validated for use in biomechanical research.
inspec,test_2008,building 3d anatomical scenes on the web. we propose a new service for building user defined 3d anatomical structures on the web. the web server is connected to a database storing more than 1000 3d anatomical models reconstructed from the visible human. users may combine existing models as well as planar oblique slices in order to create their own structured anatomical scenes. furthermore they may record sequences of scene construction and visualization actions. these actions enable the server to construct high quality video animations downloadable by the user. professionals and students in anatomy medicine and related disciplines are invited to use the server and create their own anatomical scenes.
inspec,test_2009,a survey of interactive mesh cutting techniques and a new method for implementing generalized interactive mesh cutting using virtual tools. in our experience mesh cutting methods can be distinguished by how their solutions address the following major issues definition of the cut path primitive removal and re meshing number of new primitives created when re meshing is performed and representation of the cutting tool. many researchers have developed schemes for interactive mesh cutting with the goals of reducing the number of new primitives created creating new primitives with good aspect ratios avoiding a disconnected mesh structure between primitives in the cut path and representing the path traversed by the tool as accurately as possible. the goal of this paper is to explain how by using a very simple framework one can build a generalized cutting scheme. this method allows for any arbitrary cut to be made within a virtual object and can simulate cutting surface layered surface or tetrahedral objects using a virtual scalpel scissors or loop cautery tool. this method has been implemented in a real time haptic rate surgical simulation system allowing arbitrary cuts to be made on high resolution patient specific models.
inspec,test_201,correction to construction of panoramic image mosaics with global and local alignment. for original paper see ibid vol. 36 no 2 p 101 30 2000. the authors had given a method for the construction of panoramic image mosaics with global and local alignment. unfortunately a mistake had led to an incorrect equation which whilst making little difference in many cases for faster and assured convergence the correct formulae given here should be used.
inspec,test_2010,scale invariant segmentation of dynamic contrast enhanced perfusion mr images with inherent scale selection. selection of the best set of scales is problematic when developing signal driven approaches for pixel based image segmentation. often different possibly conflicting criteria need to be fulfilled in order to obtain the best trade off between uncertainty variance and location accuracy. the optimal set of scales depends on several factors the noise level present in the image material the prior distribution of the different types of segments the class conditional distributions associated with each type of segment as well as the actual size of the connected segments. we analyse theoretically and through experiments the possibility of using the overall and class conditional error rates as criteria for selecting the optimal sampling of the linear and morphological scale spaces. it is shown that the overall error rate is optimized by taking the prior class distribution in the image material into account. however a uniform ignorant prior distribution ensures constant class conditional error rates. consequently we advocate for a uniform prior class distribution when an uncommitted scale invariant segmentation approach is desired. experiments with a neural net classifier developed for segmentation of dynamic magnetic resonance mr images acquired with a paramagnetic tracer support the theoretical results. furthermore the experiments show that the addition of spatial features to the classifier extracted from the linear or morphological scale spaces improves the segmentation result compared to a signal driven approach based solely on the dynamic mr signal. the segmentation results obtained from the two types of features are compared using two novel quality measures that characterize spatial properties of labelled images.
inspec,test_2011,innovative phase unwrapping algorithm hybrid approach. we present a novel algorithm based on a hybrid of the global and local treatment of a wrapped map. the proposed algorithm is especially effective for the unwrapping of speckle coded interferogram contour maps. in contrast to earlier unwrapping algorithms by region we propose a local discontinuity restoring criterion to serve as the preprocessor or postprocessor of our hybrid algorithm which makes the unwrapping by region much easier and more efficient. with this hybrid algorithm a robust stable and especially time effective phase unwrapping can be achieved. additionally the criterion and limitation of this hybrid algorithm are fully described. the robustness stability and speed of this hybrid algorithm are also studied. the proposed algorithm can be easily upgraded with minor modifications to solve the unwrapping problem of maps with phase inconsistency. both numerical simulation and experimental applications demonstrate the effectiveness of the proposed algorithm.
inspec,test_2012,strain contouring using gabor filters principle and algorithm. moire interferometry is a powerful technique for high sensitivity in plane deformation contouring. however from an engineering viewpoint the derivatives of displacement i e strain are the desired parameter. thus there is a need to differentiate the displacement field. optical and digital methods have been proposed for this differentiation. optical methods provide contours that still need to be quantified while digital methods suffer from drawbacks inherent in the digital differentiation process. we describe a novel approach of strain segmentation for the moire pattern using a multichannel gabor filter. appropriate filter design allows for user specific segmentation which is essentially in engineering design and analysis.
inspec,test_2013,novel denoising algorithm for obtaining a superresolved position estimation. we present a new algorithm that uses the randomness of the noise pattern to achieve high positioning accuracy by applying a modified averaging operation. using the suggested approach noise sensitivity of the positioning accuracy can be significantly reduced. this new improved algorithm can improve the performances of tracking systems used for military as well as civil applications. the concept is demonstrated theoretically as well as by optical experiment.
inspec,test_2014,adaptive filtering for noise reduction in hue saturation intensity color space. even though the hue saturation intensity hsi color model has been widely used in color image processing and analysis the conversion formulas from the rgb color model to hsi are nonlinear and complicated in comparison with the conversion formulas of other color models. when an rgb image is degraded by random gaussian noise this nonlinearity leads to a nonuniform noise distribution in hsi making accurate image analysis more difficult. we have analyzed the noise characteristics of the hsi color model and developed an adaptive spatial filtering method to reduce the magnitude of noise and the nonuniformity of noise variance in the hsi color space. with this adaptive filtering method the filter kernel for each pixel is dynamically adjusted depending on the values of intensity and saturation. in our experiments we have filtered the saturation and hue components and generated edge maps from color gradients. we have found that by using the adaptive filtering method the minimum error rate in edge detection improves by approximately 15.
inspec,test_2015,optical recognition of three dimensional objects with scale invariance using a classical convergent correlator. we present a real time method for recognizing three dimensional 3 d objects with scale invariance. the 3 d information of the objects is codified in deformed fringe patterns using the fourier transform profilometry technique and is correlated using a classical convergent correlator. the scale invariance property is achieved using two different approaches the mellin radial harmonic decomposition and the logarithmic radial harmonic filter. thus the method is invariant for changes in the scale of the 3 d target within a defined interval of scale factors. experimental results show the utility of the proposed method.
inspec,test_2016,fully automatic algorithm for region of interest location in camera calibration. we present an automatic method for region of interest roi location in camera calibration used in computer vision inspection. an intelligent roi location algorithm based on the radon transform is developed to automate the calibration process. the algorithm remains robust even if the anchor target has a notable rotation angle in the target plane. this method functions well although the anchor target is not carefully positioned. several improvement methods are studied to avoid the algorithm s huge time space consumption problem. the algorithm runs about 100 times faster if these improvement methods are applied. using this method fully automatic camera calibration is achieved without human interactive roi specification. experiments show that this algorithm can help to calibrate the intrinsic parameters of the zoom lens and the camera parameters quickly and automatically.
inspec,test_2017,autofocus system for microscope. a technique is developed for microscope autofocusing which is called the eccentric light beam approach with high resolution wide focusing range and compact construction. the principle is described. the theoretical formula of the eccentric light beam approach deduced can be applied not only to an object lens whose objective plane is just at the focal plane but also to an object lens whose objective plane is not at the focal plane. the experimental setup uses a semiconductor laser device as the light source. the laser beam that enters into the microscope is eccentric with the main light axis. a defocused signal is acquired by a symmetrical silicon photocell for the change of the reflected light position caused by differential amplification and processed by a microprocessor. then the electric signal is power amplified and drives a dc motor which moves a fine working platform to an automatic focus of the microscope. the result of the experiments shows a or 0 1 mu m precision of autofocusing for a range of or 500 mu m defocusing. the system has high reliability and can meet the requirements of various accurate micro measurement systems.
inspec,test_2018,design and implementation of a 3 d mapping system for highly irregular shaped objects with application to semiconductor manufacturing. the basic technology for a robotic system is developed to automate the packing of polycrystalline silicon nuggets into fragile fused silica crucible in czochralski melt pulling semiconductor wafer production. the highly irregular shapes of the nuggets and the packing constraints make this a difficult and challenging task. it requires the delicate manipulation and packing of highly irregular polycrystalline silicon nuggets into a fragile fused silica crucible. for this application a dual optical 3 d surface mapping system that uses active laser triangulation has been developed and successfully tested. one part of the system measures the geometry profile of a nugget being packed and the other the profile of the nuggets already in the crucible. a resolution of 1 mm with 15 khz sampling frequency is achieved. data from the system are used by the packing algorithm which determines optimal nugget placement. the key contribution is to describe the design and implementation of an efficient and robust 3 d imaging system to map highly irregular shaped objects using conventional components in context of real commercial manufacturing processes.
inspec,test_2019,effective moving cast shadow detection for monocular color traffic image sequences. for an accurate scene analysis using monocular color traffic image sequences a robust segmentation of moving vehicles from the stationary background is generally required. however the presence of moving cast shadow may lead to an inaccurate vehicle segmentation and as a result may lead to further erroneous scene analysis. we propose an effective method for the detection of moving cast shadow. by observing the characteristics of cast shadow in the luminance chrominance gradient density and geometry domains a combined probability map called a shadow confidence score scs is obtained. from the edge map of the input image each edge pixel is examined to determine whether it belongs to the vehicle region based on its neighboring scss. the cast shadow is identified as those regions with high scss which are outside the convex hull of the selected vehicle edge pixels. the proposed method is tested on 100 vehicle images taken under different lighting conditions sunny and cloudy viewing angles roadside and overhead vehicle sizes small medium and large and colors similar to the road and not. the results indicate that an average error rate of around 14 is obtained while the lowest error rate is around 3 for large vehicles.
inspec,test_202,estimation of error in curvature computation on multi scale free form surfaces. a novel technique for multi scale curvature computation on a free form 3 d surface is presented. this is achieved by convolving local parametrisations of the surface with 2 d gaussian filters iteratively. in our technique semigeodesic coordinates are constructed at each vertex of the mesh. smoothing results are shown for 3 d surfaces with different shapes indicating that surface noise is eliminated and surface details are removed gradually. a number of evolution properties of 3 d surfaces are described. next the surface gaussian and mean curvature values are estimated accurately at multiple scales which are then mapped to colours and displayed directly on the surface. the performance of the technique when selecting different directions as an arbitrary direction for the geodesic at each vertex are also presented. the results indicate that the error observed for the estimation of gaussian and mean curvatures is quite low after only one iteration. furthermore as the surface is smoothed iteratively the error is further reduced. the results also show that the estimation error of gaussian curvature is less than that of mean curvature. our experiments demonstrate that estimation of smoothed surface curvatures are very accurate and not affected by the arbitrary direction of the first geodesic line when constructing semigeodesic coordinates. our technique is independent of the underlying triangulation and is also more efficient than volumetric diffusion techniques since 2 d rather than 3 d convolutions are employed. finally the method presented here is a generalisation of the curvature scale space method for 2 d contours. the css method has outperformed comparable techniques within the mpeg 7 evaluation framework. as a result it has been selected for inclusion in the mpeg 7 package of standards.
inspec,test_2020,restoration of broadband imagery steered with a liquid crystal optical phased array. in many imaging applications it is highly desirable to replace mechanical beam steering components i e mirrors and gimbals with a nonmechanical device. one such device is a nematic liquid crystal optical phased array lcopa. an lcopa can implement a blazed phase grating to steer the incident light. however when a phase grating is used in a broadband imaging system two adverse effects can occur. first dispersion will cause different incident wavelengths arriving at the same angle to be steered to different output angles causing chromatic aberrations in the image plane. second the device will steer energy not only to the first diffraction order but to others as well. this multiple order effect results in multiple copies of the scene appearing in the image plane. we describe a digital image restoration technique designed to overcome these degradations. the proposed postprocessing technique is based on a wiener deconvolution filter. the technique however is applicable only to scenes containing objects with approximately constant reflectivities over the spectral region of interest. experimental results are presented to demonstrate the effectiveness of this technique.
inspec,test_2021,one step digit set restricted modified signed digit adder using an incoherent correlator based on a shared content addressable memory. an efficient one step digit set restricted modified signed digit msd adder based on symbolic substitution is presented. in this technique carry propagation is avoided by introducing reference digits to restrict the intermediate carry and sum digits to 1 0 and 0 1 respectively. the proposed technique requires significantly fewer minterms and simplifies system complexity compared to the reported one step msd addition techniques. an incoherent correlator based on an optoelectronic shared content addressable memory processor is suggested to perform the addition operation. in this technique only one set of minterms needs to be stored independent of the operand length.
inspec,test_2022,two step integral imaging for orthoscopic three dimensional imaging with improved viewing resolution. we present a two step integral imaging system to obtain 3 d orthoscopic real images. by adopting a nonstationary micro optics technique we demonstrate experimentally the potential usefulness of two step integral imaging.
inspec,test_2023,diffraction limit for a circular mask with a periodic rectangular apertures array. a mask with periodic apertures imaging system is adopted very widely and plays a leading role in modern technology for uses such as pinhole cameras coded imaging systems optical information processing etc because of its high resolution its infinite depth of focus and its usefulness over a broad frequency spectra ranging from visible light to x rays and gamma rays. while the masks with periodic apertures investigated in the literature are limited only to far field diffraction they do not take the shift of apertures within the mask into consideration. therefore the derivation of the far field diffraction for a single aperture can not be applied to a mask with periodic apertures. the far field diffraction formula modified for a multiaperture mask has been proposed in the past the analysis remains too complicated to offer some practical guidance for mask design. we study a circular mask with periodic rectangular apertures and develop an easier way to interpret it. first the near field diffraction intensity of a circular aperture is calculated by means of lommel s function. then the convolution of the circular mask diffraction with periodic rectangular apertures is put together and we can present a simple mathematical tool to analyze the mask properties including the intensity distribution blurring aberration and the criterion of defining the far or near field diffraction. this concept can also be expanded to analyze different types of masks with the arbitrarily shaped apertures.
inspec,test_2024,binocular model for figure ground segmentation in translucent and occluding images. a fourier based solution to the problem of figure ground segmentation in short baseline binocular image pairs is presented. each image is modeled as an additive composite of two component images that exhibit a spatial shift due to the binocular parallax. the segmentation is accomplished by decoupling each fourier component in one of the resultant additive images into its two constituent phasors allocating each to its appropriate object specific spectrum and then reconstructing the foreground and background using the inverse fourier transform. it is shown that the foreground and background shifts can be computed from the differences of the magnitudes and phases of the fourier transform of the binocular image pair. while the model is based on translucent objects it also works with occluding objects.
inspec,test_2025,multispectral color image capture using a liquid crystal tunable filter. we describe the experimental setup of a multispectral color image acquisition system consisting of a professional monochrome ccd camera and a tunable filter in which the spectral transmittance can be controlled electronically. we perform a spectral characterization of the acquisition system taking into account the acquisition noise. to convert the camera output signals to device independent color data two main approaches are proposed and evaluated. one consists in applying regression methods to convert from the k camera outputs to a device independent color space such as ciexyz or cielab. another method is based on a spectral model of the acquisition system. by inverting the model using a principal eigenvector approach we estimate the spectral reflectance of each pixel of the imaged surface.
inspec,test_2026,iterative regularized least mean mixed norm image restoration. we develop a regularized mixed norm image restoration algorithm to deal with various types of noise. a mixed norm functional is introduced which combines the least mean square lms and the least mean fourth lmf functionals as well as a smoothing functional. two regularization parameters are introduced one to determine the relative importance of the lms and lmf functionals which is a function of the kurtosis and another to determine the relative importance of the smoothing functional. the two parameters are chosen in such a way that the proposed functional is convex so that a unique minimizer exists. an iterative algorithm is utilized for obtaining the solution and its convergence is analyzed. the novelty of the proposed algorithm is that no knowledge of the noise distribution is required and the relative contributions of the lms the lmf and the smoothing functionals are adjusted based on the partially restored image. experimental results demonstrate the effectiveness of the proposed algorithm.
inspec,test_2027,motion estimation using modified dynamic programming. a new method for computing precise estimates of the motion vector field of moving objects in a sequence of images is proposed. correspondence vector field computation is formulated as a matching optimization problem for multiple dynamic images. the proposed method is a heuristic modification of dynamic programming applied to the 2 d optimization problem. motion vector field estimates using real movie images demonstrate good performance of the algorithm in terms of dynamic motion analysis.
inspec,test_2028,centroid detection based on optical correlation. we propose three correlation based methods to simultaneously detect the centroids of multiple objects in an input scene. the first method is based on the modulus of the moment function the second method is based on squaring the moment function and the third method works with a single intensity filter. these methods are invariant to changes in the position orientation and scale of the object and result in good noise smoothing performance. we use spatial light modulators slms to directly implement the input of the image and filter information for the purpose of these approaches. we present results showing simulations from different approaches and provide comparisons between optical correlation and digital moment based methods. experimental results corresponding to an optical correlator using slms for the centroid detection are also presented.
inspec,test_2029,block truncation image bit plane coding. block truncation coding btc is a successful image compression technique due to its simple and fast computational burden. the bit rate is fixed to 2 0 bits pixel whose performance is moderate in terms of compression ratio compared to other compression schemes such as discrete cosine transform dct vector quantization vq wavelet transform coding wtc etc. two kinds of overheads are required for btc coding bit plane and quantization values respectively. a new technique is presented to reduce the bit plane overhead. conventional bit plane overhead is 1 0 bits pixel we decrease it to 0 734 bits pixel while maintaining the same decoded quality as absolute moment btc ambtc does for the lena image. compared to other published bit plane coding strategies the proposed method outperforms all of the existing methods.
inspec,test_203,plenoptic image editing. this paper presents a new class of interactive image editing operations designed to maintain consistency between multiple images of a physical 3d scene. the distinguishing feature of these operations is that edits to any one image propagate automatically to all other images as if the unknown 3d scene had itself been modified. the modified scene can then be viewed interactively from any other camera viewpoint and under different scene illuminations. the approach is useful first as a power assist that enables a user to quickly modify many images by editing just a few and second as a means for constructing and editing image based scene representations by manipulating a set of photographs. the approach works by extending operations like image painting scissoring and morphing so that they alter a scene s plenoptic function in a physically consistent way thereby affecting scene appearance from all viewpoints simultaneously. a key element in realizing these operations is a new volumetric decomposition technique for reconstructing an scene s plenoptic function from an incomplete set of camera viewpoints.
inspec,test_2030,elimination of zero order diffraction in digital holography. a simple method to suppress the zero order diffraction in the reconstructed image of digital holography is presented. in this method the laplacian of a detected hologram is used instead of the hologram itself for numerical reconstruction by computing the discrete fresnel integral. this method can significantly improve the image quality and give better resolution and higher accuracy of the reconstructed image. the main advantages of this method are its simplicity in experimental requirements and convenience in data processing.
inspec,test_2031,efficient two level image thresholding method based on bayesian formulation and the maximum entropy principle. an efficient method for two level thresholding is proposed based on the bayes formula and the maximum entropy principle in which no assumptions of the image histogram are made. an alternative criterion is derived based on maximizing entropy and used for speeding up the searching algorithm. five forms of conditional probability distributions simple linear parabola concave parabola convex and s function are employed and compared to each other for optimal threshold determination. the effect of precision on optimal threshold determination is discussed and a trade off precision epsilon 0 001 is selected experimentally. our experiments demonstrate that the proposed method achieves a significant improvement in speed from 26 to 57 times faster than the exhaustive search method.
inspec,test_2032,adaptive digital watermarking using fuzzy logic techniques. digital watermarking has been proposed for copyright protection in our digital society. we propose an adaptive digital watermarking scheme based on the human visual system model and a fuzzy logic technique. the fuzzy logic approach is employed to obtain the different strengths and lengths of a watermark by the local characteristics of the image in our proposed scheme. in our experiments this scheme provides a more robust and imperceptible watermark.
inspec,test_2033,optical encoding of color three dimensional correlation. three dimensional 3d correlation of color images considering the color distribution as the third dimension has been shown to be useful for color pattern recognition tasks. nevertheless 3d correlation can not be directly performed on an optical correlator that can only process two dimensional 2d signals. we propose a method to encode 3d functions onto 2d ones in such a way that the fourier transform and correlation of these signals that can be optically performed encode the 3d fourier transform and correlation of the 3d signals. the theory for the encoding is given and experimental results obtained in an optical correlator are shown.
inspec,test_2035,search for efficient solutions of multi criterion problems by target level method. the target level method is considered for solving continuous multi criterion maximization problems. in the first step the decision maker specifies a target level point the desired criterion values then in the set of vector evaluations we seek points that are closest to the target point in the chebyshev metric. the vector evaluations obtained in this way are in general weakly efficient. to identify the efficient evaluations the second step maximizes the sum of the criteria on the set generated in step 1. we prove the relationship between the evaluations and decisions obtained by the proposed procedure on the one hand and the efficient weakly efficient evaluations and decisions on the other hand. if the edgeworth pareto hull of the set of vector evaluations is convex the set of efficient vector evaluations can be approximated by the proposed method.
inspec,test_2036,computer processing of data on mental impairments during the acute period of concussion. the article presents results of computer processing of experimental information obtained from patients during the acute period of concussion. a number of computational procedures are described.
inspec,test_2037,regularization of linear regression problems. the study considers robust estimation of linear regression parameters by the regularization method the pseudoinverse method and the bayesian method allowing for correlations and errors in the data. regularizing algorithms are constructed and their relationship with pseudoinversion the bayesian approach and blue is investigated.
inspec,test_2038,choice from a three element set some lessons of the 2000 presidential campaign in the united states. we consider the behavior of four choice rules plurality voting approval voting borda count and self consistent choice when applied to choose the best option from a three element set. it is assumed that the two main options are preferred by a large majority of the voters while the third option gets a very small number of votes and influences the election outcome only when the two main options receive a close number of votes. when used to rate the main options borda count and self consistent choice contain terms that allow both for the strength of preferences of the voters and the rating of the main candidates by voters who vote for the third option. in this way it becomes possible to determine more reliably the winner when plurality voting or approval voting produce close results.
inspec,test_2039,an inverse problem for a model of a hierarchical structure. we consider the inverse problem for the identification of the coefficient in a parabolic equation. the model is applied to describe the functioning of a hierarchical structure it is also relevant for heat conduction theory. unique solvability of the inverse problem is proved.
inspec,test_204,self calibration from image derivatives. this study investigates the problem of estimating camera calibration parameters from image motion fields induced by a rigidly moving camera with unknown parameters where the image formation is modeled with a linear pinhole camera model. the equations obtained show the flow to be separated into a component due to the translation and the calibration parameters and a component due to the rotation and the calibration parameters. a set of parameters encoding the latter component is linearly related to the flow and from these parameters the calibration can be determined. however as for discrete motion in general it is not possible to decouple image measurements obtained from only two frames into translational and rotational components. geometrically the ambiguity takes the form of a part of the rotational component being parallel to the translational component and thus the scene can be reconstructed only up to a projective transformation. in general for full calibration at least four successive image frames are necessary with the 3d rotation changing between the measurements. the geometric analysis gives rise to a direct self calibration method that avoids computation of optical flow or point correspondences and uses only normal flow measurements. new constraints on the smoothness of the surfaces in view are formulated to relate structure and motion directly to image derivatives and on the basis of these constraints the transformation of the viewing geometry between consecutive images is estimated. the calibration parameters are then estimated from the rotational components of several flow fields. as the proposed technique neither requires a special set up nor needs exact correspondence it is potentially useful for the calibration of active vision systems which have to acquire knowledge about their intrinsic parameters while they perform other tasks or as a tool for analyzing image sequences in large video databases.
inspec,test_2040,inverse problems for a mathematical model of ion exchange in a compressible ion exchanger. a mathematical model of ion exchange is considered allowing for ion exchanger compression in the process of ion exchange. two inverse problems are investigated for this model unique solvability is proved and numerical solution methods are proposed. the efficiency of the proposed methods is demonstrated by a numerical experiment.
inspec,test_2041,application of multiprocessor systems for computation of jets. the article describes the implementation of methods for numerical solution of gas dynamic problems on a wide class of multiprocessor systems conventionally characterized as cluster systems. a standard data transfer interface the so called message passing interface is used for parallelization of application algorithms among processors. simulation of jets escaping into a low pressure region is chosen as a computational example.
inspec,test_2042,hybrid simulation of space plasmas models with massless fluid representation of electrons. iv. kelvin helmholtz instability. for pt iii. see prikl. mat. informatika maks press no 4 p 5 56 2000. this is a survey of the literature on hybrid simulation of the kelvin helmholtz instability. we start with a brief review of the theory the simplest model of the instability a transition layer in the form of a tangential discontinuity compressibility of the medium finite size of the velocity shear region pressure anisotropy. we then describe the electromagnetic hybrid model ions as particles and electrons as a massless fluid and the main numerical schemes. we review the studies on two dimensional and three dimensional hybrid simulation of the process of particle mixing across the magnetopause shear layer driven by the onset of a kelvin helmholtz instability. the article concludes with a survey of literature on hybrid simulation of the kelvin helmholtz instability in finite size objects jets moving across the magnetic field in the middle of the field reversal layer interaction between a magnetized plasma flow and a cylindrical plasma source with zero own magnetic field.
inspec,test_2043,limits for computational electromagnetics codes imposed by computer architecture. the algorithmic complexity of the innermost loops that determine the complexity of algorithms in computational electromagnetics cem codes are analyzed according to their operation count and the impact of the underlying computer hardware. as memory chips are much slower than arithmetic processors codes that involve a high data movement compared to the number of arithmetic operations are executed comparatively slower. hence matrix matrix multiplications are much faster than matrix vector multiplications. it is seen that it is not sufficient to compare only the complexity but also the actual performance of algorithms to judge on faster execution. implications involve fdtd loops lu factorizations and iterative solvers for dense matrices. run times on two reference platforms namely an athlon 900 mhz and an hp pa 8600 processor verify the findings.
inspec,test_2044,three dimensional geometrical optics code for indoor propagation. this paper presents a program go 3d for computing the fields of a transmitter in an indoor environment using geometrical optics. the program uses an image tree data structure to construct the images needed to compute all the rays carrying fields above a preset threshold value no matter how many reflections are needed. the paper briefly describes the input file required to define wall construction the floor plan the transmitter and the receiver locations. a case study consisting of a long corridor with a small room on one side is used to demonstrate the features of the go 3d program.
inspec,test_2045,building a better game through dynamic programming a flip analysis. flip is a solitaire board game produced by craft woodworkers. we analyze flip and suggest modifications to the rules to make the game more marketable. in addition to being an interesting application of dynamic programming this case shows the use of operations research in managerial decision making.
inspec,test_2046,designing and delivering a university course a process or operations management perspective. with over 30 years of academic experience in both engineering and management faculties involving trial and error experimentation in teaching as well as reading relevant literature and observing other instructors in action the author has accumulated a number of ideas regarding the preparation and delivery of a university course that should be of interest to other instructors. this should be particularly the case for those individuals who have had little or no teaching experience e g those whose graduate education was recently completed at research oriented institutions providing little guidance with respect to teaching. a particular perspective is used to convey the ideas namely one of viewing the preparation and delivery of a course as two major processes that should provide outputs or outcomes that are of value to a number of customers in particular students.
inspec,test_2047,a generalized pert cpm implementation in a spreadsheet. this paper describes the implementation of the traditional pert cpm algorithm for finding the critical path in a project network in a spreadsheet. the problem is of importance due to the recent shift of attention to using the spreadsheet environment as a vehicle for delivering management science operations research ms or techniques to end users.
inspec,test_2048,an object oriented version of simlib a simple simulation package. this paper introduces an object oriented version of simlib an easy to understand discrete event simulation package. the object oriented version is preferable to the original procedural language versions of simlib in that it is easier to understand and teach simulation from an object point of view. a single server queue simulation is demonstrated using the object oriented simlib.
inspec,test_2049,the maximum possible evpi. in this paper we calculate the maximum expected value of perfect information evpi for any probability distribution for the states of the world. this maximum evpi is an upper bound for the evpi with given probabilities and thus an upper bound for any partial information about the states of the world.
inspec,test_205,geotensity combining motion and lighting for 3d surface reconstruction. this paper is about automatically reconstructing the full 3d surface of an object observed in motion by a single static camera. based on the two paradigms structure from motion and linear intensity subspaces we introduce the geotensity constraint that governs the relationship between four or more images of a moving object. we show that it is possible in theory to solve for 3d lambertian surface structure for the case of a single point light source and propose that a solution exists for an arbitrary number point light sources. the surface may or may not be textured. we then give an example of automatic surface reconstruction of a face under a point light source using arbitrary unknown object motion and a single fixed camera.
inspec,test_2050,who wants to be a millionaire r the classroom edition. this paper introduces a version of the internationally popular television game show who wants to be a millionaire r that has been created for use in the classroom using microsoft powerpoint r. a suggested framework for its classroom use is presented instructions on operating and editing the classroom version of who wants to be a millionaire r are provided and sample feedback from students who have played the classroom version of who wants to be a millionaire r is offered.
inspec,test_2051,who wants to see a million error. inspired by the popular television show who wants to be a millionaire. this case discusses the monetary decisions contestants face on a game consisting of 15 increasingly difficult multiple choice questions. since the game continues as long as a contestant answers correctly this case at its core is one of sequential decision analysis amenable to analysis via stochastic dynamic programming. the case is also suitable for a course dealing with single decision analysis allowing for discussion of utility theory and bayesian probability revision. in developing a story line for the case the author has sprinkled in much background material on probability and statistics. this material is placed in a historical context illuminating some of the influential scholars involved in the development of these subjects as well as the birth of operations research and the management sciences.
inspec,test_2052,blitzograms interactive histograms. as computers become ever faster more and more procedures that were once viewed as iterative will continue to become instantaneous. the blitzogram is the application of this trend to histograms which the author hopes will lead to a better tacit understanding of probability distributions among both students and managers. and this is not just an academic exercise. commercial monte carlo simulation packages like risk and crystal ball and my insight xla are widely available.
inspec,test_2053,teaching management science with spreadsheets from decision models to decision support. the 1990s were a decade of enormous change for management science ms educators. while the outlook at the beginning of the decade was somewhat bleak the renaissance in ms education brought about by the use of spreadsheets as the primary delivery vehicle for quantitative modeling techniques has resulted in a much brighter future. this paper takes inventory of the current state of ms education and suggests some promising new directions in the area of decision support systems for ms educators to consider for the future.
inspec,test_2054,teaching modeling in management science. this essay discusses how we can most effectively teach management science to students in mba or similar programs who will be at best part time practitioners of these arts. i take as a working hypothesis the radical proposition that the heart of management science itself is not the impressive array of tools that have been built up over the years optimization simulation decision analysis queuing and so on but rather the art of reasoning logically with formal models. i believe it is necessary with this group of students to teach basic modeling skills and in fact it is only when such students have these basic skills as a foundation that they are prepared to acquire the more sophisticated skills needed to employ management science. in this paper i present a hierarchy of modeling skills from numeracy skills through sophisticated management science skills as a framework within which to plan courses for the occasional practitioner.
inspec,test_2055,causes of the decline of the business school management science course. the business school management science course is suffering serious decline. the traditional model and algorithm based course fails to meet the needs of mba programs and students. poor student mathematical preparation is a reality and is not an acceptable justification for poor teaching outcomes. management science ph d s are often poorly prepared to teach in a general management program having more experience and interest in algorithms than management. the management science profession as a whole has focused its attention on algorithms and a narrow subset of management problems for which they are most applicable. in contrast mba s rarely encounter problems that are suitable for straightforward application of management science tools living instead in a world where problems are ill defined data is scarce time is short politics is dominant and rational decision makers are non existent. the root cause of the profession s failure to address these issues seems to be in russell ackoff s words a habit of professional introversion that caused the profession to be uninterested in what mba s really do on the job and how management science can help them.
inspec,test_2056,gifts to a science academic librarian. gifts by their altruistic nature perfectly fit into the environment of universities and academic libraries. as a university s community and general public continue to donate materials libraries accept donations willingly both in kind and monetary. eight steps of gift processing are listed in the paper. positive and negative aspects of gift acceptance are discussed. gifts bring value for academic libraries. gifts can be considered additional routes to contribute to library collections without direct purchases options to add money to the library budget and the cement of social relationships. but unfortunately large donations are time consuming labor intensive and costly to process. great amounts of staff time and processing space are two main negative aspects that cause concern and put the value of gift acceptance under consideration by librarians. some strategies in handling gifts are recommended. to be effective academic science librarians need to approach gifts as an investment. librarians are not to be forced by moral and public notions and should be able to make professional decisions in evaluating proposed collections.
inspec,test_2057,four factors influencing the fair market value of out of print books. 2. fot pt 1 see ibid p 71 8 2002. data from the fifty six titles examined qualitatively in the patterson study are examined quantitatively. in addition to the four factors of edition condition dust jacket and autograph that were hypothesized to influence the value of a book four other factors for which information was available in the data were examined.
inspec,test_2058,four factors influencing the fair market value of out of print books 1. four factors edition condition dust jacket and autograph that are hypothesized to influence the value of books are identified and linked to basic economic principles which are explained. a sample of fifty six titles is qualitatively examined to test the hypothesis.
inspec,test_2059,acquiring materials in the history of science technology and medicine. this article provides detailed advice on acquiring new out of print and rare materials in the history of science technology and medicine for the beginner in these fields. the focus is on the policy formation basic reference tools and methods of collection development and acquisitions that are the necessary basis for success in this endeavor.
inspec,test_206,information architecture looking ahead. it may be a bit strange to consider where the field of information architecture ia is headed. after all many would argue that it s too new to be considered as a field at all or that it is mislabeled and by no means is there a widely accepted definition of what information architecture actually is. practicing information architects probably number in the thousands and this vibrant group is already building various forms of communal infrastructure ranging from an ia journal and a self organizing library of resources to a passel of local professional groups and degree granting academic programs. so the profession has achieved a beachhead that will enable it to stabilize and perhaps even grow during these difficult times.
inspec,test_2060,decisions decisions decisions a tale of special collections in the small academic library. a case study of a special collections department in a small academic library and how its collections have been acquired and developed over the years is described. it looks at the changes that have occurred in the academic environment and what effect if any these changes may have had on the department and how it has adapted to them. it raises questions about development and acquisitions policies and procedures.
inspec,test_2061,acquisitions in the james ford bell library. this article presents basic acquisitions philosophy and approaches in a noted special collection with commentary on just saying no and on how the electronic revolution has changed the acquisition of special collections materials.
inspec,test_2062,underground poetry collecting poetry and the librarian. a powerful encounter with underground poetry and its important role in poetry literature and culture is discussed. the acquisitions difficulties encountered in the unique publishing world of underground poetry are introduced. strategies for acquiring underground poetry for library collections are proposed including total immersion and local focus with accompanying action.
inspec,test_2063,on emotion and bounded rationality reply to hanoch. the author refers to the comment made by hanoch see ibid. vol 49 2000 on his model of bounded rationality and the role of the yerkes dodson law and emotional arousal in it. the author points out that hanoch s comment however conspicuously fails to challenge much less contradict the central hypothesis of his paper. in addition several of hanoch s criticisms are based on a wrong characterization of the positions.
inspec,test_2064,the effects of emotions on bounded rationality a comment on kaufman. bruce kaufman s article 1999  emotional arousal as a source of bounded rationality  objective is to present an additional source of bounded rationality one that is not due to cognitive constraints but to high emotional arousal. in doing so kaufman is following a long tradition of thinkers who have contrasted emotion with reason claiming for the most part that emotions are a violent force hindering rational thinking. this paper aims to challenge kaufman s unidimensional idea regarding the connection between high emotional arousal and decision making.
inspec,test_2065,emotion and self control. a biology based model of choice is used to examine time inconsistent preferences and the problem of self control. emotion is shown to be the biological substrate of choice in that emotional systems assign value to goods in the environment and also facilitate the learning of expectations regarding alternative options for acquiring those goods. a third major function of the emotional choice systems is motivation. self control is shown to be the result of a problem with the inhibition of the motive force of emotion where this inhibition is necessary for higher level deliberation.
inspec,test_2066,product and process innovations in the life cycle of an industry. filson 2001 uses industry level data on firm numbers price quantity and quality along with an equilibrium model of industry evolution to estimate the nature and effects of quality and cost improvements in the personal computer industry and four other new industries. this paper studies the personal computer industry in more detail and shows that the model explains some peculiar patterns that can not be explained by previous life cycle models. the model estimates are evaluated using historical studies of the evolution of the personal computer industry and patterns that require further model development are described.
inspec,test_2067,a comparison of the discounted utility model and hyperbolic discounting models in the case of social and private intertemporal preferences for health. whilst there is substantial evidence that hyperbolic discounting models describe intertemporal preferences for monetary outcomes better than the discounted utility du model there is only very limited evidence in the context of health outcomes. this study elicits private and social intertemporal preferences for non fatal changes in health. specific functional forms of the du model and three hyperbolic models are fitted. the results show that the stationarity axiom is violated and that the hyperbolic models fit the data better than the du model. intertemporal preferences for private and social decisions are found to be very similar.
inspec,test_2068,modeling the labor market as an evolving institution model artemis. a stylized french labor market is modeled as an endogenously evolving institution. boundedly rational firms and individuals strive to decrease the cost or increase utility. the labor market is coordinated by a search process and decentralized setting of hiring standards but intermediaries can speed up matching. the model reproduces the dynamics of the gross flows and spectacular changes in mobility patterns of some demographic groups when the oil crisis in the 1970 s occurred notably the sudden decline of the integration in good jobs. the internal labor markets of large firms are shown to increase unemployment if the secondary temporary or bad jobs do not exist.
inspec,test_2069,the ultimate control group. empirical research on the organization of firms requires that firms be classified on the basis of their control structures. this should be done in a way that can potentially be made operational. it is easy to identify the ultimate controller of a hierarchical organization and the literature has largely focused on this case. however many organizational structures mix hierarchy with collective choice procedures such as voting or use circular structures under which superiors are accountable to their subordinates. the author develops some analytic machinery that can be used to map the authority structures of such organizations and show that under mild restrictions there is a well defined ultimate control group. the results are consistent with intuitions about the nature of control in familiar economic settings.
inspec,test_207,information architecture for bilingual web sites. creating an information architecture for a bilingual web site presents particular challenges beyond those that exist for single and multilanguage sites. this article reports work in progress on the development of a content based bilingual web site to facilitate the sharing of resources and information between speech and language therapists. the development of the information architecture is based on a combination of two aspects an abstract structural analysis of existing bilingual web designs focusing on the presentation of bilingual material and a bilingual card sorting activity conducted with potential users. issues for bilingual developments are discussed and some observations are made regarding the use of card sorting activities.
inspec,test_2070,modularity in technology and organization. the paper is an attempt to raid both the literature on modular design and the literature on property rights to create the outlines of a modularity theory of the firm. such a theory will look at firms and other organizations in terms of the partitioning of rights understood as protected spheres of authority among cooperating parties. it will assert that organizations reflect nonmodular structures that is structures in which decision rights rights of alienation and residual claims to income do not all reside in the same hands.
inspec,test_208,designing a new urban internet. the parallel between designing a web site and the construction of a building is a familiar one but how often do we think of the internet as having parks and streets. it would be absurd to say that the internet could ever take the place of real livable communities however it is safe to say that the context for using the internet is on a path of change. as the internet evolves beyond a simple linkage of disparate web sites and applications the challenge for information architects is establishing a process by which to structure organize and design networked environments. the principles that guide new urbanism can offer much insight into networked electronic environment design. at the core of every new urbanism principle is the idea of wholeness  of making sure that neighborhoods and communities are knit together in a way that supports civic activities economic development efficient ecosystems aesthetic beauty and human interaction.
inspec,test_2081,three dimensional optimum design of the cooling lines of injection moulds based on boundary element design sensitivity analysis. a three dimensional numerical simulation using the boundary element method is proposed which can predict the cavity temperature distributions in the cooling stage of injection moulding. then choosing the radii and positions of cooling lines as design variables the boundary integral sensitivity formulations are deduced. for the optimum design of cooling lines the squared difference between the objective temperature and temperature of the cavity is taken as the objective function. based on the optimization techniques with design sensitivity analysis an iterative algorithm to reach the minimum value of the objective function is introduced which leads to the optimum design of cooling lines at the same time.
inspec,test_2082,managing safety and strategic stocks to improve materials requirements planning performance. this paper provides a methodology for managing safety and strategic stocks in materials requirements planning mrp environments to face uncertainty in market demand. a set of recommended guidelines suggest where to position how to dimension and when to replenish both safety and strategic stocks. trade offs between stock positioning and dimensioning and between stock positioning and replenishment order triggering are outlined. the study reveals also that most of the decisions are system specific so that they should be evaluated in a quantitative manner through simulation. a case study is reported where the benefits from adopting the new proposed methodology lie in achieving the target service level even under peak demand conditions with the value of safety stocks as a whole growing only by about 20 per cent.
inspec,test_2083,innovative manufacture of impulse turbine blades for wave energy power conversion. an innovative approach to the manufacture of impulse turbine blades using rapid prototyping fused decomposition modelling fdm is presented. these blades were designed and manufactured by the wave energy research team wert at the university of limerick for the experimental analysis of a 0 6 m impulse turbine with fixed guide vanes for wave energy power conversion. the computer aided design manufacture cad cam package pro engineer 2000i was used for three dimensional solid modelling of the individual blades. a detailed finite element analysis of the blades under centrifugal loads was performed using pro mechanica. based on this analysis and fdm machine capabilities blades were redesigned. finally pro e data were transferred to an fdm machine for the manufacture of turbine blades. the objective of this paper is to present the innovative method used to design modify and manufacture blades in a time and cost effective manner using a concurrent engineering approach.
inspec,test_2084,evaluation of combined dispatching and routeing strategies for a flexible manufacturing system. this paper deals with the evaluation of combined dispatching and routeing strategies on the performance of a flexible manufacturing system. three routeing policies no alternative routings alternative routeing dynamics and alternative routeing plans are considered with four dispatching rules with finite buffer capacity. in addition the effect of changing part mix ratios is also discussed. the performance measures considered are makespan average machine utilization average flow time and average delay at local input buffers. simulation results indicate that the alternative routings dynamic policy gives the best results in three performance measures except for average delay at local input buffers. further the effect of changing part mix ratios is not significant.
inspec,test_2085,an intelligent fuzzy decision system for a flexible manufacturing system with multi decision points. this paper describes an intelligent fuzzy decision support system for real time scheduling and dispatching of parts in a flexible manufacturing system fms with alternative routing possibilities for all parts. a fuzzy logic approach is developed to improve the system performance by considering multiple performance measures and at multiple decision points. the characteristics of the system status instead of parts are fed back to assign priority to the parts waiting to be processed. a simulation model is developed and it is shown that the proposed intelligent fuzzy decision support system keeps all performance measures at a good level. the proposed intelligent system is a promising tool for dealing with scheduling fmss in contrast to traditional rules.
inspec,test_2086,a design to cost system for innovative product development. presents a prototype object oriented and rule based system for product cost modelling and design for automation at an early design stage. the developed system comprises a computer aided design cad solid modelling system a material selection module a knowledge based system kbs a process optimization module a design for assembly module a cost estimation module and a user interface. two manufacturing processes namely machining and injection moulding processes were considered in the developed system. the main function of the system besides estimating the product cost is to generate initial process planning including the generation and selection of machining processes their sequence and their machining parameters and to recommend the most economical assembly technique for a product and provide design improvement suggestions based on a design feasibility technique. in addition a feature by feature cost estimation report is generated using the proposed system to highlight the features of high manufacturing cost. two case studies were used to validate the developed system.
inspec,test_2087,re examining the machining frictional boundary conditions using fractals. presents experimental evidence for the existence of non euclidean contact geometry at the tool chip interface in the machining of aluminium alloy which challenges conventional assumptions. the geometry of contact at the tool rake face is modelled using fractals and a dimension is computed for its description. the variation in the fractal dimension with the cutting speed is explored.
inspec,test_2088,layer based machining recent development and support structure design. there is growing interest in additive and subtractive shaping theories that are synthesized to integrate the layered manufacturing process and material removal process. layer based machining has emerged as a promising method for integrated additive and subtractive shaping theory. in the paper major layer based machining systems are reviewed and compared according to characteristics of stock layers numerical control machining configurations stacking operations input format and raw materials. support structure a major issue in machining based systems which has seldom been addressed in previous research is investigated in the paper with considerations of four situations floating overhang cantilever vaulted overhang and ceiling. except for the floating overhang where a support structure should not be overlooked the necessity for support structures for the other three situations is determined by stress and deflection analysis. this is demonstrated by the machining of a large castle model.
inspec,test_2089,world s biggest battery helps to stabilise alaska. in this paper the author describes a battery energy storage system which is under construction to provide voltage compensation in support of alaska s 138 kv northern intertie.
inspec,test_209,information interaction providing a framework for information architecture. information interaction is the process that people use in interacting with the content of an information system. information architecture is a blueprint and navigational aid to the content of information rich systems. as such information architecture performs an important supporting role in information interactivity. this article elaborates on a model of information interactivity that crosses the no man s land between user and computer articulating a model that includes user content and system illustrating the context for information architecture.
inspec,test_2090,all optical logic nor gate using two cascaded semiconductor optical amplifiers. the authors present a novel all optical logic nor gate using two cascaded semiconductor optical. amplifiers soas in a counterpropagating feedback configuration. this configuration accentuates the gain nonlinearity due to the mutual gain modulation of the two soas. the all optical nor gate feasibility has been demonstrated delivering an extinction ratio higher than 12 db over a wide range of wavelength.
inspec,test_2091,prospects for quantitative computed tomography imaging in the presence of foreign metal bodies using statistical image reconstruction. x ray computed tomography ct images of patients bearing metal intracavitary applicators or other metal foreign objects exhibit severe artifacts including streaks and aliasing. we have systematically evaluated via computer simulations the impact of scattered radiation the polyenergetic spectrum and measurement noise on the performance of three reconstruction algorithms conventional filtered backprojection fbp deterministic iterative deblurring and a new iterative algorithm alternating minimization am based on a ct detector model that includes noise scatter and polyenergetic spectra. contrary to the dominant view of the literature fbp streaking artifacts are due mostly to mismatches between fbp s simplified model of ct detector response and the physical process of signal acquisition. artifacts on am images are significantly mitigated as this algorithm substantially reduces detector model mismatches. however metal artifacts are reduced to acceptable levels only when prior knowledge of the metal object in the patient including its pose shape and attenuation map are used to constrain am s iterations. am image reconstruction in combination with object constrained ct to estimate the pose of metal objects in the patient is a promising approach for effectively mitigating metal artifacts and making quantitative estimation of tissue attenuation coefficients a clinical possibility.
inspec,test_2092,matching pet and ct scans of the head and neck area development of method and validation. positron emission tomography pet provides important information on tumor biology but lacks detailed anatomical information. our aim in the present study was to develop and validate an automatic registration method for matching pet and ct scans of the head and neck. three difficulties in achieving this goal are 1 nonrigid motions of the neck can hamper the use of automatic ridged body transformations 2 emission scans contain too little anatomical information to apply standard image fusion methods and 3 no objective way exists to quantify the quality of the match results. these problems are solved as follows accurate and reproducible positioning of the patient was achieved by using a radiotherapy treatment mask. the proposed method makes use of the transmission rather than the emission scan. to obtain sufficient anatomical information for matching two bed positions for the transmission scan were included in the protocol. a mutual information based algorithm was used as a registration technique. pet and ct data were obtained in seven patients. each patient had two ct scans and one pet scan. the datasets were used to estimate the consistency by matching pet to ct sub 1  ct sub 1 to ct sub 2  and ct sub 2 to pet using the full circle consistency test. it was found that using our method consistency could be obtained of 4 mm and 1 3 degrees on average. the pet voxels used for registration were 5 15 mm so the errors compared quite favorably with the voxel size. cropping the images removing the scanner bed from images did not improve the consistency of the algorithm. the transmission scan however could potentially be reduced to a single position using this approach. in conclusion the represented algorithm and validation technique has several features that are attractive from both theoretical and practical point of view it is a user independent automatic validation technique for matching ct and pet scans of the head and neck which gives the opportunity to compare different image enhancements.
inspec,test_2093,fresh tracks food processing. bar code labels and wireless terminals linked to a centralized database accurately track meat products from receiving to customers for farmland foods.
inspec,test_2094,statistical inference with partial prior information based on a gauss type inequality. potter and anderson 1983 have developed a bayesian decision procedure requiring the specification of a class of prior distributions restricted to have a minimal probability content for a given subset of the parameter space. they do not however provide a method for the selection of that subset. we show how a generalization of gauss inequality can be used to determine the relevant parameter subset.
inspec,test_2095,global stability of the attracting set of an enzyme catalysed reaction system. the essential feature of enzymatic reactions is a nonlinear dependency of reaction rate on metabolite concentration taking the form of saturation kinetics. recently it has been shown that this feature is associated with the phenomenon of loss of system coordination liu 1999. in this paper we study a system of ordinary differential equations representing a branched biochemical system of enzyme mediated reactions. we show that this system can become very sensitive to changes in certain maximum enzyme activities. in particular we show that the system exhibits three distinct responses a unique globally stable steady state large amplitude oscillations and asymptotically unbounded solutions with the transition between these states being almost instantaneous. it is shown that the appearance of large amplitude stable limit cycles occurs due to a false bifurcation or canard explosion. the subsequent disappearance of limit cycles corresponds to the collapse of the domain of attraction of the attracting set for the system and occurs due to a global bifurcation in the flow namely a saddle connection. subsequently almost all nonnegative data become unbounded under the action of the dynamical system and correspond exactly to loss of system coordination. we discuss the relevance of these results to the possible consequences of modulating such systems.
inspec,test_2096,a spatial rainfall simulator for crop production modeling in southern africa. this paper describes a methodology for simulating rainfall in dekads across a set of spatial units in areas where long term meteorological records are available for a small number of sites only. the work forms part of a larger simulation model of the food system in a district of zimbabwe which includes a crop production component for yields of maize small grains and groundnuts. only a limited number of meteorological stations are available within or surrounding the district that have long time series of rainfall records. preliminary analysis of rainfall data for these stations suggested that intra seasonal temporal correlation was negligible but that rainfall at any given station was correlated with rainfall at neighbouring stations. this spatial correlation structure can be modeled using a multivariate normal distribution consisting of 30 related variables representing dekadly rainfall in each of the 30 wards. for each ward log transformed rainfall for each of the 36 dekads in the year was characterized by a mean and standard deviation which were interpolated from surrounding meteorological stations. a covariance matrix derived from a distance measure was then used to represent the spatial correlation between wards. sets of random numbers were then drawn from this distribution to simulate rainfall across the wards in any given dekad. cross validation of estimated rainfall parameters against observed parameters for the one meteorological station within the district suggests that the interpolation process works well. the methodology developed is useful in situations where long term climatic records are scarce and where rainfall shows pronounced spatial correlation but negligible temporal correlation.
inspec,test_2097,an algorithm to generate all spanning trees with flow. spanning tree enumeration in undirected graphs is an important issue and task in many problems encountered in computer network and circuit analysis. this paper discusses the spanning tree with flow for the case that there are flow requirements between each node pair. an algorithm based on minimal paths mps is proposed to generate all spanning trees without flow. the proposed algorithm is a structured approach which splits the system into structural mps first and also all steps in it are easy to follow.
inspec,test_2098,nonlinear systems arising from nonisothermal non newtonian hele shaw flows in the presence of body forces and sources. in this paper we first give a formal derivation of several systems of equations for injection moulding. this is done starting from the basic equations for nonisothermal non newtonian flows in a three dimensional domain. we derive systems for both t sup 0  p sup 0 and t sup 1  p sup 1 in the presence of body forces and sources. we find that body forces and sources have a nonlinear effect on the systems. we also derive a nonlinear darcy law. our formulation includes not only the pressure gradient but also body forces and sources which play the role of a nonlinearity. later we prove the existence of weak solutions to certain boundary value problems and initial boundary value problems associated with the resulting equations for t sup 0  p sup 0 but in a more general mathematical setting.
inspec,test_2099,analyzing the potential of a firm an operations research approach. an approach to analyzing the potential of a firm which is understood as the firm s ability to provide goods or and services to be supplied to a marketplace under restrictions imposed by a business environment in which the firm functions is proposed. the approach is based on using linear inequalities and generally mixed variables in modelling this ability for a broad spectrum of industrial transportation agricultural and other types of firms and allows one to formulate problems of analyzing the potential of a firm as linear programming problems or mixed programming problems with linear constraints. this approach generalizes a previous one which was proposed for a more narrow class of models and allows one to effectively employ a widely available software for solving practical problems of the considered kind especially for firms described by large scale models of mathematical programming.
inspec,test_21,discrete output feedback sliding mode control of second order systems a moving switching line approach. the sliding mode control systems smcs for which the switching variable is designed independent of the initial conditions are known to be sensitive to parameter variations and extraneous disturbances during the reaching phase. for second order systems this drawback is eliminated by using the moving switching line technique where the switching line is initially designed to pass the initial conditions and is subsequently moved towards a predetermined switching line. in this paper we make use of the above idea of moving switching line together with the reaching law approach to design a discrete output feedback sliding mode control. the main contributions of this work are such that we do not require to use system states as it makes use of only the output samples for designing the controller. and by using the moving switching line a low sensitivity system is obtained through shortening the reaching phase. simulation results show that the fast output sampling feedback guarantees sliding motion similar to that obtained using state feedback.
inspec,test_210,when a better interface and easy navigation are n t enough examining the information architecture in a law enforcement agency. an information architecture that allows users to easily navigate through a system and quickly recover from mistakes is often defined as a highly usable system. but usability in systems design goes beyond a good interface and efficient navigation. in this article we describe two database systems in a law enforcement agency. one system is a legacy text based system with cumbersome navigation rms the newer system is a graphical user interface with simplified navigation copnet. it is hypothesized that law enforcement users will evaluate copnet higher than rms but experts of the older system will evaluate it higher than others will. we conducted two user studies. one study examined what users thought of rms and copnet and compared rms experts evaluations with nonexperts. we found that all users evaluated copnet as more effective easier to use and easier to navigate than rms and this was especially noticeable for users who were not experts with the older system. the second follow up study examined use behavior after copnet was deployed some time later. the findings revealed that evaluations of copnet were not associated with its use. if the newer system had a better interface and was easier to navigate than the older legacy system why were law enforcement personnel reluctant to switch. we discuss reasons why switching to a new system is difficult especially for those who are most adept at using the older system. implications for system design and usability are also discussed.
inspec,test_2100,optimization of planning an advertising campaign of goods and services. a generalization of the mathematical model and operations research problems formulated on its basis which were presented by belenky 2001 in the framework of an approach to planning an advertising campaign of goods and services is considered and corresponding nonlinear programming problems with linear constraints are formulated.
inspec,test_2101,all optical xor gate using semiconductor optical amplifiers without additional input beam. the novel design of an all optical xor gate by using cross gain modulation of semiconductor optical amplifiers has been suggested and demonstrated successfully at 10 gb s. boolean ab and ab of the two input signals a and b have been obtained and combined to achieve the all optical xor gate. no additional input beam such as a clock signal or continuous wave light is used in this new design which is required in other all optical xor gates.
inspec,test_2102,trust in online advice. many people are now influenced by the information and advice they find on the internet much of it of dubious quality. this article describes two studies concerned with those factors capable of influencing people s response to online advice. the first study is a qualitative account of a group of house hunters attempting to find worthwhile information online. the second study describes a survey of more than 2 500 people who had actively sought advice over the internet. a framework for understanding trust in online advice is proposed in which first impressions are distinguished from more detailed evaluations. good web design can influence the first process but three key factors source credibility personalization and predictability are shown to predict whether people actually follow the advice given.
inspec,test_2103,the social impact of internet gambling. technology has always played a role in the development of gambling practices and continues to provide new market opportunities. one of the fastest growing areas is that of internet gambling. the effect of such technologies should not be accepted uncritically particularly as there may be areas of potential concern based on what is known about problem gambling offline. this article has three aims. first it overviews some of the main social concerns about the rise of internet gambling. second it looks at the limited research that has been carried out in this area. third it examines whether internet gambling is doubly addictive given research that suggests that the internet can be addictive itself. it is concluded that technological developments in internet gambling will increase the potential for problem gambling globally but that many of the ideas and speculations outlined in this article need to be addressed further by large scale empirical studies.
inspec,test_2104,computer mediated communication and remote management integration or isolation. the use of intranets and e mails to communicate with remote staff is increasing rapidly within organizations. for many companies this is viewed as a speedy and cost effective way of keeping in contact with staff and ensuring their continuing commitment to company goals. this article highlights the problems experienced by staff when managers use intranets and e mails in an inappropriate fashion for these purposes. issues of remoteness and isolation are discussed along with the reports of frustration and disidentification experienced. however it will be shown that when used appropriately communication using these technologies can facilitate shared understanding and help remote staff to view their company as alive and exciting. theoretical aspects are highlighted and the implications of these findings are discussed.
inspec,test_2105,collective action in the age of the internet mass communication and online mobilization. this article examines how the internet transforms collective action. current practices on the web bear witness to thriving collective action ranging from persuasive to confrontational individual to collective undertakings. even more influential than direct calls for action is the indirect mobilizing influence of the internet s powers of mass communication which is boosted by an antiauthoritarian ideology on the web. theoretically collective action through the otherwise socially isolating computer is possible because people rely on internalized group memberships and social identities to achieve social involvement. empirical evidence from an online survey among environmental activists and nonactivists confirms that online action is considered an equivalent alternative to offline action by activists and nonactivists alike. however the internet may slightly alter the motives underlying collective action and thereby alter the nature of collective action and social movements. perhaps more fundamental is the reverse influence that successful collective action will have on the nature and function of the internet.
inspec,test_2106,explanations for the perpetration of and reactions to deception in a virtual community. cases of identity deception on the internet are not uncommon. several cases of a revealed identity deception have been reported in the media. the authors examine a case of deception in an online community composed primarily of information technology professionals. in this case an established community member df invented a character nowheremom whom he fell in love with and who was eventually killed in a tragic accident. when other members of the community eventually began to question nowheremom s actual identity df admitted that he invented her. the discussion board was flooded with reactions to df s revelation. the authors propose several explanations for the perpetration of identity deception including psychiatric illness identity play and expressions of true self. they also analyze the reactions of community members and propose three related explanations social identity deviance and norm violation to account for their reactions. it is argued that virtual communities reactions to such threatening events provide invaluable clues for the study of group processes on the internet.
inspec,test_2107,the effects of asynchronous computer mediated group interaction on group processes. this article reports a study undertaken to investigate some of the social psychological processes underlying computer supported group discussion in natural computer mediated contexts. based on the concept of deindividuation it was hypothesized that personal identifiability and group identity would be important factors that affect the perceptions and behavior of members of computer mediated groups. the degree of personal identifiability and the strength of group identity were manipulated across groups of geographically dispersed computer users who took part in e mail discussions during a 2 week period. the results do not support the association between deindividuation and uninhibited behavior cited in much previous research. instead the data provide some support for a social identity perspective of computer mediated communication which explains the higher levels uninhibited in identifiable computer mediated groups. however predictions based on social identity theory regarding group polarization and group cohesion were not supported. possible explanations for this are discussed and further research is suggested to resolve these discrepancies.
inspec,test_2108,online longitudinal survey research viability and participation. this article explores the viability of conducting longitudinal survey research using the internet in samples exposed to trauma. a questionnaire battery assessing psychological adjustment following adverse life experiences was posted online. participants who signed up to take part in the longitudinal aspect of the study were contacted 3 and 6 months after initial participation to complete the second and third waves of the research. issues of data screening and sample attrition rates are considered and the demographic profiles and questionnaire scores of those who did and did not take part in the study during successive time points are compared. the results demonstrate that it is possible to conduct repeated measures survey research online and that the similarity in characteristics between those who do and do not take part during successive time points mirrors that found in traditional pencil and paper trauma surveys.
inspec,test_2109,internet based psychological experimenting five dos and five do n ts. internet based psychological experimenting is presented as a method that needs careful consideration of a number of issues from potential data corruption to revealing confidential information about participants. ten issues are grouped into five areas of actions to be taken when developing an internet experiment dos and five errors to be avoided do n ts. dos include a utilizing dropout as a dependent variable b the use of dropout to detect motivational confounding c placement of questions for personal information d using a collection of techniques and e using internet based tools. do n ts are about a unprotected directories b public access to confidential data c revealing the experiment s structure d ignoring the internet s technical variance and e improper use of form elements.
inspec,test_211,pervasive computing goes to work interfacing to the enterprise. the paperless office is an idea whose time has come and come and come again. to see how pervasive computing applications might bring some substance to this dream the author spoke recently with key managers and technologists at mckesson corporation san francisco a healthcare supplier service and technology company with us 50 billion in sales last year and also at avantgo hayward calif a provider of mobile infrastructure software and services. for the past several years mckesson has used mobility middleware developed by avantgo to deploy major supply chain applications with thousands of pervasive clients and multiple servers that replace existing paper based tracking systems. according to mckesson s managers their system greatly reduced errors and associated costs caused by redelivery or loss of valuable products giving mckesson a solid return on its investment.
inspec,test_2110,psychology and the internet. this article presents an overview of the way that the internet is being used to assist psychological research and mediate psychological practice. it shows how psychologists are using the internet to examine the interactions between people and computers and highlights some of the ways that this research is important to the design and development of useable and acceptable computer systems. in particular this introduction reviews the research presented at the international conference on psychology and the internet held in the united kingdom. the final part introduces the eight articles in this special edition. the articles are representative of the breadth of research being conducted on psychology and the internet there are two on methodological issues three on group processes one on organizational implications and two on social implications of internet use.
inspec,test_2111,extended depth of focus imaging of chlorophyll fluorescence from intact leaves. imaging dynamic changes in chlorophyll a fluorescence provides a valuable means with which to examine localised changes in photosynthetic function. microscope based systems provide excellent spatial resolution which allows the response of individual cells to be measured. however such systems have a restricted depth of focus and as leaves are inherently uneven only a small proportion of each image at any given focal plane is in focus. in this report we describe the development of algorithms specifically adapted for imaging chlorophyll fluorescence and photosynthetic function in living plant cells which allow extended focus images to be reconstructed from images taken in different focal planes. we describe how these procedures can be used to reconstruct images of chlorophyll fluorescence and calculated photosynthetic parameters as well as producing a map of leaf topology. the robustness of this procedure is demonstrated using leaves from a number of different plant species.
inspec,test_2112,allan variance and fractal brownian motion. noise filtering is the subject of a voluminous literature in radio engineering. the methods of filtering require knowledge of the frequency response which is usually unknown. d w allan see proc. ieee vol 54 no 2 p 221 30 1966 ieee trans. instr. measur vol im 36 p 646 54 1987 proposed a simple method of determining the interval between equally accurate observations which does without this information. in this method the variances of the increments of noise and signal are equal so that in observations with a greater step the variations caused by noise are smaller than those caused by the signal. this method is the standard accepted by the usa metrology community. the present paper is devoted to a statistical analysis of the allan method and acquisition of additional information.
inspec,test_2113,ideal sliding mode in the problems of convex optimization. the characteristics of the sliding mode that appears with using continuous convex programming algorithms based on the exact penalty functions were discussed. for the case under study the ideal sliding mode was shown to occur in the absence of infinite number of switchings.
inspec,test_2114,automation of the recovery of efficiency of complex structure systems. basic features are set forth of the method for automation of the serviceability recovery of systems of complex structures in real time without the interruption of operation. specific features of the method are revealed in an important example of the system of control of hardware components of ships.
inspec,test_2115,control of combustion processes in an internal combustion engine by low temperature plasma. a new method of operation of internal combustion engines enhances power and reduces fuel consumption and exhaust toxicity. low temperature plasma control combines working processes of thermal engines and steam machines into a single process.
inspec,test_2116,optimization of the characteristics of computational processes in scalable resources. the scalableness of resources is taken to mean the possibility of the prior change in the obtained dynamic characteristics of computational processes for a certain basic set of processors and the communication medium in an effort to optimize the dynamics of software applications. a method is put forward for the generation of optimal strategies a set of the versions of the fulfillment of programs on the basis of a vector criterion. the method is urgent for the effective use of resources of computational clusters and metacomputational media and also for dynamic control of processes in real time on the basis of the static scaling.
inspec,test_2117,the p p rearrangement and failure tolerance of double p ary multirings and generalized hypercubes. it is shown that an arbitrary grouped p element permutation can be implemented in a conflict free way through the commutation of channels on the double p ary multiring or the double p ary hypercube. it is revealed that in arbitrary single element permutations these commutators display the property of the p 1 nodal failure tolerance and the generalized hypercube displays in addition the property of the p 1 channel failure tolerance.
inspec,test_2118,solutions for cooperative games. a new concept of the characteristic function is defined. it matches cooperative games far better than the classical characteristic function and is useful in reducing the number of decisions that can be used as the unique solution of a game.
inspec,test_2119,location of transport nets on a heterogeneous territory. the location of transport routes on a heterogeneous territory is studied. the network joins a given set of terminal points and a certain number of additional branch points. the problem is formulated properties of the optimal solution for a tree like network and the number of branch points are studied. a stepwise optimization algorithm for a network with given adjacency matrix based on an algorithm for constructing minimal cost routes is designed.
inspec,test_212,knowledge management capturing the skills of key performers in the power industry. the growing pressure to reduce the cost of electrical power in recent years has resulted in an enormous brain drain within the power industry. a novel approach has been developed by eskom to capture these skills before they are lost and to incorporate these into a computer based programme called knowledge management.
inspec,test_2120,control in active systems based on criteria and motivation. for active systems where the principal varies the agents goal functions by adding to them appropriately weighted goal functions of other agents or a balanced system of inter agent transfers the paper formulated and solved the problems of control based on criteria and motivation. linear active systems were considered by way of example.
inspec,test_2121,flexibility analysis of complex technical systems under uncertainty. an important problem in designing technical systems under partial uncertainty of the initial physical chemical and technological data is the determination of a design in which the technical system is flexible i e its control system is capable of guaranteeing that the constraints hold even under changes in external and internal factors and application of fuzzy mathematical models in its design. three flexibility problems viz the flexibility of a technical system of given structure structural flexibility of a technical system and the optimal design guaranteeing the flexibility of a technical system are studied. two approaches to these problems are elaborated. results of a computation experiment are given.
inspec,test_2122,a fuzzy logic adaptation circuit for control systems of deformable space vehicles its design. a fuzzy logic adaptation algorithm is designed for adjusting the discreteness period of a control system for ensuring the stability and quality of control process with regard to the elastic structural vibrations of a deformable space vehicle. its performance is verified by digital modeling of a discrete control system with two objects.
inspec,test_2123, hidden convexity of finite dimensional stationary linear discrete time systems under conical constraints. new properties of finite dimensional linear discrete time systems under conical control constraints that are similar to the hidden convexity of continuous time systems are studied.
inspec,test_2124,the set of stable polynomials of linear discrete systems its geometry. the multidimensional stability domain of linear discrete systems is studied. its configuration is determined from the parameters of its intersection with coordinate axes coordinate planes and certain auxiliary planes. counterexamples for the discrete variant of the kharitonov theorem are given.
inspec,test_2125,stochastic systems with a random jump in phase trajectory stability of their motions. the probabilistic stability of the perturbed motion of a system with parameters under the action of a general markov process is studied. the phase vector is assumed to experience random jumps when the structure the system suffers random jumps. such a situation is encountered for example in the motion of a solid with random jumps in its mass. the mean square stability of random structure linear systems and stability. of nonlinear systems in the first approximation are studied. the applied approach is helpful in studying the asymptotic probabilistic stability and mean square exponential stability of stochastic systems through the stability of the respective deterministic systems.
inspec,test_2126,a nonlinear time optimal control problem. sufficient conditions for the existence of an optimal control in a time optimal control problem with fixed ends for a smooth nonlinear control system are formulated. the properties of this system for characterizing the optimal control switching points are studied.
inspec,test_2127,system embedding. polynomial equations. the class of solutions of the polynomial equations including their generalizations in the form of the bezout matrix identities was constructed analytically using the technology of constructive system embedding. the structure of a solution depends on the number of steps of the euclidean algorithm and is obtained explicitly by appropriate substitutions. illustrative and descriptive examples are presented.
inspec,test_2128,an optimal control algorithm based on reachability set approximation and linearization. the terminal functional of a general control system is refined by studying an analogous problem for a variational system and regularization. a sequential refinement method is designed by combining the local approximation of the reachability set and reduction. the corresponding algorithm has relaxation properties. an illustrative example is given.
inspec,test_2129,a universal decomposition of the integration range for exponential functions. the problem of determining the independent constants for decomposition of the integration range of exponential functions was solved on the basis of a similar approach to polynomials. the constants obtained enable one to decompose the integration range in two so that the integrals over them are equal independently of the function parameters. for the nontrigonometrical polynomials of even functions an alternative approach was presented.
inspec,test_213,an application of fuzzy linear regression to the information technology in turkey. fuzzy set theory deals with the vagueness of human thought. a major contribution of fuzzy set theory is its capability of representing vague knowledge. fuzzy set theory is very practical when sufficient and reliable data is n t available. information technology it is the acquisition processing storage and dissemination of information in all its forms auditory pictorial textual and numerical through a combination of computers telecommunication networks and electronic devices. it includes matters concerned with the furtherance of computer science and technology design development installation and implementation of information systems and applications. in the paper assuming that there are n independent variables and the regression function is linear the possible levels of information technology the sale levels of computer equipment in turkey are forecasted by using fuzzy linear regression. the independent variables assumed are the import level and the export level of computer equipment.
inspec,test_2130,synchronizing experiments with linear interval systems. concerns generalized control problems without exact information. p a method of constructing a minimal synchronizing sequence for a linear interval system over the field of real numbers is developed. this problem is reduced to a system of linear inequalities.
inspec,test_2131,diagnosis of the technical state of heat systems. a step by step approach to the diagnosis of the technical state of heat systems is stated. the class of physical defects is supplemented by the behavioral defects of objects which are related to the disturbance of the modes of their operation. the implementation of the approach is illustrated by an example of the solution of a specific problem of the diagnosis of a closed heat consumption system.
inspec,test_2132,fault tolerant computer aided control systems with multiversion threshold adaptation adaptation methods reliability estimation and choice of an architecture. for multiversion majority redundant computer aided control systems systematization of adaptation methods that are stable to hardware and software failures a method for estimating their reliability from an event graph model and a method for selecting a standard architecture with regard for reliability requirements are studied.
inspec,test_2133,nonlockability in multirings and hypercubes at serial transmission of data blocks. for the multiring and hypercube a method of conflictless realization of an arbitrary permutation of large data items that can be divided into many smaller data blocks was considered and its high efficiency was demonstrated.
inspec,test_2134,linear models of circuits based on the multivalued components. linearization and planarization of the circuit models is pivotal to the submicron technologies. on the other hand the characteristics of the vlsi circuits can be sometimes improved by using the multivalued components. it was shown that any l level circuit based on the multivalued components is representable as an algebraic model based on l linear arithmetic polynomials mapped correspondingly into l decision diagrams that are linear and planar by nature. complexity of representing a circuit as the linear decision diagram was estimated as o g with g for the number of multivalued components in the circuit. the results of testing the lineardesignmv algorithm on circuits of more than 8000 lgsynth 93 multivalued components were presented.
inspec,test_2135,a new approach to the problem of structural identification. ii. the subject under discussion is a new approach to the problem of structural identification which relies on the recognition of a decisive role of the human factor in the process of structural identification. potential possibilities of the suggested approach are illustrated by the statement of a new mathematical problem of structural identification.
inspec,test_2136,a method of determining a sequence of the best solutions to the problems of optimization on finite sets and the problem of network reconstruction. a method of determining a sequence of the best solutions to the problems of optimization on finite sets was proposed. its complexity was estimated by a polynomial of the dimension of problem input given number of sequence terms and complexity of completing the design of the original extremal problem. the technique developed was applied to the typical problem of network reconstruction with the aim of increasing its throughput under restricted reconstruction costs.
inspec,test_2137,stabilization of a linear object by frequency modulated pulsed signals. a control system consisting of an unstable continuous linear part and a pulse frequency modulator in the feedback circuit is studied. conditions for the boundedness of the solutions of the system under any initial data are determined.
inspec,test_2138,reachability sets of a class of multistep control processes their design. an upper estimate and an iterative restriction algorithm for the reachability set for determining the optimal control for a class of multistep control processes are designed.
inspec,test_2139,generalized confidence sets for a statistically indeterminate random vector. a problem is considered for the construction of confidence sets for a random vector the information on distribution parameters of which is incomplete. to obtain exact estimates and a detailed analysis of the problem the notion is introduced of a generalized confidence set for a statistically indeterminate random vector. properties of generalized confidence sets are studied. it is shown that the standard method of estimation which relies on the unification of confidence sets leads in many cases to wider confidence estimates. for a normally distributed random vector with an inaccurately known mean value generalized confidence sets are built tip and the dependence of sizes of a generalized confidence set on the forms and parameters of a set of possible mean values is examined.
inspec,test_214,evolution of the high end computing market in the usa. this paper focuses on the technological change in the high end computing market. the discussion combines historical analysis with strategic analysis to provide a framework to analyse a key component of the computer industry. this analysis begins from the perspective of government research and development spending then examines the confusion around the evolution of the high end computing market in the context of standard theories of technology strategy and new product innovation. rather than the high end market being dead  one should view the market as changing due to increased capability and competition from the low end personal computer market. the high end market is also responding to new product innovation from the introduction of new parallel computing architectures. in the conclusion key leverage points in the market are identified and the trends in high end computing are highlighted with implications.
inspec,test_2140,strong active solution in non cooperative games. for the non cooperative games and the problems of accepting or rejecting a proposal a new notion of equilibrium was proposed its place among the known basic equilibria was established and its application to the static and dynamic game problems was demonstrated.
inspec,test_2141,system embedding. control with reduced observer. two interrelated problems design of the reduced observer of plant state separately and together with its control system were considered from the standpoint of designing the multivariable linear systems from the desired matrix transfer functions. the matrix equations defining the entire constructive class of solutions of the posed problems were obtained using the system embedding technology. as was demonstrated control based on the reduced observer is capable to provide the desired response to the control input as well as the response to the nonzero initial conditions only for the directly measurable part of the components of the state vector. an illustrative example was presented.
inspec,test_2142,spectral characteristics of the linear systems over a bounded time interval. consideration was given to the spectral characteristics of the linear dynamic systems over a bounded time interval. singular characteristics of standard dynamic blocks transcendental characteristic equations and partial spectra of the singular functions were studied. relationship between the spectra under study and the classical frequency characteristic was demonstrated.
inspec,test_2143,quantum computing with solids. science and technology could be revolutionized by quantum computers but building them from solid state devices will not be easy. the author outlines the challenges in scaling up the technology from lab experiments to practical devices.
inspec,test_2144,the perils of privacy. the recent string of failures among dotcom companies has heightened fears of privacy abuse. what should happen to the names and addresses on a customer list if these details were obtained under a privacy policy which specified no disclosure to any third party. should the personal data in the list be deemed to be an asset of a failing company which can be transferred to any future third party purchaser for its purposes. or should the privacy policy take precedence over the commercial concerns of the purchaser.
inspec,test_2145,enterprise in focus at netsec 2002. netsec 2002 took place in san francisco amid industry reflection on the balance to be struck between combatting cyber terrorism and safeguarding civil liberties post 9 11. the author reports on the punditry and the pedagogy at the csi event focusing on security in the enterprise.
inspec,test_2146,trusted or trustworthy the search for a new paradigm for computer and network security. this paper sets out a number of major questions and challenges which include a just what is meant by trusted or trustworthy systems after 20 years of experience or more likely lack of business level experience with the trusted computer system criteria anyway b does anyone really care about the adoption of international standards for computer system security evaluation by it product and system manufacturers and suppliers is 15408 and if so how does it all relate to business risk management anyway is 17799 c with the explosion of adoption of the microcomputer and personal computer some 20 years ago has the industry abandoned all that it learnt about security during the mainframe era  or  whatever happened to multics and its lessons d has education kept up with security requirements by industry and government alike in the need for safe and secure operation of large scale and networked information systems on national and international bases particularly where web or internet based information services are being proposed as the major next best thing in the it industry e has the fourth generation of computer professionals inherited the spirit of information systems management and control that resided by necessity with the last generation  the professionals who developed and created the applications for shared mainframe and minicomputer systems.
inspec,test_2147,much ado about nothing win32 perrun. jpeg files do not contain any executable code and it is impossible to infect such files. the author takes a look at the details surrounding the win32 perrun virus and make clear exactly what it does. the main virus feature is its ability to affect jpeg image files compressed graphic images and to spread via affected jpeg files. the virus affects or modifies or alters jpeg files but does not infect them.
inspec,test_2148,information security policy what do international information security standards say. one of the most important information security controls is the information security policy. this vital direction giving document is however not always easy to develop and the authors thereof battle with questions such as what constitutes a policy. this results in the policy authors turning to existing sources for guidance. one of these sources is the various international information security standards. these standards are a good starting point for determining what the information security policy should consist of but should not be relied upon exclusively for guidance. firstly they are not comprehensive in their coverage and furthermore tending to rather address the processes needed for successfully implementing the information security policy. it is far more important the information security policy must fit in with the organisation s culture and must therefore be developed with this in mind.
inspec,test_2149,security crisis management the basics. of the more pervasive problems in any kind of security event is how the security event is managed from the inception to the end. there s a lot written about how to manage a specific incident or how to deal with a point problem such as a firewall log but little tends to be written about how to deal with the management of a security event as part of corporate crisis management. this article discusses the basics of security crisis management and of the logical steps required to ensure that a security crisis does not get out of hand.
inspec,test_215,a conceptual framework for evaluation of information technology investments. the decision to acquire a new information technology poses a number of serious evaluation and selection problems to technology managers because the new system must not only meet current information requirements of the organisation but also the needs for future expansion. tangible and intangible benefits factors as well as risks factors must be identified and evaluated. the paper provides a review of ten major evaluation categories and available models which fall under each category showing their advantages and disadvantages in handling the above difficulties. this paper describes strategic implications involved in the selection decision and the inherent difficulties in 1 choosing or developing a model 2 obtaining realistic inputs for the model and 3 making tradeoffs among the conflicting factors. it proposes a conceptual framework to help the decision maker in choosing the most appropriate methodology in the evaluation process. it also offers a new model called gahp for the evaluation problem combining integer goal linear programming and analytic hierarchy process ahp in a single hybrid multiple objective multi criteria model. a goal programming methodology with zero one integer variables and mixed integer constraints is used to set goal target values against which information technology alternatives are evaluated and selected. ahp is used to structure the evaluation process providing pairwise comparison mechanisms to quantify subjective nonmonetary intangible benefits and risks factors in deriving data for the model. a case illustration is provided showing how gahp can be formulated and solved.
inspec,test_2150,data storage re format. closely tracking a fast moving sector. in the past few years the data center market has changed dramatically forcing many companies into consolidation or bankruptcy. gone are the days when companies raised millions of dollars to acquire large industrial buildings and transform them into glittering high tech palaces filled with the latest telecommunication and data technology. whereas manufacturers of communication technology deliver the racked equipment in these often mission critical facilities abb focuses mainly on the building infrastructure. besides the very important redundant power supply abb also provides the redundant air conditioning and the security system.
inspec,test_2151,industrial sup it for performance buildings. abb has taken a close look at how buildings are used and has come up with a radical solution for the technical infrastructure that places the end user s processes at the center and integrates all the building s systems around their needs. the new solution is based on the realization that tasks like setting up an office meeting registering a hotel guest or moving a patient in a hospital can all benefit from the same industrial it concepts employed by abb to optimize manufacturing for example in the automotive industry.
inspec,test_2152,virtual engineering office a state of the art platform for engineering collaboration. a sales force in latin america the design department in europe and production in asia. arrangements of this kind are the new business reality for today s global manufacturing companies. but how are such global operations to be effectively coordinated. abb s answer was to develop and implement a new platform for high performance real time collaboration. globally distributed engineering teams can now work together regardless of time location or the cad system they use making abb easier to do business with for customers as well as suppliers.
inspec,test_2153,post haste. 100th robotic containerization system installed in us mail sorting center. spot welding machine tending material handling picking packing painting palletizing assembly the list of tasks being performed by abb robots keeps on growing. adding to this portfolio is a new robot containerization system rcs that abb developed specifically for the united states postal service usps. the rcs has brought new levels of speed accuracy efficiency and productivity to the process of sorting and containerizing mail and packages. recently the 100th abb rcs was installed at the usps processing and distribution center in columbus ohio.
inspec,test_2154,optimize sup it robot condition monitoring tool. as robots have gained more and more humanlike capability users have looked increasingly to their builders for ways to measure the critical variables the robotic equivalent of a physical check up in order to monitor their condition and schedule maintenance more effectively. this is all the more essential considering the tremendous pressure there is to improve productivity in today s global markets. developed for abb robots with an s4 family controller and based on the company s broad process know how optimize sup it robot condition monitoring offers maintenance routines with embedded checklists that give a clear indication of a robot s operating condition. it performs semi automatic measurements that support engineers during trouble shooting and enable action to be taken to prevent unplanned stops. by comparing these measurements with reference data negative trends can be detected early and potential breakdowns predicted. armed with all these features optimize sup it robot condition monitoring provides the ideal basis for reliability centered maintenance rcm for robots.
inspec,test_2156,pane relief. robotic solutions for car windshield assembly. just looking through a car s windshield does n t give us much reason to wonder about how it s made. the idea that special manufacturing expertise might be required can hardly occur to anyone but that s exactly what is needed to ensure crystal clear visibility not to mention a perfect fit every time one is pressed into place on a car production line. comprising two thin glass sheets joined by a vinyl interlayer windshields are assembled usually manually to very precise product and environmental specifications. to make sure this is done as perfectly as possible the industry invests heavily in the equipment used for their fabrication. abb has now developed a robot based compact assembling system for the automatic assembly of laminated windshields that speeds up production and increases cost efficiency.
inspec,test_2157,shaping the future. bendwizard a tool for off line programming of robotic tending systems. setting up a robot to make metal cabinets or cases for desktop computers can be a complex operation. for instance one expert might be required to carry out a feasibility study and then another to actually program the robot. understandably the need for so much expertise and the time that s required generally limits the usefulness of automation to high volume production. workshops producing parts in batches smaller than 50 or so or which rely heavily on semiskilled operators are therefore often discouraged from investing in automation and so miss out on its many advantages. what is needed is a software tool that operators without special knowledge of robotics or with no more than rudimentary cad skills can use. one which allows easy offline programming and simulation of the work cell on a pc.
inspec,test_2158,press shop. industrial it solutions for the press shop. globalization of the world s markets is challenging the traditional limits of manufacturing efficiency. the competitive advantage belongs to those who understand the new requirements and opportunities and who commit to integrated solutions that span the value chain all the way from demand to production. abb s automation and it expertise and the process know how gained from its long involvement with the automotive industry have been brought together in new state of the art software solutions for press shops. integrated into industrial it architecture they allow the full potential of the shops to be realized with advantages at every step in the supply chain.
inspec,test_2159,real time enterprise solutions for discrete manufacturing and consumer goods. customer satisfaction and a focus on core competencies have dominated the thinking of a whole host of industries in recent years. however one outcome the outsourcing of noncore activities has made the production of goods from order entry to final delivery more and more complex. suppliers subsuppliers producers and customers are therefore busy adopting a new more collaborative approach. this is mainly taking the form of order driven planning and scheduling of production but it is also being steered by a need to reduce inventories and working capital as well as a desire to increase throughput and optimize production.
inspec,test_216,extinction cross sections of realistic raindrops data bank established using t matrix method and nonlinear fitting technique. a new computer program is developed based on the t matrix method to generate a large number of total extinction cross sections tcs values of the realistic raindrops that are deformed due to a balance of the forces that act on a drop failing under gravity and were described in shape by pruppacher and pitter 1971. these data for various dimensions of the raindrops mean effective radius from 0 to 3 25 mm frequencies 10 to 80 ghz horizontal and vertical polarizations and temperatures 0 10 and 20 degrees c are stored to establish a data bank. furthermore a curve fitting technique i e interpolation of order 3 is implemented for the tcs values in the data bank. therefore the interpolated tcs results can be obtained readily from the interpolation process with negligible or even null computational time and efforts. error analysis is carried out to show the high accuracy of the present analysis and applicability of the interpolation. at three operating frequencies of 15 21 225 and 38 ghz locally used in singapore some new tcs values are obtained from the new fast and efficient interpolation with a good accuracy.
inspec,test_2160,challenges and trends in discrete manufacturing. over 50 years ago the 100 000 workers at ford s rouge automobile factory turned out 1200 cars per day. nowadays ford s plant on that same site still produces 800 cars each day but with just 3000 workers. similar stories abound in the manufacturing industries technology revolution and evolution a shift from vertical integration better business and production practices and improved industrial relations all have changed manufacturing beyond recognition. so what are the current challenges and trends in manufacturing. certainly the relentless advance of technology will continue as will user pressure for more customized design or improved environmental friendliness. some trends are already with us and more as yet indiscernible will come. but one major fundamental shift now resounding throughout industry is the way in which information involving every single aspect of the manufacturing process is being integrated into one seamless system.
inspec,test_2161,on the beth properties of some intuitionistic modal logics. let l be one of the intuitionistic modal logics. as in the classical modal case we define two different forms of the beth property for l which are denoted by b1 and b2 in this paper we study the relation among b1 b2 and the interpolation properties c1 and c2. it turns out that c1 implies b1 but contrary to the boolean case is not equivalent to b1. it is shown that b2 and c2 are independent and moreover it comes out that in contrast to classical case there exists an extension of the intuitionistic modal logic of s sub 4  type that has not the property b2. finally we give two algebraic properties that characterize respectively b1 and b2.
inspec,test_2162,more constructions for boolean algebras. we construct boolean algebras with prescribed behaviour concerning depth for the free product of two boolean algebras over a third in zfc using pcf assuming squares we get results on ultraproducts. we also deal with the family of cardinalities and topological density of homomorphic images of boolean algebras you can translate it to topology on the cardinalities of closed subspaces and lastly we deal with inequalities between cardinal invariants mainly d b sup kappa  b implies ind b  sup kappa v depth b or log b.
inspec,test_2163,it as a key enabler to law firm competitiveness. professional services firms have traditionally been able to thrive in virtually any market conditions. they have been consistently successful for several decades without ever needing to reexamine or change their basic operating model. however gradual but inexorable change in client expectations and the business environment over recent years now means that more of the same is no longer enough. in future law firms will increasingly need to exploit it more effectively in order to remain competitive. to do this they will need to ensure that all their information systems function as an integrated whole and are available to their staff clients and business partners. the authors set out the lessons to be learned for law firms in the light of the recent pa consulting survey.
inspec,test_2164,electronic signatures much ado. whilst the market may be having a crisis of confidence regarding the prospects for e commerce the eu and the government continue apace to develop the legal framework. most recently this has resulted in the electronic signatures regulations 2002. these regulations were made on 13 february 2002 and came into force on 8 march 2002. the regulations implement the european electronic signatures directive 1999 93 ec. critics may say that the regulations were implemented too late they were due to have been implemented by 19 july 2001 with too short a consultation period 25 january 2002 to 12 february 2002 and with an unconvincing case as to what they add to english law as to which read on. the author explains the latest development on e signatures and the significance of certification service providers csps.
inspec,test_2165,naomi campbell drugs distress and the data protection act. in the first case of its kind naomi campbell successfully sued mirror group newspapers for damage and distress caused by breach of the data protection act 1998. partner n wildish and assistant m turle of city law firm field fisher waterhouse discuss the case and the legal implications of which online publishers should be aware.
inspec,test_2166,do n t always believe what you reed optimisation techniques for web sites and trade mark infringement. on 20 may 2002 mr justice pumfrey gave judgment in the case of 1 reed executive plc 2 reed solutions plc versus 1 reed business information limited 2 reed elsevier uk limited 3 totaljobs com limited. the case explored for the first time in any detail the extent to which the use of various optimisation techniques for web sites could give rise to new forms of trade mark infringement and passing off. the author reports on the case and offers his comments.
inspec,test_2167,finally. some sensible european legislation on software. the european commission has formally tabled a draft directive on the protection by patents of computer implemented inventions. the aim of this very important directive is to harmonise national patent laws relating to inventions using software. it follows an extensive consultation launched by the commission in october 2000. the impetus behind the directive was the recognition at eu level of a total lack of unity between the european patent office and european national courts in deciding what was or was not deemed patentable when it came to the subject of computer programs.
inspec,test_2168,cyberobscenity and the ambit of english criminal law. the author looks at a recent case and questions the court of appeal s approach. in the author s submission the court of appeal s decision in perrin was wrong. p published no material in england and wales and should not have been convicted of any offence under english law even if it were proved that he sought to attract english subscribers to his site. that may be an unpalatable conclusion but if the content of foreign hosted internet sites is to be controlled the only sensible way forward is through international agreement and cooperation. the council of europe s cybercrime convention provides some indication of the limited areas over which widespread international agreement might be achieved.
inspec,test_2169,e government. the author provides an introduction to the main issues surrounding e government modernisation and electronic delivery of all public services by 2005. the author makes it clear that e government is about transformation not computers and hints at the special legal issues which may arise.
inspec,test_217,vendor qualifications for it staff and networking. in some cases vendor run accreditation schemes can offer an objective measure of a job applicant s skills but they do not always indicate the true extent of practical abilities.
inspec,test_2170,evolution of litigation support systems. for original paper see ibid vol. 12 no 6  the e mail of the species. the author responds to that paper and argues that printing scanning and imaging e mails or other electronic rather than paper documents prior to listing and disclosure seems to be unnecessary not proportionate from a costs point of view and not particularly helpful to either side. he asks how litigation support systems might evolve to help and support the legal team in their task.
inspec,test_2171,evicting orang utans from the office electronic storage of legal files. having espoused the principle of the paperless office some time ago we decided to apply it to our stored files. first we consulted the law society rules governing storage of files on electronic media. the next step was for us to draw up a protocol for scanning the files. the benefits of the exercise have been significant. the area previously used for storage has been freed for other use. files are now available online instantaneously. when we have needed to send out files to the client or following a change of solicitor we have been able to do so almost immediately by e mail retaining a copy for our future reference. the files are protected from loss or deterioration back up copies having been taken which are stored off site. the complete stored file archive can be put in your pocket in cd rom format or on a laptop facilitating remote working.
inspec,test_2172,electronic data exchange for real estate. with hm land registry s consultation now underway no one denies that the property industry is facing a period of unprecedented change. pisces property information systems common exchange is a property focused electronic data exchange standard. the standard is a set of definitions and rules to facilitate electronic transfer of data between key business areas and between different types of software packages that are used regularly by the property industry. it is not itself a piece of software but an enabling technology that allows software providers to prepare solutions within their own packages to transfer data between databases. this provides the attractive prospect of seamless transfer of data within and between systems and organisations.
inspec,test_2173,e mail and the legal profession. the widespread use of e mail can be found in all areas of commerce and the legal profession is one that has embraced this new medium of communication. e mail is not without its drawbacks however. due to the nature of the technologies behind the medium it is a less secure form of communication than many of those traditionally used by the legal profession including dx facsimile and standard and registered post. there are a number of ways in which e mails originating from the practice may be protected including software encryption hardware encryption and various methods of controlling and administering access to the e mails.
inspec,test_2174,spam solution. the author describes a solution to spam e mails disposable e mail addresses dea. mailshell s free trial web based e mail service allows you if you start getting spammed on that dea just to delete the dea in mailshell and all e mail thereafter sent to that address will automatically be junked though you can later restore that address if you want. mailshell allows any number of dea.
inspec,test_2175,7 key tests in choosing your web site firm. most legal firms now have a web site and are starting to evaluate the return on their investment. the paper looks at factors involved when choosing a firm to help set up or improve a web site. 1 look for a company that combines technical skills and business experience. 2 look for a company that offers excellent customer service. 3 check that the web site firm is committed to developing and proactively updating the web site. 4 make sure the firm has a proven track record and a good portfolio. 5 look for a company with both a breadth as well as depth of skills. 6 make sure the firm can deliver work on target in budget and to specification. 7 ensure that you will enjoy working and feel comfortable with the web site firm staff.
inspec,test_2176,why your web strategy is err wrong. an awkward look at a few standard views from the author who thinks that most people have got it err wrong. like every other investment when the time comes to sign the contract the question that should be asked is not whether it is a good investment but whether it is the best investment the firm can make with the money. the author argues that he would be surprised if any law firm web site he has seen yet would jump that particular hurdle.
inspec,test_2177,a humanist s legacy in medical informatics visions and accomplishments of professor jean raoul scherrer. the objective is to report on the work of prof jean raoul scherrer and show how his humanist vision medical skills and scientific background have enabled and shaped the development of medical informatics over the last 30 years. starting with the mainframe based patient centred hospital information system diogene in the 70s prof scherrer developed implemented and evolved innovative concepts of man machine interfaces distributed and federated environments leading the way with information systems that obstinately focused on the support of care providers and patients. through a rigorous design of terminologies and ontologies the diogene data would then serve as a basis for the development of clinical research data mining and lead to innovative natural language processing techniques. in parallel prof scherrer supported the development of medical image management ranging from a distributed picture archiving and communication systems pacs to molecular imaging of protein electrophoreses. recognizing the need for improving the quality and trustworthiness of medical information of the web prof scherrer created the health on the net hon foundation. these achievements made possible thanks to his visionary mind deep humanism creativity generosity and determination have made of prof scherrer a true pioneer and leader of the human centered patient oriented application of information technology for improving healthcare.
inspec,test_2178,medicine in the 21 st century global problems global solutions. the objectives are to discuss application areas of information technology in medicine and health care on the occasion of the opening of the private universitat fur medizinische informatik and technik tirol university for health informatics and technology tyrol limit at innsbruck tyrol austria. important application areas of information technology in medicine and health are appropriate individual access to medical knowledge new engineering developments such as new radiant imaging methods and the implantable pacemaker defibrillator devices mathematical modeling for understanding the workings of the human body the computer based patient record as well as new knowledge in molecular biology human genetics and biotechnology. challenges and responsibilities for medical informatics research include medical data privacy and intellectual property rights inherent in the content of the information systems.
inspec,test_2179,guidelines the internet and personal health insights from the canadian healnet experience. the objectives are to summarize the insights gained in collaborative research in a canadian network of centres of excellence devoted to the promotion of evidence based practice and to relate this experience to internet support of health promotion and consumer health informatics. a subjective review of insights is undertaken. work directed the development of systems incorporating guidelines care maps etc for use by professionals met with limited acceptance. evidence based tools for health care consumers are a desirable complement but require radically different content and delivery modes. in addition to evidence based material offered by professionals a wide array of internet based products and services provided by consumers for consumers emerged and proved a beneficial complement. the consumer driven products and services provided via the internet are a potentially important and beneficial complement of traditional health services. they affect the health consumer provider roles and require changes in healthcare practices.
inspec,test_218,iscsi poised to lower san costs. it managers building storage area networks or expanding their capacity may be able to save money by using iscsi and ip systems rather than fibre channel technologies.
inspec,test_2180,standard protocol for exchange of health checkup data based on sgml the health checkup data markup language hdml. the objectives are to develop a health medical data interchange model for efficient electronic exchange of data among health checkup facilities. a health checkup data markup language hdml was developed on the basis of the standard generalized markup language sgml and a feasibility study carried out involving data exchange between two health checkup facilities. the structure of hdml is described. the transfer of numerical lab data summary findings and health status assessment was successful. hdml is an improvement to laboratory data exchange. further work has to address the exchange of qualitative and textual data.
inspec,test_2181,development of a health guidance support system for lifestyle improvement. the objective is to provide automated advice for lifestyle adjustment based on an assessment of the results of a questionnaire and medical examination or health checkup data. a system was developed that gathers data based on questions regarding weight gain exercise smoking sleep eating habits salt intake animal fat intake snacks alcohol and oral hygiene body mass index resting blood pressure fasting blood sugar total cholesterol triglycerides uric acid and liver function tests. based on the relationships between the lifestyle data and the health checkup data a health assessment sheet was generated for persons being allocated to a multiple risk factor syndrome group. health assessment and useful advice for lifestyle improvement were automatically extracted with the system toward the high risk group for life style related diseases. the system is operational. in comparison with conventional limited advice methods we developed a practical system that defined the necessity for lifestyle improvement more clearly and made giving advice easier.
inspec,test_2182,organization design the continuing influence of information technology. drawing from an information processing perspective this paper examines how information technology it has been a catalyst in the development of new forms of organizational structures. the article draws a historical linkage between the relative stability of an organization s task environment starting after the second world war to the present environmental instability that now characterizes many industries. specifically the authors suggest that advances in it have enabled managers to adapt existing forms and create new models for organizational design that better fit requirements of an unstable environment. time has seemingly borne out this hypothesis as the bureaucratic structure evolved to the matrix to the network and now to the emerging shadow structure. it has gone from a support mechanism to a substitute for organizational structures in the form of the shadow structure. the article suggests that the evolving and expanding role of it will continue for organizations that face unstable environments.
inspec,test_2183,knowledge based structures and organisational commitment. organisational commitment the emotional attachment of an employee to the employing organisation has attracted a substantial body of literature relating the concept to various antecedents including organisational structure and to a range of consequences including financially important performance factors such as productivity and staff turnover. the new areas of knowledge management and learning organisations offer substantial promise as imperatives for the organisation of business enterprises. as organisations in the contemporary environment adopt knowledge based structures to improve their competitive position there is value in examining these structures against other performance related factors. theoretical knowledge based structures put forward by r miles et al 1997 and j quinn et al 1996 and an existing implementation are examined to determine common features inherent in these approaches. these features are posited as a typical form and their impact on organisational commitment and hence on individual and organisational performance is examined.
inspec,test_2184,the evolution of information systems their impact on organizations and structures. information systems and organization structures have been highly interconnected with each other. over the years information systems architectures as well as organization structures have evolved from centralized to more decentralized forms. this research looks at the evolution of both information systems and organization structures. in the process it looks into the impact of computers on organizations and examines the ways organization structures have changed in association with changes in information system architectures. it also suggests logical linkages between information system architectures and their fit with certain organization structures and strategies. it concludes with some implications for emerging and future organizational forms and provides a quick review of the effect of the internet on small businesses traditionally using stand alone computers.
inspec,test_2185,in search of a general enterprise model. many organisations particularly smes are reluctant to invest time and money in models to support decision making. such reluctance could be overcome if a model could be used for several purposes rather than using a traditional single perspective model. this requires the development of a general enterprise model gem which can be applied to a wide range of problem domains with unlimited scope. current enterprise modelling frameworks only deal effectively with nondynamic modelling issues whilst dynamic modelling issues have traditionally only been addressed at the operational level. although the majority of research in this area relates to manufacturing companies the framework for a gem must be equally applicable to service and public sector organisations. the paper identifies five key design issues that need to be considered when constructing a gem. a framework for such a gem is presented based on a plug and play methodology and demonstrated by a simple case study.
inspec,test_2186,strategies for high throughput templated zeolite synthesis. the design and redesign of high throughput experiments for zeolite synthesis are addressed. a model that relates materials function to the chemical composition of the zeolite and the structure directing agent is introduced. using this model several monte carlo like design protocols are evaluated. multi round protocols are bound to be effective and strategies that use a priori information about the structure directing libraries are found to be the best.
inspec,test_2187,variable structure intelligent control for pm synchronous servo motor drive. the variable structure control vsc of discrete time systems based on intelligent control is presented in this paper. a novel approach is proposed for the state estimation. a linear observer is firstly designed. then a neural network is used for compensating uncertainty. the parameter of the vsc scheme is adjusted online by a neural network. practical operating results from a pm synchronous motor pmsm illustrate the effectiveness and practicability of the proposed approach.
inspec,test_2188,a nonlinear modulation strategy for hybrid ac dc power systems. a nonlinear control strategy to improve transient stability of a multi machine ac power system with several dc links terminated in the presence of large disturbances is presented. the approach proposed in this paper is based on differential geometric theory and the hvdc systems are taken as a variable admittance connected at the inverter or rectifier ac bus. after deriving the analytical description of the relationship between the variable admittance and active power flows of each generator the traditional generator dynamic equations can thus be expressed with the variable admittance of hvdc systems as an additional state variable and changed to an affine form which is suitable for global linearization method being used to determine its control variable. an important feature of the proposed method is that the modulated dc power is an adaptive and non linear function of ac system states and it can be realized by local feedback and less transmitted data from adjacent generators. the design procedure is tested on a dual infeed hybrid ac dc system.
inspec,test_2189,mobile computing killer app competition. design competitions offer students an excellent way to gain hands on experience in engineering and computer science courses. the university of florida in partnership with motorola has held two mobile computing design competitions. in spring and fall 2001 students in abdelsalam helal s mobile computing class designed killer apps for a motorola smart phone.
inspec,test_219,firewall card shields data. the slotshield 3000 firewall on a pci card saves power and space but might not offer enough security for large networks.
inspec,test_2190,standards for service discovery and delivery. for the past five years competing industries and standards developers have been hotly pursuing automatic configuration now coined the broader term service discovery. jini universal plug and play upnp salutation and service location protocol are among the front runners in this new race. however choosing service discovery as the topic of the hour goes beyond the need for plug and play solutions or support for the soho small office home office user. service discovery s potential in mobile and pervasive computing environments motivated my choice.
inspec,test_2191,the role of speech input in wearable computing. speech recognition seems like an attractive input mechanism for wearable computers and as we saw in this magazine s first issue several companies are promoting products that use limited speech interfaces for specific tasks. however we must overcome several challenges to using speech recognition in more general contexts and interface designers must be wary of applying the technology to situations where speech is inappropriate.
inspec,test_2192,the ubiquitous provisioning of internet services to portable devices. advances in mobile telecommunications and device miniaturization call for providing both standard and novel location and context dependent internet services to mobile clients. mobile agents are dynamic asynchronous and autonomous making the ma programming paradigm suitable for developing novel middleware for mobility enabled services.
inspec,test_2193,integrating virtual and physical context to support knowledge workers. the kimura system augments and integrates independent tools into a pervasive computing system that monitors a user s interactions with the computer an electronic whiteboard and a variety of networked peripheral devices and data sources.
inspec,test_2194,data management in location dependent information services. location dependent information services have great promise for mobile and pervasive computing environments. they can provide local and nonlocal news weather and traffic reports as well as directory services. before they can be implemented on a large scale however several research issues must be addressed.
inspec,test_2195,modeling privacy control in context aware systems. significant complexity issues challenge designers of context aware systems with privacy control. information spaces provide a way to organize information resources and services around important privacy relevant contextual factors. in this article we describe a theoretical model for privacy control in context aware systems based on a core abstraction of information spaces. we have previously focused on deriving socially based privacy objectives in pervasive computing environments. building on ravi sandhu s four layer om am objectives models architectures and mechanisms idea we aim to use information spaces to construct a model for privacy control that supports our socially based privacy objectives. we also discuss how we can introduce decentralization a desirable property for many pervasive computing systems into our information space model using unified privacy tagging.
inspec,test_2196,conchat a context aware chat program. conchat is a context aware chat program that enriches electronic communication by providing contextual information and resolving potential semantic conflicts between users conchat uses contextual information to improve electronic communication. using contextual cues users can infer during a conversation what the other person is doing and what is happening in his or her immediate surroundings. for example if a user learns that the other person is talking with somebody else or is involved in some urgent activity he or she knows to expect a slower response. conversely if the user learns that the other person is sitting in a meeting directly related to the conversation he or she then knows to respond more quickly. also by informing users about the other person s context and tagging potentially ambiguous chat messages conchat explores how context can improve electronic communication by reducing semantic conflicts.
inspec,test_2197,a context aware decision engine for content adaptation. building a good content adaptation service for mobile devices poses many challenges. to meet these challenges this quality of service aware decision engine automatically negotiates for the appropriate adaptation decision for synthesizing an optimal content version.
inspec,test_2198,reconfigurable context sensitive middleware for pervasive computing. context sensitive applications need data from sensors devices and user actions and might need ad hoc communication support to dynamically discover new devices and engage in spontaneous information exchange. reconfigurable context sensitive middleware facilitates the development and runtime operations of context sensitive pervasive computing software.
inspec,test_2199,activity and location recognition using wearable sensors. using measured acceleration and angular velocity data gathered through inexpensive wearable sensors this dead reckoning method can determine a user s location detect transitions between preselected locations and recognize and classify sitting standing and walking behaviors. experiments demonstrate the proposed method s effectiveness.
inspec,test_22,analyzing the benefits of 300 mm conveyor based amhs. while the need for automation in 300 mm fabs is not debated the form and performance of such automation is still in question. software simulation that compares conveyor based continuous flow transport technology to conventional car based wafer lot delivery has detailed delivery time and throughput advantages to the former.
inspec,test_220,how to avoid merger pitfalls. paul diamond of consultancy kpmg explains why careful it asset management is crucial to the success of mergers.
inspec,test_2200,labscape a smart environment for the cell biology laboratory. labscape is a smart environment that we designed to improve the experience of people who work in a cell biology laboratory. our goal in creating it was to simplify laboratory work by making information available where it is needed and by collecting and organizing data where and when it is created into a formal representation that others can understand and process. by helping biologists produce a more complete record of their work with less effort labscape is designed to foster improved collaboration in conjunction with increased individual efficiency and satisfaction. a user driven system although technologically conservative embraces a central goal of ubiquitous computing to enhance the ability to perform domain tasks through fluid interaction with computational resources. smart environments could soon replace the pen and paper commonly used in the laboratory setting.
inspec,test_223,broadcasts keep staff in picture intranets. mark hawkins chief operating officer at uk based streaming media specialist twofourtv explains how firms can benefit by linking their corporate intranets to broadcasting technology.
inspec,test_224,java portability put to the test. sun microsystems recently launched java verification program aims to enable companies to assess the cross platform portability of applications written in java and to help software vendors ensure that their solutions can run in heterogenous j2ee application server environments.
inspec,test_225,the eyes have it hotel security. cctv systems can help lodging establishments accomplish a range of objectives from deterring criminals to observing staff interactions with clientele. but pitfalls can arise if the cctv system has not been properly integrated into the overall hotel security plan. cctv system designs at new hotel properties are often too sophisticated too complicated and too costly and do not take into consideration the security realities of site management. these problems arise when the professionals designing or installing the system including architects construction engineers integrators and consultants are not familiar with a hotel s operating strategies or security standards.
inspec,test_226,online masquerade whose e mail is it. e mails carrying viruses like the recent klez worm use deceptively simple techniques and known vulnerabilities to spread from one computer to another with ease.
inspec,test_227,relativistic constraints on the distinguishability of orthogonal quantum states. the constraints imposed by special relativity on the distinguishability of quantum states are discussed. an explicit expression relating the probability of an error in distinguishing two orthogonal single photon states to their structure the time t at which a measurement starts and the interval of time t elapsed from the start of the measurement until the time at which the outcome is obtained by an observer is given as an example.
inspec,test_228,rapid microwell polymerase chain reaction with subsequent ultrathin layer gel electrophoresis of dna. large scale genotyping mapping and expression profiling require affordable fully automated high throughput devices enabling rapid high performance analysis using minute quantities of reagents. in this paper we describe a new combination of microwell polymerase chain reaction pcr based dna amplification technique with automated ultrathin layer gel electrophoresis analysis of the resulting products. this technique decreases the reagent consumption total reaction volume 0 75 1 mu l the time requirement of the pcr 15 20 min and subsequent ultrathin layer gel electrophoresis based fragment analysis 5 min by automating the current manual procedure and reducing the human intervention using sample loading robots and computerized real time data analysis. small aliquots 0 2 mu l of the submicroliter size pcr reaction were transferred onto loading membranes and analyzed by ultrathin layer gel electrophoresis which is a novel high performance and automated microseparation technique. this system employs integrated scanning laser induced fluorescence avalanche photodiode detection and combines the advantages of conventional slab and capillary gel electrophoresis. visualization of the dna fragments was accomplished by in migratio complexation with ethidium bromide during the electrophoresis process also enabling real time imaging and data analysis.
inspec,test_229,simple minds health care it. a few things done properly and soon is the short term strategy for the uk nhs it programme. can it deliver this time.
inspec,test_23,absorption of long waves by nonresonant parametric microstructures. using simple acoustical and mechanical models we consider the conceptual possibility of designing an active absorbing nonreflecting coating in the form of a thin layer with small scale stratification and fast time modulation of parameters. algorithms for space time modulation of the controlled layer structure are studied in detail for a one dimensional boundary value problem. these algorithms do not require wave field measurements which eliminates the self excitation problem that is characteristic of active systems. the majority of the considered algorithms of parametric control transform the low frequency incident wave to high frequency waves of the technological band for which the waveguiding medium inside the layer is assumed to be opaque absorbing. the efficient use conditions are found for all the algorithms. it is shown that the absorbing layer can be as thin as desired with respect to the minimum spatial scale of the incident wave and ensures efficient absorption in a wide frequency interval starting from zero frequency that is bounded from above only by a finite space time resolution of the parameter control operations. the structure of a three dimensional parametric  black coating whose efficiency is independent of the angle of incidence of an incoming wave is developed on the basis of the studied one dimensional problems. the general solution of the problem of diffraction of incident waves from such a coating is obtained. this solution is analyzed in detail for the case of a disk shaped element.
inspec,test_230,2002 in house fulfillment systems report publishing. cm s 13th annual survey of in house fulfillment system suppliers brings you up to date on the current capabilities of the leading publication software packages.
inspec,test_231,writing the fulfillment rfp publishing. for the uninitiated writing a request for proposal can seem both mysterious and daunting. here s a format that will make you look like a pro the first time out.
inspec,test_232,library services today and tomorrow lessons from ilumina a digital library for creating and sharing teaching resources. this article is based on the emerging experience associated with a digital library of instructional resources ilumina in which the contributors of resources and the users of those resources are the same an open community of instructors in science mathematics engineering and technology. moreover it is not the resources most of which will be distributed across the internet but metadata about the resources that is the focus of the central ilumina repository and its support services for resource contributors and users. the distributed ilumina library is a community sharing library for repurposing and adding value to potentially useful mostly non commercial instructional resources that are typically more granular in nature than commercially developed course materials. the experience of developing ilumina is raising a range of issues that have nothing to do with the place and time characteristics of the instructional context in which ilumina instructional resources are created or used. the issues instead have their locus in the democratization of both the professional roles of librarians and the quality assurance mechanisms associated with traditional peer review.
inspec,test_233,the canadian national site licensing project. in january 2000 a consortium of 64 universities in canada signed a historic inter institutional agreement that launched the canadian national site licensing project cnslp a three year pilot project aimed at bolstering the research and innovation capacity of the country s universities. cnslp tests the feasibility of licensing on a national scale electronic versions of scholarly publications in its initial phases the project is focused on full text electronic journals and research databases in science engineering health and environmental disciplines. this article provides an overview of the cnslp initiative summarizes organizational and licensing accomplishments to date and offers preliminary observations on challenges and opportunities for subsequent phases of the project.
inspec,test_234,the uk s national electronic site licensing initiative nesli. in 1998 the uk created the national electronic site licensing initiative nesli to increase and improve access to electronic journals and to negotiate license agreements on behalf of academic libraries. the use of a model license agreement and the success of site licensing is discussed. highlights from an interim evaluation by the joint information systems committee jisc are noted and key issues and questions arising from the evaluation are identified.
inspec,test_235,the role of caul council of australian libraries in consortial purchasing. the council of australian university librarians constituted in 1965 for the purposes of cooperative action and the sharing of information assumed the role of consortial purchasing agent in 1996 on behalf of its members and associate organisations in australia and new zealand. this role continues to grow in tandem with the burgeoning of electronic publication and the acceptance of publishers of the advantages of dealing with consortia. the needs of the australian university community overlap significantly with consortia in north america and europe but important differences are highlighted.
inspec,test_236,licensing experiences in the netherlands. the licensing strategy of university libraries in the netherlands is closely connected with university policies to develop document servers and to make research publications available on the web. national agreements have been made with major publishers such as elsevier science and kluwer academic to provide access to a wide range of scientific information and to experiment with new ways of providing information and new business models.
inspec,test_237,international library consortia positive starts promising futures. library consortia have grown substantially over the past ten years both within north america and globally. as this resurgent consortial movement has begun to mature and as publishers and vendors have begun to adapt to consortial purchasing models consortia have expanded their agendas for action. the movement to globalize consortia is traced including the development and current work of the international coalition of library consortia icolc. a methodology is explored to classify library consortia by articulating the key factors that affect and distinguish consortia as organizations within three major areas strategic tactical and practical or managerial concerns. common consortial values are examined and a list of known international library consortia is presented.
inspec,test_238,the open archives initiative realizing simple and effective digital library interoperability. the open archives initiative oai is dedicated to solving problems of digital library interoperability. its focus has been on defining simple protocols most recently for the exchange of metadata from archives. the oai evolved out of a need to increase access to scholarly publications by supporting the creation of interoperable digital libraries. as a first step towards such interoperability a metadata harvesting protocol was developed to support the streaming of metadata from one repository to another ultimately to a provider of user services such as browsing searching or annotation. this article provides an overview of the mission philosophy and technical framework of the oai.
inspec,test_239,content standards for electronic books the oebf publication structure and the role of public interest participation. in the emerging world of electronic publishing how we create distribute and read books will be in a large part determined by an underlying framework of content standards that establishes the range of technological opportunities and constraints for publishing and reading systems. but efforts to develop content standards based on sound engineering models must skillfully negotiate competing and sometimes apparently irreconcilable objectives if they are to produce results relevant to the rapidly changing course of technology. the open ebook forum s publication structure an xml based specification for electronic books is an example of the sort of timely and innovative problem solving required for successful real world standards development. as a result of this effort the electronic book industry will not only happen sooner and on a larger scale than it would have otherwise but the electronic books it produces will be more functional more interoperable and more accessible to all readers. public interest participants have a critical role in this process.
inspec,test_24,fuzzy modeling based on generalized conjunction operations. an approach to fuzzy modeling based on the tuning of parametric conjunction operations is proposed. first some methods for the construction of parametric generalized conjunction operations simpler than the known parametric classes of conjunctions are considered and discussed. second several examples of function approximation by fuzzy models based on the tuning of the parameters of the new conjunction operations are given and their approximation performances are compared with the approaches based on a tuning of membership functions and other approaches proposed in the literature. it is seen that the tuning of the conjunction operations can be used for obtaining fuzzy models with a sufficiently good performance when the tuning of membership functions is not possible or not desirable.
inspec,test_240,project euclid and the role of research libraries in scholarly publishing. project euclid a joint electronic journal publishing initiative of cornell university library and duke university press is discussed in the broader contexts of the changing patterns of scholarly communication and the publishing scene of mathematics. specific aspects of the project such as partnerships and the creation of an economic model are presented as well as what it takes to be a publisher. libraries have gained important and relevant experience through the creation and management of digital libraries but they need to develop further skills if they want to adopt a new role in the life cycle of scholarly communication.
inspec,test_241,perspectives on scholarly online books the columbia university online books evaluation project. the online books evaluation project at columbia university studied the potential for scholarly online books from 1995 to 1999. issues included scholars interest in using online books the role they might play in scholarly life features that scholars and librarians sought in online books the costs of producing and owning print and online books and potential marketplace arrangements. scholars see potential for online books to make their research learning and teaching more efficient and effective. librarians see potential to serve their scholars better. librarians may face lower costs if they can serve their scholars with online books instead of print books. publishers may be able to offer scholars greater opportunities to use their books while enhancing their own profitability.
inspec,test_242,the california digital library and the escholarship program. the escholarship program was launched in 2000 to foster faculty led innovation in scholarly publishing. an initiative of the university of california uc and a program of the california digital library the escholarship program has stimulated significant interest in its short life. its modest but visible accomplishments garner praise from many quarters within and beyond the university of california. in perhaps the best indication of its timeliness and momentum there are more proposals submitted to escholarship today than the cdl can manage. this early success is due in part to the sheer power of an idea whose time has come but also to the unique approach on which cdl was founded and the escholarship initiative was first launched.
inspec,test_243,bioone a new model for scholarly publishing. this article describes a unique electronic journal publishing project involving the university of kansas the big 12 plus libraries consortium the american institute of biological sciences allen press and sparc the scholarly publishing and academic resources coalition. this partnership has created bioone a database of 40 full text society journals in the biological and environmental sciences which was launched in april 2001. the genesis and development of the project is described and financial technical and intellectual property models for the project are discussed. collaborative strategies for the project are described.
inspec,test_244,symbiosis or alienation advancing the university press research library relationship through electronic scholarly communication. university presses and research libraries have a long tradition of collaboration. the rapidly expanding electronic scholarly communication environment offers important new opportunities for cooperation and for innovative new models of publishing. the economics of libraries and scholarly publishers have strained the working relationship and promoted debates on important information policy issues. this article explores the context for advancing the partnership cites examples of joint efforts in electronic publishing and presents an action plan for working together.
inspec,test_245,support vector machines model for classification of thermal error in machine tools. this paper addresses a change in the concept of machine tool thermal error prediction which has been hitherto carried out by directly mapping them with the temperature of critical elements on the machine. the model developed herein using support vector machines a powerful data training algorithm seeks to account for the impact of specific operating conditions in addition to temperature variation on the effective prediction of thermal errors. several experiments were conducted to study the error pattern which was found to change significantly with variation in operating conditions. this model attempts to classify the error based on operating conditions. once classified the error is then predicted based on the temperature states. this paper also briefly describes the concept of the implementation of such a comprehensive model along with an on line error assessment and calibration system in a pc based open architecture controller environment so that it could be employed in regular production for the purpose of periodic calibration of machine tools.
inspec,test_246,adaptive and efficient mutual exclusion. the paper presents adaptive algorithms for mutual exclusion using only read and write operations the performance of the algorithms depends only on the point contention i e the number of processes that are concurrently active during algorithm execution and not on n the total number of processes. our algorithm has o k remote step complexity and o log k system response time where k is the point contention. the remote step complexity is the maximal number of steps performed by a process where a wait is counted as one step. the system response time is the time interval between subsequent entries to the critical section where one time unit is the minimal interval in which every active process performs at least one step. the space complexity of this algorithm is o n log n where n is the range of process names. we show how to make the space complexity of our algorithm depend solely on n while preserving the other performance measures of the algorithm.
inspec,test_247,the congenial talking philosophers problem in computer networks. group mutual exclusion occurs naturally in situations where a resource can be shared by processes of the same group but not by processes of different groups. for example suppose data is stored in a cd jukebox. then when a disc is loaded for access users that need data on the disc can concurrently access the disc while users that need data on a different disc have to wait until the current disc is unloaded. the design issues for group mutual exclusion have been modeled as the congenial talking philosophers problem and solutions for shared memory models have been proposed y j. young 2000 p keane and m moir 1999. as in ordinary mutual exclusion and many other problems in distributed systems however techniques developed for shared memory do not necessarily apply to message passing and vice versa. we investigate solutions for congenial talking philosophers in computer networks where processes communicate by asynchronous message passing. we first present a solution that is a straightforward adaptation from g ricart and a k agrawala s 1981 algorithm for ordinary mutual exclusion. then we show that the simple modification suffers a severe performance degradation that could cause the system to behave as though only one process of a group can be in the critical section at a time. we then present a more efficient and highly concurrent distributed algorithm for the problem the first such solution in computer networks.
inspec,test_248,universal dynamic synchronous self stabilization. we prove the existence of a universal synchronous self stabilizing protocol that is a protocol that allows a distributed system to stabilize to a desired nonreactive behaviour as long as a protocol stabilizing to that behaviour exists. previous proposals required drastic increases in asymmetry and knowledge to work whereas our protocol does not use any additional knowledge and does not require more symmetry breaking conditions than available thus it is also stabilizing with respect to dynamic changes in the topology. we prove an optimal quiescence time n d for a synchronous network of n processors and diameter d the protocol can be made finite state with a negligible loss in quiescence time. moreover an optimal d 1 protocol is given for the case of unique identifiers. as a consequence we provide an effective proof technique that allows one to show whether self stabilization to a certain behaviour is possible under a wide range of models.
inspec,test_249,randomized two process wait free test and set. we present the first explicit and currently simplest randomized algorithm for two process wait free test and set. it is implemented with two 4 valued single writer single reader atomic variables. a test and set takes at most 11 expected elementary steps while a reset takes exactly 1 elementary step. based on a finite state analysis the proofs of correctness and expected length are compressed into one table.
inspec,test_25,identification of evolving fuzzy rule based models. an approach to identification of evolving fuzzy rule based er models is proposed. er models implement a method for the noniterative update of both the rule base structure and parameters by incremental unsupervised learning. the rule base evolves by adding more informative rules than those that previously formed the model. in addition existing rules can be replaced with new rules based on ranking using the informative potential of the data. in this way the rule base structure is inherited and updated when new informative data become available rather than being completely retrained. the adaptive nature of these evolving rule based models in combination with the highly transparent and compact form of fuzzy rules makes them a promising candidate for modeling and control of complex processes competitive to neural networks. the approach has been tested on a benchmark problem and on an air conditioning component modeling application using data from an installation serving a real building. the results illustrate the viability and efficiency of the approach.
inspec,test_250,aim for the enterprise microsoft project 2002. a long time favorite of project managers microsoft project 2002 is making its enterprise debut. its new web based collaboration tools and improved scalability with olap support make it much easier to manage multiple web projects with disparate workgroups and budgets.
inspec,test_251,central hub for design assets adobe golive 6 0. adobe golive is a strong contender for web authoring and publishing. version 6 0 features a flexible gui environment combined with a comprehensive workgroup and collaboration server plus tight integration with leading design tools.
inspec,test_252,reaching for five nines activewatch and siteseer. every web admin s dream is achieving the fabled five nines 99 999 percent uptime. to attain such availability your web site must be down no more than about five minutes per year. technologies like raid clustering and load balancing make this easier but to actually track uptime maintain auditable records and discover patterns in failures to prevent downtime in the future you ll need to set up external monitoring. because your internet connection is a key factor in measuring uptime you must monitor your site from the internet itself beyond your firewall. you could monitor with custom software on remote hosts or you could use one of the two reasonably priced services available mercury interactive s activewatch and freshwater software s siteseer. freshwater software has been a subsidiary of mercury interactive for about a year now. the two services offer a slightly different mix of features and target different markets. both services offer availability and performance monitoring from several remote locations alerts to email or pager and periodic reports. they differ in what s most easily monitored and in the way you interact with the services.
inspec,test_253,accessible streaming content. make sure your web site is offering quality service to all your users. the article provides some tips and tactics for making your streaming media accessible. accessibility of streaming content for people with disabilities is often not part of the spec for multimedia projects but it certainly affects your quality of service. most of the resources available on web accessibility deal with html. fortunately rich media and streaming content developers have a growing number of experts to turn to for information and assistance. the essentials of providing accessible streaming content are simple blind and visually impaired people need audio to discern important visual detail and interface elements while deaf and hard of hearing people need text to access sound effects and dialog. actually implementing these principles is quite a challenge though. now due to a relatively new law in the us known as section 508 dealing with accessibility issues is becoming an essential part of publishing on the web.
inspec,test_254,what you get is what you see web performance monitoring. to get the best possible performance from your web infrastructure you ll need a complete view. do n t neglect the big picture because you re too busy concentrating on details. the increasing complexity of web sites and the content they provide has consequently increased the complexity of the infrastructure that supports them. but with some knowledge of networking a handful of useful tools and the insight that those tools provide designing and operating for optimal performance and reliability is within your grasp.
inspec,test_255,the culture of usability. now that most of us agree that usability testing is an integral investment in site development it s time to recognize that the standard approach falls short. it is possible to do less work and get better results while spending less money. by bringing usability testing in house and breaking tests into more manageable sessions you can vastly improve your online offering without affecting your profit margin.
inspec,test_256,debugging web applications. the author considers how one can save time tracking down bugs in web based applications by arming yourself with the right tools and programming practices. a wide variety of debugging tools have been written with web developers in mind.
inspec,test_257,unsafe at any speed. while sun prides itself on java s secure sandbox programming model microsoft takes a looser approach. its c language incorporates c like concepts including pointers and memory management. but is unsafe code really a boon to programmers or is it a step backward.
inspec,test_258,building digital collections at the oac current strategies with a view to future uses. providing a context for the exploration of user defined virtual collections the article describes the history and recent development of the online archive of california oac. stating that usability and user needs are primary factors in digital resource development issues explored include collaborations to build digital collections reliance upon professional standards for description and encoding system architecture interface design the need for user tools and the role of archivists as interpreters in the digital environment.
inspec,test_259,nuts and bolts implementing descriptive standards to enable virtual collections. to date online archival information systems have relied heavily on legacy finding aids for data to encode and provide to end users despite fairly strong indications in the archival literature that such legacy data is problematic even as a mediated access tool. archivists have only just begun to study the utility of archival descriptive data for end users in unmediated settings such as via the web. the ability of future archival information systems to respond to the expectations and needs of end users is inextricably linked to archivists getting their collective data house in order. the general international standard archival description isad g offers the profession a place from which to start extricating ourselves from the idiosyncracies of our legacy data and description practices.
inspec,test_26,learning weights for the quasi weighted means. we study the determination of weights for quasi weighted means also called quasi linear means when a set of examples is given. we consider first a simple case the learning of weights for weighted means and then we extend the approach to the more general case of a quasi weighted mean. we consider the case of a known arbitrary generator f. the paper finishes considering the use of parametric functions that are suitable when the values to aggregate are measure values or ratio.
inspec,test_260,prospecting virtual collections. virtual collections are a distinct sub species of digital collections and digital archives. archivists and curators as archivists and curators do not construct virtual collections rather they enable virtual collections through the application of descriptive and other standards. virtual collections are constructed by end users.
inspec,test_261,union outreach a pilgrim s progress. as the american labor movement continues on its path toward reorganization and rejuvenation archivists are challenged to ensure that the organizational political and cultural changes labor unions are experiencing are fully documented. the article examines the need for labor archivists to reach out actively to unions and the problems they face in getting their message across not only to union leadership but also to union members. outreach by labor archivists is vital on three critical fronts the need to secure union funding in support of labor archival programs obtaining union cooperation in reviewing and amending obsolete deposit agreements and coordinating efforts with unions to save the records of closing district and local union offices. attempting to resolve these outstanding issues labor archivists are pulled between two distinct institutional cultures one academic in nature the other enmeshed in a union bureaucracy and often have their own labor archival programs compromised by the internal dynamics and politics inherent in administering large academic libraries and unions. if labor archivists are to be successful they must find their collective voice within the labor movement and establish their relevancy to unions during a period of momentous change and restructuring. moreover archivists need to give greater thought to designing and implementing outreach programs that bridge the fundamental disconnect between union bureaucracies and the rank and file and unions and the public.
inspec,test_262,the impact of ead adoption on archival programs a pilot survey of early implementers. the article reports the results of a survey conducted to assess the impact that the implementation of encoded archival description ead has on archival programs. by gathering data related to the funding staffing and evaluation of ead programs and about institutional goals for ead implementation the study explored how ead has affected the operations of the institutions which are utilizing it and the extent to which ead has become a part of regular repository functions.
inspec,test_263,k 12 instruction and digital access to archival materials. providing k 12 schools with digital access to archival materials can strengthen both student learning and archival practice although it can not replace direct physical access to records. the article compares a variety of electronic and nonelectronic projects to promote teaching with primary source materials. the article also examines some of the different historiographical and pedagogical approaches used in archival web sites geared for k 12 instruction focusing on differences between the educational sites sponsored by the library of congress and the national archives and records administration.
inspec,test_264,the archival imagination of david bearman revisited. many archivists regard the archival imagination evidenced in the writings of david bearman as avant garde. archivist l henry 1998 has sharply criticized bearman for being irreverent toward the archival theory and practice outlined by classical american archivist t r schellenberg. although bearman is sometimes credited and sometimes berated for establishing a new paradigm centered on the archival management of electronic records his methods and strategies are intended to encompass all forms of record keeping. the article provides general observations on bearman s archival imagination lists some of its components and addresses elements of henry s critique. although the long lasting impact of bearman s imagination upon the archival profession might be questioned it nonetheless deserves continued consideration by archivists and inclusion as a component of graduate archival education.
inspec,test_265,pattern recognition strategies for molecular surfaces. ii. surface complementarity. for pt i see ibid vol 23 p 1176 87 2002. fuzzy logic based algorithms for the quantitative treatment of complementarity of molecular surfaces are presented. therein the overlapping surface patches defined in part i of this series are used. the identification of complementary surface patches can be considered as a first step for the solution of molecular docking problems. standard technologies can then be used for further optimization of the resulting complex structures. the algorithms are applied to 33 biomolecular complexes. after the optimization with a downhill simplex method for all these complexes one structure was found which is in very good agreement with the experimental results.
inspec,test_266,pattern recognition strategies for molecular surfaces. i pattern generation using fuzzy set theory. a new method for the characterization of molecules based on the model approach of molecular surfaces is presented. we use the topographical properties of the surface as well as the electrostatic potential the local lipophilicity hydrophilicity and the hydrogen bond density on the surface for characterization. the definition and the calculation method for these properties are reviewed. the surface is segmented into overlapping patches with similar molecular properties. these patches can be used to represent the characteristic local features of the molecule in a way that is beyond the atomistic resolution but can nevertheless be applied for the analysis of partial similarities of different molecules as well as for the identification of molecular complementarity in a very general sense. the patch representation can be used for different applications which will be demonstrated in subsequent articles.
inspec,test_267,an efficient parallel algorithm for the calculation of canonical mp2 energies. we present the parallel version of a previous serial algorithm for the efficient calculation of canonical mp2 energies. it is based on the saebo almlof direct integral transformation coupled with an efficient prescreening of the ao integrals. the parallel algorithm avoids synchronization delays by spawning a second set of slaves during the bin sort prior to the second half transformation. results are presented for systems with up to 2000 basis functions. mp2 energies for molecules with 400 500 basis functions can be routinely calculated to microhartree accuracy on a small number of processors 6 8 in a matter of minutes with modern pc based parallel computers.
inspec,test_268,a method for correlations analysis of coordinates applications for molecular conformations. we describe a new method to analyze multiple correlations between subsets of coordinates that represent a sample. the correlation is established only between specific regions of interest at the coordinates. first the region s of interest are selected at each molecular coordinate. next a correlation matrix is constructed for the selected regions. the matrix is subject to further analysis illuminating the multidimensional structural characteristics that exist in the conformational space. the method s abilities are demonstrated in several examples it is used to analyze the conformational space of complex molecules it is successfully applied to compare related conformational spaces and it is used to analyze a diverse set of protein folding trajectories.
inspec,test_269,genetic algorithm guided selection variable selection and subset selection. a novel genetic algorithm guided selection method gas has been described. the method utilizes a simple encoding scheme which can represent both compounds and variables used to construct a qsar qspr model. a genetic algorithm is then utilized to simultaneously optimize the encoded variables that include both descriptors and compound subsets. the gas method generates multiple models each applying to a subset of the compounds. typically the subsets represent clusters with different chemotypes. also a procedure based on molecular similarity is presented to determine which model should be applied to a given test set compound. the variable selection method implemented in gas has been tested and compared using the selwood data set n 31 compounds nu 53 descriptors. the results showed that the method is comparable to other published methods. the subset selection method implemented in gas has been first tested using an artificial data set n 100 points nu 1 descriptor to examine its ability to subset data points and second applied to analyze the xlogp data set n 1831 compounds nu 126 descriptors. the method is able to correctly identify artificial data points belonging to various subsets. the analysis of the xlogp data set shows that the subset selection method can be useful in improving a qsar qspr model when the variable selection method fails.
inspec,test_27,a formal model of computing with words. classical automata are formal models of computing with values. fuzzy automata are generalizations of classical automata where the knowledge about the system s next state is vague or uncertain. it is worth noting that like classical automata fuzzy automata can only process strings of input symbols. therefore such fuzzy automata are still abstract devices for computing with values although a certain vagueness or uncertainty are involved in the process of computation. we introduce a new kind of fuzzy automata whose inputs are instead strings of fuzzy subsets of the input alphabet. these new fuzzy automata may serve as formal models of computing with words. we establish an extension principle from computing with values to computing with words. this principle indicates that computing with words can be implemented with computing with values with the price of a big amount of extra computations.
inspec,test_270,using molecular equivalence numbers to visually explore structural features that distinguish chemical libraries. a molecular equivalence number meqnum classifies a molecule with respect to a class of structural features or topological shapes such as its cyclic system or its set of functional groups. meqnums can be used to organize molecular structures into nonoverlapping yet highly relatable classes. we illustrate the construction of some different types of meqnums and present via examples some methods of comparing diverse chemical libraries based on meqnums. in the examples we compare a library which is a random sample from the mdl drug data report mddr with a library which is a random sample from the available chemical directory acd. in our analyses we discover some interesting features of the topological shape of a molecule and its set of functional groups that are strongly linked with compounds occurring in the mddr but not in the acd. we also illustrate the utility of molecular equivalence indices in delineating the structural domain over which an sar conclusion is valid.
inspec,test_271,on the use of neural network ensembles in qsar and qspr. despite their growing popularity among neural network practitioners ensemble methods have not been widely adopted in structure activity and structure property correlation. neural networks are inherently unstable in that small changes in the training set and or training parameters can lead to large changes in their generalization performance. recent research has shown that by capitalizing on the diversity of the individual models ensemble techniques can minimize uncertainty and produce more stable and accurate predictors. in this work we present a critical assessment of the most common ensemble technique known as bootstrap aggregation or bagging as applied to qsar and qspr. although aggregation does offer definitive advantages we demonstrate that bagging may not be the best possible choice and that simpler techniques such as retraining with the full sample can often produce superior results. these findings are rationalized using krogh and vedelsby s 1995 decomposition of the generalization error into a term that measures the average generalization performance of the individual networks and a term that measures the diversity among them. for networks that are designed to resist over fitting the benefits of aggregation are clear but not overwhelming.
inspec,test_272,median partitioning a novel method for the selection of representative subsets from large compound pools. a method termed median partitioning mp has been developed to select diverse sets of molecules from large compound pools. unlike many other methods for subset selection the mp approach does not depend on pairwise comparison of molecules and can therefore be applied to very large compound collections. the only time limiting step is the calculation of molecular descriptors for database compounds. mp employs arrays of property descriptors with little correlation to divide large compound pools into partitions from which representative molecules can be selected. in each of n subsequent steps a population of molecules is divided into subpopulations above and below the median value of a property descriptor until a desired number of 2 sup n partitions are obtained. for descriptor evaluation and selection an entropy formulation was embedded in a genetic algorithm. mp has been applied to generate a subset of the available chemicals directory and the results have been compared with cell based partitioning.
inspec,test_273,chemical information based scaling of molecular descriptors a universal chemical scale for library design and analysis. scaling is a difficult issue for any analysis of chemical properties or molecular topology when disparate descriptors are involved. to compare properties across different data sets a common scale must be defined. using several publicly available databases acd cmc mddr and nci as a basis we propose to define chemically meaningful scales for a number of molecular properties and topology descriptors. these chemically derived scaling functions have several advantages. first it is possible to define chemically relevant scales greatly simplifying similarity and diversity analyses across data sets. second this approach provides a convenient method for setting descriptor boundaries that define chemically reasonable topology spaces. for example descriptors can be scaled so that compounds with little potential for biological activity bioavailability or other drug like characteristics are easily identified as outliers. we have compiled scaling values for 314 molecular descriptors. in addition the 10th and 90th percentile values for each descriptor have been calculated for use in outlier filtering.
inspec,test_274,mtd pls a pls based variant of the mtd method. ii. mapping ligand receptor interactions. enzymatic acetic acid esters hydrolysis. the pls variant of the mtd method t i oprea et al sar qsar environ. res. 2001 12 75 92 was applied to a series of 25 acetylcholinesterase hydrolysis substrates. statistically significant mtd pls models q sup 2 between 0 7 and 0 8 are in agreement with previous mtd models with the advantage that local contributions are understood beyond the occupancy nonoccupancy interpretation in mtd. a chemically intuitive approach further forces mtd pls coefficients to assume only negative or zero values for fragmental volume descriptors and positive or zero values for fragmental hydrophobicity descriptors. this further separates the various kinds of local interactions at each vertex of the mtd hypermolecule making this method suitable for medicinal chemistry synthesis planning.
inspec,test_275,prediction of ultraviolet spectral absorbance using quantitative structure property relationships. high performance liquid chromatography hplc with ultraviolet uv spectrophotometric detection is a common method for analyzing reaction products in organic chemistry. this procedure would benefit from a computational model for predicting the relative response of organic molecules. models are now reported for the prediction of the integrated uv absorbance for a diverse set of organic compounds using a quantitative structure property relationship qspr approach. a seven descriptor linear correlation with a squared correlation coefficient r sup 2 of 0 815 is reported for a data set of 521. compounds. using the sum of zindo oscillator strengths in the integration range as an additional descriptor allowed reduction in the number of descriptors producing a robust model for 460 compounds with five descriptors and a squared correlation coefficient 0 857. the descriptors used in the models are discussed with respect to the physical nature of the uv absorption process.
inspec,test_276,assessment of the macrocyclic effect for the complexation of crown ethers with alkali cations using the substructural molecular fragments method. the substructural molecular fragments method solov ev v p varnek a a wipff g j chem. inf. comput. sci. 2000 40 847 858 was applied to assess stability constants logk of the complexes of crown ethers polyethers and glymes with na sup  k sup  and cs sup  in methanol. one hundred forty seven computational models including different fragment sets coupled with linear or nonlinear fitting equations were applied for the data sets containing 69 na sup  123 k sup  and 31 cs sup  compounds. to account for the macrocyclic effect for crown ethers an additional cyclicity descriptor was used. predicted stability constants both for macrocyclic compounds and for their open chain analogues are in good agreement with the experimental data reported earlier and with those studied experimentally in this work. the macrocyclic effect as a function of cation and ligand is quantitatively estimated for all studied crown ethers.
inspec,test_277,improving the predicting power of partial order based qsars through linear extensions. partial order theory pot is an attractive and operationally simple method that allows ordering of compounds based on selected structural and or electronic descriptors modeled order or based on their end points e g solubility experimental order. if the modeled order resembles the experimental order compounds that are not experimentally investigated can be assigned a position in the model that eventually might lead to a prediction of an end point value. however in the application of pot in quantitative structure activity relationship modeling only the compounds directly comparable to the noninvestigated compounds are applied. to explore the possibilities of improving the methodology the theory is extended by application of the so called linear extensions of the model order. the study show that partial ordering combined with linear extensions appears as a promising tool providing probability distribution curves in the range of possible end point values for compounds not being experimentally investigated.
inspec,test_278,novel ze isomerism descriptors derived from molecular topology and their application to qsar analysis. we introduce several series of novel ze isomerism descriptors derived directly from two dimensional molecular topology. these descriptors make use of a quantity named ze isomerism correction which is added to the vertex degrees of atoms connected by double bonds in z and e configurations. this approach is similar to the one described previously for topological chirality descriptors golbraikh a et al. j chem. inf. comput. sci. 2001 41 147 158. the ze isomerism descriptors include modified molecular connectivity indices overall zagreb indices extended connectivity overall connectivity and topological charge indices. they can be either real or complex numbers. mathematical properties of different subgroups of ze isomerism descriptors are discussed. these descriptors circumvent the inability of conventional topological indices to distinguish between z and e isomers. the applicability of ze isomerism descriptors to qsar analysis is demonstrated in the studies of a series of 131 anticancer agents inhibiting tubulin polymerization.
inspec,test_279,computer mediated communication and university international students. the design for the preliminary study presented was based on the experiences of the international students and faculty members of a small southwest university being surveyed and interviewed. the data collection procedure blends qualitative and quantitative data. a strong consensus was found that supports the study s premise that there is an association between the use of computer mediated communication cmc and teaching and learning performance of international students. both groups believe cmc to be an effective teaching and learning tool by increasing the frequency and quality of communication between students and instructors improving language skills through increased writing and communication opportunities allowing students and instructors to stay current and to compete effectively providing alternative teaching and learning methods to increase students confidence in their ability to communicate effectively with peers and instructors and improving the instructors pedagogical focus and questioning techniques.
inspec,test_28,uncertainty bounds and their use in the design of interval type 2 fuzzy logic systems. we derive inner and outer bound sets for the type reduced set of an interval type 2 fuzzy logic system fls based on a new mathematical interpretation of the karnik mendel iterative procedure for computing the type reduced set. the bound sets can not only provide estimates about the uncertainty contained in the output of an interval type 2 fls but can also be used to design an interval type 2 fls. we demonstrate by means of a simulation experiment that the resulting system can operate without type reduction and can achieve similar performance to one that uses type reduction. therefore our new design method based on the bound sets can relieve the computation burden of an interval type 2 fls during its operation which makes an interval type 2 fls useful for real time applications.
inspec,test_280,entrepreneurs in action a web case model. much of the traditional schooling in america is built around systems of compliance and control characteristics which stifle the creative and entrepreneurial instincts of the children who are subjected to these tactics. the article explores a different approach to education one that involves capturing the interest of the student through the use of problem and project based instruction delivered via the internet. called entrepreneurs in action this program seeks to involve students in a problem at the outset and to promote the learning of traditional subject areas as a process of the problem solving activities that are undertaken. the program s details are explained from elementary school through university level courses and the authors outline their plans to test the efficacy of the program at each level.
inspec,test_281,factors contributing to preservice teachers discomfort in a web based course structured as an inquiry. a report is given of a qualitative emergent design study of a science technology society interaction sts web enhanced course. students discomfort during the pilot test provided insight into the intellectual scaffolding that preservice secondary science teachers needed to optimize their performance when required to develop understanding through open ended inquiry in a web environment. eight factors identified contributed to student discomfort computer skills paradigm shifts trust time management thinking about their own thinking systematic inquiry self assessment and scientific discourse. these factors suggested developing understanding through inquiry by conducting a self designed open ended systematic inquiry required autonomous learning involving metacognitive skills and time management skills. to the extent in which students either came into the course with this scaffolding or developed it during the course they were successful in learning about sts and its relationship to science teaching. changes in the web site made to accommodate learners needs as they surfaced are described.
inspec,test_282,recommendations for implementing internet inquiry projects. the purpose of the study presented was to provide recommendations to teachers who are interested in implementing internet inquiry projects. four classes of ninth and tenth grade honors students n 100 participated in an internet inquiry project in which they were presented with an ecology question that required them to make a decision based on information that they gathered analyzed and synthesized from the internet and their textbook. students then composed papers with a rationale for their decision. students in one group had access to pre selected relevant web sites access to the entire internet and were provided with less online support. students in the other group had access to only pre selected relevant web sites but were provided with more online support. two of the most important recommendations were 1 to provide students with more online support and 2 to provide students with pre selected relevant web sites and allow them to search the internet for information.
inspec,test_283,alien rescue a problem based hypermedia learning environment for middle school science. the article describes an innovative hypermedia product for sixth graders in space science alien rescue. using a problem based learning approach that is highly interactive alien rescue engages students in scientific investigations aimed at finding solutions to complex and meaningful problems. problem based learning pbl is an instructional strategy proven to be effective in medical and business fields and it is increasingly popular in education. however using pbl in k 12 classrooms is challenging and requires access to rich knowledge bases and cognitive tools. alien rescue is designed to provide such cognitive support for successful use of pbl in sixth grade classrooms. the design and development of alien rescue is guided by current educational research. research is an integral part of this project. results of formative evaluation and research studies are being integrated into the development and improvement of the program. alien rescue is designed in accordance with the national science standards and the texas essential knowledge and skills teks for science. so far alien rescue has been field tested by approximately 1400 sixth graders. more use in middle schools is in progress and more research on its use is planned.
inspec,test_284,project based learning teachers learning and using high tech to preserve cajun culture. using project based learning pedagogy in edtc 658 advances in educational technology the author has trained inservice teachers in southwestern louisiana with an advanced computer multimedia program called director r macromedia inc. the content of this course focused on modeling the project based learning pedagogy and researching acadian s traditions and legacy. with the multi functions of microcomputers new technologies were used to preserve and celebrate the local culture with superiority of text graphics animation sound and video. the article describes how several groups of school teachers in the surrounding areas of a regional state university of louisiana learned computer multimedia using project based learning and integrated their learning into local cultural heritage.
inspec,test_285,presentation media information complexity and learning outcomes. multimedia computing provides a variety of information presentation modality combinations. educators have observed that visuals enhance learning which suggests that multimedia presentations should be superior to text only and text with static pictures in facilitating optimal human information processing and therefore comprehension. the article reports the findings from a 3 text only overhead slides and multimedia presentation 2 high and low information complexity factorial experiment. subjects read a text script viewed an acetate overhead slide presentation or viewed a multimedia presentation depicting the greenhouse effect low complexity or photocopier operation high complexity. multimedia was superior to text only and overhead slides for comprehension. information complexity diminished comprehension and perceived presentation quality. multimedia was able to reduce the negative impact of information complexity on comprehension and increase the extent of sustained attention to the presentation. these findings suggest that multimedia presentations invoke the use of both the verbal and visual working memory channels resulting in a reduction of the cognitive load imposed by increased information complexity. moreover multimedia superiority in facilitating comprehension goes beyond its ability to increase sustained attention the quality and effectiveness of information processing attained i e use of verbal and visual working memory is also significant.
inspec,test_286,real time tissue characterization on the basis of in vivo raman spectra. the application of in vivo raman spectroscopy for clinical diagnosis demands dedicated software that can perform the necessary signal processing and subsequent multivariate data analysis enabling clinically relevant parameters to be extracted and made available in real time. here we describe the design and implementation of a software package that allows for real time signal processing and data analysis of raman spectra. the design is based on automatic data exchange between grams a spectroscopic data acquisition and analysis program and matlab a program designed for array based calculations. the data analysis software has a modular design providing great flexibility in developing custom data analysis routines for different applications. the implementation is illustrated by a computationally demanding application for the classification of skin spectra using principal component analysis and linear discriminant analysis.
inspec,test_287,loudspeaker voice coil inductance losses circuit models parameter estimation and effect on frequency response. when the series resistance is separated and treated as a separate element it is shown that losses in an inductor require the ratio of the flux to mmf in the core to be frequency dependent. for small signal operation this dependence leads to a circuit model composed of a lossless inductor and a resistor in parallel both of which are frequency dependent. mathematical expressions for these elements are derived under the assumption that the ratio of core flux to mmf varies as omega sup n 1  where n is a constant. a linear regression technique is described for extracting the model parameters from measured data. experimental data are presented to justify the model for the lossy inductance of a loudspeaker voice coil. a spice example is presented to illustrate the effects of voice coil inductor losses on the frequency response of a typical driver.
inspec,test_288,complexity transitions in global algorithms for sparse linear systems over finite fields. we study the computational complexity of a very basic problem namely that of finding solutions to a very large set of random linear equations in a finite galois field modulo q using tools from statistical mechanics we are able to identify phase transitions in the structure of the solution space and to connect them to the changes in the performance of a global algorithm namely gaussian elimination. crossing phase boundaries produces a dramatic increase in memory and cpu requirements necessary for the algorithms. in turn this causes the saturation of the upper bounds for the running time. we illustrate the results on the specific problem of integer factorization which is of central interest for deciphering messages encrypted with the rsa cryptosystem.
inspec,test_289,noise effect on memory recall in dynamical neural network model of hippocampus. we investigate some noise effect on a neural network model proposed by araki and aihara 1998 for the memory recall of dynamical patterns in the hippocampus and the entorhinal cortex the noise effect is important since the release of transmitters at synaptic clefts the operation of gate of ion channels and so on are known as stochastic phenomena. we consider two kinds of noise effect due to a deterministic noise and a stochastic noise. by numerical simulations we find that reasonable values of noise give better performance on the memory recall of dynamical patterns. furthermore we investigate the effect of the strength of external inputs on the memory recall.
inspec,test_29,fuzzy polynomial neural networks hybrid architectures of fuzzy modeling. we introduce a concept of fuzzy polynomial neural networks fpnns a hybrid modeling architecture combining polynomial neural networks pnns and fuzzy neural networks fnns. the development of the fpnns dwells on the technologies of computational intelligence ci namely fuzzy sets neural networks and genetic algorithms. the structure of the fpnn results from a synergistic usage of fnn and pnn. fnns contribute to the formation of the premise part of the rule based structure of the fpnn. the consequence part of the fpnn is designed using pnns. the structure of the pnn is not fixed in advance as it usually takes place in the case of conventional neural networks but becomes organized dynamically to meet the required approximation error. we exploit a group method of data handling gmdh to produce this dynamic topology of the network. the performance of the fpnn is quantified through experimentation that exploits standard data already used in fuzzy modeling. the obtained experimental results reveal that the proposed networks exhibit high accuracy and generalization capabilities in comparison to other similar fuzzy models.
inspec,test_290,mems applications in computer disk drive dual stage servo systems. we present a decoupled discrete time pole placement design method which can be combined with a self tuning scheme to compensate variations in the microactuator s ma s resonance mode. section i of the paper describes the design and fabrication of a prototype microactuator with an integrated gimbal structure. section ii presents a decoupled track following controller design and a self tuning control scheme to compensate for the ma s resonance mode variations.
inspec,test_291,nuclear magnetic resonance molecular photography. a procedure is described for storing a two dimensional 2d pattern consisting of 32 32 1024 bits in a spin state of a molecular system and then retrieving the stored information as a stack of nuclear magnetic resonance spectra. the system used is a nematic liquid crystal the protons of which act as spin clusters with strong intramolecular interactions. the technique used is a programmable multifrequency irradiation with low amplitude. when it is applied to the liquid crystal a large number of coherent long lived sup 1 h response signals can be excited resulting in a spectrum showing many sharp peaks with controllable frequencies and amplitudes. the spectral resolution is enhanced by using a second weak pulse with a 90 degrees phase shift so that the 1024 bits of information can be retrieved as a set of well resolved pseudo 2d spectra reproducing the input pattern.
inspec,test_292,novel active noise reducing headset using earshell vibration control. active noise reducing anr headsets are available commercially in applications varying from aviation communication to consumer audio. current anr systems use passive attenuation at high frequencies and loudspeaker based active noise control at low frequencies to achieve broadband noise reduction. this paper presents a novel anr headset in which the external noise transmitted to the user s ear via earshell vibration is reduced by controlling the vibration of the earshell using force actuators acting against an inertial mass or the earshell headband. model based theoretical analysis using velocity feedback control showed that current piezoelectric actuators provide sufficient force but require lower stiffness for improved low frequency performance. control simulations based on experimental data from a laboratory headset showed that good performance can potentially be achieved in practice by a robust feedback controller while a single frequency real time control experiment verified that noise reduction can be achieved using earshell vibration control.
inspec,test_293,theoretical and experimental investigations on coherence of traffic noise transmission through an open window into a rectangular room in high rise buildings. a method for theoretically calculating the coherence between sound pressure inside a rectangular room in a high rise building and that outside the open window of the room is proposed. the traffic noise transmitted into a room is generally dominated by low frequency components to which active noise control anc technology may find an application. however good coherence between reference and error signals is essential for an effective noise reduction and should be checked first. based on traffic noise prediction methods wave theory and mode coupling theory the results of this paper enabled one to determine the potentials and limitations of anc used to reduce such a transmission. experimental coherence results are shown for two similar empty rectangular rooms located on the 17th and 30th floors of a 34 floor high rise building. the calculated results with the proposed method are generally in good agreement with the experimental results and demonstrate the usefulness of the method for predicting the coherence.
inspec,test_294,high density remote storage the ohio state university libraries depository. the article describes a high density off site book storage facility operated by the ohio state university libraries. opened in 1995 it has the capacity to house nearly 1 5 million items in only 9000 square feet by shelving books by size on 30 foot tall shelving. a sophisticated climate control system extends the life of stored materials up to 12 times. an online catalog record for each item informs patrons that the item is located in a remote location. regular courier deliveries from the storage facility bring requested materials to patrons with minimal delay.
inspec,test_295,hours of operation and service in academic libraries toward a national standard. in an effort toward establishing a standard for academic library hours the article surveys and compares hours of operation and service for arl libraries and ipeds survey respondents. the article ranks the arl association for research libraries libraries according to hours of operation and reference hours and then briefly discusses such issues as libraries offering twenty four access and factors affecting service hour decisions.
inspec,test_296,using the web to answer legal reference questions. in an effort to help non law librarians with basic legal reference questions the author highlights three basic legal web sites and outlines useful subject specific web sites that focus on statutes and regulations case law and attorney directories.
inspec,test_297,the service side of systems librarianship. describes the role of a systems librarian at a small academic library. although online catalogs and the internet are making library accessibility more convenient the need for library buildings and professionals has not diminished. typical duties of a systems librarian and the effects of new technology on librarianship are discussed. services provided to other constituencies on campus and the blurring relationship between the library and computer services are also presented.
inspec,test_298,defining electronic librarianship a content analysis of job advertisements. advances in technology create dramatic changes within libraries. the complex issues surrounding this new electronic end user environment have major ramifications and require expert knowledge. electronic services librarians and electronic resources librarians are two specialized titles that have recently emerged within the field of librarianship to fill this niche. job advertisements listed in american libraries from january 1989 to december 1998 were examined to identify responsibilities qualifications organizational and salary information relating to the newly emerging role of electronic librarian.
inspec,test_299,customer in reach and library strategic systems the case of illiad. libraries have walls. recognizing this fact the interlibrary loan department at virginia tech is creating systems and services that enable our customers to reach past our walls at anytime from anywhere. customer in reach enables virginia tech faculty students and staff anywhere in the world to obtain information and services heretofore available only to our on campus customers. illiad virginia tech s interlibrary borrowing system is the library strategic system that attains this goal. the principles that guided development of illiad are widely applicable.
inspec,test_3,nuvox shows staying power with new cash new market. who says you ca n t raise cash in today s telecom market. nuvox communications positions itself for the long run with 78 5 million in funding and a new credit facility.
inspec,test_30,improvements and critique on sugeno s and yasukawa s qualitative modeling. investigates sugeno s and yasukawa s 1993 qualitative fuzzy modeling approach. we propose some easily implementable solutions for the unclear details of the original paper such as trapezoid approximation of membership functions rule creation from sample data points and selection of important variables. we further suggest an improved parameter identification algorithm to be applied instead of the original one. these details are crucial concerning the method s performance as it is shown in a comparative analysis and helps to improve the accuracy of the built up model. finally we propose a possible further rule base reduction which can be applied successfully in certain cases. this improvement reduces the time requirement of the method by up to 16 in our experiments.
inspec,test_300,the plot thins thin client computer systems and academic libraries. the few libraries that have tried thin client architectures have noted a number of compelling reasons to do so. for starters thin client devices are far less expensive than most pcs. more importantly thin client computing devices are believed to be far less expensive to manage and support than traditional pcs.
inspec,test_301,academic libraries and community making the connection. i explore the theme of academic libraries serving and reaching out to the broader community. i highlight interesting projects reported on in the literature such as the through our parents eyes project and report on others. i look at challenges to community partnerships and recommendations for making them succeed. although i focus on links with the broader community i also took at methods for increasing cooperation among various units on campus so that the needs of campus community groups such as distance education students or disabled students are effectively addressed. though academic libraries are my focus we can learn a lot from the community building efforts of public libraries.
inspec,test_302,using internet search engines to estimate word frequency. the present research investigated internet search engines as a rapid cost effective alternative for estimating word frequencies. frequency estimates for 382 words were obtained and compared across four methods 1 internet search engines 2 the kucera and francis 1967 analysis of a traditional linguistic corpus 3 the celex english linguistic database baayen et al 1995 and 4 participant ratings of familiarity. the results showed that internet search engines produced frequency estimates that were highly consistent with those reported by kucera and francis and those calculated from celex highly consistent across search engines and very reliable over a 6 month period of time. additional results suggested that internet search engines are an excellent option when traditional word frequency analyses do not contain the necessary data e g estimates for forenames and slang. in contrast participants familiarity judgments did not correspond well with the more objective estimates of word frequency. researchers are advised to use search engines with large databases e g altavista to ensure the greatest representativeness of the frequency estimates.
inspec,test_303,visual word identification thresholds for the 260 fragmented words of the snodgrass and vanderwart pictures in spanish. word difficulty varies from language to language therefore normative data of verbal stimuli can not be imported directly from another language. we present mean identification thresholds for the 260 screen fragmented words corresponding to the total set of snodgrass and vanderwart 1980 pictures. individual words were fragmented in eight levels using turbo pascal and the resulting program was implemented on a pc microcomputer. the words were presented individually to a group of 40 spanish observers using a controlled time procedure. an unspecific learning effect was found showing that performance improved due to practice with the task. finally of the 11 psycholinguistic variables that previous researchers have shown to affect word identification only imagery accounted for a significant amount of variance in the threshold values.
inspec,test_304,a web accessible database of characteristics of the 1 945 basic japanese kanji. in 1981 the japanese government published a list of the 1 945 basic japanese kanji jooyoo kanji hyo including specifications of pronunciation. this list was established as the standard for kanji usage in print. the database for 1 945 basic japanese kanji provides 30 cells that explain in detail the various characteristics of kanji. means standard deviations distributions and information related to previous research concerning these kanji are provided in this paper. the database is saved as a microsoft excel 2000 file for windows. this kanji database is accessible on the web site of the oxford text archive oxford university http ota ahds ac uk. using this database researchers and educators will be able to conduct planned experiments and organize classroom instruction on the basis of the known characteristics of selected kanji.
inspec,test_305,full screen ultrafast video modes over clocked by simple vesa routines and registers reprogramming under ms dos. fast full screen presentation of stimuli is necessary in psychological research. although spitczok von brisinski 1994 introduced a method that achieved ultrafast display by reprogramming the registers he could not produce an acceptable full screen display. in this report the author introduces a new method combining vesa routine calling with register reprogramming that can yield a display at 640 480 resolution with a refresh rate of about 150 hz.
inspec,test_306,measuring keyboard response delays by comparing keyboard and joystick inputs. the response characteristics of pc keyboards have to be identified when they are used as response devices in psychological experiments. in the past the proposed method has been to check the characteristics independently by means of external measurement equipment. however with the availability of different pc models and the rapid pace of model change there is an urgent need for the development of convenient and accurate methods of checking. the method proposed consists of raising the precision of the pc s clock to the microsecond level and using a joystick connected to the midi terminal of a sound board to give the pc an independent timing function. statistical processing of the data provided by this method makes it possible to estimate accurately the keyboard scanning interval time and the average keyboard delay time. the results showed that measured keyboard delay times varied from 11 to 73 msec depending on the keyboard model with most values being less than 30 msec.
inspec,test_307,computer program to generate operant schedules. a computer program for programming schedules of reinforcement is described. students can use the program to experience schedules of reinforcement that are typically used with nonhuman subjects. accumulative recording of a student s response can be shown on the screen and or printed with the computer s printer. the program can also be used to program operant schedules for animal subjects. the program was tested with human subjects experiencing fixed ratio variable ratio fixed interval and variable interval schedules. performance for human subjects on a given schedule was similar to performance for nonhuman subjects on the same schedule.
inspec,test_308,on line homework quiz exam applet freely available java software for evaluating performance on line. the homework quiz exam applet is a freely available java program that can be used to evaluate student performance on line for any content authored by a teacher. it has database connectivity so that student scores are automatically recorded. it allows several different types of questions. each question can be linked to images and detailed story problems. three levels of feedback are provided to student responses. it allows teachers to randomize the sequence of questions and to randomize which of several options is the correct answer in multiple choice questions. the creation and editing of questions involves menu selections button presses and the typing of content no programming knowledge is required. the code is open source in order to encourage modifications that will meet individual pedagogical needs.
inspec,test_309,wextor a web based tool for generating and visualizing experimental designs and procedures. wextor is a javascript based experiment generator and teaching tool on the world wide web that can be used to design laboratory and web experiments in a guided step by step process. it dynamically creates the customized web pages and javascripts needed for the experimental procedure and provides experimenters with a print ready visual display of their experimental design. wextor flexibly supports complete and incomplete factorial designs with between subjects within subjects and quasi experimental factors as well as mixed designs. the software implements client side response time measurement and contains a content wizard for creating interactive materials as well as dependent measures graphical scales multiple choice items etc on the experiment pages. however it does not aim to replace a full fledged html editor. several methodological features specifically needed in web experimental design have been implemented in the web based tool and are described in this paper. wextor is platform independent. the created web pages can be uploaded to any type of web server in which data may be recorded in logfiles or via a database. the current version of wextor is freely available for educational and noncommercial purposes. its web address is http www genpsylab unizh ch wextor index html.
inspec,test_31,adaptive neural fuzzy control for interpolated nonlinear systems. adaptive control for nonlinear time varying systems is of both theoretical and practical importance. we propose an adaptive control methodology for a class of nonlinear systems with a time varying structure. this class of systems is composed of interpolations of nonlinear subsystems which are input output feedback linearizable. both indirect and direct adaptive control methods are developed where the spatially localized models in the form of takagi sugeno fuzzy systems or radial basis function neural networks are used as online approximators to learn the unknown dynamics of the system. without assumptions on rate of change of system dynamics the proposed adaptive control methods guarantee that all internal signals of the system are bounded and the tracking error is asymptotically stable. the performance of the adaptive controller is demonstrated using a jet engine control problem.
inspec,test_310,epsych interactive demonstrations and experiments in psychology. epsych http epsych msstate edu a new web site currently under active development is intended to teach students about the discipline of psychology. the site presumes little prior knowledge about the field and so may be used in introductory classes but it incorporates sufficient depth of coverage to be useful in more advanced classes as well. numerous interactive and dynamic elements are incorporated into various modules orientations and guidebooks. these elements include java based experiments and demonstrations video clips and animated diagrams. rapid access to all material is provided through a layer based navigation system that allows users to visit various worlds of the mind. active learning is encouraged by challenging students with puzzles and problems and by providing the opportunity to dig deeper to learn more about the phenomena at hand.
inspec,test_311,information architecture without internal theory an inductive design process. this article suggests that information architecture ia design is primarily an inductive process. although top level goals user attributes and available content are periodically considered the process involves bottom up design activities. ia is inductive partly because it lacks internal theory and partly because it is an activity that supports emergent phenomena user experiences from basic design components. the nature of ia design is well described by constructive induction ci a design process that involves locating the best representational framework for the design problem identifying a solution within that framework and translating it back to the design problem at hand. the future of ia if it remains inductive or develops a body of theory or both is considered.
inspec,test_312,information architecture for the web the ia matrix approach to designing children s portals. the article presents a matrix that can serve as a tool for designing the information architecture of a web portal in a logical and systematic manner. the information architect begins by inputting the portal s objective target user and target content. the matrix then determines the most appropriate information architecture attributes for the portal by filling in the applied information architecture portion of the matrix. the article discusses how the matrix works using the example of a children s web portal to provide access to museum information.
inspec,test_313,information architecture notes toward a new curriculum. there are signs that information architecture is coalescing into a field of professional practice. however if it is to become a profession it must develop a means of educating new information architects. lessons from other fields suggest that professional education typically evolves along a predictable path from apprenticeships to trade schools to college and university level education. information architecture education may develop more quickly to meet the growing demands of the information society. several pedagogical approaches employed in other fields may be adopted for information architecture education as long as the resulting curricula provide an interdisciplinary approach and balance instruction in technical and design skills with consideration of theoretical concepts. key content areas are information organization graphic. design computer science user and usability studies and communication. certain logistics must be worked out including where information architecture studies should be housed and what kinds of degrees should be offered and at what levels. the successful information architecture curriculum will be flexible and adaptable in order to meet the changing needs of students and the marketplace.
inspec,test_314,information architecture in jasist just where did we come from. the emergence of information architecture within the information systems world has been simultaneously drawn out yet rapid. those with an eye on history are quick to point to wurman s 1976 use of the term architecture of information  but it has only been in the last 2 years that ia has become the source of sufficient interest for people to label themselves professionally as information architects. the impetus for this recent emergence of ia can be traced to a historical summit supported by asis t in may 2000 at boston. it was here that several hundred of us gathered to thrash out the questions of just what ia was and what this new field might become. at the time of the summit invited to present a short talk on my return journey from the annual acm sigchi conference i entered the summit expecting little and convinced that ia was nothing new. i left 2 days later refreshed not just by the enthusiasm of the attendees for this term but by ia s potential to unify the disparate perspectives and orientations of professionals from a range of disciplines. it was at this summit that the idea for the special issue took root. i proposed the idea to don kraft hoping he would find someone else to run with it. as luck would have it i ended up taking charge of it myself with initial support from david blair. from the suggestion to the finished product has been the best part of 2 years and in that time more than 50 volunteers reviewed over 20 submissions.
inspec,test_315,the impact of the internet on public library use an analysis of the current consumer market for library and internet services. the potential impact of the internet on the public s demand for the services and resources of public libraries is an issue of critical importance. the research reported in this article provides baseline data concerning the evolving relationship between the public s use of the library and its use of the internet. the authors developed a consumer model of the american adult market for information services and resources segmented by use or nonuse of the public library and by access or lack of access to and use or nonuse of the internet. a national random digit dialing telephone survey collected data to estimate the size of each of six market segments and to describe their usage choices between the public library and the internet. the analyses presented in this article provide estimates of the size and demographics of each of the market segments describe why people are currently using the public library and the internet identify the decision criteria people use in their choices of which provider to use identify areas in which libraries and the internet appear to be competing and areas in which they appear to be complementary and identify reasons why people choose not to use the public library and or the internet. the data suggest that some differentiation between the library and the internet is taking place which may very well have an impact on consumer choices between the two. longitudinal research is necessary to fully reveal trends in these usage choices which have implications for all types of libraries in planning and policy development.
inspec,test_316,duality revisited construction of fractional frequency distributions based on two dual lotka laws. fractional frequency distributions of for example authors with a certain fractional number of papers are very irregular and therefore not easy to model or to explain. the article gives a first attempt to this by as suming two simple lotka laws with exponent 2 one for the number of authors with n papers total count here and one for the number of papers with n authors n in n based on an earlier made convolution model of egghe interpreted and reworked now for discrete scores we are able to produce theoretical fractional frequency distributions with only one parameter which are in very close agreement with the practical ones as found in a large dataset produced earlier by rao 1995. the article also shows that irregular fractional frequency distributions are a consequence of lotka s law and are not examples of breakdowns of this famous historical law.
inspec,test_317,relevance of web documents ghosts consensus method. the dominant method currently used to improve the quality of internet search systems is often called digital democracy. such an approach implies the utilization of the majority opinion of internet users to determine the most relevant documents for example citation index usage for sorting of search results google com or an enrichment of a query with terms that are asked frequently in relation with the query s theme. digital democracy is an effective instrument in many cases but it has an unavoidable shortcoming which is a matter of principle the average intellectual and cultural level of internet users is very low everyone knows what kind of information is dominant in internet query statistics. therefore when one searches the internet by means of digital democracy systems one gets answers that reflect an underlying assumption that the user s mind potential is very low and that his cultural interests are not demanding. thus it is more correct to use the term digital ochlocracy to refer to internet search systems with digital democracy. based on the well known mathematical mechanism of linear programming we propose a method to solve the indicated problem.
inspec,test_318,note on deterministic inventory lot size models under inflation with shortages and deterioration for fluctuating demand by yang et al. for original paper see h l. yang et al ibid vol 48 p 144 58 2001. yang et al extended the lot size models to allow for inflation and fluctuating demand. for this model they proved that the optimal replenishment schedule exists and is unique. they also proposed an algorithm to find the optimal policy. the present paper provides examples which show that the optimal replenishment schedule and consequently the overall optimal policy may not exist.
inspec,test_319,designing a screening experiment for highly reliable products. within a reasonable life testing time how to improve the reliability of highly reliable products is one of the great challenges. by using a resolution iii experiment together with degradation test tseng et al 1995 presented a case study of improving the reliability of fluorescent lamps. however in conducting such an experiment they did not address the problem of how to choose the optimal settings of variables such as sample size inspection frequency and termination time for each run which are influential to the correct identification of significant factors and the experimental cost. assuming that the product s degradation paths satisfy wiener processes this paper proposes a systematic approach to the aforementioned problem. first an identification rule is proposed. next under the constraints of a minimum probability of correct decision and a maximum probability of incorrect decision of the proposed identification rule the optimum test plan can be obtained by minimizing the total experimental cost. an example is provided to illustrate the proposed method.
inspec,test_32,analysis and efficient implementation of a linguistic fuzzy c means. the paper is concerned with a linguistic fuzzy c means fcm algorithm with vectors of fuzzy numbers as inputs. this algorithm is based on the extension principle and the decomposition theorem. it turns out that using the extension principle to extend the capability of the standard membership update equation to deal with a linguistic vector has a huge computational complexity. in order to cope with this problem an efficient method based on fuzzy arithmetic and optimization has been developed and analyzed. we also carefully examine and prove that the algorithm behaves in a way similar to the fcm in the degenerate linguistic case. synthetic data sets and the iris data set have been used to illustrate the behavior of this linguistic version of the fcm.
inspec,test_320,warranty reserves for nonstationary sales processes. estimation of warranty costs in the event of product failure within the warranty period is of importance to the manufacturer. costs associated with replacement or repair of the product are usually drawn from a warranty reserve fund created by the manufacturer. considering a stochastic sales process first and second moments and thereby the variance are derived for the manufacturer s total discounted warranty cost of a single sale for single component items under four different warranty policies from a manufacturer s point of view. these servicing strategies represent a renewable free replacement nonrenewable free replacement renewable pro rata and a nonrenewable minimal repair warranty plans. the results are extended to determine the mean and variance of total discounted warranty costs for the total sales over the life cycle of the product. furthermore using a normal approximation warranty reserves necessary for a certain protection level so that reserves are not completely depleted are found. results and their managerial implications are studied through an extensive example.
inspec,test_321,a multimodal data collection tool using realbasic and mac os x. this project uses realbasic 3 5 in the mac os x environment for development of a configuration tool that builds a data collection procedure for investigating the effectiveness of sonified graphs. the advantage of using realbasic with the mac os x system is that it provides rapid development of stimulus presentation direct recording of data to files and control over other procedural issues. the program can be made to run natively on the new mac os x system older mac os systems and windows 98se me 2000 pro. with modification similar programs could be used to present any number of visual auditory stimulus combinations complete with questions for each stimulus.
inspec,test_322,toward an experimental timing standards lab benchmarking precision in the real world. much discussion has taken place over the relative merits of various platforms and operating systems for real time data collection. most would agree that provided great care is taken many are capable of millisecond timing precision. however to date much of this work has focused on the theoretical aspects of raw performance. it is our belief that researchers would be better informed if they could place confidence limits on their own specific paradigms in situ and without modification. to this end we have developed a millisecond precision test rig that can control and time experiments on a second presentation machine. we report on the specialist hardware and software used. we elucidate the importance of the approach in relation to real world experimentation.
inspec,test_323,a server side program for delivering experiments with animations. a server side program for animation experiments is presented. the program is capable of delivering an experiment composed of discrete animation sequences in various file formats collecting a discrete or continuous response from the observer evaluating the appropriateness of the response and ensuring that the user is not proceeding at an unreasonable rate. most parameters of the program are controllable by experimenter edited text files or simple switches in the program code thereby minimizing the need for programming to create new experiments. a simple demonstration experiment is discussed and is freely available.
inspec,test_324,using netcloak to develop server side web based experiments without writing cgi programs. server side experiments use the web server rather than the participant s browser to handle tasks such as random assignment eliminating inconsistencies with java and other client side applications. heretofore experimenters wishing to create server side experiments have had to write programs to create common gateway interface cgi scripts in programming languages such as perl and c. netcloak uses simple html like commands to create cgis. we used netcloak to implement an experiment on probability estimation. measurements of time on task and participants ip addresses assisted quality control. without prior training in less than 1 month we were able to use netcloak to design and create a web based experiment and to help graduate students create three web based experiments of their own.
inspec,test_325,open courseware and shared knowledge in higher education. most college and university campuses in the united states and much of the developed world today maintain one two or several learning management systems lmss which are courseware products that provide students and faculty with web based tools to manage course related applications. since the mid 1990s two predominant models of web courseware management systems have emerged commercial and noncommercial. some of the commercial products available today were created in academia as noncommercial but have since become commercially encumbered. other products remain noncommercial but are struggling to survive in a world of fierce commercial competition. this article argues for an ethics of pedagogy in higher education that would be based on the guiding assumptions of the non proprietary peer to peer open source software movement.
inspec,test_326,web based experiments controlled by javascript an example from probability learning. javascript programs can be used to control web experiments. this technique is illustrated by an experiment that tested the effects of advice on performance in the classic probability learning paradigm. previous research reported that people tested via the web or in the lab tended to match the probabilities of their responses to the probabilities that those responses would be reinforced. the optimal strategy however is to consistently choose the more frequent event probability matching produces suboptimal performance. we investigated manipulations we reasoned should improve performance. a horse race scenario in which participants predicted the winner in each of a series of races between two horses was compared with an abstract scenario used previously. ten groups of learners received different amounts of advice including all combinations of 1 explicit instructions concerning the optimal strategy 2 explicit instructions concerning a monetary sum to maximize and 3 accurate information concerning the probabilities of events. the results showed minimal effects of horse race versus abstract scenario. both advice concerning the optimal strategy and probability information contributed significantly to performance in the task. this paper includes a brief tutorial on javascript explaining with simple examples how to assemble a browser based experiment.
inspec,test_327,using latent semantic analysis to assess reader strategies. we tested a computer based procedure for assessing reader strategies that was based on verbal protocols that utilized latent semantic analysis lsa. students were given self explanation reading training sert which teaches strategies that facilitate self explanation during reading such as elaboration based on world knowledge and bridging between text sentences. during a computerized version of sert practice students read texts and typed self explanations into a computer after each sentence. the use of sert strategies during this practice was assessed by determining the extent to which students used the information in the current sentence versus the prior text or world knowledge in their self explanations. this assessment was made on the basis of human judgments and lsa. both human judgments and lsa were remarkably similar and indicated that students who were not complying with sert tended to paraphrase the text sentences whereas students who were compliant with sert tended to explain the sentences in terms of what they knew about the world and of information provided in the prior text context. the similarity between human judgments and lsa indicates that lsa will be useful in accounting for reading strategies in a web based version of sert.
inspec,test_328,personality research on the internet a comparison of web based and traditional instruments in take home and in class settings. students faculty and researchers have become increasingly comfortable with the internet and many of them are interested in using the web to collect data. few published studies have investigated the differences between web based data and data collected with more traditional methods. in order to investigate these potential differences two important factors were crossed in this study whether the data were collected on line or not and whether the data were collected in a group setting at a fixed time or individually at a time of the respondent s choosing. the visions of morality scale shelton and mcadams 1990 was used and the participants were assigned to one of four conditions in class web survey in class paper and pencil survey take home web survey and take home paper and pencil survey. no significant differences in scores were found for any condition however response rates were affected by the type of survey administered with the take home web based instrument having the lowest response rate. therefore researchers need to be aware that different modes of administration may affect subject attrition and may therefore confound investigations of other independent variables.
inspec,test_329,implications of document level literacy skills for web site design. the proliferation of world wide web web sites and the low cost of publishing information on the web have placed a tremendous amount of information at the fingertips of millions of people. although most of this information is at least intended to be accurate there is much that is rumor innuendo urban legend and outright falsehood. this raises problems especially for students of all ages trying to do research or learn about some topic. finding accurate credible information requires document level literacy skills such as integration sourcing corroboration and search. this paper discusses these skills and offers a list of simple ways that designers of educational web sites can help their visitors utilize these skills.
inspec,test_33,fuzzy control of multivariable process by modified error decoupling. in this paper a control concept for the squared equal number of inputs and outputs multivariable process systems is given. the proposed control system consists of two parts single loop fuzzy controllers in each loop and a centralized decoupling unit. the fuzzy control system uses feedback control to minimize the error in the loop and the decoupler uses an adaptive technique to mitigate loop interactions. the decoupler predicts the interacting loop changes and modifies the input error of the loop controller. the controller was tested on the simulation model of single component vaporizer process.
inspec,test_330,improving computer security for authentication of users influence of proactive password restrictions. entering a user name password combination is a widely used procedure for identification and authentication in computer systems. however it is a notoriously weak method in that the passwords adopted by many users are easy to crack. in an attempt to improve security proactive password checking may be used in which passwords must meet several criteria to be more resistant to cracking. in two experiments we examined the influence of proactive password restrictions on the time that it took to generate an acceptable password and to use it subsequently to log in. the required length was a minimum of five characters in experiment i and eight characters in experiment 2. in both experiments one condition had only the length restriction and the other had additional restrictions. the additional restrictions greatly increased the time it took to generate the password but had only a small effect on the time it took to use it subsequently to log in. for the five character passwords 75 were cracked when no other restrictions were imposed and this was reduced to 33 with the additional restrictions. for the eight character passwords 17 were cracked with no other restrictions and 12 5 with restrictions. the results indicate that increasing the minimum character length reduces crackability and increases security regardless of whether additional restrictions are imposed.
inspec,test_331,multidimensional data visualization. historically data visualization has been limited primarily to two dimensions e g histograms or scatter plots. available software packages e g data desk 6 1 matlab 6 1 sas jmp 4 04 spss 10 0 are capable of producing three dimensional scatter plots with varying degrees of user interactivity. we constructed our own data visualization application with the visualization toolkit schroeder et al 1998 and tcl tk to display multivariate data through the application of glyphs ware 2000. a glyph is a visual object onto which many data parameters may be mapped each with a different visual attribute e g size or color. we used our multi dimensional data viewer to explore data from several psycholinguistic experiments. the graphical interface provides flexibility when users dynamically explore the multidimensional image rendered from raw experimental data. we highlight advantages of multidimensional data visualization and consider some potential limitations.
inspec,test_332,fitting mixed effects models for repeated ordinal outcomes with the nlmixed procedure. this paper presents an analysis of repeated ordinal outcomes arising from two psychological studies. the first case is a repeated measures analysis of variance the second is a mixed effects regression. in a longitudinal design. in both the subject specific variation is modeled by including random effects in the linear predictor inside a link function of a generalized linear model. the nlmixed procedure in sas is used to fit the mixed effects models for the categorical response data. the presentation emphasizes the parallel between the model. specifications and the sas statements. the purpose of this paper is to facilitate the use of mixed effects models in the analysis of repeated ordinal outcomes.
inspec,test_333,teaching psychology as a laboratory science in the age of the internet. for over 30 years psychologists have relied on computers to teach experimental psychology. with the advent of experiment generators students can create well designed experiments and can test sophisticated hypotheses from the start of their undergraduate training. characteristics of new net based experiment generators are discussed and compared with traditional stand alone generators. a call is made to formally evaluate the instructional effectiveness of the wide range of experiment generators now available. specifically software should be evaluated in terms of known learning outcomes using appropriate control groups. the many inherent differences between any two software programs should be made clear. the teacher s instructional method should be fully described and held constant between comparisons. finally the often complex interaction between the teacher s instructional method and the pedagogical details of the software must be considered.
inspec,test_334,capturing niche markets with copper. for last mile access in niche applications twisted copper pair may be the cable of best option to gain access and deliver desired services. the article discusses how operators can use network edge devices to serve new customers. niche market segments represent a significant opportunity for cable tv delivery of television and high speed internet signals. but the existing telecommunications infrastructure in those developments frequently presents unique challenges for the service provider to overcome.
inspec,test_335,fresh voices big ideas ibm internship program. ibm is matching up computer science and mba students with its business managers in an 11 week summer internship program and challenging them to develop innovative technology ideas.
inspec,test_338,down up it projects. despite the second quarter s gloomy gdp report savvy cios are forging ahead with big it projects that will position their companies to succeed when the economy soars again.
inspec,test_339,an automated parallel image registration technique based on the correlation of wavelet features. with the increasing importance of multiple multiplatform remote sensing missions fast and automatic integration of digital data from disparate sources has become critical to the success of these endeavors. our work utilizes maxima of wavelet coefficients to form the basic features of a correlation based automatic registration algorithm. our wavelet based registration algorithm is tested successfully with data from the national oceanic and atmospheric administration noaa advanced very high resolution radiometer avhrr and the landsat thematic mapper tm which differ by translation and or rotation. by the choice of high frequency wavelet features this method is similar to an edge based correlation method but by exploiting the multiresolution nature of a wavelet decomposition our method achieves higher computational speeds for comparable accuracies. this algorithm has been implemented on a single instruction multiple data simd massively parallel computer the maspar mp 2 as well as on the crayt3d the cray t3e and a beowulf cluster of pentium workstations.
inspec,test_34,design of pid type controllers using multiobjective genetic algorithms. the design of a pid controller is a multiobjective problem. a plant and a set of specifications to be satisfied are given. the designer has to adjust the parameters of the pid controller such that the feedback interconnection of the plant and the controller satisfies the specifications. these specifications are usually competitive and any acceptable solution requires a tradeoff among them. an approach for adjusting the parameters of a pid controller based on multiobjective optimization and genetic algorithms is presented in this paper. the mrcd multiobjective robust control design genetic algorithm has been employed. the approach can be easily generalized to design multivariable coupled and decentralized pid loops and has been successfully validated for a large number of experimental cases.
inspec,test_340,temelin casts its shadow nuclear power plant. reservations about temelin nuclear plant in the czech republic are political rather than technical. this paper discusses the problems of turbogenerator vibrations and how they were diagnosed. the paper also discusses some of the other problems of commissioning the power plant. the simulator used for training new staff is also mentioned.
inspec,test_341,how should team captains order golfers on the final day of the ryder cup matches. i used game theory to examine how team captains should select their slates for the final day of the ryder cup matches. under the assumption that golfers have different abilities and are not influenced by pressure or momentum i found that drawing names from a hat will do no worse than any other strategy.
inspec,test_342,mount sinai hospital uses integer programming to allocate operating room time. an integer programming model and a post solution heuristic allocates operating room time to the five surgical divisions at toronto s mount sinai hospital. the hospital has used this approach for several years and credits it with both administrative savings and the ability to produce quickly an equitable master surgical schedule.
inspec,test_343,using the small business innovation research program to turn your ideas into products. the us government s small business innovation research program helps small businesses transform new ideas into commercial products. the program provides an ideal means for businesses and universities to obtaining funding for cooperative projects. rules and information for the program are readily available and i will give a few helpful hints to provide guidance.
inspec,test_344,student consulting projects benefit faculty and industry. student consulting projects require students to apply or ms tools to obtain insight into the activities of firms in the community. these projects benefit faculty by providing clear feedback on the real capabilities of students a broad connection to local industry and material for case studies and research. they benefit companies by stimulating new thinking regarding their activities and delivering results they can use. projects provide insights into the end user modeling mode of or ms practice. projects support continuous improvement as the lessons gained from a crop of projects enable better teaching during the next course offering which in turn leads to better projects and further insights into teaching.
inspec,test_345,in search of strategic operations research management science. we define strategic or ms as or ms work that leads to a sustainable competitive advantage. we found evidence of strategic or ms in the literature of strategic information systems sis and or ms. we examined 30 early examples of sis many of which contained or ms work. many of the most successful had high or ms content while the least successful contained none. the inclusion of or ms work may be a key to sustaining an advantage from information technology. we also examined the edelman prize finalist articles published between 1990 and 1999. we found that 13 of the 42 private sector applications meet our definition of strategic or ms.
inspec,test_346,baseball optimization and the world wide web. the competition for baseball play off spots the fabled pennant race is one of the most closely watched american sports traditions. while play off race statistics such as games back and magic number are informative they are overly conservative and do not account for the remaining schedule of games. using optimization techniques one can model schedule effects explicitly and determine precisely when a team has secured a play off spot or has been eliminated from contention. the riot baseball play off races web site developed at the university of california berkeley provides automatic updates of new optimization based play off race statistics each day of the major league baseball season. in developing the site we found that we could determine the first place elimination status of all teams in a division using a single linear programming formulation since a minimum win threshold for teams finishing in first place applies to all teams in a division. we identified a similar but weaker result for the problem of play off elimination with wildcard teams.
inspec,test_347,from revenue management concepts to software systems. in 1999 after developing and installing over 170 revenue management rm systems for more than 70 airlines pros revenue management inc had the opportunity to develop rm systems for three companies in nonairline industries. pros research and design department designed the opportunity analysis study oas a mix of or ms consulting and software development practices to determine the applicability of rm in new business situations. pros executed oass with the three companies. in all three cases the oas supported the value of rm and led to contracts for implementation of rm systems.
inspec,test_348,lower bounds on the information rate of secret sharing schemes with homogeneous access structure. we present some new lower bounds on the optimal information rate and on the optimal average information rate of secret sharing schemes with homogeneous access structure. these bounds are found by using some covering constructions and a new parameter the k degree of a participant that is introduced in this paper. our bounds improve the previous ones in almost all cases.
inspec,test_349,a self adjusting quality of service control scheme. we propose and analyze a self adjusting quality of service qos control scheme with the goal of optimizing the system reward as a result of servicing different priority clients with varying workload qos and reward penalty requirements. our scheme is based on resource partitioning and designated degrade qos areas such that system resources are partitioned into priority areas each of which is reserved specifically to serve only clients in a corresponding class with no qos degradation plus one degraded qos area into which all clients can be admitted with qos adjustment being applied only to the lowest priority clients. we show that the best partition is dictated by the workload and the reward penalty characteristics of clients in difference priority classes. the analysis results can be used by a qos manager to optimize the system total reward dynamically in response to changing workloads at run time. we demonstrate the validity of our scheme by means of simulation and comparing the proposed qos self adjusting scheme with those that do not use resource partitioning or designated degraded qos areas.
inspec,test_35,fusion of qualitative bond graph and genetic algorithms a fault diagnosis application. in this paper the problem of fault diagnosis via integration of genetic algorithms ga s and qualitative bond graphs qbg s is addressed. we suggest that ga s can be used to search for possible fault components among a system of qualitative equations. the qbg is adopted as the modeling scheme to generate a set of qualitative equations. the qualitative bond graph provides a unified approach for modeling engineering systems in particular mechatronic systems. in order to demonstrate the performance of the proposed algorithm we have tested the proposed algorithm on an in house designed and built floating disc experimental setup. results from fault diagnosis in the floating disc system are presented and discussed. additional measurements will be required to localize the fault when more than one fault candidate is inferred. fault diagnosis is activated by a fault detection mechanism when a discrepancy between measured abnormal behavior and predicted system behavior is observed. the fault detection mechanism is not presented here.
inspec,test_350,there is no optimal routing policy for the torus. a routing policy is the method used to select a specific output channel for a message from among a number of acceptable output channels. an optimal routing policy is a policy that maximizes the probability of a message reaching its destination without delays. optimal routing policies have been proposed for several regular networks including the mesh and the hypercube. an open problem in interconnection network research has been the identification of an optimal routing policy for the torus. in this paper we show that there is no optimal routing policy for the torus. our result is demonstrated by presenting a detailed example in which the best choice of output channel is dependent on the probability of each channel being available. this result settles in the negative a conjecture by j wu 1996 concerning an optimal routing policy for the torus.
inspec,test_351,optimal online algorithm for scheduling on two identical machines with machine availability constraints. this paper considers the online scheduling on two identical machines with machine availability constraints for minimizing makespan. we assume that machine m sub j is unavailable during period from s sub j to t sub j 0 or s sub j  t sub j  j 1 2 and the unavailable periods of two machines do not overlap. we show that the competitive ratio of list scheduling is 3. we further give an optimal algorithm with a competitive ratio 5 2.
inspec,test_352,an efficient retrieval selection algorithm for video servers with random duplicated assignment storage technique. random duplicated assignment rda is an approach in which video data is stored by assigning a number of copies of each data block to different randomly chosen disks. it has been shown that this approach results in smaller response times and lower disk and ram costs compared to the well known disk stripping techniques. based on this storage approach one has to determine for each given batch of data blocks from which disk each of the data blocks is to be retrieved. this is to be done in such a way that the maximum load of the disks is minimized. the problem is called the retrieval selection problem rsp. in this paper we propose a new efficient algorithm for rsp. this algorithm is based on the breadth first search approach and is able to guarantee optimal solutions for rsp in o n sup 2  mn where m and n correspond to the number of data blocks and the number of disks respectively. we show that our proposed algorithm has a lower time complexity than an existing algorithm called the mfs algorithm.
inspec,test_353,edit distance of run length encoded strings. let x and y be two run length encoded strings of encoded lengths k and l respectively. we present a simple o x l  y k time algorithm that computes their edit distance.
inspec,test_354,fault tolerant hamiltonian laceability of hypercubes. it is known that every hypercube q sub n is a bipartite graph. assume that n or 2 and f is a subset of edges with f  or n 2. we prove that there exists a hamiltonian path in q sub n  f between any two vertices of different partite sets. moreover there exists a path of length 2 sup n 2 between any two vertices of the same partite set. assume that n or 3 and f is a subset of edges with f  or n 3. we prove that there exists a hamiltonian path in q sub n  v f between any two vertices in the partite set without v furthermore all bounds are tight.
inspec,test_355,an identity based society oriented signature scheme with anonymous signers. in this paper we propose a new society oriented scheme based on the guillou quisquater 1989 signature scheme. the scheme is identity based and the signatures are verified with respect to only one identity. that is the verifier does not have to know the identity of the co signers but just that of the organization they represent.
inspec,test_356,operational phase space probability distribution in quantum communication theory. operational phase space probability distributions are useful tools for describing quantum mechanical systems including quantum communication and quantum information processing systems. it is shown that quantum communication channels with gaussian noise and quantum teleportation of continuous variables are described by operational phase space probability distributions. the relation of operational phase space probability distribution to the extended phase space formalism proposed by chountasis and vourdas 1998 is discussed.
inspec,test_357,embedding of level continuous fuzzy sets on banach spaces. in this paper we present an extension of the minkowski embedding theorem showing the existence of an isometric embedding between the classf sub c x of compact convex and level continuous fuzzy sets on a real separable banach space x and c 0 1 b x  the banach space of real continuous functions defined on the cartesian product between 0 1 and the unit ball b x in the dual space x. also by using this embedding we give some applications to the characterization of relatively compact subsets of f sub c x. in particular an ascoli arzela type theorem is proved and applied to solving the cauchy problem x t f t x t x t sub 0  x sub 0 on f sub c x.
inspec,test_358,correlation of intuitionistic fuzzy sets by centroid method. in this paper we propose a method to calculate the correlation coefficient of intuitionistic fuzzy sets by means of centroid. this value obtained from our formula tell us not only the strength of relationship between the intuitionistic fuzzy sets but also whether the intuitionistic fuzzy sets are positively or negatively related. this approach looks better than previous methods which only evaluate the strength of the relation. furthermore we extend the centroid method to interval valued intuitionistic fuzzy sets. the value of the correlation coefficient between interval valued intuitionistic fuzzy sets lies in the interval 1 1 as computed from our formula.
inspec,test_359,neighborhood operator systems and approximations. this paper presents a framework for the study of generalizing the standard notion of equivalence relation in rough set approximation space with various categories of k step neighborhood systems. based on a binary relation on a finite universe six families of binary relations are obtained and the corresponding six classes of k step neighborhood systems are derived. extensions of pawlak s 1982 rough set approximation operators based on such neighborhood systems are proposed. properties of neighborhood operator systems and rough set approximation operators are investigated and their connections are examined.
inspec,test_36,model predictive control helps to regulate slow processes robust barrel temperature control. slow temperature control is a challenging control problem. the problem becomes even more challenging when multiple zones are involved such as in barrel temperature control for extruders. often strict closed loop performance requirements such as fast startup with no overshoot and maintaining tight temperature control during production are given for such applications. when characteristics of the system are examined it becomes clear that a commonly used proportional plus integral plus derivative pid controller can not meet such performance specifications for this kind of system. the system either will overshoot or not maintain the temperature within the specified range during the production run. in order to achieve the required performance a control strategy that utilizes techniques such as model predictive control autotuning and multiple parameter pid is formulated. this control strategy proves to be very effective in achieving the desired specifications and is very robust.
inspec,test_360,numerical representation of binary relations with a multiplicative error function. this paper studies the case of the representation of a binary relation via a numerical function with threshold error depending on both compared alternatives. the error is considered to be multiplicative its value being either directly or inversely proportional to the values of the numerical function. for the first case it is proved that a binary relation is a semiorder. moreover any semiorder can be represented in this form. in the second case the corresponding binary relation is an interval order.
inspec,test_361,a pretopological approach for structural analysis. the aim of this paper is to present a methodological approach for problems encountered in structural analysis. this approach is based upon the pretopological concepts of pseudoclosure and minimal closed subsets. the advantage of this approach is that it provides a framework which is general enough to model and formulate different types of connections that exist between the elements of a population. in addition it has enabled us to develop a new structural analysis algorithm. an explanation of the definitions and properties of the pretopological concepts applied in this work is first shown and illustrated in sample settings. the structural analysis algorithm is then described and the results obtained in an economic study of the impact of geographic proximity on scientific collaborations are presented.
inspec,test_362,on batch constructing b sup  trees algorithm and its performance evaluation. efficient construction of indexes is very important in bulk loading a database or adding a new index to an existing database since both of them should handle an enormous volume of data. in this paper we propose an algorithm for batch constructing the b sup  tree the most widely used index structure in database systems. the main characteristic of our algorithm is to simultaneously process all the key values to be placed on each b  tree page when accessing the page. this avoids the overhead due to accessing the same page multiple times which results from applying the b  tree insertion algorithm repeatedly. for performance evaluation we have analyzed our algorithm in terms of the number of disk accesses. the results show that the number of disk accesses excluding those in the relocation process is identical to the number of pages belonging to the b sup  tree. considering that the relocation process is an unavoidable preprocessing step for batch constructing of b sup  trees our algorithm requires just one disk access per b  tree page and therefore turns out to be optimal. we also present the performance tendency in relation with different parameter values via simulation. finally we show the performance enhancement effect of our algorithm compared with the one using repeated insertions through experiments.
inspec,test_363,synthetic simultaneity natural and artificial. in control loops each element introduces time delays. if those time delays are larger than the critical times for control of the system a problem exists. i show a simple approach to mitigating this problem by basing the controller s decisions not on the observations themselves but on our projections as to what the observations will be at the time our controls reach the controlled system. finally i argue that synthetic simultaneity explains libet s 1993 results better than libet s explanation.
inspec,test_364,maclp multi agent constraint logic programming. multi agent systems mas have become the key technology for decomposing complex problems in order to solve them more efficiently or for problems distributed in nature. however many industrial applications besides their distributed nature also involve a large number of parameters and constraints i e they are combinatorial. solving such particularly hard problems efficiently requires programming tools that combine mas technology with a programming schema that facilitates the modeling and solution of constraints. this paper presents maclp multi agent constraint logic programming a logic programming platform for building in a declarative way multi agent systems with constraint solving capabilities. maclp extends cspcons a logic programming system that permits distributed program execution through communicating sequential prolog processes with constraints by providing all the necessary facilities for communication between agents. these facilities abstract from the programmer all the low level details of the communication and allow him to focus on the development of the agent itself.
inspec,test_365,self organizing feature maps predicting sea levels. in this paper a new method for predicting sea levels employing self organizing feature maps is introduced. for that purpose the maps are transformed from an unsupervised learning procedure to a supervised one. two concepts originally developed to solve the problems of convergence of other network types are proposed to be applied to kohonen networks a functional relationship between the number of neurons and the number of learning examples and a criterion to break off learning. the latter one can be shown to be conform with the process of self organization by using u matrices for visualization of the learning procedure. the predictions made using these neural models are compared for accuracy with observations and with the prognoses prepared using six models two hydrodynamic models a statistical model a nearest neighbor model the persistence model and the verbal forecasts that are broadcast and kept on record by the sea level forecast service of the federal maritime and hydrography agency bsh in hamburg. before training the maps the meteorological and oceanographic situation has to be condensed as well as possible and the weight and learning vectors have to be made as small as possible. the self organizing feature maps predict sea levels better than all six models of comparison.
inspec,test_366,selecting rail grade crossing investments with a decision support system. the federal railroad administration fra has developed a series of rail and rail related analysis tools that assist fra officials metropolitan planning organizations mpos state department of transportation dot and other constituents in evaluating the cost and benefits of potential infrastructure projects. to meet agency objectives the fra wants to add a high speed rail grade crossing analysis tool to its package of rail and rail related intermodal software products. this paper presents a conceptual decision support system dss that can assist officials in achieving this goal. the paper first introduces the fra s objectives and the role of cost benefit analysis in achieving these objectives. next there is a discussion of the models needed to assess the feasibility of proposed high speed rail grade crossing investments and the presentation of a decision support system dss that can deliver these models transparently to users. then the paper illustrates a system session and examines the potential benefits from system use.
inspec,test_367,a study on meaning processing of dialogue with an example of development of travel consultation system. this paper describes an approach to processing meaning instead of processing information in computing. human intellectual activity is supported by linguistic activities in the brain. therefore processing the meaning of language instead of processing information should allow us to realize human intelligence on a computer. as an example of the proposed framework for processing meaning we build a travel consultation dialogue system which can understand utterance by a user and retrieve information through dialogue. through a simulation example of the system we show that both information processing and language processing are integrated.
inspec,test_368,from a biological to a computational model for the autonomous behavior of an animat. endowing an autonomous system like a robot with intelligent behavior is difficult for several reasons. first behavior is such a wide topic that a general framework paradigm of inspiration must be chosen in order to obtain a consistent model. such a framework can be for example biological modeling or an artificial intelligence approach. second a general framework is not sufficient to determine a fully specified program to be implemented in a robot. many choices tuning and tests must be carried out before obtaining a robust system. a biological model is presented based on the definition of cortex like automata representing elementary functions in the perceptive motor or associative domain. these automata are connected in a network whose architecture functioning and learning rules are described in a cortical framework. second the computational model derived from that biological model is specified. the way units exchange and compute variables through links is explained with reference to corresponding biological elements. it is then easier to report experiments allowing an autonomous system to learn regularities of a simple environment and to exploit them to satisfy some internal drives. even if additional biological hints can be added this model allow us to better understand how a biological model can be implemented and how biological properties can emerge from a distributed set of units.
inspec,test_369,nissan v nissan trademark dispute. is a trademark dispute a case of david v goliath or a corporation fending off a greedy opportunist. this paper discusses the case of uzi nissan who is locked in a multimillion dollar legal battle over whether or not his use of the nissan com internet domain name infringes upon japan s nissan motor co s trademark. at the heart of the matter is the impact of the global internet on trademark law which traditionally has been strongly influenced by geographic considerations. the paper discusses the background to the case from both sides and the issues involved.
inspec,test_37,design pid controllers for desired time domain or frequency domain response. practical requirements on the design of control systems especially process control systems are usually specified in terms of time domain response such as overshoot and rise time or frequency domain response such as resonance peak and stability margin. although numerous methods have been developed for the design of the proportional integral derivative pid controller little work has been done in relation to the quantitative time domain and frequency domain responses. in this paper we study the following problem given a nominal stable process with time delay we design a suboptimal pid controller to achieve the required time domain response or frequency domain response for the nominal system or the uncertain system. an h sub infinity pid controller is developed based on optimal control theory and the parameters are derived analytically. its properties are investigated and compared with that of two developed suboptimal controllers an h sub 2 pid controller and a maclaurin pid controller.
inspec,test_370,virtual borders real laws internet activity and treaties. national governments are working to tame activity on the internet. they have worked steadily to extend control over online activities that they believe affect their interests even when the activities occur outside their borders. these usually involve what governments regard as their domain protecting public order enforcing commercial laws and occasionally protecting consumer interests. methods have included assertions or legal jurisdiction based on where material is accessible instead of where it originates and the blocking of sites service providers or entire high level domains from access by citizens. such instances are mentioned in this article. whilst larger companies are able to defend themselves against overseas lawsuits individuals and smaller organizations lack the resources to defend what are often normal business activities at home but could violate the laws of local jurisdictions in countries around the world. the problems of libel are discussed as are the blocking of certain sites by certain countries. efforts to draw up internet treaties are also mentioned.
inspec,test_371,a better ballot box. election officials are examining technologies to address a wide range of voting issues. the problems observed in the november 2000 us election accelerated existing trends to get rid of lever machines punch cards and hand counted paper ballots and replace them with mark sense balloting internet and automatic teller machine atm kiosk style computer based systems. an estimated us 2  4 billion will be spent in the united states and canada to update voting systems during the next decade. voting online might enable citizens to vote even if they are unable to get to the polls. yet making these methods work right turns out to be considerably more difficult than originally thought. new electronic voting systems pose risks as well as solutions. as it turns out many of the voting products currently for sale provide less accountability poorer reliability and greater opportunity for widespread fraud than those already in use. this paper discusses the technology available and how to ensure accurate ballots.
inspec,test_373,putting pen to screen on tablet pcs. with the release of the first tablet pcs produced to microsoft corp s general specifications handheld computers may be about to leap into the ring with today s laptops. they will be about the size of the smaller laptops will be at least as powerful and maybe their biggest selling point will be able to handle handwritten text. the tablet pcs will be amply configured general purpose machines with more than enough power to run the full blown windows xp operating system. in particular they will allow handwritten text to be entered onto a digitizing tablet and recognized a functionality that s called pen based computing. the tablet pc will far outpace the computing power of existing small devices such as pdas personal digital assistants including those variants based on microsoft s own pocket pc operating system.
inspec,test_374,horizontal waypoint guidance design using optimal control. a horizontal waypoint guidance algorithm is proposed by applying line following guidance to waypoint line segments in sequence. the line following guidance is designed using an lqr linear quadratic regulator. then the optimal waypoint changing points are derived by minimizing the accelerations required for changing the waypoint line segments. also derived is a sufficient condition for the stability bound of ground speed changes based on the lyapunov stability theorem. simulation results show that the proposed algorithm can effectively guide a vehicle along the sequence of waypoint line segments.
inspec,test_375,separation and tracking of multiple broadband sources with one electromagnetic vector sensor. a structure for adaptively separating enhancing and tracking uncorrelated sources with an electromagnetic vector sensor emvs is presented. the structure consists of a set of parallel spatial processors one for each individual source. two stages of processing are involved in each spatial processor. the first preprocessing stage rejects all other sources except the one of interest while the second stage is an adaptive one for maximizing the signal to noise ratio snr and tracking the desired source. the preprocessings are designed using the latest source parameter estimates obtained from the source trackers and a redesign is activated periodically or whenever any source has been detected by the source trackers to have made significant movement. compared with conventional adaptive beamforming the algorithm has the advantage that no a priori information on any desired signal location is needed the sources are separated at maximum snr and their locations are available. the structure is also well suited for parallel implementation. numerical examples are included to illustrate the capability and performance of the algorithm.
inspec,test_376,recursive state estimation for multiple switching models with unknown transition probabilities. this work considers hybrid systems with continuous valued target states and discrete valued regime variable. the changes switches of the regime variable are modeled by a finite state markov chain with unknown and random transition probabilities following dirichlet distributions. our work analytically derives the marginal posterior distribution of the states and regime variables the transition probabilities being integrated out. this leads to a variety of recursive hybrid state estimation schemes which are an appealing intuitive and straightforward extension of standard algorithms. their performance is illustrated by a maneuvering target tracking example.
inspec,test_377,matlab code for plotting ambiguity functions. a matlab code capable of plotting ambiguity functions of many different radar signals is presented. the program makes use of matlab s sparse matrix operations and avoids loops. the program could be useful as a pedagogical tool in radar courses teaching pulse compression.
inspec,test_378,incremental motion control of linear synchronous motor. in this study a particular incremental motion control problem which is specified by the trapezoidal velocity profile using multisegment sliding mode control mssmc is proposed to control a permanent magnet linear synchronous motor pmlsm servo drive system. first the structure and operating principle of the pmlsm are described in detail. second a field oriented control pmlsm servo drive is introduced. then each segment of the multisegment switching surfaces is designed to match the corresponding part of the trapezoidal velocity profile thus the motor dynamics on the specified segment switching surface have the desired velocity or acceleration corresponding part of the trapezoidal velocity profile. in addition the proposed control system is implemented in a pc based computer control system. finally the effectiveness of the proposed pmlsm servo drive system is demonstrated by some simulated and experimental results.
inspec,test_379,feedforward maximum power point tracking of pv systems using fuzzy controller. a feedforward maximum power mp point tracking scheme is developed for the interleaved dual boost idb converter fed photovoltaic pv system using fuzzy controller. the tracking algorithm changes the duty ratio of the converter such that the solar cell array sca voltage equals the voltage corresponding to the mp point at that solar insolation. this is done by the feedforward loop which generates an error signal by comparing the instantaneous array voltage and reference voltage. the reference voltage for the feedforward loop corresponding to the mp point is obtained by an off line trained neural network. experimental data is used for off line training of the neural network which employs back propagation algorithm. the proposed fuzzy feedforward peak power tracking effectiveness is demonstrated through the simulation and experimental results and compared with the conventional proportional plus integral pi controller based system. finally a comparative study of interleaved boost and conventional boost converter for the pv applications is given and their suitability is discussed.
inspec,test_38,a pid standard what why how. the paper is written for all who develop and use p id s. it will aid in solving the long existing and continuing problem of confusing information on p id s. the acronym p id is widely understood to mean the principal document used to define the details of how a process works and how it is controlled. the isa dictionary definition for p id tells what they do  show the interconnection of process equipment and the instrumentation used to control the process. in the process industry a standard set of symbols is used to prepare drawings of processes. the instrument symbols used in these drawings are generally based on isa s5 1. in the paper the isa standard is referred to as isa 5 1. the article develops the concept of the standard and poses some of the questions that the standard can answer.
inspec,test_380,quantitative speed control for srm drive using fuzzy adapted inverse model. quantitative and robust speed control for a switched reluctance motor srm drive is considered to be rather difficult and challenging owing to its highly nonlinear dynamic behavior. a speed control scheme having two degree of freedom 2dof structure is developed here to improve the speed dynamic response of an srm drive. in the proposed control scheme the feedback controller is quantitatively designed to meet the desired regulation control requirements first. then a reference model and a command feedforward controller based on an inverse plant model are employed to yield the desired tracking response at nominal case. as the variations of system parameters and operating conditions occur the prescribed control specifications may not be satisfied any more. to improve this the inverse model is adaptively tuned by a fuzzy control scheme so that the model following tracking error is significantly reduced. in addition a simple disturbance cancellation robust controller is added to improve the tracking and regulation control performances further.
inspec,test_381,robust fuzzy controlled photovoltaic power inverter with taguchi method. this paper presents design and implementation of a robust fuzzy controlled photovoltaic pv power inverter with taguchi tuned scaling factors. to achieve fast transient response small steady state error and system robustness a robust fuzzy controller is adopted in which its input and output scaling factors are determined efficiently by using the taguchi tuning algorithm. the proposed system can operate in different modes grid connection mode and stand alone mode and can accommodate wide load variations. simulation results and hardware measurements obtained from a prototype with a microcontroller intel 80196kc are presented to verify the theoretical discussions and its adaptivity robustness and feasibility.
inspec,test_382,robust wavelet neuro control for linear brushless motors. design simulation and experimental implementation of a wavelet basis function network learning controller for linear brushless dc motors lbdcm are considered. stability robustness with position tracking is the primary concern. the proposed controller deals mainly with external disturbances e g nonlinear friction force and payload variation in motion control of linear motors. it consists of two parts one is a state feedback component and the other one is a learning feedback component. the state feedback controller is designed on the basis of a simple linear model and the learning feedback component is a wavelet neural controller. the attenuation effect of wavelet neural networks on friction force is first verified by the numerical method. the learning effect of wavelet neural networks on friction force is also shown in the numerical results. then a wavelet neural network is applied on a real lbdcm to on line suppress the friction force which may be variable due to the different lubrication. the effectiveness of the proposed control schemes is demonstrated by simulated and experimental results.
inspec,test_383,outlier resistant adaptive matched filtering. robust adaptive matched filtering amf whereby outlier data vectors are censored from the covariance matrix estimate is considered in a maximum likelihood estimation mle setting. it is known that outlier data vectors whose steering vector is highly correlated with the desired steering vector can significantly degrade the performance of amf algorithms such as sample matrix inversion smi or fast maximum likelihood fml. four new algorithms that censor outliers are presented which are derived via approximation to the mle solution. two algorithms each are related to using the smi or the fml to estimate the unknown underlying covariance matrix. results are presented using computer simulations which demonstrate the relative effectiveness of the four algorithms versus each other and also versus the smi and fml algorithms in the presence of outliers and no outliers. it is shown that one of the censoring algorithms called the reiterative censored fast maximum likelihood cfml technique is significantly superior to the other three censoring methods in stressful outlier scenarios.
inspec,test_384,brightness independent start up routine for star trackers. initial attitude acquisition by a modern star tracker is investigated here. criteria for efficient organization of the on board database are discussed with reference to a brightness independent initial acquisition algorithm. star catalog generation preprocessing is described with emphasis on the identification of minimum star brightness for detection by a sensor based on a charge coupled device ccd photodetector. this is a crucial step for proper evaluation of the attainable sky coverage when selecting the stars to be included in the on board catalog. test results are also reported both for reliability and accuracy even if the former is considered to be the primary target. probability of erroneous solution is 0 2 in the case of single runs of the procedure while attitude determination accuracy is in the order of 0 02 degrees in the average for the computation of the inertial pointing of the boresight axis.
inspec,test_385,multiple model adaptive estimation with filter spawning. multiple model adaptive estimation mmae with filter spawning is used to detect and estimate partial actuator failures on the vista f 16. the truth model is a full six degree of freedom simulation provided by calspan and general dynamics. the design models are chosen as 13 state linearized models including first order actuator models. actuator failures are incorporated into the truth model and design model assuming a failure to free stream. filter spawning is used to include additional filters with partial actuator failure hypotheses into the mmae bank. the spawned filters are based on varying degrees of partial failures in terms of effectiveness associated with the complete actuaton failure hypothesis with the highest conditional probability of correctness at the current time. thus a blended estimate of the failure effectiveness is found using the filters estimates based upon a no failure hypothesis a complete actuator failure hypothesis and the spawned filters partial failure hypotheses. this yields substantial precision in effectiveness estimation compared with what is possible without spawning additional filters making partial failure adaptation a viable methodology.
inspec,test_386,matched filter template generation via spatial filtering application to fetal biomagnetic recordings. we have developed a two step procedure for signal processing of fetal biomagnetic recordings that removes cardiac interference and noise. first a modified matched filter mf is applied to remove maternal cardiac interference then a simple signal space projection ssp is applied to remove noise. the key difference between our mf and a conventional one is that the interference template and the template scaling are derived from a signal that has been spatially filtered to isolate the interference rather than from the raw signal. unlike conventional mfs ours is able to separate maternal and fetal cardiac complexes even when they have similar morphology and overlap strongly. when followed by a ssp that preserves only the signal subspace the noise is reduced to a low level.
inspec,test_387,design and implementation of a brain computer interface with high transfer rates. this paper presents a brain computer interface bci that can help users to input phone numbers. the system is based on the steady state visual evoked potential ssvep. twelve buttons illuminated at different rates were displayed on a computer monitor. the buttons constituted a virtual telephone keypad representing the ten digits 0 9 backspace and enter. users could input phone number by gazing at these buttons. the frequency coded ssvep was used to judge which button the user desired. eight of the thirteen subjects succeeded in ringing the mobile phone using the system. the average transfer rate over all subjects was 27 15 bits min. the attractive features of the system are noninvasive signal recording little training required for use and high information transfer rate. approaches to improve the performance of the system are discussed.
inspec,test_388,noninvasive myocardial activation time imaging a novel inverse algorithm applied to clinical ecg mapping data. linear approaches like the minimum norm least square algorithm show insufficient performance when it comes to estimating the activation time map on the surface of the heart from electrocardiographic ecg mapping data. additional regularization has to be considered leading to a nonlinear problem formulation. the gauss newton approach is one of the standard mathematical tools capable of solving this kind of problem. to our experience this algorithm has specific drawbacks which are caused by the applied regularization procedure. in particular under clinical conditions the amount of regularization can not be determined clearly. for this reason we have developed an iterative algorithm solving this nonlinear problem by a sequence of regularized linear problems. at each step of iteration an individual l curve is computed. subsequent iteration steps are performed with the individual optimal regularization parameter. this novel approach is compared with the standard gauss newton approach. both methods are applied to simulated ecg mapping data as well as to single beat sinus rhythm data from two patients recorded in the catheter laboratory. the proposed approach shows excellent numerical and computational performance even under clinical conditions at which the gauss newton approach begins to break down.
inspec,test_389,bayesian nonstationary autoregressive models for biomedical signal analysis. we describe a variational bayesian algorithm for the estimation of a multivariate autoregressive model with time varying coefficients that adapt according to a linear dynamical system. the algorithm allows for time and frequency domain characterization of nonstationary multivariate signals and is especially suited to the analysis of event related data. results are presented on synthetic data and real electroencephalogram data recorded in event related desynchronization and photic synchronization scenarios.
inspec,test_39,supervisory control design based on hybrid systems and fuzzy events detection. application to an oxichlorination reactor. this paper presents a supervisory control scheme based on hybrid systems theory and fuzzy events detection. the fuzzy event detector is a linguistic model which synthesizes complex relations between process variables and process events incorporating experts knowledge about the process operation. this kind of detection allows the anticipation of appropriate control actions which depend upon the selected membership functions used to characterize the process under scrutiny. the proposed supervisory control scheme was successfully implemented for an oxichlorination reactor in a vinyl monomer plant.
inspec,test_390,automated breath detection on long duration signals using feedforward backpropagation artificial neural networks. a new breath detection algorithm is presented intended to automate the analysis of respiratory data acquired during sleep. the algorithm is based on two independent artificial neural networks ann sub insp and ann sub expi that recognize in the original signal windows of interest where the onset of inspiration and expiration occurs. postprocessing consists in finding inside each of these windows of interest minimum and maximum corresponding to each inspiration and expiration. the ann sub insp and ann sub expi correctly determine respectively 98 0 and 98 7 of the desired windows when compared with 29 820 inspirations and 29 819 expirations detected by a human expert obtained from three entire night recordings. postprocessing allowed determination of inspiration and expiration onsets with a mean difference with respect to the same human expert of mean or sd 34 or 71 ms for inspiration and 5 or 46 ms for expiration. the method proved to be effective in detecting the onset of inspiration and expiration in full night continuous recordings. a comparison of five human experts performing the same classification task yielded that the automated algorithm was undifferentiable from these human experts failing within the distribution of human expert results. besides being applicable to adult respiratory volume data the presented algorithm was also successfully applied to infant sleep data consisting of uncalibrated rib cage and abdominal movement recordings. a comparison with two previously published algorithms for breath detection in respiratory volume signal shows that the presented algorithm has a higher specificity while presenting similar or higher positive predictive values.
inspec,test_391,model selection in electromagnetic source analysis with an application to vefs. in electromagnetic source analysis it is necessary to determine how many sources are required to describe the electroencephalogram or magnetoencephalogram adequately. model selection procedures msps or goodness of fit procedures give an estimate of the required number of sources. existing and new msps are evaluated in different source and noise settings two sources which are close or distant and noise which is uncorrelated or correlated. the commonly used msp residual variance is seen to be ineffective that is it often selects too many sources. alternatives like the adjusted hotelling s test bayes information criterion and the wald test on source amplitudes are seen to be effective. the adjusted hotelling s test is recommended if a conservative approach is taken and msps such as bayes information criterion or the wald test on source amplitudes are recommended if a more liberal approach is desirable. the msps are applied to empirical data visual evoked fields.
inspec,test_392,time varying properties of renal autoregulatory mechanisms. in order to assess the possible time varying properties of renal autoregulation time frequency and time scaling methods were applied to renal blood flow under broad band forced arterial blood pressure fluctuations and single nephron renal blood flow with spontaneous oscillations obtained from normotensive sprague dawley wistar and long evans rats and spontaneously hypertensive rats. time frequency analyses of normotensive and hypertensive blood flow data obtained from either the whole kidney or the single nephron show that indeed both the myogenic and tubuloglomerular feedback tgf mechanisms have time varying characteristics. furthermore we utilized the renyi entropy to measure the complexity of blood flow dynamics in the time frequency plane in an effort to discern differences between normotensive and hypertensive recordings. we found a clear difference in renyi entropy between normotensive and hypertensive blood flow recordings at the whole kidney level for both forced p 0 037 and spontaneous arterial pressure fluctuations p 0 033 and at the single nephron level p 0 008. especially at the single nephron level the mean renyi entropy is significantly larger for hypertensive than normotensive rats suggesting more complex dynamics in the hypertensive condition. to further evaluate whether or not the separation of dynamics between normotensive and hypertensive rats is found in the prescribed frequency ranges of the myogenic and tgf mechanisms we employed multiresolution wavelet transform. our analysis revealed that exclusively over scale ranges corresponding to the frequency intervals of the myogenic and tgf mechanisms the widths of the blood flow wavelet coefficients fall into disjoint sets for normotensive and hypertensive rats. the separation of the scales at the myogenic and tgf frequency ranges is distinct and obtained with 100 accuracy. however this observation remains valid only for the whole kidney blood pressure flow data. the results suggest that understanding of the time varying properties of the two mechanisms is required for a complete description of renal autoregulation.
inspec,test_393,the use of the spsa method in ecg analysis. the classification monitoring and compression of electrocardiogram ecg signals recorded of a single patient over a relatively long period of time is considered. the particular application we have in mind is high resolution ecg analysis such as late potential analysis morphology changes in qrs during arrythmias t wave alternants or the study of drug effects on ventricular activation. we propose to apply a modification of a classical method of cluster analysis or vector quantization. the novelty of our approach is that we use a new distortion measure to quantify the distance of two ecg cycles and the class distortion measure is defined using a min max criterion. the new class distortion measure is much more sensitive to outliers than the usual distortion measures using average distance. the price of this practical advantage is that computational complexity is significantly increased. the resulting nonsmooth optimization problem is solved by an adapted version of the simultaneous perturbation stochastic approximation spsa method of j spall ieee trans. automat. contr vol. 37 p 332 41 mar 1992. the main idea is to generate a smooth approximation by a randomization procedure. the viability of the method is demonstrated on both simulated and real data. an experimental comparison with the widely used correlation method is given on real data.
inspec,test_394,model intestinal microflora in computer simulation a simulation and modeling package for host microflora interactions. the ecology of the human intestinal microflora and its interaction with the host are poorly understood. though more and more data are being acquired in part using modern molecular methods development of a quantitative theory has not kept pace with this increase in observing power. this is in part due to the complexity of the system and to the lack of simulation environments in which to test what the ecological effect of a hypothetical mechanism of interaction would be before resorting to laboratory experiments. the mimics project attempts to address this through the development of a cellular automaton for simulation of the intestinal microflora. in this paper the design and evaluation of this simulator is discussed.
inspec,test_395,conformal mapping design tools for coaxial couplers with complex cross section. numerical conformal mapping is exploited as a simple accurate and efficient tool for the analysis and design of coaxial waveguides and couplers of complex cross section. an implementation based on the schwarz christoffel toolbox a public domain matlab package is applied to slotted coaxial cables and to symmetrical coaxial couplers with circular or polygonal inner conductors and external shields. the effect of metallic diaphragms of arbitrary thickness partially separating the inner conductors is also easily taken into account. the proposed technique is validated against the results of the finite element method showing excellent agreement at a fraction of the computational cost and is also extended to the case of nonsymmetrical couplers providing the designer with important additional degrees of freedom.
inspec,test_396,convolution based global simulation technique for millimeter wave photodetector and photomixer circuits. a fast convolution based time domain approach to global photonic circuit simulation is presented that incorporates a physical device model in the complete detector or mixer circuit. the device used in the demonstration of this technique is a gaas metal semiconductor metal msm photodetector that offers a high response speed for the detection and generation of millimeter waves. global simulation greatly increases the accuracy in evaluating the complete circuit performance because it accounts for the effects of the millimeter wave embedding circuit. device and circuit performance are assessed by calculating optical responsivity and bandwidth. device only simulations using gaas msms are compared with global simulations that illustrate the strong interdependence between device and external circuit.
inspec,test_397,accurate modeling of lossy nonuniform transmission lines by using differential quadrature methods. this paper discusses an efficient numerical approximation technique called the differential quadrature method dqm which has been adapted to model lossy uniform and nonuniform transmission lines. the dqm can quickly compute the derivative of a function at any point within its bounded domain by estimating a weighted linear sum of values of the function at a small set of points belonging to the domain. using the dqm the frequency domain telegrapher s partial differential equations for transmission lines can be discretized into a set of easily solvable algebraic equations. dqm reduces interconnects into multiport models whose port voltages and currents are related by rational formulas in the frequency domain. although the rationalization process in dqm is comparable with the pade approximation of asymptotic waveform evaluation awe applied to transmission lines the derivation mechanisms in these two disparate methods are significantly different. unlike awe which employs a complex moment matching process to obtain rational approximation the dqm requires no approximation of transcendental functions thereby avoiding the process of moment generation and moment matching. due to global sampling of points in the dqm approximation it requires far fewer grid points in order to build accurate discrete models than other numerical methods do. the dqm based time domain model can be readily integrated in a circuit simulator like spice.
inspec,test_398,an unconditionally stable extended use finite element time domain solution of active nonlinear microwave circuits using perfectly matched layers. this paper proposes an extension of the unconditionally stable finite element time domain fetd method for the global electromagnetic analysis of active microwave circuits. this formulation has two advantages. first the time step size is no longer governed by the spatial discretization of the mesh but rather by the nyquist sampling criterion. second the implementation of the truncation by the perfectly matched layers pml is straightforward. an anisotropic pml absorbing material is presented for the truncation of fetd lattices. reflection less than 50 db is obtained numerically over the entire propagation bandwidth in waveguide and microstrip line. a benchmark test on a microwave amplifier indicates that this extended fetd algorithm is not only superior to finite difference time domain based algorithm in mesh flexibility and simulation accuracy but also reduces computation time dramatically.
inspec,test_399,low voltage dram sensing scheme with offset cancellation sense amplifier. a novel bitline sensing scheme is proposed for low voltage dram to achieve low power dissipation and compatibility with low voltage cmos. one of the major obstacles in low voltage dram is the degradation of data retention time due to low signal level at the memory cell which requires power consuming refresh operations more frequently. this paper proposes an offset cancellation sense amplifier scheme ocsa that improves data retention time significantly even at low supply voltage. it also improves die efficiency because the proposed scheme reduces the number of sense amplifiers by supporting more cells in each sense amplifier. measurements show that the data retention time of the proposed scheme at 1 5 v supply voltage is 2 4 times of the conventional scheme at 2 0 v.
inspec,test_4,industry insiders loading up on cheap company stock. a surge of telecom executives and directors purchasing their own companies stock in the last two months points toward a renewed optimism in the beleaguered sector say some observers who view the rash of insider buying as a vote of confidence from management. airgate pcs charter communications cox communications crown castle international nextel communications and nortel networks all have seen infusions of insider investment this summer echoing trends in both the telecom industry and the national economy.
inspec,test_40,new tuning method for pid controller. in this paper a tuning method for proportional integral derivative pid controller and the performance assessment formulas for this method are proposed. this tuning method is based on a genetic algorithm based pid controller design method. for deriving the tuning formula the genetic algorithm based design method is applied to design pid controllers for a variety of processes. the relationship between the controller parameters and the parameters that characterize the process dynamics are determined and the tuning formula is then derived. using simulation studies the rules for assessing the performance of a pid controller tuned by the proposed method are also given. this makes it possible to incorporate the capability to determine if the pid controller is well tuned or not into an autotuner. an autotuner based on this new tuning method and the corresponding performance assessment rules is also established. simulations and real time experimental results are given to demonstrate the effectiveness and usefulness of these formulas.
inspec,test_400,a 120 mw 3 d rendering engine with 6 mb embedded dram and 3 2 gb s runtime reconfigurable bus for pda chip. a low power three dimensional 3 d rendering engine is implemented as part of a mobile personal digital assistant pda chip. six megabit embedded dram macros attached to 8 pixel parallel rendering logic are logically localized with a 3 2 gb s runtime reconfigurable bus reducing the area by 25 compared with conventional local frame buffer architectures. the low power consumption is achieved by polygon dependent access to the embedded dram macros with line block mapping providing read modify write data transaction. the 3 d rendering engine with 2 22 mpolygons s drawing speed was fabricated using 0 18 mu m cmos embedded memory logic technology. its area is 24 mm sup 2 and its power consumption is 120 mw.
inspec,test_401,a digital to analog converter based on differential quad switching. a high conversion rate high resolution oversampling digital to analog converter dac for direct digital modulation is addressed in this paper. a new type of switching scheme called differential quad switching is presented. to verify the feasibility of this scheme essential parts with some auxiliary circuitry for interfacing were fabricated in a 0 8 mu m cmos technology. measured results show that the switching scheme provides 11 b resolution at 100 msamples s and 6 b at 1 gsamples s. the degradation in signal to noise ratio is not observed for the variation of the supply voltage down to 1 5 v which means the proposed scheme is suitable for low voltage applications.
inspec,test_402,fast frequency acquisition phase frequency detectors for gsamples s phase locked loops. this paper describes two techniques for designing phase frequency detectors pfds with higher operating frequencies periods of less than 8 the delay of a fan out 4 inverter fo 4 and faster frequency acquisition. prototypes designed in 0 25 mu m cmos process exhibit operating frequencies of 1 25 ghz 1 8 fo 4 and 1 5 ghz 1 6 7 fo 4 for two techniques respectively whereas a conventional pfd operates at 1 ghz 1 10 fo 4. the two proposed pfds achieve a capture range of 1 7 and 1 4 the conventional design respectively.
inspec,test_403,high voltage transistor scaling circuit techniques for high density negative gate channel erasing nor flash memories. in order to scale high voltage transistors for high density negative gate channel erasing nor flash memories two circuit techniques were developed. a proposed level shifter with low operating voltage is composed of three parts a latch holding the negative erasing voltage two coupling capacitors connected with the latched nodes in the latch and high voltage drivers inverting the latch resulting in reduction of the maximum internal voltage by 0 5 v. a proposed high voltage generator adds a path gate logic to a conventional high voltage generator to realize both low noise and low ripple voltage resulting in a reduction of the maximum internal voltage by 0 5 v. as a result these circuit techniques along with high coupling ratio cell technology can scale down the high voltage transistors by 15 and can realize higher density negative gate channel erase nor flash memories in comparison with the source erase nor flash memories.
inspec,test_404,a 0 8 v 128 kb four way set associative two level cmos cache memory using two stage wordline bitline oriented tag compare wlotc blotc scheme. this paper reports a 0 8 v 128 kb four way set associative two level cmos cache memory using a novel two stage wordline bitline oriented tag compare wlotc blotc and sense wordline bitline swl sbl tag sense amplifiers with an eight transistor 8 t tag cell in level 2 l2 and a 10 t shrunk logic swing sls memory cell. with the ground floating g f data sense amplifier in level 1 l1 for high speed operation for low voltage low power vlsi system applications. owing to the reduced loading at the swl in the new 11 t tag cell using the wlotc scheme the 10 t sls memory cell with g f sense amplifier in l1 and the split comparison of the index signal in the 8 t tag cells with swl sbl tag sense amplifiers in l2 this 0 8 v cache memory implemented in a 1 8 v 0 18 mu m cmos technology has a measured l1 l2 hit time of 11 6 20 5 ns at the average dissipation of 0 77 mw at 50 mhz.
inspec,test_405,learning spatial relations using an inductive logic programming system. the ability to learn spatial relations is a prerequisite for performing many relevant tasks such as those associated with motion orientation navigation etc. this paper reports on using an inductive logic programming ilp system for learning function free horn clause descriptions of spatial knowledge. its main contribution however is to show that an existing relation between two reference systems the speaker relative and the absolute can be automatically learned by an ilp system given the proper background knowledge and positive examples.
inspec,test_406,windows xp fast user switching. the windows nt family of operating systems has always supported the concept of multiple user accounts but they ve taken the concept a step further with windows xp s fast user switching feature. fast user switching is a new feature of windows xp that allows multiple users to log on to the same machine and quickly switch between the logged on accounts. fast user switching is implemented using some of the built in capabilities of terminal services. terminal server has been around for a while but is much more feature rich and integrated in windows xp. a machine with the terminal services remote desktop client can log on to and run applications on a remote machine running the terminal server.
inspec,test_407,generating code at run time with reflection emit. the. net framework sdk includes several tools that convert source code into executable code the c and vb net compilers get most of the attention but there are others. the regex class in the system text regularexpressions namespace has the ability to compile favorite regular expressions into a. net assembly. in fact the net common language runtime clr contains a whole namespace full of classes to help us build assemblies define types and emit their implementations all at run time. these classes which comprise the system reflection emit namespace are known collectively as reflection. emit.
inspec,test_408,. net obfuscation and intellectual property. the author considers obfuscation options for protecting. net code. many programs wo n t need obfuscation because the loss caused by reverse engineering will be nonexistent. numerous obfuscators are already available for the. net platform ranging from a basic renaming obfuscator to a fully functional obfuscator that handles mixed il native code assemblies created in any managed language including microsoft s c with managed extensions. an obfuscator simply makes your application harder to reverse engineer. it does not prevent reverse engineering. however the cost of obfuscation is insignificant when compared to the cost of a typical software development project. if you feel like an obfuscator provides you any benefit at all it s probably worth the price.
inspec,test_41,controller performance analysis with lqg benchmark obtained under closed loop conditions. this paper proposes a new method for obtaining a linear quadratic gaussian lqg benchmark in terms of the variances of process input and output from closed loop data for assessing the controller performance. lqg benchmark has been proposed in the literature to assess controller performance since the lqg tradeoff curve represents the limit of performance in terms of input and output variances. however an explicit parametric model is required to calculate the lqg benchmark. in this work we propose a data driven subspace approach to calculate the lqg benchmark under closed loop conditions with certain external excitations. the optimal lqg benchmark variances are obtained directly from the subspace matrices corresponding to the deterministic inputs and the stochastic inputs which are identified using closed loop data with setpoint excitation. these variances are used for assessing the controller performance. the method proposed in this paper is applicable to both univariate and multivariate systems. profit analysis for the implementation of feedforward control to the existing feedback only control system is also analyzed under the optimal lqg performance framework.
inspec,test_410,lossy spice models produce realistic averaged simulations. in previous averaged models the state space averaging technique or switch waveforms analysis were usually applied over perfect elements non inclusive of the ohmic losses. however if these elements play an active role in the dc transfer function they affect the small signal ac analysis by introducing various damping effects. a model is introduced in a boost voltage mode application.
inspec,test_411,cad cae software aids converter design dc dc power conversion. typically power supply design involves electronic and magnetic components. in this paper the authors describe using a flyback converter example how cad cae tools can aid the power supply engineer in both areas reducing prototyping costs and providing insights into system performance.
inspec,test_412,using virtual reality to teach disability awareness. a desktop virtual reality vr program was designed and evaluated to teach children about the accessibility and attitudinal barriers encountered by their peers with mobility impairments. within this software children sitting in a virtual wheelchair experience obstacles such as stairs narrow doors objects too high to reach and attitudinal barriers such as inappropriate comments. using a collaborative research methodology 15 youth with mobility impairments assisted in developing and beta testing the software. the effectiveness of the program was then evaluated with 60 children in grades 4 6 using a controlled pretest posttest design. the results indicated that the program was effective for increasing children s knowledge of accessibility barriers. attitudes grade level familiarity with individuals with a disability and gender were also investigated.
inspec,test_413,effects of white space in learning via the web. this study measured the effect of specific white space features on learning from instructional web materials. the study also measured learners beliefs regarding web based instruction. prior research indicated that small changes in the handling of presentation elements can affect learning. achievement results from this study indicated that in on line materials when content and overall structure are sound minor differences regarding table borders and vertical spacing in text do not hinder learning. beliefs regarding web based instruction and instructors who use it did not differ significantly between treatment groups. implications of the study and cautions regarding generalizing from the results are discussed.
inspec,test_414,the efficacy of electronic telecommunications in fostering interpersonal relationships. the effectiveness of electronic telecommunications as a supplementary aid to instruction and as a communication link between students and between students and instructors in fostering interpersonal relationships was explored in this study. more specifically the impacts of e mail one of the most accessible convenient and easy to use computer mediated communications on student attitudes toward the instructor group mates and other classmates were investigated. a posttest only experimental design was adopted. in total 68 prospective teachers enrolling in a computers in education course participated in the study for a whole semester. results from the study provided substantial evidence supporting e mail s beneficial effects on student attitudes toward the instructor and other classmates.
semeval,test_C_1,scalable grid service discovery based on uddi. efficient discovery of grid services is essential for the success of grid computing. the standardization of grids based on web services has resulted in the need for scalable web service discovery mechanisms to be deployed in grids even though uddi has been the de facto industry standard for web services discovery imposed requirements of tight replication among registries and lack of autonomous control has severely hindered its widespread deployment and usage. with the advent of grid computing the scalability issue of uddi will become a roadblock that will prevent its deployment in grids. in this paper we present our distributed web service discovery architecture called dude distributed uddi deployment engine. dude leverages dht distributed hash tables as a rendezvous mechanism between multiple uddi registries. dude enables consumers to query multiple registries still at the same time allowing organizations to have autonomous control over their registries.. based on preliminary prototype on planetlab we believe that dude architecture can support effective distribution of uddi registries thereby making uddi more robust and also addressing its scaling issues. furthermore the dude architecture for scalable distribution can be applied beyond uddi to any grid service discovery mechanism.
semeval,test_C_14,sensor deployment strategy for target detection. in order to monitor a region for traffic traversal sensors can be deployed to perform collaborative target detection. such a sensor network achieves a certain level of detection performance with an associated cost of deployment. this paper addresses this problem by proposing path exposure as a measure of the goodness of a deployment and presents an approach for sequential deployment in steps. it illustrates that the cost of deployment can be minimized to achieve the desired detection performance by appropriately choosing the number of sensors deployed in each step.
semeval,test_C_17,deployment issues of a voip conferencing system in a virtual conferencing environment. real time services have been supported by and large on circuitswitched networks. recent trends favour services ported on packet switched networks. for audio conferencing we need to consider many issues scalability quality of the conference application floor control and load on the clients servers to name a few. in this paper we describe an audio service framework designed to provide a virtual conferencing environment vce. the system is designed to accommodate a large number of end users speaking at the same time and spread across the internet. the framework is based on conference servers 14 which facilitate the audio handling while we exploit the sip capabilities for signaling purposes. client selection is based on a recent quantifier called loudness number that helps mimic a physical face to face conference. we deal with deployment issues of the proposed solution both in terms of scalability and interactivity while explaining the techniques we use to reduce the traffic. we have implemented a conference server cs application on a campus wide network at our institute.
semeval,test_C_18,an initial analysis and presentation of malware exhibiting swarm like behavior. the slammer which is currently the fastest computer worm in recorded history was observed to infect 90 percent of all vulnerable internets hosts within 10 minutes. although the main action that the slammer worm takes is a relatively unsophisticated replication of itself it still spreads so quickly that human response was ineffective. most proposed countermeasures strategies are based primarily on rate detection and limiting algorithms. however such strategies are being designed and developed to effectively contain worms whose behaviors are similar to that of slammer. in our work we put forth the hypothesis that next generation worms will be radically different and potentially such techniques will prove ineffective. specifically we propose to study a new generation of worms called swarm worms  whose behavior is predicated on the concept of emergent intelligence. emergent intelligence is the behavior of systems very much like biological systems such as ants or bees where simple local interactions of autonomous members with simple primitive actions gives rise to complex and intelligent global behavior. in this manuscript we will introduce the basic principles behind the idea of swarm worms  as well as the basic structure required in order to be considered a swarm worm. in addition we will present preliminary results on the propagation speeds of one such swarm worm called the zachik worm. we will show that zachik is capable of propagating at a rate 2 orders of magnitude faster than similar worms without swarm capabilities.
semeval,test_C_19,service interface a new abstraction for implementing and composing protocols. in this paper we compare two approaches to the design of protocol frameworks tools for implementing modular network protocols. the most common approach uses events as the main abstraction for a local interaction between protocol modules. we argue that an alternative approach that is based on service abstraction is more suitable for expressing modular protocols. it also facilitates advanced features in the design of protocols such as dynamic update of distributed protocols. we then describe an experimental implementation of a service based protocol framework in java.
semeval,test_C_20,live data center migration across wans a robust cooperative context aware approach. a significant concern for internet based service providers is the continued operation and availability of services in the face of outages whether planned or unplanned. in this paper we advocate a cooperative context aware approach to data center migration across wans to deal with outages in a non disruptive manner. we specifically seek to achieve high availability of data center services in the face of both planned and unanticipated outages of data center facilities. we make use of server virtualization technologies to enable the replication and migration of server functions. we propose new network functions to enable server migration and replication across wide area networks e g the internet and finally show the utility of intelligent and dynamic storage replication technology to ensure applications have access to data in the face of outages with very tight recovery point objectives.
semeval,test_C_22,runtime metrics collection for middleware supported adaptation of mobile applications. this paper proposes implements and evaluates in terms of worst case performance an online metrics collection strategy to facilitate application adaptation via object mobility using a mobile object framework and supporting middleware. the solution is based upon an abstract representation of the mobile object system which holds containers aggregating metrics for each specific component including host managers runtimes and mobile objects. a key feature of the solution is the specification of multiple configurable criteria to control the measurement and propagation of metrics through the system. the mobjex platform was used as the basis for implementation and testing with a number of laboratory tests conducted to measure scalability efficiency and the application of simple measurement and propagation criteria to reduce collection overhead.
semeval,test_C_23,implementation of a dynamic adjustment mechanism with efficient replica selection in data grid environments. the co allocation architecture was developed in order to enable parallel downloading of datasets from multiple servers. several co allocation strategies have been coupled and used to exploit rate differences among various client server links and to address dynamic rate fluctuations by dividing files into multiple blocks of equal sizes. however a major obstacle the idle time of faster servers having to wait for the slowest server to deliver the final block makes it important to reduce differences in finishing time among replica servers. in this paper we propose a dynamic coallocation scheme namely recursive adjustment co allocation scheme to improve the performance of data transfer in data grids. our approach reduces the idle time spent waiting for the slowest server and decreases data transfer completion time. we also provide an effective scheme for reducing the cost of reassembling data blocks.
semeval,test_C_27,a high accuracy low cost localization system for wireless sensor networks. the problem of localization of wireless sensor nodes has long been regarded as very difficult to solve when considering the realities of real world environments. in this paper we formally describe design implement and evaluate a novel localization system called spotlight. our system uses the spatio temporal properties of well controlled events in the network e g light to obtain the locations of sensor nodes. we demonstrate that a high accuracy in localization can be achieved without the aid of expensive hardware on the sensor nodes as required by other localization systems. we evaluate the performance of our system in deployments of mica2 and xsm motes. through performance evaluations of a real system deployed outdoors we obtain a 20cm localization error. a sensor network with any number of nodes deployed in a 2500m2 area can be localized in under 10 minutes using a device that costs less than 1000. to the best of our knowledge this is the first report of a sub meter localization error obtained in an outdoor environment without equipping the wireless sensor nodes with specialized ranging hardware.
semeval,test_C_28,packageblast an adaptive multi policy grid service for biological sequence comparison. in this paper we propose an adaptive task allocation framework to perform blast searches in a grid environment against sequence database segments. the framework called packageblast provides an infrastructure to choose or incorporate task allocation strategies. furthermore we propose a mechanism to compute grid nodes execution weight adapting the chosen allocation policy to the current computational power of the nodes. our results present very good speedups and also show that no single allocation strategy is able to achieve the lowest execution times for all scenarios.
semeval,test_C_29,implementation and performance evaluation of conflex g grid enabled molecular conformational space search program with omnirpc. conflex g is the grid enabled version of a molecular conformational space search program called conflex. we have implemented conflex g using a grid rpc system called omnirpc. in this paper we report the performance of conflex g in a grid testbed of several geographically distributed pc clusters. in order to explore many conformation of large bio molecules conflex g generates trial structures of the molecules and allocates jobs to optimize a trial structure with a reliable molecular mechanics method in the grid. omnirpc provides a restricted persistence model to support the parametric search applications. in this model when the initialization procedure is defined in the rpc module the module is automatically initialized at the time of invocation by calling the initialization procedure. this can eliminate unnecessary communication and initialization at each call in conflex g. conflexg can achieve performance comparable to conflex mpi and can exploit more computing resources by allowing the use of a cluster of multiple clusters in the grid. the experimental result shows that conflex g achieved a speedup of 56 5 times in the case of the 1bl1 molecule where the molecule consists of a large number of atoms and each trial structure optimization requires significant time. the load imbalance of the optimization time of the trial structure may also cause performance degradation.
semeval,test_C_3,self adaptive applications on the grid. grids are inherently heterogeneous and dynamic. one important problem in grid computing is resource selection that is finding an appropriate resource set for the application. another problem is adaptation to the changing characteristics of the grid environment. existing solutions to these two problems require that a performance model for an application is known. however constructing such models is a complex task. in this paper we investigate an approach that does not require performance models. we start an application on any set of resources. during the application run we periodically collect the statistics about the application run and deduce application requirements from these statistics. then we adjust the resource set to better fit the application needs. this approach allows us to avoid performance bottlenecks such as overloaded wan links or very slow processors and therefore can yield significant performance improvements. we evaluate our approach in a number of scenarios typical for the grid.
semeval,test_C_30,bullet high bandwidth data dissemination using an overlay mesh. in recent years overlay networks have become an effective alternative to ip multicast for efficient point to multipoint communication across the internet. typically nodes self organize with the goal of forming an efficient overlay tree one that meets performance targets without placing undue burden on the underlying network. in this paper we target high bandwidth data distribution from a single source to a large number of receivers. applications include large file transfers and real time multimedia streaming. for these applications we argue that an overlay mesh rather than a tree can deliver fundamentally higher bandwidth and reliability relative to typical tree structures. this paper presents bullet a scalable and distributed algorithm that enables nodes spread across the internet to self organize into a high bandwidth overlay mesh. we construct bullet around the insight that data should be distributed in a disjoint manner to strategic points in the network. individual bullet receivers are then responsible for locating and retrieving the data from multiple points in parallel. key contributions of this work include i an algorithm that sends data to different points in the overlay such that any data object is equally likely to appear at any node ii a scalable and decentralized algorithm that allows nodes to locate and recover missing data items and iii a complete implementation and evaluation of bullet running across the internet and in a large scale emulation environment reveals up to a factor two bandwidth improvements under a variety of circumstances. in addition we find that relative to tree based solutions bullet reduces the need to perform expensive bandwidth probing. in a tree it is critical that a node s parent delivers a high rate of application data to each child. in bullet however nodes simultaneously receive data from multiple sources in parallel making it less important to locate any single source capable of sustaining a high transmission rate.
semeval,test_C_31,apocrita a distributed peer to peer file sharing system for intranets. many organizations are required to author documents for various purposes and such documents may need to be accessible by all member of the organization. this access may be needed for editing or simply viewing a document. in some cases these documents are shared between authors via email to be edited. this can easily cause incorrect version to be sent or conflicts created between multiple users trying to make amendments to a document. there may even be multiple different documents in the process of being edited. the user may be required to search for a particular document which some search tools such as google desktop may be a solution for local documents but will not find a document on another user s machine. another problem arises when a document is made available on a user s machine and that user is offline in which case the document is no longer accessible. in this paper we present apocrita a revolutionary distributed p2p file sharing system for intranets.
semeval,test_C_32,buddycache high performance object storage for collaborative strong consistency applications in a wan. collaborative applications provide a shared work environment for groups of networked clients collaborating on a common task. they require strong consistency for shared persistent data and efficient access to fine grained objects. these properties are difficult to provide in wide area networks because of high network latency. buddycache is a new transactional caching approach that improves the latency of access to shared persistent objects for collaborative strong consistency applications in high latency network environments. the challenge is to improve performance while providing the correctness and availability properties of a transactional caching protocol in the presence of node failures and slow peers. we have implemented a buddycache prototype and evaluated its performance. analytical results confirmed by measurements of the buddycache prototype using the multiuser 007 benchmark indicate that for typical internet latencies e g ranging from 40 to 80 milliseconds round trip time to the storage server peers using buddycache can reduce by up to 50 the latency of access to shared objects compared to accessing the remote servers directly.
semeval,test_C_33,rewards based negotiation for providing context information. how to provide appropriate context information is a challenging problem in context aware computing. most existing approaches use a centralized selection mechanism to decide which context information is appropriate. in this paper we propose a novel approach based on negotiation with rewards to solving such problem. distributed context providers negotiate with each other to decide who can provide context and how they allocate proceeds. in order to support our approach we have designed a concrete negotiation model with rewards. we also evaluate our approach and show that it indeed can choose an appropriate context provider and allocate the proceeds fairly.
semeval,test_C_34,researches on scheme of pairwise key establishment for distributed sensor networks. security schemes of pairwise key establishment which enable sensors to communicate with each other securely play a fundamental role in research on security issue in wireless sensor networks. a new kind of cluster deployed sensor networks distribution model is presented and based on which an innovative hierarchical hypercube model h k u m v n and the mapping relationship between cluster deployed sensor networks and the h k u m v n are proposed. by utilizing nice properties of h k u m v n model a new general framework for pairwise key predistribution and a new pairwise key establishment algorithm are designed which combines the idea of kdc key distribution center and polynomial pool schemes. furthermore the working performance of the newly proposed pairwise key establishment algorithm is seriously inspected. theoretic analysis and experimental figures show that the new algorithm has better performance and provides higher possibilities for sensor to establish pairwise key compared with previous related works.
semeval,test_C_36,encryption enforced access control in dynamic multi domain publish subscribe networks. publish subscribe systems provide an efficient event based wide area distributed communications infrastructure. large scale publish subscribe systems are likely to employ components of the event transport network owned by cooperating but independent organisations. as the number of participants in the network increases security becomes an increasing concern. this paper extends previous work to present and evaluate a secure multi domain publish subscribe infrastructure that supports and enforces fine grained access control over the individual attributes of event types. key refresh allows us to ensure forward and backward security when event brokers join and leave the network. we demonstrate that the time and space overheads can be minimised by careful consideration of encryption techniques and by the use of caching to decrease unnecessary decryptions. we show that our approach has a smaller overall communication overhead than existing approaches for achieving the same degree of control over security in publish subscribe networks.
semeval,test_C_38,a framework for architecting peer to peer receiver driven overlays. this paper presents a simple and scalable framework for architecting peer to peer overlays called peer to peer receiverdriven overlay or pro. pro is designed for non interactive streaming applications and its primary design goal is to maximize delivered bandwidth and thus delivered quality to peers with heterogeneous and asymmetric bandwidth. to achieve this goal pro adopts a receiver driven approach where each receiver or participating peer i independently discovers other peers in the overlay through gossiping and ii selfishly determines the best subset of parent peers through which to connect to the overlay to maximize its own delivered bandwidth. participating peers form an unstructured overlay which is inherently robust to high churn rate. furthermore each receiver leverages congestion controlled bandwidth from its parents as implicit signal to detect and react to long term changes in network or overlay condition without any explicit coordination with other participating peers. independent parent selection by individual peers dynamically converge to an efficient overlay structure.
semeval,test_C_4,intra flow loss recovery and control for. best effort packet switched networks like the internet do not offer a reliable transmission of packets to applications with real time constraints such voice. thus the loss of packets impairs the application level utility. for voice this utility impairment is twofold on one hand even short bursts of lost packets may decrease significantly the ability of the receiver to conceal the packet loss and the speech signal out is interrupted. on the other hand some packets may be particular sensitive to loss as they carry more important information in terms of user perception than other packets. we first develop an end to end model based on loss lengths with which we can describe the loss distribution within a these packet level metrics are then linked to user level objective speech quality metrics. using this framework we find that for low compressing sample based codecs pcm with loss concealment isolated packet losses can be concealed well whereas burst losses have a higher perceptual impact. for high compressing frame based codecs g 729 on one hand the impact of loss is amplified through error propagation caused by the decoder filter memories though on the other hand such coding schemes help to perform loss concealment by extrapolation of decoder state. contrary to sample based codecs we show that the concealment performance may break at transitions within the speech signal however. we then propose mechanisms which differentiate between packets within a voice data to minimize the impact of packet loss. we designate these methods as loss recovery and control. at the end to end level identification of packets sensitive to loss sender as well as loss concealment receiver takes place. hop by hop support schemes then allow to statistically trade the loss of one packet which is considered more important against another one of the same flow which is of lower importance. as both. ets require the same cost in terms of network transmission a gain in user perception is obtainable. we show that significant speech quality improvements can be achieved and additional data and delay overhead can be avoided while still maintaining a network service which is virtually identical to best effort in the long term.
semeval,test_C_40,edge indexing in a grid for highly dynamic virtual environments. newly emerging game based application systems such as second life1 provide 3d virtual environments where multiple users interact with each other in real time. they are filled with autonomous mutable virtual content which is continuously augmented by the users. to make the systems highly scalable and dynamically extensible they are usually built on a client server based grid subspace division where the virtual worlds are partitioned into manageable sub worlds. in each sub world the user continuously receives relevant geometry updates of moving objects from remotely connected servers and renders them according to her viewpoint rather than retrieving them from a local storage medium. in such systems the determination of the set of objects that are visible from a user s viewpoint is one of the primary factors that affect server throughput and scalability. specifically performing real time visibility tests in extremely dynamic virtual environments is a very challenging task as millions of objects and sub millions of active users are moving and interacting. we recognize that the described challenges are closely related to a spatial database problem and hence we map the moving geometry objects in the virtual space to a set of multi dimensional objects in a spatial database while modeling each avatar both as a spatial object and a moving query. unfortunately existing spatial indexing methods are unsuitable for this kind of new environments. the main goal of this paper is to present an efficient spatial index structure that minimizes unexpected object popping and supports highly scalable real time visibility determination. we then uncover many useful properties of this structure and compare the index structure with various spatial indexing methods in terms of query quality system throughput and resource utilization. we expect our approach to lay the groundwork for next generation virtual frameworks that may merge into existing web based services in the near future. this research has been funded in part by nsf grants eec9529152 imsc erc and iis 0534761 and equipment gifts from intel corporation hewlett packard sun microsystems and raptor networks technology.
semeval,test_C_6,design and implementation of a distributed content management system. the convergence of advances in storage encoding and networking technologies has brought us to an environment where huge amounts of continuous media content is routinely stored and exchanged between network enabled devices. keeping track of or managing such content remains challenging due to the sheer volume of data. storing live continuous media such as tv or radio content adds to the complexity in that this content has no well defined start or end and is therefore cumbersome to deal with. networked storage allows content that is logically viewed as part of the same collection to in fact be distributed across a network making the task of content management all but impossible to deal with without a content management system. in this paper we present the design and implementation of the spectrum content management system which deals with rich media content effectively in this environment. spectrum has a modular architecture that allows its application to both stand alone and various networked scenarios. a unique aspect of spectrum is that it requires one or more retention policies to apply to every piece of content that is stored in the system. this means that there are no eviction policies. content that no longer has a retention policy applied to it is simply removed from the system. different retention policies can easily be applied to the same content thus naturally facilitating sharing without duplication. this approach also allows spectrum to easily apply time based policies which are basic building blocks required to deal with the storage of live continuous media to content. we not only describe the details of the spectrum architecture but also give typical use cases.
semeval,test_C_8,operation context and context based operational transformation. operational transformation ot is a technique for consistency maintenance and group undo and is being applied to an increasing number of collaborative applications. the theoretical foundation for ot is crucial in determining its capability to solve existing and new problems as well as the quality of those solutions. the theory of causality has been the foundation of all prior ot systems but it is inadequate to capture essential correctness requirements. past research had invented various patches to work around this problem resulting in increasingly intricate and complicated ot algorithms. after having designed implemented and experimented with a series of ot algorithms we reflected on what had been learned and set out to develop a new theoretical framework for better understanding and resolving ot problems reducing its complexity and supporting its continual evolution. in this paper we report the main results of this effort the theory of operation context and the cot context based ot algorithm. the cot algorithm is capable of supporting both do and undo of any operations at anytime without requiring transformation functions to preserve reversibility property convergence property 2 inverse properties 2 and 3. the cot algorithm is not only simpler and more efficient than prior ot control algorithms but also simplifies the design of transformation functions. we have implemented the cot algorithm in a generic collaboration engine and used it for supporting a range of novel collaborative applications.
semeval,test_C_86,addressing strategic behavior in a deployed microeconomic resource allocator. while market based systems have long been proposed as solutions for distributed resource allocation few have been deployed for production use in real computer systems. towards this end we present our initial experience using mirage a microeconomic resource allocation system based on a repeated combinatorial auction. mirage allocates time on a heavily used 148 node wireless sensor network testbed. in particular we focus on observed strategic user behavior over a four month period in which 312 148 node hours were allocated across 11 research projects. based on these results we present a set of key challenges for market based resource allocation systems based on repeated combinatorial auctions. finally we propose refinements to the system s current auction scheme to mitigate the strategies observed to date and also comment on some initial steps toward building an approximately strategyproof repeated combinatorial auction.
semeval,test_C_9,edas providing an environment for decentralized adaptive services. as the idea of virtualisation of compute power storage and bandwidth becomes more and more important grid computing evolves and is applied to a rising number of applications. the environment for decentralized adaptive services edas provides a grid like infrastructure for user accessed longterm services e g webserver source code repository etc. it aims at supporting the autonomous execution and evolution of services in terms of scalability and resource aware distribution. edas offers flexible service models based on distributed mobile objects ranging from a traditional clientserver scenario to a fully peer to peer based approach. automatic dynamic resource management allows optimized use of available resources while minimizing the administrative complexity.
semeval,test_H_10,regularized clustering for documents. in recent years document clustering has been receiving more and more attentions as an important and fundamental technique for unsupervised document organization automatic topic extraction and fast information retrieval or filtering. in this paper we propose a novel method for clustering documents using regularization. unlike traditional globally regularized clustering methods our method first construct a local regularized linear label predictor for each document vector and then combine all those local regularizers with a global smoothness regularizer. so we call our algorithm clustering with local and global regularization clgr. we will show that the cluster memberships of the documents can be achieved by eigenvalue decomposition of a sparse symmetric matrix which can be efficiently solved by iterative methods. finally our experimental evaluations on several datasets are presented to show the superiorities of clgr over traditional document clustering methods.
semeval,test_H_11,laplacian optimal design for imag e retrieval. relevance feedback is a powerful technique to enhance contentbased image retrieval cbir performance. it solicits the user s relevance judgments on the retrieved images returned by the cbir systems. the user s labeling is then used to learn a classifier to distinguish between relevant and irrelevant images. however the top returned images may not be the most informative ones. the challenge is thus to determine which unlabeled images would be the most informative i e improve the classifier the most if they were labeled and used as training samples. in this paper we propose a novel active learning algorithm called laplacian optimal design lod for relevance feedback image retrieval. our algorithm is based on a regression model which minimizes the least square error on the measured or labeled images and simultaneously preserves the local geometrical structure of the image space. specifically we assume that if two images are sufficiently close to each other then their measurements or labels are close as well. by constructing a nearest neighbor graph the geometrical structure of the image space can be described by the graph laplacian. we discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images which gives us the most amount of information. experimental results on corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.
semeval,test_H_12,fast generation of result snippets in web search. the presentation of query biased document snippets as part of results pages presented by search engines has become an expectation of search engine users. in this paper we explore the algorithms and data structures required as part of a search engine to allow efficient generation of query biased snippets. we begin by proposing and analysing a document compression method that reduces snippet generation time by 58 over a baseline using the zlib compression library. these experiments reveal that finding documents on secondary storage dominates the total cost of generating snippets and so caching documents in ram is essential for a fast snippet generation process. using simulation we examine snippet generation performance for different size ram caches. finally we propose and analyse document reordering and compaction revealing a scheme that increases the number of document cache hits with only a marginal affect on snippet quality. this scheme effectively doubles the number of documents that can fit in a fixed size cache.
semeval,test_H_13,the influence of caption features on clickthrough patterns in web search. web search engines present lists of captions comprising title snippet and url to help users decide which search results to visit. understanding the influence of features of these captions on web search behavior may help validate algorithms and guidelines for their improved generation. in this paper we develop a methodology to use clickthrough logs from a commercial search engine to study user behavior when interacting with search result captions. the findings of our study suggest that relatively simple caption features such as the presence of all terms query terms the readability of the snippet and the length of the url shown in the caption can significantly influence users web search behavior.
semeval,test_H_14,studying the use of popular destinations to enhance web search interaction. we present a novel web search interaction feature which for a given query provides links to websites frequently visited by other users with similar information needs. these popular destinations complement traditional search results allowing direct navigation to authoritative resources for the query topic. destinations are identified using the history of search and browsing behavior of many users over an extended time period whose collective behavior provides a basis for computing source authority. we describe a user study which compared the suggestion of destinations with the previously proposed suggestion of related queries as well as with traditional unaided web search. results show that search enhanced by destination suggestions outperforms other systems for exploratory tasks with best performance obtained from mining past user behavior at query level granularity.
semeval,test_H_16,the impact of caching on search engines. in this paper we study the trade offs in designing efficient caching systems for web search engines. we explore the impact of different approaches such as static vs dynamic caching and caching query results vs caching posting lists. using a query log spanning a whole year we explore the limitations of caching and we demonstrate that caching posting lists can achieve higher hit rates than caching query answers. we propose a new algorithm for static caching of posting lists which outperforms previous methods. we also study the problem of finding the optimal way to split the static cache between answers and posting lists. finally we measure how the changes in the query log affect the effectiveness of static caching given our observation that the distribution of the queries changes slowly over time. our results and observations are applicable to different levels of the data access hierarchy for instance for a memory disk layer or a broker remote server layer.
semeval,test_H_17,pruning policies for two tiered inverted index with correctness guarantee. the web search engines maintain large scale inverted indexes which are queried thousands of times per second by users eager for information. in order to cope with the vast amounts of query loads search engines prune their index to keep documents that are likely to be returned as top results and use this pruned index to compute the first batches of results. while this approach can improve performance by reducing the size of the index if we compute the top results only from the pruned index we may notice a significant degradation in the result quality if a document should be in the top results but was not included in the pruned index it will be placed behind the results computed from the pruned index. given the fierce competition in the online search market this phenomenon is clearly undesirable. in this paper we study how we can avoid any degradation of result quality due to the pruning based performance optimization while still realizing most of its benefit. our contribution is a number of modifications in the pruning techniques for creating the pruned index and a new result computation algorithm that guarantees that the top matching pages are always placed at the top search results even though we are computing the first batch from the pruned index most of the time. we also show how to determine the optimal size of a pruned index and we experimentally evaluate our algorithms on a collection of 130 million web pages.
semeval,test_H_18,topic segmentation with shared topic detection and alignment of multiple documents. topic detection and tracking 26 and topic segmentation 15 play an important role in capturing the local and sequential information of documents. previous work in this area usually focuses on single documents although similar multiple documents are available in many domains. in this paper we introduce a novel unsupervised method for shared topic detection and topic segmentation of multiple similar documents based on mutual information mi and weighted mutual information wmi that is a combination of mi and term weights. the basic idea is that the optimal segmentation maximizes mi or wmi. our approach can detect shared topics among documents. it can find the optimal boundaries in a document and align segments among documents at the same time. it also can handle single document segmentation as a special case of the multi document segmentation and alignment. our methods can identify and strengthen cue terms that can be used for segmentation and partially remove stop words by using term weights based on entropy learned from multiple documents. our experimental results show that our algorithm works well for the tasks of single document segmentation shared topic detection and multi document segmentation. utilizing information from multiple documents can tremendously improve the performance of topic segmentation and using wmi is even better than using mi for the multi document segmentation.
semeval,test_H_19,analyzing feature trajectories for event detection. we consider the problem of analyzing word trajectories in both time and frequency domains with the specific goal of identifying important and less reported periodic and aperiodic words. a set of words with identical trends can be grouped together to reconstruct an event in a completely unsupervised manner. the document frequency of each word across time is treated like a time series where each element is the document frequency inverse document frequency dfidf score at one time point. in this paper we 1 first applied spectral analysis to categorize features for different event characteristics important and less reported periodic and aperiodic 2 modeled aperiodic features with gaussian density and periodic features with gaussian mixture densities and subsequently detected each feature s burst by the truncated gaussian approach 3 proposed an unsupervised greedy event detection algorithm to detect both aperiodic and periodic events. all of the above methods can be applied to time series data in general. we extensively evaluated our methods on the 1 year reuters news corpus 3 and showed that they were able to uncover meaningful aperiodic and periodic events.
semeval,test_H_2,personalized query expansion for the web. the inherent ambiguity of short keyword queries demands for enhanced methods for web retrieval. in this paper we propose to improve such web queries by expanding them with terms collected from each user s personal information repository thus implicitly personalizing the search output. we introduce five broad techniques for generating the additional query keywords by analyzing user data at increasing granularity levels ranging from term and compound level analysis up to global co occurrence statistics as well as to using external thesauri. our extensive empirical analysis under four different scenarios shows some of these approaches to perform very well especially on ambiguous queries producing a very strong increase in the quality of the output rankings. subsequently we move this personalized search framework one step further and propose to make the expansion process adaptive to various features of each query. a separate set of experiments indicates the adaptive algorithms to bring an additional statistically significant improvement over the best static expansion approach.
semeval,test_H_20,new event detection based on indexing tree and named entity. new event detection ned aims at detecting from one or multiple streams of news stories that which one is reported on a new event i e not reported previously. with the overwhelming volume of news available today there is an increasing need for a ned system which is able to detect new events more efficiently and accurately. in this paper we propose a new ned model to speed up the ned task by using news indexing tree dynamically. moreover based on the observation that terms of different types have different effects for ned task two term reweighting approaches are proposed to improve ned accuracy. in the first approach we propose to adjust term weights dynamically based on previous story clusters and in the second approach we propose to employ statistics on training data to learn the named entity reweighting model for each class of stories. experimental results on two linguistic data consortium ldc datasets tdt2 and tdt3 show that the proposed model can improve both efficiency and accuracy of ned task significantly compared to the baseline system and other existing systems.
semeval,test_H_21,robust classification of rare queries using web knowledge. we propose a methodology for building a practical robust query classification system that can identify thousands of query classes with reasonable accuracy while dealing in realtime with the query volume of a commercial web search engine. we use a blind feedback technique given a query we determine its topic by classifying the web search results retrieved by the query. motivated by the needs of search advertising we primarily focus on rare queries which are the hardest from the point of view of machine learning yet in aggregation account for a considerable fraction of search engine traffic. empirical evaluation confirms that our methodology yields a considerably higher classification accuracy than previously reported. we believe that the proposed methodology will lead to better matching of online ads to rare queries and overall to a better user experience.
semeval,test_H_24,investigating the querying and browsing behavior of advanced search engine users. one way to help all users of commercial web search engines be more successful in their searches is to better understand what those users with greater search expertise are doing and use this knowledge to benefit everyone. in this paper we study the interaction logs of advanced search engine users and those not so advanced to better understand how these user groups search. the results show that there are marked differences in the queries result clicks post query browsing and search success of users we classify as advanced based on their use of query operators relative to those classified as non advanced. our findings have implications for how advanced users should be supported during their searches and how their interactions could be used to help searchers of all experience levels find more relevant information and learn improved searching strategies.
semeval,test_H_25,term feedback for information retrieval with language models. i n t hi s paper w e s t udy t er m based f eedback f or i nf or mat i on r etrieval in the language modeling approach. with term feedback a user directly judges the relevance of individual terms without interaction with feedback documents taking full control of the query expansion process. we propose a cluster based method for selecting terms to present to the user for judgment as well as effective algorithms for constructing refined query language models from user term feedback. our algorithms are shown to bring significant improvement in retrieval accuracy over a non feedback baseline and achieve comparable performance to relevance feedback. they are helpful even when there are no relevant documents in the top.
semeval,test_H_26,a support vector method for optimizing average precision. machine learning is commonly used to improve ranked retrieval systems. due to computational difficulties few learning techniques have been developed to directly optimize for mean average precision map despite its widespread use in evaluating such systems. existing approaches optimizing map either do not find a globally optimal solution or are computationally expensive. in contrast we present a general svm learning algorithm that efficiently finds a globally optimal solution to a straightforward relaxation of map. we evaluate our approach using the trec 9 and trec 10 web track corpora wt10g comparing against svms optimized for accuracy and rocarea. in most cases we show our method to produce statistically significant improvements in map scores.
semeval,test_H_29,estimation and use of uncertainty in pseudo relevance feedback. existing pseudo relevance feedback methods typically perform averaging over the top retrieved documents but ignore an important statistical dimension the risk or variance associated with either the individual document models or their combination. treating the baseline feedback method as a black box and the output feedback model as a random variable we estimate a posterior distribution for the feedback model by resampling a given query s top retrieved documents using the posterior mean or mode as the enhanced feedback model. we then perform model combination over several enhanced models each based on a slightly modified query sampled from the original query. we find that resampling documents helps increase individual feedback model precision by removing noise terms while sampling from the query improves robustness worst case performance by emphasizing terms related to multiple query aspects. the result is a meta feedback algorithm that is both more robust and more precise than the original strong baseline method.
semeval,test_H_3,using query contexts in information retrieval. user query is an element that specifies an information need but it is not the only one. studies in literature have found many contextual factors that strongly influence the interpretation of a query. recent studies have tried to consider the user s interests by creating a user profile. however a single profile for a user may not be sufficient for a variety of queries of the user. in this study we propose to use query specific contexts instead of user centric ones including context around query and context within query. the former specifies the environment of a query such as the domain of interest while the latter refers to context words within the query which is particularly useful for the selection of relevant term relations. in this paper both types of context are integrated in an ir model based on language modeling. our experiments on several trec collections show that each of the context factors brings significant improvements in retrieval effectiveness.
semeval,test_H_30,latent concept expansion using markov random fields. query expansion in the form of pseudo relevance feedback or relevance feedback is a common technique used to improve retrieval effectiveness. most previous approaches have ignored important issues such as the role of features and the importance of modeling term dependencies. in this paper we propose a robust query expansion technique based on the markov random field model for information retrieval. the technique called latent concept expansion provides a mechanism for modeling term dependencies during expansion. furthermore the use of arbitrary features within the model provides a powerful framework for going beyond simple term occurrence features that are implicitly used by most other expansion techniques. we evaluate our technique against relevance models a state of the art language modeling query expansion technique. our model demonstrates consistent and significant improvements in retrieval effectiveness across several trec data sets. we also describe how our technique can be used to generate meaningful multi term concepts for tasks such as query suggestion reformulation.
semeval,test_H_31,a study of poisson query generation model for information retrieval. many variants of language models have been proposed for information retrieval. most existing models are based on multinomial distribution and would score documents based on query likelihood computed based on a query generation probabilistic model. in this paper we propose and study a new family of query generation models based on poisson distribution. we show that while in their simplest forms the new family of models and the existing multinomial models are equivalent they behave differently for many smoothing methods. we show that the poisson model has several advantages over the multinomial model including naturally accommodating per term smoothing and allowing for more accurate background modeling. we present several variants of the new model corresponding to different smoothing methods and evaluate them on four representative trec test collections. the results show that while their basic models perform comparably the poisson model can outperform multinomial model with per term smoothing. the performance can be further improved with two stage smoothing.
semeval,test_H_32,interesting nuggets and their impact on definitional question answering. current approaches to identifying definitional sentences in the context of question answering mainly involve the use of linguistic or syntactic patterns to identify informative nuggets. this is insufficient as they do not address the novelty factor that a definitional nugget must also possess. this paper proposes to address the deficiency by building a human interest model from external knowledge. it is hoped that such a model will allow the computation of human interest in the sentence with respect to the topic. we compare and contrast our model with current definitional question answering models to show that interestingness plays an important factor in definitional question answering.
semeval,test_H_4,towards task based personal information management evaluations. personal information management pim is a rapidly growing area of research concerned with how people store manage and re find information. a feature of pim research is that many systems have been designed to assist users manage and re find information but very few have been evaluated. this has been noted by several scholars and explained by the difficulties involved in performing pim evaluations. the difficulties include that people re find information from within unique personal collections researchers know little about the tasks that cause people to re find information and numerous privacy issues concerning personal information. in this paper we aim to facilitate pim evaluations by addressing each of these difficulties. in the first part we present a diary study of information re finding tasks. the study examines the kind of tasks that require users to re find information and produces a taxonomy of re finding tasks for email messages and web pages. in the second part we propose a task based evaluation methodology based on our findings and examine the feasibility of the approach using two different methods of task creation.
semeval,test_H_5,utility based information distillation over temporally sequenced documents. this paper examines a new approach to information distillation over temporally ordered documents and proposes a novel evaluation scheme for such a framework. it combines the strengths of and extends beyond conventional adaptive filtering novelty detection and non redundant passage ranking with respect to long lasting information needs tasks with multiple queries. our approach supports fine grained user feedback via highlighting of arbitrary spans of text and leverages such information for utility optimization in adaptive settings. for our experiments we defined hypothetical tasks based on news events in the tdt4 corpus with multiple queries per task. answer keys nuggets were generated for each query and a semiautomatic procedure was used for acquiring rules that allow automatically matching nuggets against system responses. we also propose an extension of the ndcg metric for assessing the utility of ranked passages as a combination of relevance and novelty. our results show encouraging utility enhancements using the new approach compared to the baseline systems without incremental learning or the novelty detection components.
semeval,test_H_7,efficient bayesian hierarchical user modeling for recommendation systems. a content based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual user s interest. a system serving millions of users can learn a better user profile for a new user or a user with little feedback by borrowing information from other users through the use of a bayesian hierarchical model. learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive. the commonly used em algorithm converges very slowly due to the sparseness of the data in ir applications. this paper proposes a new fast learning technique to learn a large number of individual user profiles. the efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from netflix and movielens.
semeval,test_H_8,robust test collections for retrieval evaluation. low cost methods for acquiring relevance judgments can be a boon to researchers who need to evaluate new retrieval tasks or topics but do not have the resources to make thousands of judgments. while these judgments are very useful for a one time evaluation it is not clear that they can be trusted when re used to evaluate new systems. in this work we formally define what it means for judgments to be reusable the confidence in an evaluation of new systems can be accurately assessed from an existing set of relevance judgments. we then present a method for augmenting a set of relevance judgments with relevance estimates that require no additional assessor effort. using this method practically guarantees reusability with as few as five judgments per topic taken from only two systems we can reliably evaluate a larger set of ten systems. even the smallest sets of judgments can be useful for evaluation of new systems.
semeval,test_H_9,learn from web search logs to organize search results. effective organization of search results is critical for improving the utility of any search engine. clustering search results is an effective way to organize search results which allows a user to navigate into relevant documents quickly. however two deficiencies of this approach make it not always work well 1 the clusters discovered do not necessarily correspond to the interesting aspects of a topic from the user s perspective and 2 the cluster labels generated are not informative enough to allow a user to identify the right cluster. in this paper we propose to address these two deficiencies by 1 learning interesting aspects of a topic from web search logs and organizing search results accordingly and 2 generating more meaningful cluster labels using past query words entered by users. we evaluate our proposed method on a commercial search engine log data. compared with the traditional methods of clustering search results our method can give better result organization and more meaningful labels.
semeval,test_I_1,aborting tasks in bdi agents. intelligent agents that are intended to work in dynamic environments must be able to gracefully handle unsuccessful tasks and plans. in addition such agents should be able to make rational decisions about an appropriate course of action which may include aborting a task or plan either as a result of the agent s own deliberations or potentially at the request of another agent. in this paper we investigate the incorporation of aborts into a bdi style architecture. we discuss some conditions under which aborting a task or plan is appropriate and how to determine the consequences of such a decision. we augment each plan with an optional abort method analogous to the failure method found in some agent programming languages. we provide an operational semantics for the execution cycle in the presence of aborts in the abstract agent language can which enables us to specify a bdi based execution model without limiting our attention to a particular agent system such as jack jadex jason or spark. a key technical challenge we address is the presence of parallel execution threads and of sub tasks which require the agent to ensure that the abort methods for each plan are carried out in an appropriate sequence.
semeval,test_I_10,smile sound multi agent incremental learning rrb. this article deals with the problem of collaborative learning in a multi agent system. here each agent can update incrementally its beliefs b the concept representation so that it is in a way kept consistent with the whole set of information k the examples that he has received from the environment or other agents. we extend this notion of consistency or soundness to the whole mas and discuss how to obtain that at any moment a same consistent concept representation is present in each agent. the corresponding protocol is applied to supervised concept learning. the resulting method smile standing for sound multiagent incremental learning is described and experimented here. surprisingly some difficult boolean formulas are better learned given the same learning set by a multi agent system than by a single agent.
semeval,test_I_11,real time agent characterization and prediction. reasoning about agents that we observe in the world is challenging. our available information is often limited to observations of the agent s external behavior in the past and present. to understand these actions we need to deduce the agent s internal state which includes not only rational elements such as intentions and plans but also emotive ones such as fear. in addition we often want to predict the agent s future actions which are constrained not only by these inward characteristics but also by the dynamics of the agent s interaction with its environment. bee behavior evolution and extrapolation uses a faster than real time agentbased model of the environment to characterize agents internal state by evolution against observed behavior and then predict their future behavior taking into account the dynamics of their interaction with the environment.
semeval,test_I_12,sharing experiences to learn user characteristics in dynamic environments with sparse data. this paper investigates the problem of estimating the value of probabilistic parameters needed for decision making in environments in which an agent operating within a multi agent system has no a priori information about the structure of the distribution of parameter values. the agent must be able to produce estimations even when it may have made only a small number of direct observations and thus it must be able to operate with sparse data. the paper describes a mechanism that enables the agent to significantly improve its estimation by augmenting its direct observations with those obtained by other agents with which it is coordinating. to avoid undesirable bias in relatively heterogeneous environments while effectively using relevant data to improve its estimations the mechanism weighs the contributions of other agents observations based on a real time estimation of the level of similarity between each of these agents and itself. the coordination autonomy module of a coordination manager system provided an empirical setting for evaluation. simulation based evaluations demonstrated that the proposed mechanism outperforms estimations based exclusively on an agent s own observations as well as estimations based on an unweighted aggregate of all other agents observations.
semeval,test_I_14,a reinforcement learning based distributed search algorithm for hierarchical peer to peer information retrieval systems. the dominant existing routing strategies employed in peerto peer p2p based information retrieval ir systems are similarity based approaches. in these approaches agents depend on the content similarity between incoming queries and their direct neighboring agents to direct the distributed search sessions. however such a heuristic is myopic in that the neighboring agents may not be connected to more relevant agents. in this paper an online reinforcement learning based approach is developed to take advantage of the dynamic run time characteristics of p2p ir systems as represented by information about past search sessions. specifically agents maintain estimates on the downstream agents abilities to provide relevant documents for incoming queries. these estimates are updated gradually by learning from the feedback information returned from previous search sessions. based on this information the agents derive corresponding routing policies. thereafter these agents route the queries based on the learned policies and update the estimates based on the new routing policies. experimental results demonstrate that the learning algorithm improves considerably the routing performance on two test collection sets that have been used in a variety of distributed ir studies.
semeval,test_I_15,information searching and sharing in large scale dynamic networks. finding the right agents in a large and dynamic network to provide the needed resources in a timely fashion is a long standing problem. this paper presents a method for information searching and sharing that combines routing indices with tokenbased methods. the proposed method enables agents to search effectively by acquiring their neighbors interests advertising their information provision abilities and maintaining indices for routing queries in an integrated way. specifically the paper demonstrates through performance experiments how static and dynamic networks of agents can be tuned to answer queries effectively as they gather evidence for the interests and information provision abilities of others without altering the topology or imposing an overlay structure to the network of acquaintances.
semeval,test_I_16,an advanced bidding agent for advertisement selection on public displays. in this paper we present an advanced bidding agent that participates in first price sealed bid auctions to allocate advertising space on bluscreen an experimental public advertisement system that detects users through the presence of their bluetooth enabled devices. our bidding agent is able to build probabilistic models of both the behaviour of users who view the adverts and the auctions that it participates within. it then uses these models to maximise the exposure that its adverts receive. we evaluate the effectiveness of this bidding agent through simulation against a range of alternative selection mechanisms including a simple bidding strategy random allocation and a centralised optimal allocation with perfect foresight. our bidding agent significantly outperforms both the simple bidding strategy and the random allocation and in a mixed population of agents it is able to expose its adverts to 25 more users than the simple bidding strategy. moreover its performance is within 7 5 of that of the centralised optimal allocation despite the highly uncertain environment in which it must operate.
semeval,test_I_18,collaboration among a satellite swarm. the paper deals with on board planning for a satellite swarm via communication and negotiation. we aim at defining individual behaviours that result in a global behaviour that meets the mission requirements. we will present the formalization of the problem a communication protocol a solving method based on reactive decision rules and first results.
semeval,test_I_19,bidding optimally in concurrent second price auctions of perfectly substitutable goods. we derive optimal bidding strategies for a global bidding agent that participates in multiple simultaneous second price auctions with perfect substitutes. we first consider a model where all other bidders are local and participate in a single auction. for this case we prove that assuming free disposal the global bidder should always place non zero bids in all available auctions irrespective of the local bidders valuation distribution. furthermore for non decreasing valuation distributions we prove that the problem of finding the optimal bids reduces to two dimensions. these results hold both in the case where the number of local bidders is known and when this number is determined by a poisson distribution. this analysis extends to online markets where typically auctions occur both concurrently and sequentially. in addition by combining analytical and simulation results we demonstrate that similar results hold in the case of several global bidders provided that the market consists of both global and local bidders. finally we address the efficiency of the overall market and show that information about the number of local bidders is an important determinant for the way in which a global bidder affects efficiency.
semeval,test_I_20,computing the banzhaf power index in network flow games. preference aggregation is used in a variety of multiagent applications and as a result voting theory has become an important topic in multiagent system research. however power indices which reflect how much real power a voter has in a weighted voting system have received relatively little attention although they have long been studied in political science and economics. the banzhaf power index is one of the most popular it is also well defined for any simple coalitional game. in this paper we examine the computational complexity of calculating the banzhaf power index within a particular multiagent domain a network flow game. agents control the edges of a graph a coalition wins if it can send a flow of a given size from a source vertex to a target vertex. the relative power of each edge agent reflects its significance in enabling such a flow and in real world networks could be used for example to allocate resources for maintaining parts of the network. we show that calculating the banzhaf power index of each agent in this network flow domain is p complete. we also show that for some restricted network flow domains there exists a polynomial algorithm to calculate agents banzhaf power indices.
semeval,test_I_21,interactions between market barriers and communication networks in marketing systems. we investigate a framework where agents search for satisfying products by using referrals from other agents. our model of a mechanism for transmitting word of mouth and the resulting behavioural effects is based on integrating a module governing the local behaviour of agents with a module governing the structure and function of the underlying network of agents. local behaviour incorporates a satisficing model of choice a set of rules governing the interactions between agents including learning about the trustworthiness of other agents over time and external constraints on behaviour that may be imposed by market barriers or switching costs. local behaviour takes place on a network substrate across which agents exchange positive and negative information about products. we use various degree distributions dictating the extent of connectivity and incorporate both small world effects and the notion of preferential attachment in our network models. we compare the effectiveness of referral systems over various network structures for easy and hard choice tasks and evaluate how this effectiveness changes with the imposition of market barriers.
semeval,test_I_22,realistic cognitive load modeling for enhancing shared mental models in human agent collaboration. human team members often develop shared expectations to predict each other s needs and coordinate their behaviors. in this paper the concept shared belief map is proposed as a basis for developing realistic shared expectations among a team of human agent pairs haps. the establishment of shared belief maps relies on inter agent information sharing the effectiveness of which highly depends on agents processing loads and the instantaneous cognitive loads of their human partners. we investigate hmm based cognitive load models to facilitate team members to share the right information with the right party at the right time. the shared belief map concept and the cognitive processing load models have been implemented in a cognitive agent architecture smmall. a series of experiments were conducted to evaluate the concept the models and their impacts on the evolving of shared mental models of hap teams.
semeval,test_I_26,sequential decision making in parallel two sided economic search. this paper presents a two sided economic search model in which agents are searching for beneficial pairwise partnerships. in each search stage each of the agents is randomly matched with several other agents in parallel and makes a decision whether to accept a potential partnership with one of them. the distinguishing feature of the proposed model is that the agents are not restricted to maintaining a synchronized instantaneous decision protocol and can sequentially accept and reject partnerships within the same search stage. we analyze the dynamics which drive the agents strategies towards a stable equilibrium in the new model and show that the proposed search strategy weakly dominates the one currently in use for the two sided parallel economic search model. by identifying several unique characteristics of the equilibrium we manage to efficiently bound the strategy space that needs to be explored by the agents and propose an efficient means for extracting the distributed equilibrium strategies in common environments.
semeval,test_I_29,distributed management of flexible times schedules. we consider the problem of managing schedules in an uncertain distributed environment. we assume a team of collaborative agents each responsible for executing a portion of a globally pre established schedule but none possessing a global view of either the problem or solution. the goal is to maximize the joint quality obtained from the activities executed by all agents given that during execution unexpected events will force changes to some prescribed activities and reduce the utility of executing others. we describe an agent architecture for solving this problem that couples two basic mechanisms 1 a flexible times representation of the agent s schedule using a simple temporal network and 2 an incremental rescheduling procedure. the former hedges against temporal uncertainty by allowing execution to proceed from a set of feasible solutions and the latter acts to revise the agent s schedule when execution is forced outside of this set of solutions or when execution events reduce the expected value of this feasible solution set. basic coordination with other agents is achieved simply by communicating schedule changes to those agents with inter dependent activities. then as time permits the core local problem solving infra structure is used to drive an inter agent option generation and query process aimed at identifying opportunities for solution improvement through joint change. using a simulator to model the environment we compare the performance of our multi agent system with that of an expected optimal but non scalable centralized mdp solver.
semeval,test_I_30,distributed task allocation in social networks. this paper proposes a new variant of the task allocation problem where the agents are connected in a social network and tasks arrive at the agents distributed over the network. we show that the complexity of this problem remains nphard. moreover it is not approximable within some factor. we develop an algorithm based on the contract net protocol. our algorithm is completely distributed and it assumes that agents have only local knowledge about tasks and resources. we conduct a set of experiments to evaluate the performance and scalability of the proposed algorithm in terms of solution quality and computation time. three different types of networks namely small world random and scale free networks are used to represent various social relationships among agents in realistic applications. the results demonstrate that our algorithm works well and that it scales well to large scale applications.
semeval,test_I_31,reasoning about judgment and preference aggregation. agents that must reach agreements with other agents need to reason about how their preferences judgments and beliefs might be aggregated with those of others by the social choice mechanisms that govern their interactions. the recently emerging field of judgment aggregation studies aggregation from a logical perspective and considers how multiple sets of logical formulae can be aggregated to a single consistent set. as a special case judgment aggregation can be seen to subsume classical preference aggregation. we present a modal logic that is intended to support reasoning about judgment aggregation scenarios and hence as a special case about preference aggregation the logical language is interpreted directly in judgment aggregation rules. we present a sound and complete axiomatisation of such rules. we show that the logic can express aggregation rules such as majority voting rule properties such as independence and results such as the discursive paradox arrow s theorem and condorcet s paradox which are derivable as formal theorems of the logic. the logic is parameterised in such a way that it can be used as a general framework for comparing the logical properties of different types of aggregation including classical preference aggregation.
semeval,test_I_32,an adversarial environment model for bounded rational agents in zero sum interactions. multiagent environments are often not cooperative nor collaborative in many cases agents have conflicting interests leading to adversarial interactions. this paper presents a formal adversarial environment model for bounded rational agents operating in a zero sum environment. in such environments attempts to use classical utility based search methods can raise a variety of difficulties e g implicitly modeling the opponent as an omniscient utility maximizer rather than leveraging a more nuanced explicit opponent model. we define an adversarial environment by describing the mental states of an agent in such an environment. we then present behavioral axioms that are intended to serve as design principles for building such adversarial agents. we explore the application of our approach by analyzing log files of completed connect four games and present an empirical analysis of the axioms appropriateness.
semeval,test_I_33,a formal road from institutional norms to organizational structures. up to now the way institutions and organizations have been used in the development of open systems has not often gone further than a useful heuristics. in order to develop systems actually implementing institutions and organizations formal methods should take the place of heuristic ones. the paper presents a formal semantics for the notion of institution and its components abstract and concrete norms empowerment of agents roles and defines a formal relation between institutions and organizational structures. as a result it is shown how institutional norms can be refined to constructs organizational structures which are closer to an implemented system. it is also shown how such a refinement process can be fully formalized and it is therefore amenable to rigorous verification.
semeval,test_I_34,resolving conflict and inconsistency in norm regulated virtual organizations. norm governed virtual organizations define govern and facilitate coordinated resource sharing and problem solving in societies of agents. with an explicit account of norms openness in virtual organizations can be achieved new components designed by various parties can be seamlessly accommodated. we focus on virtual organizations realised as multi agent systems in which human and software agents interact to achieve individual and global goals. however any realistic account of norms should address their dynamic nature norms will change as agents interact with each other and their environment. due to the changing nature of norms or due to norms stemming from different virtual organizations there will be situations when an action is simultaneously permitted and prohibited that is a conflict arises. likewise there will be situations when an action is both obliged and prohibited that is an inconsistency arises. we introduce an approach based on first order unification to detect and resolve such conflicts and inconsistencies. in our proposed solution we annotate a norm with the set of values their variables should not have in order to avoid a conflict or an inconsistency with another norm. our approach neatly accommodates the domain dependent interrelations among actions and the indirect conflicts inconsistencies these may cause. more generally we can capture a useful notion of inter agent and inter role delegation of actions and norms associated to them and use it to address conflicts inconsistencies caused by action delegation. we illustrate our approach with an e science example in which agents support grid services.
semeval,test_I_35,distributed norm management in regulated multi agent systems. norms are widely recognised as a means of coordinating multi agent systems. the distributed management of norms is a challenging issue and we observe a lack of truly distributed computational realisations of normative models. in order to regulate the behaviour of autonomous agents that take part in multiple related activities we propose a normative model the normative structure ns an artifact that is based on the propagation of normative positions obligations prohibitions permissions as consequences of agents actions. within a ns conflicts may arise due to the dynamic nature of the mas and the concurrency of agents actions. however ensuring conflict freedom of a ns at design time is computationally intractable. we show this by formalising the notion of conflict providing a mapping of nss into coloured petri nets and borrowing well known theoretical results from that field. since online conflict resolution is required we present a tractable algorithm to be employed distributedly. we then demonstrate that this algorithm is paramount for the distributed enactment of a ns.
semeval,test_I_4,meta level coordination for solving negotiation chains in semi cooperative multi agent systems. a negotiation chain is formed when multiple related negotiations are spread over multiple agents. in order to appropriately order and structure the negotiations occurring in the chain so as to optimize the expected utility we present an extension to a singleagent concurrent negotiation framework. this work is aimed at semi cooperative multi agent systems where each agent has its own goals and works to maximize its local utility however the performance of each individual agent is tightly related to other agent s cooperation and the system s overall performance. we introduce a pre negotiation phase that allows agents to transfer meta level information. using this information the agent can build a more accurate model of the negotiation in terms of modeling the relationship of flexibility and success probability. this more accurate model helps the agent in choosing a better negotiation solution in the global negotiation chain context. the agent can also use this information to allocate appropriate time for each negotiation hence to find a good ordering of all related negotiations. the experimental data shows that these mechanisms improve the agents and the system s overall performance significantly.
semeval,test_I_5,towards self organising agent based resource allocation in a multi server environment. distributed applications require distributed techniques for efficient resource allocation. these techniques need to take into account the heterogeneity and potential unreliability of resources and resource consumers in a distributed environments. in this paper we propose a distributed algorithm that solves the resource allocation problem in distributed multiagent systems. our solution is based on the self organisation of agents which does not require any facilitator or management layer. the resource allocation in the system is a purely emergent effect. we present results of the proposed resource allocation mechanism in the simulated static and dynamic multi server environment.
semeval,test_I_6,dynamic semantics for agent communication languages. this paper proposes dynamic semantics for agent communication languages acls as a method for tackling some of the fundamental problems associated with agent communication in open multiagent systems. based on the idea of providing alternative semantic variants for speech acts and transition rules between them that are contingent on previous agent behaviour our framework provides an improved notion of grounding semantics in ongoing interaction a simple mechanism for distinguishing between compliant and expected behaviour and a way to specify sanction and reward mechanisms as part of the acl itself. we extend a common framework for commitment based acl semantics to obtain these properties discuss desiderata for the design of concrete dynamic semantics together with examples and analyse their properties.
semeval,test_I_7,commitment and extortion. making commitments e g through promises and threats enables a player to exploit the strengths of his own strategic position as well as the weaknesses of that of his opponents. which commitments a player can make with credibility depends on the circumstances. in some a player can only commit to the performance of an action in others he can commit himself conditionally on the actions of the other players. some situations even allow for commitments on commitments or for commitments to randomized actions. we explore the formal properties of these types of conditional commitment and their interrelationships. so as to preclude inconsistencies among conditional commitments we assume an order in which the players make their commitments. central to our analyses is the notion of an extortion which we define for a given order of the players as a profile that contains for each player an optimal commitment given the commitments of the players that committed earlier. on this basis we investigate for different commitment types whether it is advantageous to commit earlier rather than later and how the outcomes obtained through extortions relate to backward induction and pareto efficiency.
semeval,test_I_9,temporal linear logic as a basis for flexible agent interactions. interactions between agents in an open system such as the internet require a significant degree of flexibility. a crucial aspect of the development of such methods is the notion of commitments which provides a mechanism for coordinating interactive behaviors among agents. in this paper we investigate an approach to model commitments with tight integration with protocol actions. this means that there is no need to have an explicit mapping from protocols actions to operations on commitments and an external mechanism to process and enforce commitments. we show how agents can reason about commitments and protocol actions to achieve the end results of protocols using a reasoning system based on temporal linear logic which incorporates both temporal and resource sensitive reasoning. we also discuss the application of this framework to scenarios such as online commerce.
semeval,test_J_1,generalized trade reduction mechanisms. when designing a mechanism there are several desirable properties to maintain such as incentive compatibility ic individual rationality ir and budget balance bb. it is well known 15 that it is impossible for a mechanism to maximize social welfare whilst also being ir ic and bb. there have been several attempts to circumvent 15 by trading welfare for bb e g in domains such as double sided auctions 13 distributed markets 3 and supply chain problems 2 4. in this paper we provide a procedure called a generalized trade reduction gtr for single value players which given an ir and ic mechanism outputs a mechanism which is ir ic and bb with a loss of welfare. we bound the welfare achieved by our procedure for a wide range of domains. in particular our results improve on existing solutions for problems such as double sided markets with homogenous goods distributed markets and several kinds of supply chains. furthermore our solution provides budget balanced mechanisms for several open problems such as combinatorial double sided auctions and distributed markets with strategic transportation edges.
semeval,test_J_10,understanding user behavior in online feedback reporting. online reviews have become increasingly popular as a way to judge the quality of various products and services. previous work has demonstrated that contradictory reporting and underlying user biases make judging the true worth of a service difficult. in this paper we investigate underlying factors that influence user behavior when reporting feedback. we look at two sources of information besides numerical ratings linguistic evidence from the textual comment accompanying a review and patterns in the time sequence of reports. we first show that groups of users who amply discuss a certain feature are more likely to agree on a common rating for that feature. second we show that a user s rating partly reflects the difference between true quality and prior expectation of quality as inferred from previous reviews. both give us a less noisy way to produce rating estimates and reveal the reasons behind user bias. our hypotheses were validated by statistical evidence from hotel reviews on the tripadvisor website.
semeval,test_J_11,trading networks with price setting agents. in a wide range of markets individual buyers and sellers often trade through intermediaries who determine prices via strategic considerations. typically not all buyers and sellers have access to the same intermediaries and they trade at correspondingly different prices that reflect their relative amounts of power in the market. we model this phenomenon using a game in which buyers sellers and traders engage in trade on a graph that represents the access each buyer and seller has to the traders. in this model traders set prices strategically and then buyers and sellers react to the prices they are offered. we show that the resulting game always has a subgame perfect nash equilibrium and that all equilibria lead to an efficient i e socially optimal allocation of goods. we extend these results to a more general type of matching market such as one finds in the matching of job applicants and employers. finally we consider how the profits obtained by the traders depend on the underlying graph roughly a trader can command a positive profit if and only if it has an essential connection in the network structure thus providing a graph theoretic basis for quantifying the amount of competition among traders. our work differs from recent studies of how price is affected by network structure through our modeling of price setting as a strategic activity carried out by a subset of agents in the system rather than studying prices set via competitive equilibrium or by a truthful mechanism.
semeval,test_J_13,on the complexity of combinatorial auctions structured item graphs and hypertree decompositions. the winner determination problem in combinatorial auctions is the problem of determining the allocation of the items among the bidders that maximizes the sum of the accepted bid prices. while this problem is in general nphard it is known to be feasible in polynomial time on those instances whose associated item graphs have bounded treewidth called structured item graphs. formally an item graph is a graph whose nodes are in one to one correspondence with items and edges are such that for any bid the items occurring in it induce a connected subgraph. note that many item graphs might be associated with a given combinatorial auction depending on the edges selected for guaranteeing the connectedness. in fact the tractability of determining whether a structured item graph of a fixed treewidth exists and if so computing one was left as a crucial open problem. in this paper we solve this problem by proving that the existence of a structured item graph is computationally intractable even for treewidth 3. motivated by this bad news we investigate different kinds of structural requirements that can be used to isolate tractable classes of combinatorial auctions. we show that the notion of hypertree decomposition a recently introduced measure of hypergraph cyclicity turns out to be most useful here. indeed we show that the winner determination problem is solvable in polynomial time on instances whose bidder interactions can be represented with dual hypergraphs having bounded hypertree width. even more surprisingly we show that the class of tractable instances identified by means of our approach properly contains the class of instances having a structured item graph.
semeval,test_J_14,computing good nash equilibria in graphical games. this paper addresses the problem of fair equilibrium selection in graphical games. our approach is based on the data structure called the best response policy which was proposed by kearns et al 13 as a way to represent all nash equilibria of a graphical game. in 9 it was shown that the best response policy has polynomial size as long as the underlying graph is a path. in this paper we show that if the underlying graph is a bounded degree tree and the best response policy has polynomial size then there is an efficient algorithm which constructs a nash equilibrium that guarantees certain payoffs to all participants. another attractive solution concept is a nash equilibrium that maximizes the social welfare. we show that while exactly computing the latter is infeasible we prove that solving this problem may involve algebraic numbers of an arbitrarily high degree there exists an fptas for finding such an equilibrium as long as the best response policy has polynomial size. these two algorithms can be combined to produce nash equilibria that satisfy various fairness criteria.
semeval,test_J_15,generalized value decomposition and structured multiattribute auctions. multiattribute auction mechanisms generally either remain agnostic about traders preferences or presume highly restrictive forms such as full additivity. real preferences often exhibit dependencies among attributes yet may possess some structure that can be usefully exploited to streamline communication and simplify operation of a multiattribute auction. we develop such a structure using the theory of measurable value functions a cardinal utility representation based on an underlying order over preference differences. a set of local conditional independence relations over such differences supports a generalized additive preference representation which decomposes utility across overlapping clusters of related attributes. we introduce an iterative auction mechanism that maintains prices on local clusters of attributes rather than the full space of joint configurations. when traders preferences are consistent with the auction s generalized additive structure the mechanism produces approximately optimal allocations at approximate vcg prices.
semeval,test_J_17,truthful mechanism design for multi dimensional scheduling via cycle monotonicity. we consider the problem of makespan minimization on m unrelated machines in the context of algorithmic mechanism design where the machines are the strategic players. this is a multidimensional scheduling domain and the only known positive results for makespan minimization in such a domain are o m approximation truthful mechanisms 22 20. we study a well motivated special case of this problem where the processing time of a job on each machine may either be low or high  and the low and high values are public and job dependent. this preserves the multidimensionality of the domain and generalizes the restricted machines i e pj  setting in scheduling. we give a general technique to convert any c approximation algorithm to a 3capproximation truthful in expectation mechanism. this is one of the few known results that shows how to export approximation algorithms for a multidimensional problem into truthful mechanisms in a black box fashion. when the low and high values are the same for all jobs we devise a deterministic 2 approximation truthful mechanism. these are the first truthful mechanisms with non trivial performance guarantees for a multidimensional scheduling domain. our constructions are novel in two respects. first we do not utilize or rely on explicit price definitions to prove truthfulness instead we design algorithms that satisfy cycle monotonicity. cycle monotonicity 23 is a necessary and sufficient condition for truthfulness is a generalization of value monotonicity for multidimensional domains. however whereas value monotonicity has been used extensively and successfully to design truthful mechanisms in singledimensional domains ours is the first work that leverages cycle monotonicity in the multidimensional setting. second our randomized mechanisms are obtained by first constructing a fractional truthful mechanism for a fractional relaxation of the problem and then converting it into a truthfulin expectation mechanism. this builds upon a technique of 16 and shows the usefulness of fractional mechanisms in truthful mechanism design.
semeval,test_J_18,mediators in position auctions. a mediator is a reliable entity which can play on behalf of agents in a given game. a mediator however can not enforce the use of its services and each agent is free to participate in the game directly. in this paper we introduce a study of mediators for games with incomplete information and apply it to the context of position auctions a central topic in electronic commerce. vcg position auctions which are currently not used in practice possess some nice theoretical properties such as the optimization of social surplus and having dominant strategies. these properties may not be satisfied by current position auctions and their variants. we therefore concentrate on the search for mediators that will allow to transform current position auctions into vcg position auctions. we require that accepting the mediator services and reporting honestly to the mediator will form an ex post equilibrium which satisfies the following rationality condition an agent s payoff can not be negative regardless of the actions taken by the agents who did not choose the mediator s services or by the agents who report false types to the mediator. we prove the existence of such desired mediators for the next price google like position auctions as well as for a richer class of position auctions including all k price position auctions k 1. for k 1 the self price position auction we show that the existence of such mediator depends on the tie breaking rule used in the auction.
semeval,test_J_2,worst case optimal redistribution of vcg payments in heterogeneous item auctions with unit demand. many important problems in multiagent systems involve the allocation of multiple resources among the agents. for resource allocation problems the well known vcg mechanism satisfies a list of desired properties including efficiency strategy proofness individual rationality and the non deficit property. however vcg is generally not budget balanced. under vcg agents pay the vcg payments which reduces social welfare. to offset the loss of social welfare due to the vcg payments vcg redistribution mechanisms were introduced. these mechanisms aim to redistribute as much vcg payments back to the agents as possible while maintaining the aforementioned desired properties of the vcg mechanism. we continue the search for worst case optimal vcg redistribution mechanisms mechanisms that maximize the fraction of total vcg payment redistributed in the worst case. previously a worst case optimal vcg redistribution mechanism denoted by wco was characterized for multi unit auctions with nonincreasing marginal values 7. later wco was generalized to settings involving heterogeneous items 4 resulting in the hetero mechanism. 4 conjectured that hetero is feasible and worst case optimal for heterogeneous item auctions with unit demand. in this paper we propose a more natural way to generalize the wco mechanism. we prove that our generalized mechanism though represented differently actually coincides with hetero. based on this new representation of hetero we prove that hetero is indeed feasible and worst case optimal in heterogeneous item auctions with unit demand. finally we conjecture that hetero remains feasible and worst case optimal in the even more general setting of combinatorial auctions with gross substitutes.
semeval,test_J_20,clearing algorithms for barter exchange markets enabling nationwide kidney exchanges. in barter exchange markets agents seek to swap their items with one another in order to improve their own utilities. these swaps consist of cycles of agents with each agent receiving the item of the next agent in the cycle. we focus mainly on the upcoming national kidney exchange market where patients with kidney disease can obtain compatible donors by swapping their own willing but incompatible donors. with over 70 000 patients already waiting for a cadaver kidney in the us this market is seen as the only ethical way to significantly reduce the 4 000 deaths per year attributed to kidney disease. the clearing problem involves finding a social welfare maximizing exchange when the maximum length of a cycle is fixed. long cycles are forbidden since for incentive reasons all transplants in a cycle must be performed simultaneously. also in barter exchanges generally more agents are affected if one drops out of a longer cycle. we prove that the clearing problem with this cycle length constraint is np hard. solving it exactly is one of the main challenges in establishing a national kidney exchange. we present the first algorithm capable of clearing these markets on a nationwide scale. the key is incremental problem formulation. we adapt two paradigms for the task constraint generation and column generation. for each we develop techniques that dramatically improve both runtime and memory usage. we conclude that column generation scales drastically better than constraint generation. our algorithm also supports several generalizations as demanded by real world kidney exchanges. our algorithm replaced cplex as the clearing algorithm of the alliance for paired donation one of the leading kidney exchanges. the match runs are conducted every two weeks and transplants based on our optimizations have already been conducted.
semeval,test_J_21,a strategic model for information markets. information markets which are designed specifically to aggregate traders information are becoming increasingly popular as a means for predicting future events. recent research in information markets has resulted in two new designs market scoring rules and dynamic parimutuel markets. we develop an analytic method to guide the design and strategic analysis of information markets. our central contribution is a new abstract betting game the projection game that serves as a useful model for information markets. we demonstrate that this game can serve as a strategic model of dynamic parimutuel markets and also captures the essence of the strategies in market scoring rules. the projection game is tractable to analyze and has an attractive geometric visualization that makes the strategic moves and interactions more transparent. we use it to prove several strategic properties about the dynamic parimutuel market. we also prove that a special form of the projection game is strategically equivalent to the spherical scoring rule and it is strategically similar to other scoring rules. finally we illustrate two applications of the model to analysis of complex strategic scenarios we analyze the precision of a market in which traders have inertia and a market in which a trader can profit by manipulating another trader s beliefs.
semeval,test_J_22,betting on permutations. we consider a permutation betting scenario where people wager on the final ordering of n candidates for example the outcome of a horse race. we examine the auctioneer problem of risklessly matching up wagers or equivalently finding arbitrage opportunities among the proposed wagers. requiring bidders to explicitly list the orderings that they d like to bet on is both unnatural and intractable because the number of orderings is n. and the number of subsets of orderings is 2n.. we propose two expressive betting languages that seem natural for bidders and examine the computational complexity of the auctioneer problem in each case. subset betting allows traders to bet either that a candidate will end up ranked among some subset of positions in the final ordering for example  horse a will finish in positions 4 9 or 13 21  or that a position will be taken by some subset of candidates for example horse a b or d will finish in position 2. for subset betting we show that the auctioneer problem can be solved in polynomial time if orders are divisible. pair betting allows traders to bet on whether one candidate will end up ranked higher than another candidate for example horse a will beat horse b. we prove that the auctioneer problem becomes np hard for pair betting. we identify a sufficient condition for the existence of a pair betting match that can be verified in polynomial time. we also show that a natural greedy algorithm gives a poor approximation for indivisible orders.
semeval,test_J_23,frugality ratios and improved truthful mechanisms for vertex cover. in set system auctions there are several overlapping teams of agents and a task that can be completed by any of these teams. the auctioneer s goal is to hire a team and pay as little as possible. examples of this setting include shortest path auctions and vertex cover auctions. recently karlin kempe and tamir introduced a new definition offrugality ratio for this problem. informally the frugality ratio is the ratio of the total payment of a mechanism to a desired payment bound. the ratio captures the extent to which the mechanism overpays relative to perceived fair cost in a truthful auction. in this paper we propose a new truthful polynomial time auction for the vertex cover problem and bound its frugality ratio. we show that the solution quality is with a constant factor of optimal and the frugality ratio is within a constant factor of the best possible worst case bound this is the first auction for this problem to have these properties. moreover we show how to transform any truthful auction into a frugal one while preserving the approximation ratio. also we consider two natural modifications of the definition of karlin et al and we analyse the properties of the resulting payment bounds such as monotonicity computational hardness and robustness with respect to the draw resolution rule. we study the relationships between the different payment bounds both for general set systems and for specific set system auctions such as path auctions and vertex cover auctions. we use these new definitions in the proof of our main result for vertex cover auctions via a bootstrapping technique which may be of independent interest.
semeval,test_J_25,betting boolean style a framework for trading in securities based on logical formulas. we develop a framework for trading in compound securities financial instruments that pay off contingent on the outcomes of arbitrary statements in propositional logic. buying or selling securities which can be thought of as betting on or against a particular future outcome allows agents both to hedge risk and to profit in expectation on subjective predictions. a compound securities market allows agents to place bets on arbitrary boolean combinations of events enabling them to more closely achieve their optimal risk exposure and enabling the market as a whole to more closely achieve the social optimum. the tradeoff for allowing such expressivity is in the complexity of the agents and auctioneer s optimization problems. we develop and motivate the concept of a compound securities market presenting the framework through a series of formal definitions and examples. we then analyze in detail the auctioneer s matching problem. we show that with n events the matching problem is co np complete in the divisible case and σp2 complete in the indivisible case. we show that the latter hardness result holds even under severe language restrictions on bids. with log n events the problem is polynomial in the divisible case and np complete in the indivisible case. we briefly discuss matching algorithms and tractable special cases.
semeval,test_J_26,combinatorial agency. much recent research concerns systems such as the internet whose components are owned and operated by different parties each with his own selfish goal. the field of algorithmic mechanism design handles the issue of private information held by the different parties in such computational settings. this paper deals with a complementary problem in such settings handling the hidden actions that are performed by the different parties. our model is a combinatorial variant of the classical principalagent problem from economic theory. in our setting a principal must motivate a team of strategic agents to exert costly effort on his behalf but their actions are hidden from him. our focus is on cases where complex combinations of the efforts of the agents influence the outcome. the principal motivates the agents by offering to them a set of contracts which together put the agents in an equilibrium point of the induced game. we present formal models for this setting suggest and embark on an analysis of some basic issues but leave many questions open.
semeval,test_J_27,learning from revealed preference. a sequence of prices and demands are rationalizable if there exists a concave continuous and monotone utility function such that the demands are the maximizers of the utility function over the budget set corresponding to the price. afriat 1 presented necessary and sufficient conditions for a finite sequence to be rationalizable. varian 20 and later blundell et al 3 4 continued this line of work studying nonparametric methods to forecasts demand. their results essentially characterize learnability of degenerate classes of demand functions and therefore fall short of giving a general degree of confidence in the forecast. the present paper complements this line of research by introducing a statistical model and a measure of complexity through which we are able to study the learnability of classes of demand functions and derive a degree of confidence in the forecasts. our results show that the class of all demand functions has unbounded complexity and therefore is not learnable but that there exist interesting and potentially useful classes that are learnable from finite samples. we also present a learning algorithm that is an adaptation of a new proof of afriat s theorem due to teo and vohra 17.
semeval,test_J_28,approximately strategyproof and tractable multi unit auctions. we present an approximately efficient and approximatelystrategyproof auction mechanism for a single good multi unit allocation problem. the bidding language in our auctions allows marginal decreasing piecewise constant curves. first we develop a fully polynomial time approximation scheme for the multi unit allocation problem which computes a 1 e approximation in worst case time t o n3 e given n bids each with a constant number of pieces. second we embed this approximation scheme within a vickrey clarke groves vcg mechanism and compute payments to n agents for an asymptotic cost of o t log n. the maximal possible gain from manipulation to a bidder in the combined scheme is bounded by e 1 e v where v is the total surplus in the efficient outcome.
semeval,test_J_3,budget optimization in search based advertising auctions. internet search companies sell advertisement slots based on users search queries via an auction. while there has been previous work on the auction process and its game theoretic aspects most of it focuses on the internet company. in this work we focus on the advertisers who must solve a complex optimization problem to decide how to place bids on keywords to maximize their return the number of user clicks on their ads for a given budget. we model the entire process and study this budget optimization problem. while most variants are np hard we show perhaps surprisingly that simply randomizing between two uniform strategies that bid equally on all the keywords works well. more precisely this strategy gets at least a 1 1 e fraction of the maximum clicks possible. as our preliminary experiments show such uniform strategies are likely to be practical. we also present inapproximability results and optimal algorithms for variants of the budget optimization problem.
semeval,test_J_30,implementation with a bounded action space. while traditional mechanism design typically assumes isomorphism between the agents type and action spaces in many situations the agents face strict restrictions on their action space due to e g technical behavioral or regulatory reasons. we devise a general framework for the study of mechanism design in single parameter environments with restricted action spaces. our contribution is threefold. first we characterize sufficient conditions under which the information theoretically optimal social choice rule can be implemented in dominant strategies and prove that any multilinear social choice rule is dominant strategy implementable with no additional cost. second we identify necessary conditions for the optimality of action bounded mechanisms and fully characterize the optimal mechanisms and strategies in games with two players and two alternatives. finally we prove that for any multilinear social choice rule the optimal mechanism with k actions incurs an expected loss of o k21 compared to the optimal mechanisms with unrestricted action spaces. our results apply to various economic and computational settings and we demonstrate their applicability to signaling games public good models and routing in networks.
semeval,test_J_31,computing the optimal strategy to commit to. in multiagent systems strategic settings are often analyzed under the assumption that the players choose their strategies simultaneously. however this model is not always realistic. in many settings one player is able to commit to a strategy before the other player makes a decision. such models are synonymously referred to as leadership commitment or stackelberg models and optimal play in such models is often significantly different from optimal play in the model where strategies are selected simultaneously. the recent surge in interest in computing game theoretic solutions has so far ignored leadership models with the exception of the interest in mechanism design where the designer is implicitly in a leadership position. in this paper we study how to compute optimal strategies to commit to under both commitment to pure strategies and commitment to mixed strategies in both normal form and bayesian games. we give both positive results efficient algorithms and negative results np hardness results.
semeval,test_J_32,nash equilibria in graphical games on trees revisited. graphical games have been proposed as a game theoretic model of large scale distributed networks of non cooperative agents. when the number of players is large and the underlying graph has low degree they provide a concise way to represent the players payoffs. it has recently been shown that the problem of finding nash equilibria in a general degree 3 graphical game with two actions per player is complete for the complexity class ppad indicating that it is unlikely that there is any polynomial time algorithm for this problem. in this paper we study the complexity of graphical games with two actions per player on bounded degree trees. this setting was first considered by kearns littman and singh who proposed a dynamic programming based algorithm that computes all nash equilibria of such games. the running time of their algorithm is exponential though approximate equilibria can be computed efficiently. later littman kearns and singh proposed a modification to this algorithm that can find a single nash equilibrium in polynomial time. we show that this modified algorithm is incorrect the output is not always a nash equilibrium. we then propose a new algorithm that is based on the ideas of kearns et al and computes all nash equilibria in quadratic time if the input graph is a path and in polynomial time if it is an arbitrary graph of maximum degree 2. moreover our algorithm can be used to compute nash equilibria of graphical games on arbitrary trees but the running time can be exponential even when the tree has bounded degree. we show that this is inevitable any algorithm of this type will take exponential time even on bounded degree trees with pathwidth 2. it is an open question whether our algorithm runs in polynomial time on graphs with pathwidth 1 but we show that finding a nash equilibrium for a 2 action graphical game in which the underlying graph has maximum degree 3 and constant pathwidth is ppad complete so is unlikely to be tractable. this research is supported by the epsrc research grants algorithmics of network sharing games and discontinuous behaviour in the complexity of randomized algorithms.
semeval,test_J_4,revenue analysis of a family of ranking rules for keyword auctions. keyword auctions lie at the core of the business models of today s leading search engines. advertisers bid for placement alongside search results and are charged for clicks on their ads. advertisers are typically ranked according to a score that takes into account their bids and potential clickthrough rates. we consider a family of ranking rules that contains those typically used to model yahoo and google s auction designs as special cases. we find that in general neither of these is necessarily revenue optimal in equilibrium and that the choice of ranking rule can be guided by considering the correlation between bidders values and click through rates. we propose a simple approach to determine a revenue optimal ranking rule within our family taking into account effects on advertiser satisfaction and user experience. we illustrate the approach using monte carlo simulations based on distributions fitted to yahoo bid and click through rate data for a high volume keyword.
semeval,test_J_7,the role of compatibility in the diffusion of technologies through social networks. in many settings competing technologies for example operating systems instant messenger systems or document formats can be seen adopting a limited amount of compatibility with one another in other words the difficulty in using multiple technologies is balanced somewhere between the two extremes of impossibility and effortless interoperability. there are a range of reasons why this phenomenon occurs many of which based on legal social or business considerations seem to defy concise mathematical models. despite this we show that the advantages of limited compatibility can arise in a very simple model of diffusion in social networks thus offering a basic explanation for this phenomenon in purely strategic terms. our approach builds on work on the diffusion of innovations in the economics literature which seeks to model how a new technology a might spread through a social network of individuals who are currently users of technology b. we consider several ways of capturing the compatibility of a and b focusing primarily on a model in which users can choose to adopt a adopt b or at an extra cost adopt both a and b. we characterize how the ability of a to spread depends on both its quality relative to b and also this additional cost of adopting both and find some surprising non monotonicity properties in the dependence on these parameters in some cases for one technology to survive the introduction of another the cost of adopting both technologies must be balanced within a narrow intermediate range. we also extend the framework to the case of multiple technologies where we find that a simple this work has been supported in part by nsf grants ccf0325453 iis 0329064 cns 0403340 and bcs 0537606 a google research grant a yahoo research alliance grant the institute for the social sciences at cornell and the john d and catherine t macarthur foundation. model captures the phenomenon of two firms adopting a limited strategic alliance to defend against a new third technology.
semeval,test_J_8,strong equilibrium in cost sharing connection games. in this work we study cost sharing connection games where each player has a source and sink he would like to connect and the cost of the edges is either shared equally fair connection games or in an arbitrary way general connection games. we study the graph topologies that guarantee the existence of a strong equilibrium where no coalition can improve the cost of each of its members regardless of the specific costs on the edges. our main existence results are the following 1 for a single source and sink we show that there is always a strong equilibrium both for fair and general connection games. 2 for a single source multiple sinks we show that for a series parallel graph a strong equilibrium always exists both for fair and general connection games. 3 for multi source and sink we show that an extension parallel graph always admits a strong equilibrium in fair connection games. as for the quality of the strong equilibrium we show that in any fair connection games the cost of a strong equilibrium is θ log n from the optimal solution where n is the number of players. this should be contrasted with the ω n price of anarchy for the same setting. for single source general connection games and single source single sink fair connection games we show that a strong equilibrium is always an optimal solution. research supported in part by a grant of the israel science foundation binational science foundation bsf germanisraeli foundation gif lady davis fellowship an ibm faculty award and the ist programme of the european community under the pascal network of excellence ist 2002 506778. this publication only reflects the authors views.
semeval,test_J_9,computation in a distributed information market. according to economic theory supported by empirical and laboratory evidence the equilibrium price of a financial security reflects all of the information regarding the security s value. we investigate the computational process on the path toward equilibrium where information distributed among traders is revealed step by step over time and incorporated into the market price. we develop a simplified model of an information market along with trading strategies in order to formalize the computational properties of the process. we show that securities whose payoffs can not be expressed as weighted threshold functions of distributed input bits are not guaranteed to converge to the proper equilibrium predicted by economic theory. on the other hand securities whose payoffs are threshold functions are guaranteed to converge for all prior probability distributions. moreover these threshold securities converge in at most n rounds where n is the number of bits of distributed information. we also prove a lower bound showing a type of threshold security that requires at least n 2 rounds to converge in the worst case. this work was supported by the dod university research initiative uri administered by the office of naval research under grant n00014 01 1 0795. supported in part by onr grant n00014 01 0795 and nsf grants ccr 0105337 ccr tc 0208972 ani 0207399 and itr 0219018. this work conducted while at nec laboratories america princeton nj.
semeval,train_C_41,evaluating adaptive resource management for distributed real time embedded systems. a challenging problem faced by researchers and developers of distributed real time and embedded dre systems is devising and implementing effective adaptive resource management strategies that can meet end to end quality of service qos requirements in varying operational conditions. this paper presents two contributions to research in adaptive resource management for dre systems. first we describe the structure and functionality of the hybrid adaptive resourcemanagement middleware hyarm which provides adaptive resource management using hybrid control techniques for adapting to workload fluctuations and resource availability. second we evaluate the adaptive behavior of hyarm via experiments on a dre multimedia system that distributes video in real time. our results indicate that hyarm yields predictable stable and high system performance even in the face of fluctuating workload and resource availability.
semeval,train_C_42,demonstration of grid enabled ensemble kalman filter data assimilation methodology for reservoir characterization. ensemble kalman filter data assimilation methodology is a popular approach for hydrocarbon reservoir simulations in energy exploration. in this approach an ensemble of geological models and production data of oil fields is used to forecast the dynamic response of oil wells. the schlumberger eclipse software is used for these simulations. since models in the ensemble do not communicate message passing implementation is a good choice. each model checks out an eclipse license and therefore parallelizability of reservoir simulations depends on the number licenses available. we have grid enabled the ensemble kalman filter data assimilation methodology for the tigre grid computing environment. by pooling the licenses and computing resources across the collaborating institutions using gridway metascheduler and tigre environment the computational accuracy can be increased while reducing the simulation runtime. in this paper we provide an account of our efforts in gridenabling the ensemble kalman filter data assimilation methodology. potential benefits of this approach observations and lessons learned will be discussed.
semeval,train_C_44,msp multi sequence positioning of wireless sensor nodes. wireless sensor networks have been proposed for use in many location dependent applications. most of these need to identify the locations of wireless sensor nodes a challenging task because of the severe constraints on cost energy and effective range of sensor devices. to overcome limitations in existing solutions we present a multi sequence positioning msp method for large scale stationary sensor node localization in outdoor environments. the novel idea behind msp is to reconstruct and estimate two dimensional location information for each sensor node by processing multiple one dimensional node sequences easily obtained through loosely guided event distribution. starting from a basic msp design we propose four optimizations which work together to increase the localization accuracy. we address several interesting issues such as incomplete partial node sequences and sequence flip found in the mirage test bed we built. we have evaluated the msp system through theoretical analysis extensive simulation as well as two physical systems an indoor version with 46 micaz motes and an outdoor version with 20 micaz motes. this evaluation demonstrates that msp can achieve an accuracy within one foot requiring neither additional costly hardware on sensor nodes nor precise event distribution. it also provides a nice tradeoff between physical cost anchors and soft cost events while maintaining localization accuracy.
semeval,train_C_45,stardust a flexible architecture for passive localization in wireless sensor networks. the problem of localization in wireless sensor networks where nodes do not use ranging hardware remains a challenging problem when considering the required location accuracy energy expenditure and the duration of the localization phase. in this paper we propose a framework called stardust for wireless sensor network localization based on passive optical components. in the stardust framework sensor nodes are equipped with optical retro reflectors. an aerial device projects light towards the deployed sensor network and records an image of the reflected light. an image processing algorithm is developed for obtaining the locations of sensor nodes. for matching a node id to a location we propose a constraint based label relaxation algorithm. we propose and develop localization techniques based on four types of constraints node color neighbor information deployment time for a node and deployment location for a node. we evaluate the performance of a localization system based on our framework by localizing a network of 26 sensor nodes deployed in a 120 x 60ft2 area. the localization accuracy ranges from 2ft to 5 ft while the localization time ranges from 10 milliseconds to 2 minutes.
semeval,train_C_46,tsar a two tier sensor storage architecture using interval skip graphs. archival storage of sensor data is necessary for applications that query mine and analyze such data for interesting features and trends. we argue that existing storage systems are designed primarily for flat hierarchies of homogeneous sensor nodes and do not fully exploit the multi tier nature of emerging sensor networks where an application can comprise tens of tethered proxies each managing tens to hundreds of untethered sensors. we present tsar a fundamentally different storage architecture that envisions separation of data from metadata by employing local archiving at the sensors and distributed indexing at the proxies. at the proxy tier tsar employs a novel multi resolution ordered distributed index structure the interval skip graph for efficiently supporting spatio temporal and value queries. at the sensor tier tsar supports energy aware adaptive summarization that can trade off the cost of transmitting metadata to the proxies against the overhead offalse hits resultingfrom querying a coarse grain index. we implement tsar in a two tier sensor testbed comprising stargatebased proxies and mote based sensors. our experiments demonstrate the benefits and feasibility of using our energy efficient storage architecture in multi tier sensor networks.
semeval,train_C_48,multi dimensional range queries in sensor networks. in many sensor networks data or events are named by attributes. many of these attributes have scalar values so one natural way to query events of interest is to use a multidimensional range query. an example is  list all events whose temperature lies between 50 and 60  and whose light levels lie between 10 and 15. such queries are useful for correlating events occurring within the network. in this paper we describe the design of a distributed index that scalably supports multi dimensional range queries. our distributed index for multi dimensional data or dim uses a novel geographic embedding of a classical index data structure and is built upon the gpsr geographic routing algorithm. our analysis reveals that under reasonable assumptions about query distributions dims scale quite well with network size both insertion and query costs scale as o n. in detailed simulations we show that in practice the insertion and query costs of other alternatives are sometimes an order of magnitude more than the costs of dims even for moderately sized network. finally experiments on a small scale testbed validate the feasibility of dims.
semeval,train_C_49,evaluating opportunistic routing protocols with large realistic contact traces. traditional mobile ad hoc network manet routing protocols assume that contemporaneous end to end communication paths exist between data senders and receivers. in some mobile ad hoc networks with a sparse node population an end to end communication path may break frequently or may not exist at any time. many routing protocols have been proposed in the literature to address the problem but few were evaluated in a realistic opportunistic network setting. we use simulation and contact traces derived from logs in a production network to evaluate and compare five existing protocols direct delivery epidemic random prophet and link state as well as our own proposed routing protocol. we show that the direct delivery and epidemic routing protocols suffer either low delivery ratio or high resource usage and other protocols make tradeoffs between delivery ratio and resource usage.
semeval,train_C_50,cenwits a sensor based loosely coupled search and rescue system using witnesses. university of colorado campus box 0430 boulder co 80309 0430. this paper describes the design implementation and evaluation of a search and rescue system called cenwits. cenwits uses several small commonly available rf based sensors and a small number of storage and processing devices. it is designed for search and rescue of people in emergency situations in wilderness areas. a key feature of cenwits is that it does not require a continuously connected sensor network for its operation. it is designed for an intermittently connected network that provides only occasional connectivity. it makes a judicious use of the combined storage capability of sensors to filter organize and store important information combined battery power of sensors to ensure that the system remains operational for longer time periods and intermittent network connectivity to propagate information to a processing center. a prototype of cenwits has been implemented using berkeley mica2 motes. the paper describes this implementation and reports on the performance measured from it.
semeval,train_C_52,fairness in dead reckoning based distributed multi player games. in a distributed multi player game that uses dead reckoning vectors to exchange movement information among players there is inaccuracy in rendering the objects at the receiver due to network delay between the sender and the receiver. the object is placed at the receiver at the position indicated by the dead reckoning vector but by that time the real position could have changed considerably at the sender. this inaccuracy would be tolerable if it is consistent among all players that is at the same physical time all players see inaccurate with respect to the real position of the object but the same position and trajectory for an object. but due to varying network delays between the sender and different receivers the inaccuracy is different at different players as well. this leads to unfairness in game playing. in this paper we first introduce an error measure for estimating this inaccuracy. then we develop an algorithm for scheduling the sending of dead reckoning vectors at a sender that strives to make this error equal at different receivers over time. this algorithm makes the game very fair at the expense of increasing the overall mean error of all players. to mitigate this effect we propose a budget based algorithm that provides improved fairness without increasing the mean error thereby maintaining the accuracy of game playing. we have implemented both the scheduling algorithm and the budget based algorithm as part of bzflag a popular distributed multi player game. we show through experiments that these algorithms provide fairness among players in spite of widely varying network delays. an additional property of the proposed algorithms is that they require less number of drs to be exchanged compared to the current implementation of bzflag to achieve the same level of accuracy in game playing.
semeval,train_C_53,globally synchronized dead reckoning with local lag for continuous distributed multiplayer games. dead reckoning dr is an effective method to maintain consistency for continuous distributed multiplayer games cdmg. since dr can filter most unnecessary state updates and improve the scalability of a system it is widely used in commercial cdmg. however dr can not maintain high consistency and this constrains its application in highly interactive games. with the help of global synchronization dr can achieve higher consistency but it still can not eliminate before inconsistency. in this paper a method named globally synchronized dr with local lag gs dr ll which combines local lag and globally synchronized dr gs dr is presented. performance evaluation shows that gs dr ll can effectively decrease before inconsistency and the effects increase with the lag.
semeval,train_C_54,remote access to large spatial databases. enterprises in the public and private sectors have been making their large spatial data archives available over the internet. however interactive work with such large volumes of online spatial data is a challenging task. we propose two efficient approaches to remote access to large spatial data. first we introduce a client server architecture where the work is distributed between the server and the individual clients for spatial query evaluation data visualization and data management. we enable the minimization of the requirements for system resources on the client side while maximizing system responsiveness as well as the number of connections one server can handle concurrently. second for prolonged periods of access to large online data we introduce appoint an approach for peer to peer offloading the internet. this is a centralized peer to peer approach that helps internet users transfer large volumes of online data efficiently. in appoint active clients of the clientserver architecture act on the server s behalf and communicate with each other to decrease network latency improve service bandwidth and resolve server congestions.
semeval,train_C_55,context awareness for group interaction support. in this paper we present an implemented system for supporting group interaction in mobile distributed computing environments. first an introduction to context computing and a motivation for using contextual information to facilitate group interaction is given. we then present the architecture of our system which consists of two parts a subsystem for location sensing that acquires information about the location of users as well as spatial proximities between them and one for the actual context aware application which provides services for group interaction.
semeval,train_C_56,a hierarchical process execution support for grid computing. grid is an emerging infrastructure used to share resources among virtual organizations in a seamless manner and to provide breakthrough computing power at low cost. nowadays there are dozens of academic and commercial products that allow execution of isolated tasks on grids but few products support the enactment of long running processes in a distributed fashion. in order to address such subject this paper presents a programming model and an infrastructure that hierarchically schedules process activities using available nodes in a wide grid environment. their advantages are automatic and structured distribution of activities and easy process monitoring and steering.
semeval,train_C_57,congestion games with load dependent failures identical resources. we define a new class of games congestion games with loaddependent failures cglfs which generalizes the well known class of congestion games by incorporating the issue of resource failures into congestion games. in a cglf agents share a common set of resources where each resource has a cost and a probability of failure. each agent chooses a subset of the resources for the execution of his task in order to maximize his own utility. the utility of an agent is the difference between his benefit from successful task completion and the sum of the costs over the resources he uses. cglfs possess two novel features. it is the first model to incorporate failures into congestion settings which results in a strict generalization of congestion games. in addition it is the first model to consider load dependent failures in such framework where the failure probability of each resource depends on the number of agents selecting this resource. although as we show cglfs do not admit a potential function and in general do not have a pure strategy nash equilibrium our main theorem proves the existence of a pure strategy nash equilibrium in every cglf with identical resources and nondecreasing cost functions.
semeval,train_C_58,a scalable distributed information management system. we present a scalable distributed information management system sdims that aggregates information about large scale networked systems and that can serve as a basic building block for a broad range of large scale distributed applications by providing detailed views of nearby information and summary views of global information. to serve as a basic building block a sdims should have four properties scalability to many nodes and attributes flexibility to accommodate a broad range of applications administrative isolation for security and availability and robustness to node and network failures. we design implement and evaluate a sdims that 1 leverages distributed hash tables dht to create scalable aggregation trees 2 provides flexibility through a simple api that lets applications control propagation of reads and writes 3 provides administrative isolation through simple extensions to current dht algorithms and 4 achieves robustness to node and network reconfigurations through lazy reaggregation on demand reaggregation and tunable spatial replication. through extensive simulations and micro benchmark experiments we observe that our system is an order of magnitude more scalable than existing approaches achieves isolation properties at the cost of modestly increased read latency in comparison to flat dhts and gracefully handles failures.
semeval,train_C_61,authority assignment in distributed multi player proxy based games. we present a proxy based gaming architecture and authority assignment within this architecture that can lead to better game playing experience in massively multi player online games. the proposed game architecture consists of distributed game clients that connect to game proxies referred to as communication proxies which forward game related messages from the clients to one or more game servers. unlike proxy based architectures that have been proposed in the literature where the proxies replicate all of the game state the communication proxies in the proposed architecture support clients that are in proximity to it in the physical network and maintain information about selected portions of the game space that are relevant only to the clients that they support. using this architecture we propose an authority assignment mechanism that divides the authority for deciding the outcome of different actions events that occur within the game between client and servers on a per action event basis. we show that such division of authority leads to a smoother game playing experience by implementing this mechanism in a massively multi player online game called rpgquest. in addition we argue that cheat detection techniques can be easily implemented at the communication proxies if they are made aware of the game play mechanics.
semeval,train_C_62,network monitors and contracting systems competition and innovation. today s internet industry suffers from several well known pathologies but none is as destructive in the long term as its resistance to evolution. rather than introducing new services isps are presently moving towards greater commoditization. it is apparent that the network s primitive system of contracts does not align incentives properly. in this study we identify the network s lack of accountability as a fundamental obstacle to correcting this problem employing an economic model we argue that optimal routes and innovation are impossible unless new monitoring capability is introduced and incorporated with the contracting system. furthermore we derive the minimum requirements a monitoring system must meet to support first best routing and innovation characteristics. our work does not constitute a new protocol rather we provide practical and specific guidance for the design of monitoring systems as well as a theoretical framework to explore the factors that influence innovation.
semeval,train_C_65,shooter localization and weapon classification with soldier wearable networked sensors. the paper presents a wireless sensor network based mobile countersniper system. a sensor node consists of a helmetmounted microphone array a cots micaz mote for internode communication and a custom sensorboard that implements the acoustic detection and time of arrival toa estimation algorithms on an fpga. a 3 axis compass provides self orientation and bluetooth is used for communication with the soldier s pda running the data fusion and the user interface. the heterogeneous sensor fusion algorithm can work with data from a single sensor or it can fuse toa or angle of arrival aoa observations of muzzle blasts and ballistic shockwaves from multiple sensors. the system estimates the trajectory the range the caliber and the weapon type. the paper presents the system design and the results from an independent evaluation at the us army aberdeen test center. the system performance is characterized by 1degree trajectory precision and over 95 caliber estimation accuracy for all shots and close to 100 weapon estimation accuracy for 4 out of 6 guns tested.
semeval,train_C_66,heuristics based scheduling of composite web service workloads. web services can be aggregated to create composite workflows that provide streamlined functionality for human users or other systems. although industry standards and recent research have sought to define best practices and to improve end to end workflow composition one area that has not fully been explored is the scheduling of a workflow s web service requests to actual service provisioning in a multi tiered multi organisation environment. this issue is relevant to modern business scenarios where business processes within a workflow must complete within qos defined limits. because these business processes are web service consumers service requests must be mapped and scheduled across multiple web service providers each with its own negotiated service level agreement. in this paper we provide heuristics for scheduling service requests from multiple business process workflows to web service providers such that a business value metric across all workflows is maximised. we show that a genetic search algorithm is appropriate to perform this scheduling and through experimentation we show that our algorithm scales well up to a thousand workflows and produces better mappings than traditional approaches.
semeval,train_C_67,a holistic approach to high performance computing xgrid experience. the ringling school of art and design is a fully accredited fouryear college of visual arts and design. with a student to computer ratio of better than 2 to 1 the ringling school has achieved national recognition for its large scale integration of technology into collegiate visual art and design education. we have found that mac os x is the best operating system to train future artists and designers. moreover we can now buy macs to run high end graphics nonlinear video editing animation multimedia web production and digital video applications rather than expensive unix workstations. as visual artists cross from paint on canvas to creating in the digital realm the demand for a highperformance computing environment grows. in our public computer laboratories students use the computers most often during the workday at night and on weekends the computers see only light use. in order to harness the lost processing time for tasks such as video rendering we are testing xgrid a suite of mac os x applications recently developed by apple for parallel and distributed high performance computing. as with any new technology deployment it managers need to consider a number of factors as they assess plan and implement xgrid. therefore we would like to share valuable information we learned from our implementation of an xgrid environment with our colleagues. in our report we will address issues such as assessing the needs for grid computing potential applications management tools security authentication integration into existing infrastructure application support user training and user support. furthermore we will discuss the issues that arose and the lessons learned during and after the implementation process.
semeval,train_C_68,an evaluation of availability latency in carrier based vehicular ad hoc networks shahram. on demand delivery of audio and video clips in peer to peer vehicular ad hoc networks is an emerging area of research. our target environment uses data carriers termed zebroids where a mobile device carries a data item on behalf of a server to a client thereby minimizing its availability latency. in this study we quantify the variation in availability latency with zebroids as a function of a rich set of parameters such as car density storage per device repository size and replacement policies employed by zebroids. using analysis and extensive simulations we gain novel insights into the design of carrier based systems. significant improvements in latency can be obtained with zebroids at the cost of a minimal overhead. these improvements occur even in scenarios with lower accuracy in the predictions of the car routes. two particularly surprising findings are 1 a naive random replacement policy employed by the zebroids shows competitive performance and 2 latency improvements obtained with a simplified instantiation of zebroids are found to be robust to changes in the popularity distribution of the data items. categories and subject descriptors c 2 4 distributed systems client server.
semeval,train_C_69,pthinc a thin client architecture for mobile wireless web. although web applications are gaining popularity on mobile wireless pdas web browsers on these systems can be quite slow and often lack adequate functionality to access many web sites. we have developed pthinc a pda thinclient solution that leverages more powerful servers to run full function web browsers and other application logic then sends simple screen updates to the pda for display. pthinc uses server side screen scaling to provide high fidelity display and seamless mobility across a broad range of different clients and screen sizes including both portrait and landscape viewing modes. pthinc also leverages existing pda control buttons to improve system usability and maximize available screen resolution for application display. we have implemented pthinc on windows mobile and evaluated its performance on mobile wireless devices. our results compared to local pda web browsers and other thin client approaches demonstrate that pthinc provides superior web browsing performance and is the only pda thin client that effectively supports crucial browser helper applications such as video playback. categories and subject descriptors c 2 4 computercommunication networks distributed systems client server.
semeval,train_C_71,a point distribution index and its application to sensor grouping in wireless sensor networks. we propose t a novel index for evaluation of point distribution. t is the minimum distance between each pair of points normalized by the average distance between each pair of points. we find that a set of points that achieve a maximum value of t result in a honeycomb structure. we propose that t can serve as a good index to evaluate the distribution of the points which can be employed in coverage related problems in wireless sensor networks wsns. to validate this idea we formulate a general sensorgrouping problem for wsns and provide a general sensing model. we show that locally maximizing t at sensor nodes is a good approach to solve this problem with an algorithm called maximizingt node deduction mind. simulation results verify that mind outperforms a greedy algorithm that exploits sensor redundancy we design. this demonstrates a good application of employing t in coverage related problems for wsns.
semeval,train_C_72,guess gossiping updates for efficient spectrum sensing. wireless radios of the future will likely be frequency agile that is supporting opportunistic and adaptive use of the rf spectrum. such radios must coordinate with each other to build an accurate and consistent map of spectral utilization in their surroundings. we focus on the problem of sharing rf spectrum data among a collection of wireless devices. the inherent requirements of such data and the time granularity at which it must be collected makes this problem both interesting and technically challenging. we propose guess a novel incremental gossiping approach to coordinated spectral sensing. it 1 reduces protocol overhead by limiting the amount of information exchanged between participating nodes 2 is resilient to network alterations due to node movement or node failures and 3 allows exponentially fast information convergence. we outline an initial solution incorporating these ideas and also show how our approach reduces network overhead by up to a factor of 2 4 and results in up to 2 7 times faster information convergence than alternative approaches.
semeval,train_C_74,adapting asynchronous messaging middleware to ad hoc networking. the characteristics of mobile environments with the possibility of frequent disconnections and fluctuating bandwidth have forced a rethink of traditional middleware. in particular the synchronous communication paradigms often employed in standard middleware do not appear to be particularly suited to ad hoc environments in which not even the intermittent availability of a backbone network can be assumed. instead asynchronous communication seems to be a generally more suitable paradigm for such environments. message oriented middleware for traditional systems has been developed and used to provide an asynchronous paradigm of communication for distributed systems and recently also for some specific mobile computing systems. in this paper we present our experience in designing implementing and evaluating emma epidemic messaging middleware for ad hoc networks an adaptation of java message service jms for mobile ad hoc environments. we discuss in detail the design challenges and some possible solutions showing a concrete example of the feasibility and suitability of the application of the asynchronous paradigm in this setting and outlining a research roadmap for the coming years.
semeval,train_C_75,composition of a dids by integrating heterogeneous idss on grids. this paper considers the composition of a dids distributed intrusion detection system by integrating heterogeneous idss intrusion detection systems. a grid middleware is used for this integration. in addition an architecture for this integration is proposed and validated through simulation.
semeval,train_C_76,assured service quality by improved fault management service oriented event correlation. the paradigm shift from device oriented to service oriented management has also implications to the area of event correlation. today s event correlation mainly addresses the correlation of events as reported from management tools. however a correlation of user trouble reports concerning services should also be performed. this is necessary to improve the resolution time and to reduce the effort for keeping the service agreements. we refer to such a type of correlation as service oriented event correlation. the necessity to use this kind of event correlation is motivated in the paper. to introduce service oriented event correlation for an it service provider an appropriate modeling of the correlation workflow and of the information is necessary. therefore we examine the process management frameworks it infrastructure library itil and enhanced telecom operations map etom for their contribution to the workflow modeling in this area. the different kinds of dependencies that we find in our general scenario are then used to develop a workflow for the service oriented event correlation. the mnm service model which is a generic model for it service management proposed by the munich network management mnm team is used to derive an appropriate information modeling. an example scenario the web hosting service of the leibniz supercomputing center lrz is used to demonstrate the application of service oriented event correlation.
semeval,train_C_77,tracking immediate predecessors in distributed computations. a distributed computation is usually modeled as a partially ordered set of relevant events the relevant events are a subset of the primitive events produced by the computation. an important causality related distributed computing problem that we call the immediate predecessors tracking ipt problem consists in associating with each relevant event on the fly and without using additional control messages the set of relevant events that are its immediate predecessors in the partial order. so ipt is the on the fly computation of the transitive reduction i e hasse diagram of the causality relation defined by a distributed computation. this paper addresses the ipt problem it presents a family of protocols that provides each relevant event with a timestamp that exactly identifies its immediate predecessors. the family is defined by a general condition that allows application messages to piggyback control information whose size can be smaller than n the number of processes. in that sense this family defines message size efficient ipt protocols. according to the way the general condition is implemented different ipt protocols can be obtained. two of them are exhibited.
semeval,train_C_78,an architectural framework and a middleware for cooperating smart components. u lisboa u ulm u lisboa casim di fc ul pt kaiser informatik uni pjv di fc ul pt ulm de. in a future networked physical world a myriad of smart sensors and actuators assess and control aspects of their environments and autonomously act in response to it. examples range in telematics traffic management team robotics or home automation to name a few. to a large extent such systems operate proactively and independently of direct human control driven by the perception of the environment and the ability to organize respective computations dynamically. the challenging characteristics of these applications include sentience and autonomy of components issues of responsiveness and safety criticality geographical dispersion mobility and evolution. a crucial design decision is the choice of the appropriate abstractions and interaction mechanisms. looking to the basic building blocks of such systems we may find components which comprise mechanical components hardware and software and a network interface thus these components have different characteristics compared to pure software components. they are able to spontaneously disseminate information in response to events observed in the physical environment or to events received from other component via the network interface. larger autonomous components may be composed recursively from these building blocks. the paper describes an architectural framework and a middleware supporting a component based system and an integrated view on events based communication comprising the real world events and the events generated in the system. it starts by an outline of the component based system construction. the generic event architecture gear is introduced which describes the event based interaction between the components via a generic event layer. the generic event layer hides the different communication channels including this work was partially supported by the ec through project ist 2000 26031 cortex and by the fct through the large scale informatic systems laboratory lasige and project posi 1999 chs 33996 defeats. the interactions through the environment. an appropriate middleware is presented which reflects these needs and allows to specify events which have quality attributes to express temporal constraints. this is complemented by the notion of event channels which are abstractions of the underlying network and allow to enforce quality attributes. they are established prior to interaction to reserve the needed computational and network resources for highly predictable event dissemination.
semeval,train_C_79,a cross layer approach to resource discovery and distribution in mobile ad hoc networks. this paper describes a cross layer approach to designing robust p2p system over mobile ad hoc networks. the design is based on simple functional primitives that allow routing at both p2p and network layers to be integrated to reduce overhead. with these primitives the paper addresses various load balancing techniques. preliminary simulation results are also presented.
semeval,train_C_80,consistency preserving caching of dynamic database content. with the growing use of dynamic web content generated from relational databases traditional caching solutions for throughput and latency improvements are ineffective. we describe a middleware layer called ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results. it achieves this reduction through the use of cryptographic hashing to detect similarities with previous results. these benefits do not require any compromise of the strict consistency semantics provided by the back end database. further ganesh does not require modifications to applications web servers or database servers and works with closed source applications and databases. using two benchmarks representative of dynamic web sites measurements of our prototype show that it can increase end to end throughput by as much as twofold for non data intensive applications and by as much as tenfold for data intensive ones.
semeval,train_C_81,adaptive duty cycling for energy harvesting systems. jasonh kansal szahedi mbs ee ucla edu vijay nec labs com. harvesting energy from the environment is feasible in many applications to ameliorate the energy limitations in sensor networks. in this paper we present an adaptive duty cycling algorithm that allows energy harvesting sensor nodes to autonomously adjust their duty cycle according to the energy availability in the environment. the algorithm has three objectives namely a achieving energy neutral operation i e energy consumption should not be more than the energy provided by the environment b maximizing the system performance based on an application utility model subject to the above energyneutrality constraint and c adapting to the dynamics of the energy source at run time. we present a model that enables harvesting sensor nodes to predict future energy opportunities based on historical data. we also derive an upper bound on the maximum achievable performance assuming perfect knowledge about the future behavior of the energy source. our methods are evaluated using data gathered from a prototype solar energy harvesting platform and we show that our algorithm can utilize up to 58 more environmental energy compared to the case when harvesting aware power management is not used.
semeval,train_C_83,concept and architecture of a pervasive document editing and managing system. collaborative document processing has been addressed by many approaches so far most of which focus on document versioning and collaborative editing. we address this issue from a different angle and describe the concept and architecture of a pervasive document editing and managing system. it exploits database techniques and real time updating for sophisticated collaboration scenarios on multiple devices. each user is always served with upto date documents and can organize his work based on document meta data. for this we present our conceptual architecture for such a system and discuss it with an example.
semeval,train_C_84,selfish caching in distributed systems a game theoretic analysis. we analyze replication of resources by server nodes that act selfishly using a game theoretic approach. we refer to this as the selfish caching problem. in our model nodes incur either cost for replicating resources or cost for access to a remote replica. we show the existence of pure strategy nash equilibria and investigate the price of anarchy which is the relative cost of the lack of coordination. the price of anarchy can be high due to undersupply problems but with certain network topologies it has better bounds. with a payment scheme the game can always implement the social optimum in the best case by giving servers incentive to replicate.
semeval,train_H_35,adarank a boosting algorithm for information retrieval. in this paper we address the issue of learning to rank for document retrieval. in the task a model is automatically created with some training data and then is utilized for ranking of documents. the goodness of a model is usually evaluated with performance measures such as map mean average precision and ndcg normalized discounted cumulative gain. ideally a learning algorithm would train a ranking model that could directly optimize the performance measures with respect to the training data. existing methods however are only able to train ranking models by minimizing loss functions loosely related to the performance measures. for example ranking svm and rankboost train ranking models by minimizing classification errors on instance pairs. to deal with the problem we propose a novel learning algorithm within the framework of boosting which can minimize a loss function directly defined on the performance measures. our algorithm referred to as adarank repeatedly constructs weak rankers on the basis of re weighted training data and finally linearly combines the weak rankers for making ranking predictions. we prove that the training process of adarank is exactly that of enhancing the performance measure used. experimental results on four benchmark datasets show that adarank significantly outperforms the baseline methods of bm25 ranking svm and rankboost.
semeval,train_H_37,relaxed online svms for spam filtering. spam is a key problem in electronic communication including large scale email systems and the growing number of blogs. content based filtering is one reliable method of combating this threat in its various forms but some academic researchers and industrial practitioners disagree on how best to filter spam. the former have advocated the use of support vector machines svms for content based filtering as this machine learning methodology gives state of the art performance for text classification. however similar performance gains have yet to be demonstrated for online spam filtering. additionally practitioners cite the high cost of svms as reason to prefer faster if less statistically robust bayesian methods. in this paper we offer a resolution to this controversy. first we show that online svms indeed give state of the art classification performance on online spam filtering on large benchmark data sets. second we show that nearly equivalent performance may be achieved by a relaxed online svm rosvm at greatly reduced computational cost. our results are experimentally verified on email spam blog spam and splog detection tasks.
semeval,train_H_38,diffusionrank a possible penicillin for web spamming. while the pagerank algorithm has proven to be very effective for ranking web pages the rank scores of web pages can be manipulated. to handle the manipulation problem and to cast a new insight on the web structure we propose a ranking algorithm called diffusionrank. diffusionrank is motivated by the heat diffusion phenomena which can be connected to web ranking because the activities flow on the web can be imagined as heat flow the link from a page to another can be treated as the pipe of an air conditioner and heat flow can embody the structure of the underlying web graph. theoretically we show that diffusionrank can serve as a generalization of pagerank when the heat diffusion coefficient y tends to infinity. in such a case 1  y 0 diffusionrank pagerank has low ability of anti manipulation. when y 0 diffusionrank obtains the highest ability of anti manipulation but in such a case the web structure is completely ignored. consequently  y is an interesting factor that can control the balance between the ability of preserving the original web and the ability of reducing the effect of manipulation. it is found empirically that when y 1 diffusionrank has a penicillin like effect on the link manipulation. moreover diffusionrank can be employed to find group to group relations on the web to divide the web graph into several parts and to find link communities. experimental results show that the diffusionrank algorithm achieves the above mentioned advantages as expected.
semeval,train_H_40,cross lingual query suggestion using query logs of different languages. query suggestion aims to suggest relevant queries for a given query which help users better specify their information needs. previously the suggested terms are mostly in the same language of the input query. in this paper we extend it to cross lingual query suggestion clqs for a query in one language we suggest similar or relevant queries in other languages. this is very important to scenarios of cross language information retrieval clir and cross lingual keyword bidding for search engine advertisement. instead of relying on existing query translation technologies for clqs we present an effective means to map the input query of one language to queries of the other language in the query log. important monolingual and cross lingual information such as word translation relations and word co occurrence statistics etc are used to estimate the cross lingual query similarity with a discriminative model. benchmarks show that the resulting clqs system significantly outperforms a baseline system based on dictionary based query translation. besides the resulting clqs is tested with french to english clir tasks on trec collections. the results demonstrate higher effectiveness than the traditional query translation methods.
semeval,train_H_41,sigir 2007 proceedings session 20 link analysis hits on the web how does it compare.. this paper describes a large scale evaluation of the effectiveness of hits in comparison with other link based ranking algorithms when used in combination with a state ofthe art text retrieval algorithm exploiting anchor text. we quantified their effectiveness using three common performance measures the mean reciprocal rank the mean average precision and the normalized discounted cumulative gain measurements. the evaluation is based on two large data sets a breadth first search crawl of 463 million web pages containing 17 6 billion hyperlinks and referencing 2 9 billion distinct urls and a set of 28 043 queries sampled from a query log each query having on average 2 383 results about 17 of which were labeled by judges. we found that hits outperforms pagerank but is about as effective as web page in degree. the same holds true when any of the link based features are combined with the text retrieval algorithm. finally we studied the relationship between query specificity and the effectiveness of selected features and found that link based features perform better for general queries whereas bm25f performs better for specific queries.
semeval,train_H_42,hits hits trec exploring ir evaluation results with network analysis. we propose a novel method of analysing data gathered from trec or similar information retrieval evaluation experiments. we define two normalized versions of average precision that we use to construct a weighted bipartite graph of trec systems and topics. we analyze the meaning of well known and somewhat generalized indicators from social network analysis on the systems topics graph. we apply this method to an analysis of trec 8 data among the results we find that authority measures systems performance that hubness of topics reveals that some topics are better than others at distinguishing more or less effective systems that with current measures a system that wants to be effective in trec needs to be effective on easy topics and that by using different effectiveness measures this is no longer the case.
semeval,train_H_43,combining content and link for classification using matrix factorization. the world wide web contains rich textual contents that are interconnected via complex hyperlinks. this huge database violates the assumption held by most of conventional statistical methods that each web page is considered as an independent and identical sample. it is thus difficult to apply traditional mining or learning methods for solving web mining problems e g web page classification by exploiting both the content and the link structure. the research in this direction has recently received considerable attention but are still in an early stage. though a few methods exploit both the link structure or the content information some of them combine the only authority information with the content information and the others first decompose the link structure into hub and authority features then apply them as additional document features. being practically attractive for its great simplicity this paper aims to design an algorithm that exploits both the content and linkage information by carrying out a joint factorization on both the linkage adjacency matrix and the document term matrix and derives a new representation for web pages in a low dimensional factor space without explicitly separating them as content hub or authority factors. further analysis can be performed based on the compact representation of web pages. in the experiments the proposed method is compared with state of the art methods and demonstrates an excellent accuracy in hypertext classification on the webkb and cora benchmarks.
semeval,train_H_44,a time machine for text search. text search over temporally versioned document collections such as web archives has received little attention as a research problem. as a consequence there is no scalable and principled solution to search such a collection as of a specified time t. in this work we address this shortcoming and propose an efficient solution for time travel text search by extending the inverted file index to make it ready for temporal search. we introduce approximate temporal coalescing as a tunable method to reduce the index size without significantly affecting the quality of results. in order to further improve the performance of time travel queries we introduce two principled techniques to trade off index size for its performance. these techniques can be formulated as optimization problems that can be solved to near optimality. finally our approach is evaluated in a comprehensive series of experiments on two large scale real world datasets. results unequivocally show that our methods make it possible to build an efficient time machine scalable to large versioned text collections.
semeval,train_H_45,query performance prediction in web search environments. current prediction techniques which are generally designed for content based queries and are typically evaluated on relatively homogenous test collections of small sizes face serious challenges in web search environments where collections are significantly more heterogeneous and different types of retrieval tasks exist. in this paper we present three techniques to address these challenges. we focus on performance prediction for two types of queries in web search environments content based and named page finding. our evaluation is mainly performed on the gov2 collection. in addition to evaluating our models for the two types of queries separately we consider a more challenging and realistic situation that the two types of queries are mixed together without prior information on query types. to assist prediction under the mixed query situation a novel query classifier is adopted. results show that our prediction of web query performance is substantially more accurate than the current stateof the art prediction techniques. consequently our paper provides a practical approach to performance prediction in realworld web settings.
semeval,train_H_46,broad expertise retrieval in sparse data environments. expertise retrieval has been largely unexplored on data other than the w3c collection. at the same time many intranets of universities and other knowledge intensive organisations offer examples of relatively small but clean multilingual expertise data covering broad ranges of expertise areas. we first present two main expertise retrieval tasks along with a set of baseline approaches based on generative language modeling aimed at finding expertise relations between topics and people. for our experimental evaluation we introduce and release a new test set based on a crawl of a university site. using this test set we conduct two series of experiments. the first is aimed at determining the effectiveness of baseline expertise retrieval methods applied to the new test set. the second is aimed at assessing refined models that exploit characteristic features of the new test set such as the organizational structure of the university and the hierarchical structure of the topics in the test set. expertise retrieval models are shown to be robust with respect to environments smaller than the w3c collection and current techniques appear to be generalizable to other settings.
semeval,train_H_47,a semantic approach to contextual advertising. contextual advertising or context match cm refers to the placement of commercial textual advertisements within the content of a generic web page while sponsored search ss advertising consists in placing ads on result pages from a web search engine with ads driven by the originating query. in cm there is usually an intermediary commercial ad network entity in charge of optimizing the ad selection with the twin goal of increasing revenue shared between the publisher and the ad network and improving the user experience. with these goals in mind it is preferable to have ads relevant to the page content rather than generic ads. the ss market developed quicker than the cm market and most textual ads are still characterized by bid phrases representing those queries where the advertisers would like to have their ad displayed. hence the first technologies for cm have relied on previous solutions for ss by simply extracting one or more phrases from the given page content and displaying ads corresponding to searches on these phrases in a purely syntactic approach. however due to the vagaries of phrase extraction and the lack of context this approach leads to many irrelevant ads. to overcome this problem we propose a system for contextual ad matching based on a combination of semantic and syntactic features.
semeval,train_H_48,a new approach for evaluating query expansion query document term mismatch. the effectiveness of information retrieval ir systems is influenced by the degree of term overlap between user queries and relevant documents. query document term mismatch whether partial or total is a fact that must be dealt with by ir systems. query expansion qe is one method for dealing with term mismatch. ir systems implementing query expansion are typically evaluated by executing each query twice with and without query expansion and then comparing the two result sets. while this measures an overall change in performance it does not directly measure the effectiveness of ir systems in overcoming the inherent issue of term mismatch between the query and relevant documents nor does it provide any insight into how such systems would behave in the presence of query document term mismatch. in this paper we propose a new approach for evaluating query expansion techniques. the proposed approach is attractive because it provides an estimate of system performance under varying degrees of query document term mismatch it makes use of readily available test collections and it does not require any additional relevance judgments or any form of manual processing.
semeval,train_H_49,performance prediction using spatial autocorrelation. evaluation of information retrieval systems is one of the core tasks in information retrieval. problems include the inability to exhaustively label all documents for a topic nongeneralizability from a small number of topics and incorporating the variability of retrieval systems. previous work addresses the evaluation of systems the ranking of queries by difficulty and the ranking of individual retrievals by performance. approaches exist for the case of few and even no relevance judgments. our focus is on zero judgment performance prediction of individual retrievals. one common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments. if documents are embedded in a high dimensional space as they often are we can apply techniques from spatial data analysis to detect correlations between document scores. we find that the low correlation between scores of topically close documents often implies a poor retrieval performance. when compared to a state of the art baseline we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance. these new predictors can also be incorporated with classic predictors to improve performance further. we also describe the first large scale experiment to evaluate zero judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.
semeval,train_H_50,an outranking approach for rank aggregation in information retrieval. research in information retrieval usually shows performance improvement when many sources of evidence are combined to produce a ranking of documents e g texts pictures sounds etc. in this paper we focus on the rank aggregation problem also called data fusion problem where rankings of documents searched into the same collection and provided by multiple methods are combined in order to produce a new ranking. in this context we propose a rank aggregation method within a multiple criteria framework using aggregation mechanisms based on decision rules identifying positive and negative reasons for judging whether a document should get a better rank than another. we show that the proposed method deals well with the information retrieval distinctive features. experimental results are reported showing that the suggested method performs better than the well known combsum and combmnz operators.
semeval,train_H_52,vocabulary independent spoken term detection. we are interested in retrieving information from speech data like broadcast news telephone conversations and roundtable meetings. today most systems use large vocabulary continuous speech recognition tools to produce word transcripts the transcripts are indexed and query terms are retrieved from the index. however query terms that are not part of the recognizer s vocabulary can not be retrieved and the recall of the search is affected. in addition to the output word transcript advanced systems provide also phonetic transcripts against which query terms can be matched phonetically. such phonetic transcripts suffer from lower accuracy and can not be an alternative to word transcripts. we present a vocabulary independent system that can handle arbitrary queries exploiting the information provided by having both word transcripts and phonetic transcripts. a speech recognizer generates word confusion networks and phonetic lattices. the transcripts are indexed for query processing and ranking purpose. the value of the proposed method is demonstrated by the relative high performance of our system which received the highest overall ranking for us english speech data in the recent nist spoken term detection evaluation 1.
semeval,train_H_53,context sensitive stemming for web search. traditionally stemming has been applied to information retrieval tasks by transforming words in documents to the their root form before indexing and applying a similar transformation to query terms. although it increases recall this naive strategy does not work well for web search since it lowers precision and requires a significant amount of additional computation. in this paper we propose a context sensitive stemming method that addresses these two issues. two unique properties make our approach feasible for web search. first based on statistical language modeling we perform context sensitive analysis on the query side. we accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine. this dramatically reduces the number of bad expansions which in turn reduces the cost of additional computation and improves the precision at the same time. second our approach performs a context sensitive document matching for those expanded variants. this conservative strategy serves as a safeguard against spurious stemming and it turns out to be very important for improving precision. using word pluralization handling as an example of our stemming approach our experiments on a major web search engine show that stemming only 29 of the query traffic we can improve relevance as measured by average discounted cumulative gain dcg5 by 6 1 on these queries and 1 8 over all query traffic.
semeval,train_H_54,knowledge intensive conceptual retrieval and passage extraction of biomedical literature. this paper presents a study of incorporating domain specific knowledge i e information about concepts and relationships between concepts in a certain domain in an information retrieval ir system to improve its effectiveness in retrieving biomedical literature. the effects of different types of domain specific knowledge in performance contribution are examined. based on the trec platform we show that appropriate use of domainspecific knowledge in a proposed conceptual retrieval model yields about 23 improvement over the best reported result in passage retrieval in the genomics track of trec 2006.
semeval,train_H_60,a frequency based and a poisson based definition of the probability of being informative. this paper reports on theoretical investigations about the assumptions underlying the inverse document frequency idf. we show that an intuitive idf based probability function for the probability of a term being informative assumes disjoint document events. by assuming documents to be independent rather than disjoint we arrive at a poisson based probability of being informative. the framework is useful for understanding and deciding the parameter estimation and combination in probabilistic retrieval models.
semeval,train_H_61,impedance coupling in content targeted advertising. the current boom of the web is associated with the revenues originated from on line advertising. while search based advertising is dominant the association of ads with a web page during user navigation is becoming increasingly important. in this work we study the problem of associating ads with a web page referred to as content targeted advertising from a computer science perspective. we assume that we have access to the text of the web page the keywords declared by an advertiser and a text associated with the advertiser s business. using no other information and operating in fully automatic fashion we propose ten strategies for solving the problem and evaluate their effectiveness. our methods indicate that a matching strategy that takes into account the semantics of the problem referred to as aak for ads and keywords can yield gains in average precision figures of 60 compared to a trivial vector based strategy. further a more sophisticated impedance coupling strategy which expands the text of the web page to reduce vocabulary impedance with regard to an advertisement can yield extra gains in average precision of 50. these are first results. they suggest that great accuracy in content targeted advertising can be attained with appropriate algorithms.
semeval,train_H_62,implicit user modeling for personalized search. information retrieval systems e g web search engines are critical for overcoming information overload. a major deficiency of existing retrieval systems is that they generally lack user modeling and are not adaptive to individual users resulting in inherently non optimal retrieval performance. for example a tourist and a programmer may use the same word java to search for different information but the current search systems would return the same results. in this paper we study how to infer a user s interest from the user s search context and use the inferred implicit user model for personalized search. we present a decision theoretic framework and develop techniques for implicit user modeling in information retrieval. we develop an intelligent client side web search agent ucair that can perform eager implicit feedback e g query expansion based on previous queries and immediate result reranking based on clickthrough information. experiments on web search show that our search agent can improve search accuracy over the popular google search engine.
semeval,train_H_63,location based indexing scheme for days. data dissemination through wireless channels for broadcasting information to consumers is becoming quite common. many dissemination schemes have been proposed but most of them push data to wireless channels for general consumption. push based broadcast 1 is essentially asymmetric i e the volume of data being higher from the server to the users than from the users back to the server. push based scheme requires some indexing which indicates when the data will be broadcast and its position in the broadcast. access latency and tuning time are the two main parameters which may be used to evaluate an indexing scheme. two of the important indexing schemes proposed earlier were tree based and the exponential indexing schemes. none of these schemes were able to address the requirements of location dependent data ldd which is highly desirable feature of data dissemination. in this paper we discuss the broadcast of ldd in our project data in your space days and propose a scheme for indexing ldd. we argue that this scheme when applied to ldd significantly improves performance in terms of tuning time over the above mentioned schemes. we prove our argument with the help of simulation results.
semeval,train_H_64,machine learning for information architecture in a large governmental website. this paper describes ongoing research into the application of machine learning techniques for improving access to governmental information in complex digital libraries. under the auspices of the govstat project our goal is to identify a small number of semantically valid concepts that adequately spans the intellectual domain of a collection. the goal of this discovery is twofold. first we desire a practical aid for information architects. second automatically derived documentconcept relationships are a necessary precondition for realworld deployment of many dynamic interfaces. the current study compares concept learning strategies based on three document representations keywords titles and full text. in statistical and user based studies human created keywords provide significant improvements in concept learning over both title only and full text representations.
semeval,train_H_69,ranking web objects from multiple communities. vertical search is a promising direction as it leverages domainspecific knowledge and can provide more precise information for users. in this paper we study the web object ranking problem one of the key issues in building a vertical search engine. more specifically we focus on this problem in cases when objects lack relationships between different web communities and take high quality photo search as the test bed for this investigation. we proposed two score fusion methods that can automatically integrate as many web communities web forums with rating information as possible. the proposed fusion methods leverage the hidden links discovered by a duplicate photo detection algorithm and aims at minimizing score differences of duplicate photos in different forums. both intermediate results and user studies show the proposed fusion methods are practical and efficient solutions to web object ranking in cases we have described. though the experiments were conducted on high quality photo ranking the proposed algorithms are also applicable to other ranking problems such as movie ranking and music ranking.
semeval,train_H_73,unified utility maximization framework for resource selection. this paper presents a unified utility framework for resource selection of distributed text information retrieval. this new framework shows an efficient and effective way to infer the probabilities of relevance of all the documents across the text databases. with the estimated relevance information resource selection can be made by explicitly optimizing the goals of different applications. specifically when used for database recommendation the selection is optimized for the goal of highrecall include as many relevant documents as possible in the selected databases when used for distributed document retrieval the selection targets the high precision goal high precision in the final merged list of documents. this new model provides a more solid framework for distributed information retrieval. empirical studies show that it is at least as effective as other state of the art algorithms.
semeval,train_H_77,automatic extraction of titles from general documents using machine learning. in this paper we propose a machine learning approach to title extraction from general documents. by general documents we mean documents that can belong to any one of a number of specific genres including presentations book chapters technical papers brochures reports and letters. previously methods have been proposed mainly for title extraction from research papers. it has not been clear whether it could be possible to conduct automatic title extraction from general documents. as a case study we consider extraction from office including word and powerpoint. in our approach we annotate titles in sample documents for word and powerpoint respectively and take them as training data train machine learning models and perform title extraction using the trained models. our method is unique in that we mainly utilize formatting information such as font size as features in the models. it turns out that the use of formatting information can lead to quite accurate extraction from general documents. precision and recall for title extraction from word is 0 810 and 0 837 respectively and precision and recall for title extraction from powerpoint is 0 875 and 0 895 respectively in an experiment on intranet data. other important new findings in this work include that we can train models in one domain and apply them to another domain and more surprisingly we can even train models in one language and apply them to another language. moreover we can significantly improve search ranking results in document retrieval by using the extracted titles.
semeval,train_H_79,beyond pagerank machine learning for static ranking. since the publication of brin and page s paper on pagerank many in the web community have depended on pagerank for the static query independent ordering of web pages. we show that we can significantly outperform pagerank using features that are independent of the link structure of the web. we gain a further boost in accuracy by using data on the frequency at which users visit web pages. we use ranknet a ranking machine learning algorithm to combine these and other static features based on anchor text and domain characteristics. the resulting model achieves a static ranking pairwise accuracy of 67 3 vs 56 7 for pagerank or 50 for random.
semeval,train_H_81,distance measures for mpeg 7 based retrieval. in visual information retrieval the careful choice of suitable proximity measures is a crucial success factor. the evaluation presented in this paper aims at showing that the distance measures suggested by the mpeg 7 group for the visual descriptors can be beaten by general purpose measures. eight visual mpeg 7 descriptors were selected and 38 distance measures implemented. three media collections were created and assessed performance indicators developed and more than 22500 tests performed. additionally a quantisation model was developed to be able to use predicate based distance measures on continuous data as well. the evaluation shows that the distance measures recommended in the mpeg 7 standard are among the best but that other measures perform even better.
semeval,train_H_82,downloading textual hidden web content through keyword queries. an ever increasing amount of information on the web today is available only through search interfaces the users have to type in a set of keywords in a search form in order to access the pages from certain web sites. these pages are often referred to as the hidden web or the deep web. since there are no static links to the hidden web pages search engines can not discover and index such pages and thus do not return them in the results. however according to recent studies the content provided by many hidden web sites is often of very high quality and can be extremely valuable to many users. in this paper we study how we can build an effective hidden web crawler that can autonomously discover and download pages from the hidden web. since the only entry point to a hidden web site is a query interface the main challenge that a hidden web crawler has to face is how to automatically generate meaningful queries to issue to the site. here we provide a theoretical framework to investigate the query generation problem for the hidden web and we propose effective policies for generating queries automatically. our policies proceed iteratively issuing a different query in every iteration. we experimentally evaluate the effectiveness of these policies on 4 real hidden web sites and our results are very promising. for instance in one experiment one of our policies downloaded more than 90 of a hidden web site that contains 14 million documents after issuing fewer than 100 queries.
semeval,train_H_83,estimating the global pagerank of web communities. localized search engines are small scale systems that index a particular community on the web. they offer several benefits over their large scale counterparts in that they are relatively inexpensive to build and can provide more precise and complete search capability over their relevant domains. one disadvantage such systems have over large scale search engines is the lack of global pagerank values. such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole. in this paper we present well motivated algorithms to estimate the global pagerank values of a local domain. the algorithms are all highly scalable in that given a local domain of size n they use o n resources that include computation time bandwidth and storage. we test our methods across a variety of localized domains including site specific domains and topic specific domains. we demonstrate that by crawling as few as n or 2n additional pages our methods can give excellent global pagerank estimates.
semeval,train_H_84,event threading within news topics. with the overwhelming volume of online news available today there is an increasing need for automatic techniques to analyze and present news to the user in a meaningful and efficient manner. previous research focused only on organizing news stories by their topics into a flat hierarchy. we believe viewing a news topic as a flat collection of stories is too restrictive and inefficient for a user to understand the topic quickly. in this work we attempt to capture the rich structure of events and their dependencies in a news topic through our event models. we call the process of recognizing events and their dependencies event threading. we believe our perspective of modeling the structure of a topic is more effective in capturing its semantics than a flat list of on topic stories. we formally define the novel problem suggest evaluation metrics and present a few techniques for solving the problem. besides the standard word based features our approaches take into account novel features such as temporal locality of stories for event recognition and time ordering for capturing dependencies. our experiments on a manually labeled data sets show that our models effectively identify the events and capture dependencies among them.
semeval,train_H_85,learning user interaction models for predicting web search result preferences. evaluating user preferences of web search results is crucial for search engine development deployment and maintenance. we present a real world study of modeling the behavior of web search users to predict web search result preferences. accurate modeling and interpretation of user behavior has important applications to ranking click spam detection web search personalization and other tasks. our key insight to improving robustness of interpreting implicit feedback is to model query dependent deviations from the expected noisy user behavior. we show that our model of clickthrough interpretation improves prediction accuracy over state of the art clickthrough methods. we generalize our approach to model user behavior beyond clickthrough which results in higher preference prediction accuracy than models based on clickthrough information alone. we report results of a large scale experimental evaluation that show substantial improvements over published implicit feedback interpretation methods.
semeval,train_H_87,robustness of adaptive filtering methods in a cross benchmark evaluation. this paper reports a cross benchmark evaluation of regularized logistic regression lr and incremental rocchio for adaptive filtering. using four corpora from the topic detection and tracking tdt forum and the text retrieval conferences trec we evaluated these methods with non stationary topics at various granularity levels and measured performance with different utility settings. we found that lr performs strongly and robustly in optimizing t11su a trec utility function while rocchio is better for optimizing ctrk the tdt tracking cost a high recall oriented objective function. using systematic cross corpus parameter optimization with both methods we obtained the best results ever reported on tdt5 trec10 and trec11. relevance feedback on a small portion 0 05 0 2 of the tdt5 test documents yielded significant performance improvements measuring up to a 54 reduction in ctrk and a 20 9 increase in t11su with β 0 1 compared to the results of the top performing system in tdt2004 without relevance feedback information.
semeval,train_H_88,controlling overlap in content oriented xml retrieval. the direct application of standard ranking techniques to retrieve individual elements from a collection of xml documents often produces a result set in which the top ranks are dominated by a large number of elements taken from a small number of highly relevant documents. this paper presents and evaluates an algorithm that re ranks this result set with the aim of minimizing redundant content while preserving the benefits of element retrieval including the benefit of identifying topic focused components contained within relevant documents. the test collection developed by the initiative for the evaluation of xml retrieval inex forms the basis for the evaluation.
semeval,train_H_90,context sensitive information retrieval using implicit feedback. a major limitation of most existing retrieval models and systems is that the retrieval decision is made based solely on the query and document collection information about the actual user and search context is largely ignored. in this paper we study how to exploit implicit feedback information including previous queries and clickthrough information to improve retrieval accuracy in an interactive information retrieval setting. we propose several contextsensitive retrieval algorithms based on statistical language models to combine the preceding queries and clicked document summaries with the current query for better ranking of documents. we use the trec ap data to create a test collection with search context information and quantitatively evaluate our models using this test set. experiment results show that using implicit feedback especially the clicked document summaries can improve retrieval performance substantially.
semeval,train_H_92,improving web search ranking by incorporating user behavior information. we show that incorporating user behavior data can significantly improve ordering of top results in real web search setting. we examine alternatives for incorporating feedback into the ranking process and explore the contributions of user feedback compared to other common web search features. we report results of a large scale evaluation over 3 000 queries and 12 million user interactions with a popular web search engine. we show that incorporating implicit feedback can augment other features improving the accuracy of a competitive web search ranking algorithms by as much as 31 relative to the original performance.
semeval,train_H_95,handling locations in search engine queries. this paper proposes simple techniques for handling place references in search engine queries an important aspect of geographical information retrieval. we address not only the detection but also the disambiguation of place references by matching them explicitly with concepts at an ontology. moreover when a query does not reference any locations we propose to use information from documents matching the query exploiting geographic scopes previously assigned to these documents. evaluation experiments using topics from clef campaigns and logs from real search engine queries show the effectiveness of the proposed approaches.
semeval,train_H_96,a study of factors affecting the utility of implicit relevance feedback. implicit relevance feedback irf is the process by which a search system unobtrusively gathers evidence on searcher interests from their interaction with the system. irf is a new method of gathering information on user interest and if irf is to be used in operational ir systems it is important to establish when it performs well and when it performs poorly. in this paper we investigate how the use and effectiveness of irf is affected by three factors search task complexity the search experience of the user and the stage in the search. our findings suggest that all three of these factors contribute to the utility of irf.
semeval,train_H_97,feature representation for effective action item detection. e mail users face an ever growing challenge in managing their inboxes due to the growing centrality of email in the workplace for task assignment action requests and other roles beyond information dissemination. whereas information retrieval and machine learning techniques are gaining initial acceptance in spam filtering and automated folder assignment this paper reports on a new task automated action item detection in order to flag emails that require responses and to highlight the specific passage s indicating the request s for action. unlike standard topic driven text classification action item detection requires inferring the sender s intent and as such responds less well to pure bag of words classification. however using enriched feature sets such as n grams up to n 4 with chi squared feature selection and contextual cues for action item location improve performance by up to 10 over unigrams using in both cases state of the art classifiers such as svms with automated model selection via embedded cross validation.
semeval,train_H_98,using asymmetric distributions to improve text classifier probability estimates. text classifiers that give probability estimates are more readily applicable in a variety of scenarios. for example rather than choosing one set decision threshold they can be used in a bayesian risk model to issue a run time decision which minimizes a userspecified cost function dynamically chosen at prediction time. however the quality of the probability estimates is crucial. we review a variety of standard approaches to converting scores and poor probability estimates from text classifiers to high quality estimates and introduce new models motivated by the intuition that the empirical score distribution for the extremely irrelevant  hard to discriminate  and obviously relevant items are often significantly different. finally we analyze the experimental performance of these models over the outputs of two text classifiers. the analysis demonstrates that one of these models is theoretically attractive introducing few new parameters while increasing flexibility computationally efficient and empirically preferable.
semeval,train_I_37,a framework for agent based distributed machine learning and data mining. this paper proposes a framework for agent based distributed machine learning and data mining based on i the exchange of meta level descriptions of individual learning processes among agents and ii online reasoning about learning success and learning progress by learning agents. we present an abstract architecture that enables agents to exchange models of their local learning processes and introduces a number of different methods for integrating these processes. this allows us to apply existing agent interaction mechanisms to distributed machine learning tasks thus leveraging the powerful coordination methods available in agent based computing and enables agents to engage in meta reasoning about their own learning decisions. we apply this architecture to a real world distributed clustering application to illustrate how the conceptual framework can be used in practical systems in which different learners may be using different datasets hypotheses and learning algorithms. we report on experimental results obtained using this system review related work on the subject and discuss potential future extensions to the framework.
semeval,train_I_38,bidding algorithms for a distributed combinatorial auction. distributed allocation and multiagent coordination problems can be solved through combinatorial auctions. however most of the existing winner determination algorithms for combinatorial auctions are centralized. the pause auction is one of a few efforts to release the auctioneer from having to do all the work it might even be possible to get rid of the auctioneer. it is an increasing price combinatorial auction that naturally distributes the problem of winner determination amongst the bidders in such a way that they have an incentive to perform the calculation. it can be used when we wish to distribute the computational load among the bidders or when the bidders do not wish to reveal their true valuations unless necessary. pause establishes the rules the bidders must obey. however it does not tell us how the bidders should calculate their bids. we have developed a couple of bidding algorithms for the bidders in a pause auction. our algorithms always return the set of bids that maximizes the bidder s utility. since the problem is np hard run time remains exponential on the number of items but it is remarkably better than an exhaustive search. in this paper we present our bidding algorithms discuss their virtues and drawbacks and compare the solutions obtained by them to the revenue maximizing solution found by a centralized winner determination algorithm.
semeval,train_I_42,a complete distributed constraint optimization method for non traditional pseudotree arrangements. distributed constraint optimization dcop is a general framework that can model complex problems in multi agent systems. several current algorithms that solve general dcop instances including adopt and dpop arrange agents into a traditional pseudotree structure. we introduce an extension to the dpop algorithm that handles an extended set of pseudotree arrangements. our algorithm correctly solves dcop instances for pseudotrees that include edges between nodes in separate branches. the algorithm also solves instances with traditional pseudotree arrangements using the same procedure as dpop. we compare our algorithm with dpop using several metrics including the induced width of the pseudotrees the maximum dimensionality of messages and computation and the maximum sequential path cost through the algorithm. we prove that for some problem instances it is not possible to generate a traditional pseudotree using edge traversal heuristics that will outperform a cross edged pseudotree. we use multiple heuristics to generate pseudotrees and choose the best pseudotree in linear space time complexity. for some problem instances we observe significant improvements in message and computation sizes compared to dpop.
semeval,train_I_43,dynamics based control with an application to area sweeping problems. in this paper we introduce dynamics based control dbc an approach to planning and control of an agent in stochastic environments. unlike existing approaches which seek to optimize expected rewards e g in partially observable markov decision problems pomdps dbc optimizes system behavior towards specified system dynamics. we show that a recently developed planning and control approach extended markov tracking emt is an instantiation of dbc. emt employs greedy action selection to provide an efficient control algorithm in markovian environments. we exploit this efficiency in a set of experiments that applied multitarget emt to a class of area sweeping problems searching for moving targets. we show that such problems can be naturally defined and efficiently solved using the dbc framework and its emt instantiation.
semeval,train_I_45,implementing commitment based interactions. although agent interaction plays a vital role in mas and messagecentric approaches to agent interaction have their drawbacks present agent oriented programming languages do not provide support for implementing agent interaction that is flexible and robust. instead messages are provided as a primitive building block. in this paper we consider one approach for modelling agent interactions the commitment machines framework. this framework supports modelling interactions at a higher level using social commitments resulting in more flexible interactions. we investigate how commitmentbased interactions can be implemented in conventional agent oriented programming languages. the contributions of this paper are a mapping from a commitment machine to a collection of bdi style plans extensions to the semantics of bdi programming languages and an examination of two issues that arise when distributing commitment machines turn management and race conditions and solutions to these problems.
semeval,train_I_46,modular interpreted systems. we propose a new class of representations that can be used for modeling and model checking temporal strategic and epistemic properties of agents and their teams. our representations borrow the main ideas from interpreted systems of halpern fagin et al however they are also modular and compact in the way concurrent programs are. we also mention preliminary results on model checking alternating time temporal logic for this natural class of models.
semeval,train_I_47,operational semantics of multiagent interactions. the social stance advocated by institutional frameworks and most multi agent system methodologies has resulted in a wide spectrum of organizational and communicative abstractions which have found currency in several programming frameworks and software platforms. still these tools and frameworks are designed to support a limited range of interaction capabilities that constrain developers to a fixed set of particular pre defined abstractions. the main hypothesis motivating this paper is that the variety of multi agent interaction mechanisms both organizational and communicative share a common semantic core. in the realm of software architectures the paper proposes a connector based model of multi agent interactions which attempts to identify the essential structure underlying multi agent interactions. furthermore the paper also provides this model with a formal execution semantics which describes the dynamics of social interactions. the proposed model is intended as the abstract machine of an organizational programming language which allows programmers to accommodate an open set of interaction mechanisms.
semeval,train_I_48,normative system games. we develop a model of normative systems in which agents are assumed to have multiple goals of increasing priority and investigate the computational complexity and game theoretic properties of this model. in the underlying model of normative systems we use kripke structures to represent the possible transitions of a multiagent system. a normative system is then simply a subset of the kripke structure which contains the arcs that are forbidden by the normative system. we specify an agent s goals as a hierarchy of formulae of computation tree logic ctl a widely used logic for representing the properties of kripke structures the intuition is that goals further up the hierarchy are preferred by the agent over those that appear further down the hierarchy. using this scheme we define a model of ordinal utility which in turn allows us to interpret our kripke based normative systems as games in which agents must determine whether to comply with the normative system or not. we then characterise the computational complexity of a number of decision problems associated with these kripke based normative system games for example we show that the complexity of checking whether there exists a normative system which has the property of being a nash implementation is np complete.
semeval,train_I_49,a multilateral multi issue negotiation protocol. in this paper we present a new protocol to address multilateral multi issue negotiation in a cooperative context. we consider complex dependencies between multiple issues by modelling the preferences of the agents with a multi criteria decision aid tool also enabling us to extract relevant information on a proposal assessment. this information is used in the protocol to help in accelerating the search for a consensus between the cooperative agents. in addition the negotiation procedure is defined in a crisis management context where the common objective of our agents is also considered in the preferences of a mediator agent.
semeval,train_I_50,agents beliefs and plausible behavior in a temporal setting. logics of knowledge and belief are often too static and inflexible to be used on real world problems. in particular they usually offer no concept for expressing that some course of events is more likely to happen than another. we address this problem and extend ctlk computation tree logic with knowledge with a notion of plausibility which allows for practical and counterfactual reasoning. the new logic ctlkp ctlk with plausibility includes also a particular notion of belief. a plausibility update operator is added to this logic in order to change plausibility assumptions dynamically. furthermore we examine some important properties of these concepts. in particular we show that for a natural class of models belief is a kd45 modality. we also show that model checking ctlkp is ptime complete and can be done in time linear with respect to the size of models and formulae.
semeval,train_I_51,learning and joint deliberation through argumentation in multi agent systems. in this paper we will present an argumentation framework for learning agents amal designed for two purposes 1 for joint deliberation and 2 for learning from communication. the amal framework is completely based on learning from examples the argument preference relation the argument generation policy and the counterargument generation policy are case based techniques. for join deliberation learning agents share their experience by forming a committee to decide upon some joint decision. we experimentally show that the argumentation among committees of agents improves both the individual and joint performance. for learning from communication an agent engages into arguing with other agents in order to contrast its individual hypotheses and receive counterexamples the argumentation process improves their learning scope and individual performance.
semeval,train_I_52,a unified and general framework for argumentation based negotiation. this paper proposes a unified and general framework for argumentation based negotiation in which the role of argumentation is formally analyzed. the framework makes it possible to study the outcomes of an argumentation based negotiation. it shows what an agreement is how it is related to the theories of the agents when it is possible and how this can be attained by the negotiating agents in this case. it defines also the notion of concession and shows in which situation an agent will make one as well as how it influences the evolution of the dialogue.
semeval,train_I_53,a randomized method for the shapley value for the voting game. the shapley value is one of the key solution concepts for coalition games. its main advantage is that it provides a unique and fair solution but its main problem is that for many coalition games the shapley value can not be determined in polynomial time. in particular the problem of finding this value for the voting game is known to be p complete in the general case. however in this paper we show that there are some specific voting games for which the problem is computationally tractable. for other general voting games we overcome the problem of computational complexity by presenting a new randomized method for determining the approximate shapley value. the time complexity of this method is linear in the number of players. we also show through empirical studies that the percentage error for the proposed method is always less than 20 and in most cases less than 5.
semeval,train_I_54,approximate and online multi issue negotiation. this paper analyzes bilateral multi issue negotiation between selfinterested autonomous agents. the agents have time constraints in the form of both deadlines and discount factors. there are m 1 issues for negotiation where each issue is viewed as a pie of size one. the issues are indivisible i e individual issues can not be split between the parties each issue must be allocated in its entirety to either agent. here different agents value different issues differently. thus the problem is for the agents to decide how to allocate the issues between themselves so as to maximize their individual utilities. for such negotiations we first obtain the equilibrium strategies for the case where the issues for negotiation are known a priori to the parties. then we analyse their time complexity and show that finding the equilibrium offers is an np hard problem even in a complete information setting. in order to overcome this computational complexity we then present negotiation strategies that are approximately optimal but computationally efficient and show that they form an equilibrium. we also analyze the relative error i e the difference between the true optimum and the approximate. the time complexity of the approximate equilibrium strategies is o nm  2 where n is the negotiation deadline and the relative error. finally we extend the analysis to online negotiation where different issues become available at different time points and the agents are uncertain about their valuations for these issues. specifically we show that an approximate equilibrium exists for online negotiation and show that the expected difference between the optimum and the approximate is o m. these approximate strategies also have polynomial time complexity.
semeval,train_I_55,searching for joint gains in automated negotiations based on multi criteria decision making theory. it is well established by conflict theorists and others that successful negotiation should incorporate creating value as well as claiming value. joint improvements that bring benefits to all parties can be realised by i identifying attributes that are not of direct conflict between the parties ii tradeoffs on attributes that are valued differently by different parties and iii searching for values within attributes that could bring more gains to one party while not incurring too much loss on the other party. in this paper we propose an approach for maximising joint gains in automated negotiations by formulating the negotiation problem as a multi criteria decision making problem and taking advantage of several optimisation techniques introduced by operations researchers and conflict theorists. we use a mediator to protect the negotiating parties from unnecessary disclosure of information to their opponent while also allowing an objective calculation of maximum joint gains. we separate out attributes that take a finite set of values simple attributes from those with continuous values and we show that for simple attributes the mediator can determine the pareto optimal values. in addition we show that if none of the simple attributes strongly dominates the other simple attributes then truth telling is an equilibrium strategy for negotiators during the optimisation of simple attributes. we also describe an approach for improving joint gains on non simple attributes by moving the parties in a series of steps towards the pareto optimal frontier.
semeval,train_I_56,unifying distributed constraint algorithms in a bdi negotiation framework. this paper presents a novel unified distributed constraint satisfaction framework based on automated negotiation. the distributed constraint satisfaction problem dcsp is one that entails several agents to search for an agreement which is a consistent combination of actions that satisfies their mutual constraints in a shared environment. by anchoring the dcsp search on automated negotiation we show that several well known dcsp algorithms are actually mechanisms that can reach agreements through a common belief desire intention bdi protocol but using different strategies. a major motivation for this bdi framework is that it not only provides a conceptually clearer understanding of existing dcsp algorithms from an agent model perspective but also opens up the opportunities to extend and develop new strategies for dcsp. to this end a new strategy called unsolicited mutual advice uma is proposed. performance evaluation shows that the uma strategy can outperform some existing mechanisms in terms of computational cycles.
semeval,train_I_57,rumours and reputation evaluating multi dimensional trust within a decentralised reputation system. in this paper we develop a novel probabilistic model of computational trust that explicitly deals with correlated multi dimensional contracts. our starting point is to consider an agent attempting to estimate the utility of a contract and we show that this leads to a model of computational trust whereby an agent must determine a vector of estimates that represent the probability that any dimension of the contract will be successfully fulfilled and a covariance matrix that describes the uncertainty and correlations in these probabilities. we present a formalism based on the dirichlet distribution that allows an agent to calculate these probabilities and correlations from their direct experience of contract outcomes and we show that this leads to superior estimates compared to an alternative approach using multiple independent beta distributions. we then show how agents may use the sufficient statistics of this dirichlet distribution to communicate and fuse reputation within a decentralised reputation system. finally we present a novel solution to the problem of rumour propagation within such systems. this solution uses the notion of private and shared information and provides estimates consistent with a centralised reputation system whilst maintaining the anonymity of the agents and avoiding bias and overconfidence.
semeval,train_I_58,an efficient heuristic approach for security against multiple adversaries. in adversarial multiagent domains security commonly defined as the ability to deal with intentional threats from other agents is a critical issue. this paper focuses on domains where these threats come from unknown adversaries. these domains can be modeled as bayesian games much work has been done on finding equilibria for such games. however it is often the case in multiagent security domains that one agent can commit to a mixed strategy which its adversaries observe before choosing their own strategies. in this case the agent can maximize reward by finding an optimal strategy without requiring equilibrium. previous work has shown this problem of optimal strategy selection to be np hard. therefore we present a heuristic called asap with three key advantages to address the problem. first asap searches for the highest reward strategy rather than a bayes nash equilibrium allowing it to find feasible strategies that exploit the natural first mover advantage of the game. second it provides strategies which are simple to understand represent and implement. third it operates directly on the compact bayesian game representation without requiring conversion to normal form. we provide an efficient mixed integer linear program milp implementation for asap along with experimental results illustrating significant speedups and higher rewards over other approaches.
semeval,train_I_59,an agent based approach for privacy preserving recommender systems. recommender systems are used in various domains to generate personalized information based on personal user data. the ability to preserve the privacy of all participants is an essential requirement of the underlying information filtering architectures because the deployed recommender systems have to be accepted by privacy aware users as well as information and service providers. existing approaches neglect to address privacy in this multilateral way. we have developed an approach for privacy preserving recommender systems based on multi agent system technology which enables applications to generate recommendations via various filtering techniques while preserving the privacy of all participants. we describe the main modules of our solution as well as an application we have implemented based on this approach.
semeval,train_I_60,on the benefits of cheating by self interested agents in vehicular networks. as more and more cars are equipped with gps and wi fi transmitters it becomes easier to design systems that will allow cars to interact autonomously with each other e g regarding traffic on the roads. indeed car manufacturers are already equipping their cars with such devices. though currently these systems are a proprietary we envision a natural evolution where agent applications will be developed for vehicular systems e g to improve car routing in dense urban areas. nonetheless this new technology and agent applications may lead to the emergence of self interested car owners who will care more about their own welfare than the social welfare of their peers. these car owners will try to manipulate their agents such that they transmit false data to their peers. using a simulation environment which models a real transportation network in a large city we demonstrate the benefits achieved by self interested agents if no counter measures are implemented.
semeval,train_I_61,distributed agent based air traffic flow management. air traffic flow management is one of the fundamental challenges facing the federal aviation administration faa today. the faa estimates that in 2005 alone there were over 322 000 hours of delays at a cost to the industry in excess of three billion dollars. finding reliable and adaptive solutions to the flow management problem is of paramount importance if the next generation air transportation systems are to achieve the stated goal of accommodating three times the current traffic volume. this problem is particularly complex as it requires the integration and or coordination of many factors including new data e g changing weather info potentially conflicting priorities e g different airlines limited resources e g air traffic controllers and very heavy traffic volume e g over 40 000 flights over the us airspace. in this paper we use facet an air traffic flow simulator developed at nasa and used extensively by the faa and industry to test a multi agent algorithm for traffic flow management. an agent is associated with a fix a specific location in 2d space and its action consists of setting the separation required among the airplanes going though that fix. agents use reinforcement learning to set this separation and their actions speed up or slow down traffic to manage congestion. our facet based results show that agents receiving personalized rewards reduce congestion by up to 45 over agents receiving a global reward and by up to 67 over a current industry approach monte carlo estimation.
semeval,train_I_62,a q decomposition and bounded rtdp approach to resource allocation. this paper contributes to solve effectively stochastic resource allocation problems known to be np complete. to address this complex resource management problem a qdecomposition approach is proposed when the resources which are already shared among the agents but the actions made by an agent may influence the reward obtained by at least another agent. the q decomposition allows to coordinate these reward separated agents and thus permits to reduce the set of states and actions to consider. on the other hand when the resources are available to all agents no qdecomposition is possible and we use heuristic search. in particular the bounded real time dynamic programming bounded rtdp is used. bounded rtdp concentrates the planning on significant states only and prunes the action space. the pruning is accomplished by proposing tight upper and lower bounds on the value function.
semeval,train_I_63,combinatorial resource scheduling for multiagent mdps. optimal resource scheduling in multiagent systems is a computationally challenging task particularly when the values of resources are not additive. we consider the combinatorial problem of scheduling the usage of multiple resources among agents that operate in stochastic environments modeled as markov decision processes mdps. in recent years efficient resource allocation algorithms have been developed for agents with resource values induced by mdps. however this prior work has focused on static resource allocation problems where resources are distributed once and then utilized in infinite horizon mdps. we extend those existing models to the problem of combinatorial resource scheduling where agents persist only for finite periods between their predefined arrival and departure times requiring resources only for those time periods. we provide a computationally efficient procedure for computing globally optimal resource assignments to agents over time. we illustrate and empirically analyze the method in the context of a stochastic jobscheduling domain.
semeval,train_I_64,organizational self design in semi dynamic environments. in this paper we propose a run time approach to organization that is contingent on the task structure of the problem being solved and the environmental conditions under which it is being solved. we use t1ems as the underlying representation for our problems and describe a framework that uses organizational self design osd to allocate tasks and resources to the agents and coordinate their activities.
semeval,train_I_65,graphical models for online solutions to interactive pomdps. we develop a new graphical representation for interactive partially observable markov decision processes i pomdps that is significantly more transparent and semantically clear than the previous representation. these graphical models called interactive dynamic influence diagrams i dids seek to explicitly model the structure that is often present in real world problems by decomposing the situation into chance and decision variables and the dependencies between the variables. i dids generalize dids which may be viewed as graphical representations of pomdps to multiagent settings in the same way that i pomdps generalize pomdps. i dids may be used to compute the policy of an agent online as the agent acts and observes in a setting that is populated by other interacting agents. using several examples we show how i dids may be applied and demonstrate their usefulness.
semeval,train_I_66,letting loose a spider on a network of pomdps generating quality guaranteed policies. distributed partially observable markov decision problems distributed pomdps are a popular approach for modeling multi agent systems acting in uncertain domains. given the significant complexity of solving distributed pomdps particularly as we scale up the numbers of agents one popular approach has focused on approximate solutions. though this approach is efficient the algorithms within this approach do not provide any guarantees on solution quality. a second less popular approach focuses on global optimality but typical results are available only for two agents and also at considerable computational cost. this paper overcomes the limitations of both these approaches by providing spider a novel combination of three key features for policy generation in distributed pomdps i it exploits agent interaction structure given a network of agents i e allowing easier scale up to larger number of agents ii it uses a combination of heuristics to speedup policy search and iii it allows quality guaranteed approximations allowing a systematic tradeoff of solution quality for time. experimental results show orders of magnitude improvement in performance when compared with previous global optimal algorithms.
semeval,train_I_68,on opportunistic techniques for solving decentralized markov decision processes with temporal constraints. decentralized markov decision processes dec mdps are a popular model of agent coordination problems in domains with uncertainty and time constraints but very difficult to solve. in this paper we improve a state of the art heuristic solution method for dec mdps called oc dec mdp that has recently been shown to scale up to larger dec mdps. our heuristic solution method called value function propagation vfp combines two orthogonal improvements of oc dec mdp. first it speeds up oc decmdp by an order of magnitude by maintaining and manipulating a value function for each state as a function of time rather than a separate value for each pair of sate and time interval. furthermore it achieves better solution qualities than oc dec mdp because as our analytical results show it does not overestimate the expected total reward like oc dec mdp. we test both improvements independently in a crisis management domain as well as for other types of domains. our experimental results demonstrate a significant speedup of vfp over oc dec mdp as well as higher solution qualities in a variety of situations.
semeval,train_I_70,a multi agent system for building dynamic ontologies. ontologies building from text is still a time consuming task which justifies the growth of ontology learning. our system named dynamo is designed along this domain but following an original approach based on an adaptive multi agent architecture. in this paper we present a distributed hierarchical clustering algorithm core of our approach. it is evaluated and compared to a more conventional centralized algorithm. we also present how it has been improved using a multi criteria approach. with those results in mind we discuss the limits of our system and add as perspectives the modifications required to reach a complete ontology building solution.
semeval,train_I_71,a formal model for situated semantic alignment. ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge based applications and therefore to enable their interoperability in distributed environments such as multiagent systems. most ontology matching mechanisms however assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources. in this paper we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in. it hence makes the situation in which the alignment occurs explicit in the model. we resort to channel theory to carry out the formalisation.
semeval,train_I_72,learning consumer preferences using semantic similarity reyhan aydo gan pınar yolum. in online dynamic environments the services requested by consumers may not be readily served by the providers. this requires the service consumers and providers to negotiate their service needs and offers. multiagent negotiation approaches typically assume that the parties agree on service content and focus on finding a consensus on service price. in contrast this work develops an approach through which the parties can negotiate the content of a service. this calls for a negotiation approach in which the parties can understand the semantics of their requests and offers and learn each other s preferences incrementally over time. accordingly we propose an architecture in which both consumers and producers use a shared ontology to negotiate a service. through repetitive interactions the provider learns consumers needs accurately and can make better targeted offers. to enable fast and accurate learning of preferences we develop an extension to version space and compare it with existing learning techniques. we further develop a metric for measuring semantic similarity between services and compare the performance of our approach using different similarity metrics.
semeval,train_I_73,exchanging reputation values among heterogeneous agent reputation models an experience on art testbed. in open mas it is often a problem to achieve agents interoperability. the heterogeneity of its components turns the establishment of interaction or cooperation among them into a non trivial task since agents may use different internal models and the decision about trust other agents is a crucial condition to the formation of agents cooperation. in this paper we propose the use of an ontology to deal with this issue. we experiment this idea by enhancing the art reputation model with semantic data obtained from this ontology. this data is used during interaction among heterogeneous agents when exchanging reputation values and may be used for agents that use different reputation models.
semeval,train_I_74,on the relevance of utterances in formal inter agent dialogues. work on argumentation based dialogue has defined frameworks within which dialogues can be carried out established protocols that govern dialogues and studied different properties of dialogues. this work has established the space in which agents are permitted to interact through dialogues. recently there has been increasing interest in the mechanisms agents might use to choose how to act the rhetorical manoeuvring that they use to navigate through the space defined by the rules of the dialogue. key in such considerations is the idea of relevance since a usual requirement is that agents stay focussed on the subject of the dialogue and only make relevant remarks. here we study several notions of relevance showing how they can be related to both the rules for carrying out dialogues and to rhetorical manoeuvring.
semeval,train_I_75,hypotheses refinement under topological communication constraints. we investigate the properties of a multiagent system where each distributed agent locally perceives its environment. upon perception of an unexpected event each agent locally computes its favoured hypothesis and tries to propagate it to other agents by exchanging hypotheses and supporting arguments observations. however we further assume that communication opportunities are severely constrained and change dynamically. in this paper we mostly investigate the convergence of such systems towards global consistency. we first show that for a wide class of protocols that we shall define the communication constraints induced by the topology will not prevent the convergence of the system at the condition that the system dynamics guarantees that no agent will ever be isolated forever and that agents have unlimited time for computation and arguments exchange. as this assumption can not be made in most situations though we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange. we study a critical situation involving a number of agents aiming at escaping from a burning building. the results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.
semeval,train_I_76,negotiation by abduction and relaxation. this paper studies a logical framework for automated negotiation between two agents. we suppose an agent who has a knowledge base represented by a logic program. then we introduce methods of constructing counter proposals in response to proposals made by an agent. to this end we combine the techniques of extended abduction in artificial intelligence and relaxation in cooperative query answering for databases. these techniques are respectively used for producing conditional proposals and neighborhood proposals in the process of negotiation. we provide a negotiation protocol based on the exchange of these proposals and develop procedures for computing new proposals.
semeval,train_I_77,the logic negotiation model. successful negotiators prepare by determining their position along five dimensions legitimacy options goals independence and commitment logic. we introduce a negotiation model based on these dimensions and on two primitive concepts intimacy degree of closeness and balance degree of fairness. the intimacy is a pair of matrices that evaluate both an agent s contribution to the relationship and its opponent s contribution each from an information view and from a utilitarian view across the five logic dimensions. the balance is the difference between these matrices. a relationship strategy maintains a target intimacy for each relationship that an agent would like the relationship to move towards in future. the negotiation strategy maintains a set of options that are in line with the current intimacy level and then tactics wrap the options in argumentation with the aim of attaining a successful deal and manipulating the successive negotiation balances towards the target intimacy.
semeval,train_J_33,bid expressiveness and clearing algorithms in multiattribute double auctions. we investigate the space of two sided multiattribute auctions focusing on the relationship between constraints on the offers traders can express through bids and the resulting computational problem of determining an optimal set of trades. we develop a formal semantic framework for characterizing expressible offers and show conditions under which the allocation problem can be separated into first identifying optimal pairwise trades and subsequently optimizing combinations of those trades. we analyze the bilateral matching problem while taking into consideration relevant results from multiattribute utility theory. network flow models we develop for computing global allocations facilitate classification of the problem space by computational complexity and provide guidance for developing solution algorithms. experimental trials help distinguish tractable problem classes for proposed solution techniques.
semeval,train_J_34,in stability properties of limit order dynamics. we study the stability properties of the dynamics of the standard continuous limit order mechanism that is used in modern equity markets. we ask whether such mechanisms are susceptible to butterfly effects  the infliction of large changes on common measures of market activity by only small perturbations of the order sequence. we show that the answer depends strongly on whether the market consists of absolute traders who determine their prices independent of the current order book state or relative traders who determine their prices relative to the current bid and ask. we prove that while the absolute trader model enjoys provably strong stability properties the relative trader model is vulnerable to great instability. our theoretical results are supported by large scale experiments using limit order data from inet a large electronic exchange for nasdaq stocks.
semeval,train_J_35,efficiency and nash equilibria in a scrip system for p2p networks. a model of providing service in a p2p network is analyzed. it is shown that by adding a scrip system a mechanism that admits a reasonable nash equilibrium that reduces free riding can be obtained. the effect of varying the total amount of money scrip in the system on efficiency i e social welfare is analyzed and it is shown that by maintaining the appropriate ratio between the total amount of money and the number of agents efficiency is maximized. the work has implications for many online systems not only p2p networks but also a wide variety of online forums for which scrip systems are popular but formal analyses have been lacking.
semeval,train_J_36,playing games in many possible worlds. in traditional game theory players are typically endowed with exogenously given knowledge of the structure of the game either full omniscient knowledge or partial but fixed information. in real life however people are often unaware of the utility of taking a particular action until they perform research into its consequences. in this paper we model this phenomenon. we imagine a player engaged in a questionand answer session asking questions both about his or her own preferences and about the state of reality thus we call this setting socratic game theory. in a socratic game players begin with an a priori probability distribution over many possible worlds with a different utility function for each world. players can make queries at some cost to learn partial information about which of the possible worlds is the actual world before choosing an action. we consider two query models 1 an unobservable query model in which players learn only the response to their own queries and 2 an observable query model in which players also learn which queries their opponents made. the results in this paper consider cases in which the underlying worlds of a two player socratic game are either constant sum games or strategically zero sum games a class that generalizes constant sum games to include all games in which the sum of payoffs depends linearly on the interaction between the players. when the underlying worlds are constant sum we give polynomial time algorithms to find nash equilibria in both the observable and unobservable query models. when the worlds are strategically zero sum we give efficient algorithms to find nash equilibria in unobservablequery socratic games and correlated equilibria in observablequery socratic games.
semeval,train_J_37,finding equilibria in large sequential games of imperfect information. finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory but current techniques do not scale to large games. to address this we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation. for a multi player sequential game of imperfect information with observable actions and an ordered signal space we prove that any nash equilibrium in an abstracted smaller game obtained by one or more applications of the transformation can be easily converted into a nash equilibrium in the original game. we present an algorithm gameshrink for abstracting the game using our isomorphism exhaustively. its complexity is o n2 where n is the number of nodes in a structure we call the signal tree. it is no larger than the game tree and on nontrivial games it is drastically smaller so gameshrink has time and space complexity sublinear in the size of the game tree. using gameshrink we find an equilibrium to a poker game with 3 1 billion nodes over four orders of magnitude more than in the largest poker game solved previously. we discuss several electronic commerce applications for gameshrink. to address even larger games we introduce approximation methods that do not preserve equilibrium but nevertheless yield ex post provably close to optimal strategies.
semeval,train_J_38,multi attribute coalitional games t. we study coalitional games where the value of cooperation among the agents are solely determined by the attributes the agents possess with no assumption as to how these attributes jointly determine this value. this framework allows us to model diverse economic interactions by picking the right attributes. we study the computational complexity of two coalitional solution concepts for these games the shapley value and the core. we show how the positive results obtained in this paper imply comparable results for other games studied in the literature.
semeval,train_J_39,the sequential auction problem on ebay an empirical analysis and a solution. bidders on ebay have no dominant bidding strategy when faced with multiple auctions each offering an item of interest. as seen through an analysis of 1 956 auctions on ebay for a dell e193fp lcd monitor some bidders win auctions at prices higher than those of other available auctions while others never win an auction despite placing bids in losing efforts that are greater than the closing prices of other available auctions. these misqueues in strategic behavior hamper the efficiency of the system and in so doing limit the revenue potential for sellers. this paper proposes a novel options based extension to ebay s proxy bidding system that resolves this strategic issue for buyers in commoditized markets. an empirical analysis of ebay provides a basis for computer simulations that investigate the market effects of the options based scheme and demonstrates that the options based scheme provides greater efficiency than ebay while also increasing seller revenue.
semeval,train_J_40,networks preserving evolutionary equilibria and the power of randomization. we study a natural extension of classical evolutionary game theory to a setting in which pairwise interactions are restricted to the edges of an undirected graph or network. we generalize the definition of an evolutionary stable strategy ess and show a pair of complementary results that exhibit the power of randomization in our setting subject to degree or edge density conditions the classical ess of any game are preserved when the graph is chosen randomly and the mutation set is chosen adversarially or when the graph is chosen adversarially and the mutation set is chosen randomly. we examine natural strengthenings of our generalized ess definition and show that similarly strong results are not possible for them.
semeval,train_J_41,an analysis of alternative slot auction designs for sponsored search. billions of dollars are spent each year on sponsored search a form of advertising where merchants pay for placement alongside web search results. slots for ad listings are allocated via an auction style mechanism where the higher a merchant bids the more likely his ad is to appear above other ads on the page. in this paper we analyze the incentive efficiency and revenue properties of two slot auction designs  rank by bid rbb and rank by revenue rbr which correspond to stylized versions of the mechanisms currently used by yahoo and google respectively. we also consider first and second price payment rules together with each of these allocation rules as both have been used historically. we consider both the short run incomplete information setting and the long run complete information setting. with incomplete information neither rbb nor rbr are truthful with either first or second pricing. we find that the informational requirements of rbb are much weaker than those of rbr but that rbr is efficient whereas rbb is not. we also show that no revenue ranking of rbb and rbr is possible given an arbitrary distribution over bidder values and relevance. with complete information we find that no equilibrium exists with first pricing using either rbb or rbr. we show that there typically exists a multitude of equilibria with second pricing and we bound the divergence of economic value in such equilibria from the value obtained assuming all merchants bid truthfully.
semeval,train_J_42,the dynamics of viral marketing. we present an analysis of a person to person recommendation network consisting of 4 million people who made 16 million recommendations on half a million products. we observe the propagation of recommendations and the cascade sizes which we explain by a simple stochastic model. we then establish how the recommendation network grows over time and how effective it is from the viewpoint of the sender and receiver of the recommendations. while on average recommendations are not very effective at inducing purchases and do not spread very far we present a model that successfully identifies product and pricing categories for which viral marketing seems to be very effective.
semeval,train_J_44,scouts promoters and connectors the roles of ratings in nearest neighbor collaborative filtering. recommender systems aggregate individual user ratings into predictions of products or services that might interest visitors. the quality of this aggregation process crucially affects the user experience and hence the effectiveness of recommenders in e commerce. we present a novel study that disaggregates global recommender performance metrics into contributions made by each individual rating allowing us to characterize the many roles played by ratings in nearestneighbor collaborative filtering. in particular we formulate three roles scouts promoters and connectors that capture how users receive recommendations how items get recommended and how ratings of these two types are themselves connected resp.. these roles find direct uses in improving recommendations for users in better targeting of items and most importantly in helping monitor the health of the system as a whole. for instance they can be used to track the evolution of neighborhoods to identify rating subspaces that do not contribute or contribute negatively to system performance to enumerate users who are in danger of leaving and to assess the susceptibility of the system to attacks such as shilling. we argue that the three rating roles presented here provide broad primitives to manage a recommender system and its community.
semeval,train_J_45,empirical mechanism design methods with application to a supply chain scenario. our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings. we illustrate our approach with a design task from a supply chain trading competition. designers adopted several rule changes in order to deter particular procurement behavior but the measures proved insufficient. our empirical mechanism analysis models the relation between a key design parameter and outcomes confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect. more generally we show that under certain conditions the estimator of optimal mechanism parameter setting based on empirical data is consistent.
semeval,train_J_47,on the computational power of iterative auctions. we embark on a systematic analysis of the power and limitations of iterative combinatorial auctions. most existing iterative combinatorial auctions are based on repeatedly suggesting prices for bundles of items and querying the bidders for their demand under these prices. we prove a large number of results showing the boundaries of what can be achieved by auctions of this kind. we first focus on auctions that use a polynomial number of demand queries and then we analyze the power of different kinds of ascending price auctions.
semeval,train_J_49,information markets vs opinion pools an empirical comparison. in this paper we examine the relative forecast accuracy of information markets versus expert aggregation. we leverage a unique data source of almost 2000 people s subjective probability judgments on 2003 us national football league games and compare with the market probabilities given by two different information markets on exactly the same events. we combine assessments of multiple experts via linear and logarithmic aggregation functions to form pooled predictions. prices in information markets are used to derive market predictions. our results show that at the same time point ahead of the game information markets provide as accurate predictions as pooled expert assessments. in screening pooled expert predictions we find that arithmetic average is a robust and efficient pooling function weighting expert assessments according to their past performance does not improve accuracy of pooled predictions and logarithmic aggregation functions offer bolder predictions than linear aggregation functions. the results provide insights into the predictive performance of information markets and the relative merits of selecting among various opinion pooling methods.
semeval,train_J_50,communication complexity of common voting rules. we determine the communication complexity of the common voting rules. the rules sorted by their communication complexity from low to high are plurality plurality with runoff single transferable vote stv condorcet approval bucklin cup maximin borda copeland and ranked pairs. for each rule we first give a deterministic communication protocol and an upper bound on the number of bits communicated in it then we give a lower bound on even the nondeterministic communication requirements of the voting rule. the bounds match for all voting rules except stv and maximin.
semeval,train_J_51,complexity of iterated dominance. we study various computational aspects of solving games using dominance and iterated dominance. we first study both strict and weak dominance not iterated and show that checking whether a given strategy is dominated by some mixed strategy can be done in polynomial time using a single linear program solve. we then move on to iterated dominance. we show that determining whether there is some path that eliminates a given strategy is np complete with iterated weak dominance. this allows us to also show that determining whether there is a path that leads to a unique solution is np complete. both of these results hold both with and without dominance by mixed strategies. a weaker version of the second result only without dominance by mixed strategies was already known 7. iterated strict dominance on the other hand is path independent both with and without dominance by mixed strategies and can therefore be done in polynomial time. we then study what happens when the dominating strategy is allowed to place positive probability on only a few pure strategies. first we show that finding the dominating strategy with minimum support size is np complete both for strict and weak dominance. then we show that iterated strict dominance becomes path dependent when there is a limit on the support size of the dominating strategies and that deciding whether a given strategy can be eliminated by iterated strict dominance under this restriction is np complete even when the limit on the support size is 3. finally we study bayesian games. we show that unlike in normal form games deciding whether a given pure strategy is dominated by another pure strategy in a bayesian game is np complete both with strict and weak dominance however deciding whether a strategy is dominated by some mixed strategy can still be done in polynomial time with a single linear program solve both with strict and weak this material is based upon work supported by the national science foundation under itr grants iis 0121678 and iis 0427858 and a sloan fellowship. dominance. finally we show that iterated dominance using pure strategies can require an exponential number of iterations in a bayesian game both with strict and weak dominance.
semeval,train_J_52,hidden action in multi hop routing. in multi hop networks the actions taken by individual intermediate nodes are typically hidden from the communicating endpoints all the endpoints can observe is whether or not the end to end transmission was successful. therefore in the absence of incentives to the contrary rational i e selfish intermediate nodes may choose to forward packets at a low priority or simply not forward packets at all. using a principal agent model we show how the hidden action problem can be overcome through appropriate design of contracts in both the direct the endpoints contract with each individual router and recursive each router contracts with the next downstream router cases. we further demonstrate that per hop monitoring does not necessarily improve the utility of the principal or the social welfare in the system. in addition we generalize existing mechanisms that deal with hidden information to handle scenarios involving both hidden information and hidden action.
semeval,train_J_53,a price anticipating resource allocation mechanism for distributed shared clusters. game to understand the performance of a distributed marketbased resource allocation system. multiple users decide how to distribute their budget bids among multiple machines according to their individual preferences to maximize their individual utility. we look at both the efficiency and the fairness of the allocation at the equilibrium where fairness is evaluated through the measures of utility uniformity and envy freeness. we show analytically and through simulations that despite being highly decentralized such a system converges quickly to an equilibrium and unlike the social optimum that achieves high efficiency but poor fairness the proposed allocation scheme achieves a nice balance of high degrees of efficiency and fairness at the equilibrium.
semeval,train_J_55,from optimal limited to unlimited supply auctions. we investigate the class of single round sealed bid auctions for a set of identical items to bidders who each desire one unit. we adopt the worst case competitive framework defined by 9 5 that compares the profit of an auction to that of an optimal single price sale of least two items. in this paper we first derive an optimal auction for three items answering an open question from 8. second we show that the form of this auction is independent of the competitive framework used. third we propose a schema for converting a given limited supply auction into an unlimited supply auction. applying this technique to our optimal auction for three items we achieve an auction with a competitive ratio of 3 25 which improves upon the previously best known competitive ratio of 3 39 from 7. finally we generalize a result from 8 and extend our understanding of the nature of the optimal competitive auction by showing that the optimal competitive auction occasionally offers prices that are higher than all bid values.
semeval,train_J_56,robust solutions for combinatorial auctions. bids submitted in auctions are usually treated as enforceable commitments in most bidding and auction theory literature. in reality bidders often withdraw winning bids before the transaction when it is in their best interests to do so. given a bid withdrawal in a combinatorial auction finding an alternative repair solution of adequate revenue without causing undue disturbance to the remaining winning bids in the original solution may be difficult or even impossible. we have called this the bid taker s exposure problem. when faced with such unreliable bidders it is preferable for the bid taker to preempt such uncertainty by having a solution that is robust to bid withdrawal and provides a guarantee that possible withdrawals may be repaired easily with a bounded loss in revenue. in this paper we propose an approach to addressing the bidtaker s exposure problem. firstly we use the weighted super solutions framework 13 from the field of constraint programming to solve the problem of finding a robust solution. a weighted super solution guarantees that any subset of bids likely to be withdrawn can be repaired to form a new solution of at least a given revenue by making limited changes. secondly we introduce an auction model that uses a form of leveled commitment contract 26 27 which we have called mutual bid bonds to improve solution reparability by facilitating backtracking on winning bids by the bid taker. we then examine the trade off between robustness and revenue in different economically motivated auction scenarios for different constraints on the revenue of repair solutions. we also demonstrate experimentally that fewer winning bids partake in robust solutions thereby reducing any associated overhead in dealing with extra bidders. robust solutions can also provide a means of selectively discriminating against distrusted bidders in a measured manner.
semeval,train_J_57,marginal contribution nets a compact representation scheme for coalitional games. we present a new approach to representing coalitional games based on rules that describe the marginal contributions of the agents. this representation scheme captures characteristics of the interactions among the agents in a natural and concise manner. we also develop efficient algorithms for two of the most important solution concepts the shapley value and the core under this representation. the shapley value can be computed in time linear in the size of the input. the emptiness of the core can be determined in time exponential only in the treewidth of a graphical interpretation of our representation.
semeval,train_J_58,towards truthful mechanisms for binary demand games a general framework. the family of vickrey clarke groves vcg mechanisms is arguably the most celebrated achievement in truthful mechanism design. however vcg mechanisms have their limitations. they only apply to optimization problems with a utilitarian or affine objective function and their output should optimize the objective function. for many optimization problems finding the optimal output is computationally intractable. if we apply vcg mechanisms to polynomial time algorithms that approximate the optimal solution the resulting mechanisms may no longer be truthful. in light of these limitations it is useful to study whether we can design a truthful non vcg payment scheme that is computationally tractable for a given allocation rule o. in this paper we focus our attention on binary demand games in which the agents only available actions are to take part in the a game or not to. for these problems we prove that a truthful mechanism m o p exists with a proper payment method p iff the allocation rule o satisfies a certain monotonicity property. we provide a general framework to design such p. we further propose several general composition based techniques to compute p efficiently for various types of output. in particular we show how p can be computed through or and combinations round based combinations and some more complex combinations of the outputs from subgames.
semeval,train_J_59,cost sharing in a job scheduling problem using the shapley value. a set of jobs need to be served by a single server which can serve only one job at a time. jobs have processing times and incur waiting costs linear in their waiting time. the jobs share their costs through compensation using monetary transfers. we characterize the shapley value rule for this model using fairness axioms. our axioms include a bound on the cost share of jobs in a group efficiency and some independence properties on the the cost share of a job.
semeval,train_J_60,on decentralized incentive compatible mechanisms for partially informed environments. algorithmic mechanism design focuses on dominant strategy implementations. the main positive results are the celebrated vickrey clarke groves vcg mechanisms and computationally efficient mechanisms for severely restricted players single parameter domains. as it turns out many natural social goals can not be implemented using the dominant strategy concept 35 32 22 20. this suggests that the standard requirements must be relaxed in order to construct general purpose mechanisms. we observe that in many common distributed environments computational entities can take advantage of the network structure to collect and distribute information. we thus suggest a notion of partially informed environments. even if the information is recorded with some probability this enables us to implement a wider range of social goals using the concept of iterative elimination of weakly dominated strategies. as a result cooperation is achieved independent of agents belief. as a case study we apply our methods to derive peer to peer network mechanism for file sharing.
semeval,train_J_61,ice an iterative combinatorial exchange david c parkes s ruggiero cavallos nick elprins adam judas s ebastien lahaies. we present the first design for an iterative combinatorial exchange ice. the exchange incorporates a tree based bidding language that is concise and expressive for ces. bidders specify lower and upper bounds on their value for different trades. these bounds allow price discovery and useful preference elicitation in early rounds and allow termination with an efficient trade despite partial information on bidder valuations. all computation in the exchange is carefully optimized to exploit the structure of the bid trees and to avoid enumerating trades. a proxied interpretation of a revealedpreference activity rule ensures progress across rounds. a vcg based payment scheme that has been shown to mitigate opportunities for bargaining and strategic behavior is used to determine final payments. the exchange is fully implemented and in a validation phase.
semeval,train_J_62,weak monotonicity suffices for truthfulness on convex domains. weak monotonicity is a simple necessary condition for a social choice function to be implementable by a truthful mechanism. roberts 10 showed that it is sufficient for all social choice functions whose domain is unrestricted. lavi mu alem and nisan 6 proved the sufficiency of weak monotonicity for functions over order based domains and gui muller and vohra 5 proved sufficiency for order based domains with range constraints and for domains defined by other special types of linear inequality constraints. here we show the more general result conjectured by lavi mu alem and nisan 6 that weak monotonicity is sufficient for functions defined on any convex domain.
semeval,train_J_63,negotiation range mechanisms exploring the limits of truthful efficient markets. this paper introduces a new class of mechanisms based on negotiation between market participants. this model allows us to circumvent myerson and satterthwaite s impossibility result and present a bilateral market mechanism that is efficient individually rational incentive compatible and budget balanced in the single unit heterogeneous setting. the underlying scheme makes this combination of desirable qualities possible by reporting a price range for each buyer seller pair that defines a zone of possible agreements while the final price is left open for negotiation.
semeval,train_J_65,privacy in electronic commerce and the economics of immediate gratification. dichotomies between privacy attitudes and behavior have been noted in the literature but not yet fully explained. we apply lessons from the research on behavioral economics to understand the individual decision making process with respect to privacy in electronic commerce. we show that it is unrealistic to expect individual rationality in this context. models of self control problems and immediate gratification offer more realistic descriptions of the decision process and are more consistent with currently available data. in particular we show why individuals who may genuinely want to protect their privacy might not do so because of psychological distortions well documented in the behavioral literature we show that these distortions may affect not only na ıve individuals but also sophisticated ones and we prove that this may occur also when individuals perceive the risks from not protecting their privacy as significant.
semeval,train_J_66,expressive negotiation over donations to charities. when donating money to a say charitable cause it is possible to use the contemplated donation as negotiating material to induce other parties interested in the charity to donate more. such negotiation is usually done in terms of matching offers where one party promises to pay a certain amount if others pay a certain amount. however in their current form matching offers allow for only limited negotiation. for one it is not immediately clear how multiple parties can make matching offers at the same time without creating circular dependencies. also it is not immediately clear how to make a donation conditional on other donations to multiple charities when the donator has different levels of appreciation for the different charities. in both these cases the limited expressiveness of matching offers causes economic loss it may happen that an arrangement that would have made all parties donators as well as charities better off can not be expressed in terms of matching offers and will therefore not occur. in this paper we introduce a bidding language for expressing very general types of matching offers over multiple charities. we formulate the corresponding clearing problem deciding how much each bidder pays and how much each charity receives and show that it is np complete to approximate to any ratio even in very restricted settings. we give a mixed integer program formulation of the clearing problem and show that for concave bids the program reduces to a linear program. we then show that the clearing problem for a subclass of concave bids is at least as hard as the decision variant of linear programming. subsequently we show that the clearing problem is much easier when bids are quasilinear for surplus the problem decomposes across charities and for payment maximization a greedy approach is optimal if the bids are concave although this latter problem is weakly np complete when the bids are not concave. for the quasilinear setting we study the mechanism design question. we show that an ex post efficient mechanism is supported by nsf under career award iri 9703122 grant iis 9800994 itr iis 0081246 and itr iis 0121678. impossible even with only one charity and a very restricted class of bids. we also show that there may be benefits to linking the charities from a mechanism design standpoint.
semeval,train_J_67,mechanism design for online real time scheduling. for the problem of online real time scheduling of jobs on a single processor previous work presents matching upper and lower bounds on the competitive ratio that can be achieved by a deterministic algorithm. however these results only apply to the non strategic setting in which the jobs are released directly to the algorithm. motivated by emerging areas such as grid computing we instead consider this problem in an economic setting in which each job is released to a separate self interested agent. the agent can then delay releasing the job to the algorithm inflate its length and declare an arbitrary value and deadline for the job while the center determines not only the schedule but the payment of each agent. for the resulting mechanism design problem in which we also slightly strengthen an assumption from the non strategic setting we present a mechanism that addresses each incentive issue while only increasing the competitive ratio by one. we then show a matching lower bound for deterministic mechanisms that never pay the agents.
semeval,train_J_69,robust incentive techniques for peer to peer networks. lack of cooperation free riding is one of the key problems that confronts today s p2p systems. what makes this problem particularly difficult is the unique set of challenges that p2p systems pose large populations high turnover asymmetry of interest collusion zero cost identities and traitors. to tackle these challenges we model the p2p system using the generalized prisoner s dilemma gpd and propose the reciprocative decision function as the basis of a family of incentives techniques. these techniques are fully distributed and include discriminating server selection maxflowbased subjective reputation and adaptive stranger policies. through simulation we show that these techniques can drive a system of strategic users to nearly optimal levels of cooperation.
semeval,train_J_70,self interested automated mechanism design and implications for optimal combinatorial auctions. often an outcome must be chosen on the basis of the preferences reported by a group of agents. the key difficulty is that the agents may report their preferences insincerely to make the chosen outcome more favorable to themselves. mechanism design is the art of designing the rules of the game so that the agents are motivated to report their preferences truthfully and a desirable outcome is chosen. in a recently proposed approach called automated mechanism design a mechanism is computed for the preference aggregation setting at hand. this has several advantages but the downside is that the mechanism design optimization problem needs to be solved anew each time. unlike the earlier work on automated mechanism design that studied a benevolent designer in this paper we study automated mechanism design problems where the designer is self interested. in this case the center cares only about which outcome is chosen and what payments are made to it. the reason that the agents preferences are relevant is that the center is constrained to making each agent at least as well off as the agent would have been had it not participated in the mechanism. in this setting we show that designing optimal deterministic mechanisms is np complete in two important special cases when the center is interested only in the payments made to it and when payments are not possible and the center is interested only in the outcome chosen. we then show how allowing for randomization in the mechanism makes problems in this setting computationally easy. finally we show that the payment maximizing amd problem is closely related to an interesting variant of the optimal revenuemaximizing combinatorial auction design problem where the bidders have best only preferences. we show that here too designing an optimal deterministic auction is npcomplete but designing an optimal randomized auction is easy. supported by nsf under career award iri 9703122 grant iis 9800994 itr iis 0081246 and itr iis 0121678.
semeval,train_J_71,a dynamic pari mutuel market for hedging wagering and information aggregation. i develop a new mechanism for risk allocation and information speculation called a dynamic pari mutuel market dpm. a dpm acts as hybrid between a pari mutuel market and a continuous double auction cda inheriting some of the advantages of both. like a pari mutuel market a dpm offers infinite buy in liquidity and zero risk for the market institution like a cda a dpm can continuously react to new information dynamically incorporate information into prices and allow traders to lock in gains or limit losses by selling prior to event resolution. the trader interface can be designed to mimic the familiar double auction format with bid ask queues though with an addition variable called the payoff per share. the dpm price function can be viewed as an automated market maker always offering to sell at some price and moving the price appropriately according to demand. since the mechanism is pari mutuel i e redistributive it is guaranteed to pay out exactly the amount of money taken in. i explore a number of variations on the basic dpm analyzing the properties of each and solving in closed form for their respective price functions.
semeval,train_J_72,applying learning algorithms to preference elicitation. we consider the parallels between the preference elicitation problem in combinatorial auctions and the problem of learning an unknown function from learning theory. we show that learning algorithms can be used as a basis for preference elicitation algorithms. the resulting elicitation algorithms perform a polynomial number of queries. we also give conditions under which the resulting algorithms have polynomial communication. our conversion procedure allows us to generate combinatorial auction protocols from learning algorithms for polynomials monotone dnf and linear threshold functions. in particular we obtain an algorithm that elicits xor bids with polynomial communication.
semeval,train_J_73,competitive algorithms for vwap and limit order trading. we introduce new online models for two important aspects of modern financial markets volume weighted average price trading and limit order books. we provide an extensive study of competitive algorithms in these models and relate them to earlier online algorithms for stock trading.
semeval,train_J_74,on cheating in sealed bid auctions. motivated by the rise of online auctions and their relative lack of security this paper analyzes two forms of cheating in sealed bid auctions. the first type of cheating we consider occurs when the seller spies on the bids of a second price auction and then inserts a fake bid in order to increase the payment of the winning bidder. in the second type a bidder cheats in a first price auction by examining the competing bids before deciding on his own bid. in both cases we derive equilibrium strategies when bidders are aware of the possibility of cheating. these results provide insights into sealedbid auctions even in the absence of cheating including some counterintuitive results on the effects of overbidding in a first price auction.
termith-eval,test_archeologie_08_0040093_tei,petit gibier et fonction de sites à le paléolithique supérieur les ensembles fauniques de la grotte d anecrial porto de mos estremadure portugal. le gisement en grotte d anecrial livre des ensembles fauniques dominés par les lagomorphes genre oryctolagus  représentés par peu d individus. la dispersion des restes les parties de le squelette et les types de fracturation cylindres précisent l origine de l accumulation et les hypothèses fonctionnelles de le site. le gisement est interprété comme un bivouac utilisé à le moins à trois reprises par un groupe humain réduit orienté vers l acquisition spécifique de ce petit gibier. la comparaison avec d autres gisements met en évidence l importance des léporidés dans l alimentation des hommes de le paléolithique supérieur moyen et final en particulier à le portugal et aborde les relations entre des facteurs environnementaux et des modèles socio économiques humains.
termith-eval,test_archeologie_08_0040094_tei,les fieux une occupation gravettienne de le causse quercinois. le matériel lithique de la couche e de le gisement des fieux avait été attribué à l epipaléolithique puis à le protomagdalénien par f champagne qui fouilla le site de 1967 à 1991. la présence de pointes et micropointes de la gravette ainsi que des burins de le raysse permet de fait de rattacher cet ensemble à le gravettien. cependant la question de son originalité demeure. celle ci ne. peut être interprétée comme la conséquence d un processus taphonomique l étude technologique et typologique appuyant l hypothèse d homogénéité de la majeure partie de l ensemble. par ailleurs la forte proportion d armatures envisagée comme une conséquence de la spécialisation de le site dans l activité cynégétique met en avant le facteur fonctionnel dans cette interprétation. celui ci est en mesure de répondre partiellement à la question de l association peu commune de différents types d outils dans l ensemble de la couche e d une part les lamelles à dos tronquées nombreuses à le sein d un ensemble où les pointes et micropointes de la gravette sont bien représentées témoignent d une stratégie d exploitation des ressources siliceuses très adaptée à l environnement optimisée pour répondre à l objectif d une occupation spécialisée. d autre part d après les travaux de l klaric sur le gravettien moyen à burins de le raysse dans la partie septentrionale de la france l interprétation des assemblages de le sud ouest de la france associant des éléments rayssiens à ceux d un système de production d armatures à dos doit être discutée. ainsi les trois prismes d interprétation de le polymorphisme de le technocomplexe gravettien sont toujours d actualité regroupant la chronologie le régionalisme et la fonction des sites.
termith-eval,test_archeologie_08_0040095_tei,l occupation de l aurignacien ancien de barbas iii creysse dordogne  résultats prélimainaires sur la fonction de le site. le présent article a comme objectif de définir à partir des premiers résultats obtenus par le croisement des données technologiques fonctionnelles et spatiales le statut techno économique de l occupation de plein air aurignacien ancien de barbas iii. le site de barbas iii est localisé sur la commune de creysse sur la rive gauche de la dordogne. la stratigraphie comprend un niveau moustérien de tradition acheuléenne daté de 38 300 500 b p et 43 500 2 200 b p boëda et al 1996  un niveau châtelperronien et un niveau aurignacien ancien. c est sur cette dernière occupation que nous avons axé notre étude. les matières premières utilisées durant l occupation aurignacienne sont de trois types roches sédimentaires silex silex calcédonieux calcaire  roches cristallines quartz et roches métamorphiques dolérite grès basalte et stéatite. parmi les roches sédimentaires trois types de roches siliceuses le silex de le bergeracois le silex dit de le sénonien et le silex calcédonieux ont été déterminés seul un pourcentage très faible inférieur à 0 2  demeure sans détermination origine incertaine. le silex de le bergeracois constitue la matière quasi exclusivement exploitée  98 . à les alentours de l occupation les argiles maestrich tiennes contenant les blocs de silex devaient très certainement affleurer et constituer un lieu d approvisionnement privilégié. sur ces affleurements les blocs de silex introduits bruts et ou testés ont fait l objet d une sélection raisonnée. a chaque gabarit de blocs de silex introduits dans l occupation correspond une chaîne opératoire laminaire dissociée. chacune d elles est orientée vers l obtention de produits spécifiques que ce soit pour la production des très grandes lames rectilignes 27 x 6 x 2 2 cm en moyenne que celles de modules inférieurs plus graciles et de profil plus courbe de 8 à 16 cm de longueur. les variables dimensionnelles des objectifs et une réduction prononcée et volontaire des étapes de mise en forme des volumes laminaires guident incontestablement le choix lors de l approvisionnement. deux chaînes opératoires lamellaires complètent les productions laminaires. la première orientée vers l obtention de lamelles droites est obtenue à partir de nucléus sur éclat ou sur fragment de bloc. la seconde permet d obtenir de petites lamelles courbes à partir des nucleus type grattoirs carénés. enfin une production d éclats est présente. l outillage retouché est peu représenté inférieur à 5 . les outils sont néanmoins typiques de le faciès ancien de l aurignacien lames à retouche aurignacienne lames étranglées grattoirs carénés complétés par quelques rares burins des grattoirs simples mais surtout par une gamme d outils dits de le fond commun moustérien  encoches denticulés racloirs ainsi qu une pièce façonnée. l analyse fonctionnelle réalisée sur une partie de ces objets confirme l implication de ces outils retouchés tout comme certains supports bruts à le sein de chaînes opératoires de transformation de matières d oeuvre variées. cette étude fonctionnelle réalisée sur un échantillon de 44 pièces lithiques est représentative de l ensemble des schémas opératoires laminaires et lamellaires. elle illustre la particularité de cette occupation par la pratique d activités liées à le travail de la peau et des matières osseuses os et bois animal. ces travaux qui montrent l importance des activités artisanales autres que la fabrication des supports lithiques à le sein de cette occupation. parmi le travail de la peau celui de la peau sèche apparaît le plus abondant bien que l ensemble de la chaîne opératoire de traitement de ce matériau semble représentée sur le gisement jusqu à l adoucissement la confection et l exécution des produits en cuir. pour certaines phases de traitement assouplissement et conservation l utilisation de poudre d ocre obtenue sur place est attestée.
termith-eval,test_archeologie_08_0040096_tei,le burin des vachons apports d une relecture technologique à la compréhension de l aurignacien récent de le nord de l aquitaine et des charentes. la couche 2 des vachons a livré un type de burin particulier reconnu par j coiffard coiffard 1914 1922  puis j bouyssonie bouyssonie 1948 et défini par m perpère comme le burin des vachons  perpère 1972 a et b. le façonnage de ces burins correspond à une intention de production lamellaire orientée vers la recherche de lamelles à tendance rectiligne mesurant de 20 à 60 mm de long. un schéma opératoire complexe peut alors être restitué. cette redéfinition confirme la forte charge culturelle de ce procédé dont témoigne sa position chronologique dans les gisements de le nord de l aquitaine. en effet les ensembles comprenant des burins des vachons clôturent certaines séquences aurignaciennes classiques dont la ferrassie le roc de combe l abri pataud le facteur et le flageolet i la nature de le procédé opératoire et de l objectif sous jacent révèlent un changement fort dans les conceptions lamellaires de la fin de l aurignacien en décalage avec les productions antérieures issues des burins busqués. ce travail propose de documenter cette évolution technique qui permet d envisager sur des bases nouvelles les dernières phases de l aurignacien.
termith-eval,test_archeologie_08_0040097_tei,les couches supérieures de la micoque dordogne. la couche 6 n de le site de la micoque découvert en 1895 est la couche éponyme de le micoquien dont la définition varie fortement selon les auteurs. cette couche 6 n est cependant plus accessible sur le terrain et l ancienneté des fouilles ainsi que la dispersion des pièces dans le monde entier rendent difficile une définition de son contenu. en outre le système stratigraphique d un des fouilleurs principaux hauser n avait jusqu à présent pas pu être raccordé à les autres stratigraphies. ce système correspond cependant presque parfaitement à la stratigraphie connue et documente en outre la présence de deux couches sus jacentes 7 et 8. le contenu de ces trois couches est étudié ici. elles diffèrent fortement en ce qui concerne l usure et le fractionnement des pièces ce qui permet de les intégrer dans le système de sédimentation proposé pour la micoque et consistant en une alternance de dépôts de versant et de dépôts fluviatiles de haute énergie. ceci indique que l âge des couches 6 et 7 à le moins n est probablement que légèrement inférieur à celui des couches sous jacentes. l étude typo technologique des couches 6 7 et 8 a démontré que celles ci ne diffèrent guère l une de l autre tant de le point de vue de le débitage qui contient très peu de levallois de le discoïde des nucléus en forme de lingot et un débitage opportuniste de courtes séries d éclats que de le point de vue typologique. seule la présence de nombreux objets bifaciaux dans la couche 6 la différencie clairement des deux autres. ces outils bifaciaux obéissent à deux schémas conceptuels différents permettant de produire soit des bifaces soit des couteaux bifaciaux. ces caractéristiques permettent de placer l industrie de la couche 6 dans le micoquien maintenant appelé keilmessergruppen kmg  mais se pose la question de la pertinence d une attribution culturelle sur la seule base de la présence ou de l absence de certains éléments dits diagnostiques en ce cas les outils bifaciaux.
termith-eval,test_archeologie_08_0040098_tei,l économie de le silex à le paléolithique supérieur dans le bassin d aquitaine. le cas des silex à lépidorbitoïdes des pyrénées centrales. caractérisation et implications méthodologiques. un type particulier de silex le silex maastrichtien à lepidorbitoides a été individualisé dès 1988 parmi des artefacts provenant de le nord de l aquitaine. la géologie régionale indique que cette roche ne peut provenir que de la partie méridionale de le bassin d aquitaine le piémont pyrénéen. une provenance possible de ces matières premières se localise en chalosse sud de le département des landes où des silex pouvant être assimilés à ce type avaient été signalés dès 1984. leur appartenance à ce type lithologique a été confirmée. parallèlement une approche géologique régionale conduisait à ne pas restreindre à cette zone l aire potentielle dans laquelle ces silex avaient pu se former. on connaît en effet dans les pyrénées centrales les chaînons des petites pyrénées dans lesquels affleurent des calcaires maastrichtiens à orbitoïdidés. il eut été raisonnable de garder ces possibilités en mémoire et non point de les nier et ainsi de les intégrer dans les reconstitutions palethnologiques récentes. des travaux récents ont porté sur 186 échantillons de silex provenant de la région des petites pyrénées et de la chalosse. l objectif de cette étude était de mettre en évidence la présence de niveaux à silex à lepidorbitoides dans les pyrénées centrales et d établir des critères objectifs utilisables pour différencier les différentes zones géographiques de provenance. nous avons pu  dans les pyrénées centrales donner la diagnose d un type de silex le silex de tarté contenant un cortège paléontologique de le maastrichtien supérieur avec des lépidorbitodés ainsi qu un autre type de matière première siliceuse le silex de montsaunès carrière  ayant des caractéristiques très particulières rendant sa reconnaissance facile  mettre en évidence le silex de tarte  ce qui confirme l hypothèse formulée depuis longtemps de l existence de matières premières siliceuses à lépidorbitoïdés dans cette partie des pyrénées  à partir des échantillons provenant d audignon et de bastennes gaujacq chalosse  montrer des différences notables entre ces différentes sources ce qui permettra de les distinguer entre elles ainsi que de les séparer des silex de tarte. les éléments analytiques apportés devraient conduire à plus de précisions dans les déterminations d origine de ces diverses catégories de silex et par voie de conséquence à plus de vraisemblance dans les recherches sur les provenances de ces matériaux pendant le paléolithique.
termith-eval,test_archeologie_08_0168746_tei,transformation et utilisation préhistoriques des matières osseuses à le retour de la chasse observations expérimentales concernant les impacts sur le gibier la récupération et la maintenance des projectiles dans le magdalénien supérieur d isturitz pyrénées atlantiques. le présent article réunit plusieurs réflexions inspirées par l étude de le matériel expérimental issu d une séance de tir de répliques de projectiles paléolithiques sur cible animale qui s est déroulée en janvier 2003 à le cedarc musée de le malgré tout treignes belgique. le projet initialement organisé dans l objectif de vérifier l hypothèse d une utilisation des pointes à bases fourchues magdaléniennes comme armatures a également permis de récolter une série d informations annexes qui pourraient s avérer particulièrement intéressantes dans l interprétation des activités cynégétiques sur notre site de référence isturitz. après un bref rappel de le protocole expérimental nous nous arrêterons sur trois aspects les traces d impacts balistiques relevées sur les ossements des animaux utilisés comme cibles l identification sur certaines pointes de stigmates liés à leur récupération dans la carcasse des animaux et enfin une comparaison entre l état de fragmentation des pointes de sagaies à la fin de l expérimentation et les pointes archéologiques d isturitz.
termith-eval,test_archeologie_08_0168754_tei,transformation et utilisation préhistoriques des matières osseuses identification d un type particulier d objet en bois de cervidé à le gravettien les matrices outils  association de deux concepts a priori distincts. le gravettien moyen à burins de noailles d isturitz et le gravettien récent de laugerie haute ont livré une riche industrie osseuse à le sein de laquelle nous avons isolé un type d objet particulier les matrices outils  que nous avons subdivisé en deux catégories. la première présente sur les deux gisements repose sur une récupération opportuniste de matrices de débitage transformées en outils biseautés de deuxième intention. la seconde attestée uniquement à laugerie haute est constituée de matrices outils de première intention  témoignant d une volonté de produire simultanément un support et un outil biseauté. ces deux objectifs sont étroitement liés et répondent à des règles précises dans le choix de la partie anatomique exploitée ainsi que dans les procédés de débitage employés. la création de l outil n est pas ici subordonnée à la production d un support mais on constate à le contraire que le débitage de la matrice a été conduit de façon à ne pas nuire à la réalisation de cet outil. ainsi les gravettiens de laugerie haute ont su combiner à le sein d une même opération technique deux concepts a priori bien distincts le débitage et le façonnage.
termith-eval,test_archeologie_08_0168755_tei,transformation et utilisation préhistoriques des matières osseuses le travail des matières dures animales dans le site gravettien la vigne brun  loire france  apport de l analyse tracéologique des outillages lithiques. découvert dans les années 80 le site de plein air de la vigne brun loire france est un gisement gravettien sans équivalent dans le contexte des sites de le début de le paléolithique supérieur en europe occidentale. l excellent état de conservation de l industrie lithique localisée dans des structures d habitat bien définiess autorise la réalisation d une étude interdisciplinaire incluant l analyse tracéologique. celle ci intégrée à l analyse technologique et à la répartition spatiale des vestiges contribue à la détermination des activités pratiquées dans le gisement. l étude des traces d utilisation de le matériel lithique provenant de l unité op 10 a ainsi permis d identifier les taches et les matières travaillées à le moyen des outils de silex dans cette structure. nous ne présenterons ici que les résultats relatifs à le travail de matières dures animales. l emploi des burins et des grattoirs domine dans les processus techniques de transformation de l os et de le bois de cervidé. les burins ont servi essentiellement à le travail des matériaux osseux. cet outil semble concentrer différentes opérations techniques telles que le rainurage le sciage et le raclage. pour le rainurage des liens ont pu être établis avec la morphologie de la zone active formée par l extrémité burinante. les grattoirs essentiellement utilisés dans le traitement de la peau sont intervenus plus ponctuellement sur le bois de cervidé. l état actuel de l analyse tracéologique montre que l exploitation des matières dures animales fait partie de le spectre d activités pratiquées à le sein de l unité op 10. a partir des résultats obtenus la reconstitution des processus techniques des artefacts osseux est abordée les traces d usure identifiées semblent correspondre à des phases de fabrication et ou d entretien.
termith-eval,test_archeologie_08_0168756_tei,transformation et utilisation préhistoriques des matières osseuses les industries osseuses de le paléolithique supérieur récent de le sud est de la france essai d une caractérisation typo technologique. réalisée dans le cadre d une maîtrise cette étude a été consacrée à la caractérisation de l industrie en matières dures animales de la fin de le paléolithique supérieur dans le sud est de la france. cette industrie et ses auteurs posent question quant à leur rattachement chronologique et culturel à les ensembles mieux connus de le sud ouest de la france ou de le nord de l italie. c est à cette interrogation majeure de la connaissance de le peuplement de le sud est de la france que nous avons tenté d apporter des éléments de réponse à travers une analyse typo fonctionnelle et technologique des séries de trois sites vauclusiens chinchon i charasse i soubevras.
termith-eval,test_archeologie_08_0168990_tei,les coquillages alimentaires des dépôts et amas coquilliers de le mésolithique récent final de la façade atlantique de la france de la fouille à un modèle d organisation logistique de le territoire. les populations mésolithiques vivant à proximité ou sur des zones de déchets coquilliers ont par le passé été associées à une image très négative. ces ramasseurs de coquillages auraient ainsi établi leur campement dans des zones marginales dont personne ne voulait. cette vision des populations côtières de le mésolithique tend actuellement a être modifiée par l analyse de leur mode de subsistance et de résidence jusque là peu prise en compte. les caractéristiques de l exploitation de la malacofaune marine montrent que la diversité des substrats et des espèces les plus accessibles a été exploitée. elle traduit un comportement opportuniste de ces populations qui ne se sont pas limitées à les coquillages mais qui ont collecté péché et chassé tout ce qui était disponible dans leur environnement. d autre part les points communs à les différents sites de le mésolithique tendent vers un meilleur rendement de l exploitation des coquillages en limitant les sous systèmes techniques de l acquisition et de la consommation de cette denrée. enfin des différences sont aussi observées. elles opposent des sites à la faible diversité spécifique de la malacofaune à d autres de plus grande diversité. d autres éléments tendent à dissocier ces deux types de sites. les amas à la plus grande diversité spécifique se composent d autres restes fauniques mammifères terrestres et marins oiseaux poissons crustacés  et le temps de résidence semble y être plus prolongé que pour les autres sites òu aucun reste de faune autre que les coquillages a été observé. même si l ébauche d une organisation logistique de le territoire demande à être validée cette étude montre que ces populations mésolithiques ne sont pas isolées des autres groupes humains contemporains.
termith-eval,test_archeologie_08_0169166_tei,la barrière dans les gravures rupestres de le sud marocain. cet article examine un type de gravure bien délaissé par les auteurs parce que trop souvent assimilé à un passe temps tardif. or le rectangle est authentiquement une gravure à le trait poli ou incisé de le style de tazina pour autant que le contexte prête à cette insertion. l auteur propose de rapprocher ses diverses formes élémentaires en les regroupant sous le terme de barrières. l analyse de ces formes puis l examen attentif des scènes où la barrière côtoie la faune ou leur est reliée voire même paraissant abattue par son action conduisent à d autres significations que celle de la géométrie dans laquelle le graveur tazinien excelle. il peut s agir soit d un simple obstacle conduisant les proies vers leur destin soit de l engin lui même destiné à les capturer. l article vise notamment à donner quelques clés pour se retrouver entre ces directions diverses par exemple la prise en compte de le modelé naturel ou rectifié des surfaces rocheuses. car les auteurs de ces gravures ont joué de tout pour exprimer des anecdotes cynégétiques aussi bien que d autres intentions plus élevées. des modèles réels sont proposés. à le final la barrière pourrait être l un des indicateurs de le style de tazina.
termith-eval,test_archeologie_08_0169210_tei,l établissement rural de la tène moyenne de la gaudine à vivoin sarthe et ses activités de transformation. les fouilles préventives liées à les travaux autoroutiers de l a 28 alençon le mans ont permis la découverte près d un méandre de la sarthe d un établissement rural datable de la tène moyenne. il est formé d un modeste enclos fossoyé de forme trapézoïdale d environ 2000 m 2 de surface. l abondant mobilier livré par les fossés céramique lithique terres cuites et ossements reflète les activités menées sur le site domestiques agricoles élevage de le boeuf et de transformation boucherie et meunerie.
termith-eval,test_archeologie_08_0169230_tei,l occupation de l âge de le fer à les chaloignes mozé sur louet maine et loire. un ensemble complexe et énigmatique de creusements à proximité d un établissement rural de l âge de le fer à les chaloignes mozé sur louet a livré un lot important de céramiques associées à d autres mobiliers dont certains dits de prestige. bien que fragmenté et hétérogène ce mobilier permet une datation de l occupation et ouvre de nouvelles perspectives quant à la définition des horizons de l âge de le fer des marges méridionales de le massif armoricain. mais l étude de la céramique et de le mobilier associé plus qu un simple instrument de datation se propose d aborder le statut de le site où existent des pratiques de dépôt encore mal définies et d ouvrir une réflexion d ordre culturel dans une région dans la partie aval de la loire où se mêlent diverses influences.
termith-eval,test_archeologie_08_0169441_tei,les amas coquilliers de mauritanie occidentale et leur contexte paléoenvironnemental  viie iie millénaires bp. l ensemble des amas coquilliers de le littoral de mauritanie représente un exemple exceptionnel en milieu tropical sec de l utilisation de ressources marines de le rivage. pendant à le moins 6 millénaires des hommes ont vécu sur le rivage ou l ont saisonnièrement fréquenté pour pêcher et pour collecter bivalves et gastéropodes. l étude des vestiges de mollusques dans leur milieu et associés à d autres éléments archéologiques fournit des éléments essentiels d interprétation sur de longues périodes des variations de l hydroclimat et de le climat terrestre ainsi que des variations de le niveau de la mer facteurs qui ont joué un rôle essentiel dans l évolution de le mode de vie des populations de le sahara atlantique. des méthodes récentes permettent d envisager à partir d analyses isotopiques des coquilles elles mêmes des reconstitutions très fines des caractéristiques des climats littoraux à diverses périodes de le passé et peuvent contribuer à mieux comprendre les liens entre atmosphère et océan. que ce soit pour l alimentation ou l ornementation voire pour des usages industriels  les mollusques ont constitué la base de plusieurs économies successives de sociétés néolithiques et protohistoriques sahariennes ou sahéliennes qui ne sont sans rappeler certains systèmes d exploitation actuels dans d autres régions de l afrique occidentale. a travers les vestiges de ces usages transparaissent la diversité des écosystèmes littoraux et leur évolution parfois rapide et éventuellement liée à des phénomènes de surexploitation constituant une source d enseignements pour la période actuelle et le futur proche en matière de gestion des ressources vivantes côtières et d aménagement de le littoral.
termith-eval,test_archeologie_08_0169462_tei,le site aurignacien de plein air de combemenue à brignac la plaine corrèze  apport de la géoarchéologie et de l étude de l industrie lithique à la compréhension des processus taphonomiques. le site paléolithique de combemenue en corrèze a livré un niveau d occupation d aurignacien récent enfoui à faible profondeur sur un replat près de le sommet d un versant. le contexte de faible enfouissement laissant suspecter des perturbations significatives de le niveau archéologique dues à une longue exposition à les agents naturels en surface ou en subsurface de le sol une étude taphonomique détaillée a été entreprise. différents points ont été examinés la distribution spatiale de le matériel la disposition des objets fabrique  leur granulométrie leur état de surface ainsi que les remontages. les résultats obtenus ont été confrontés de manière à proposer un scénario qui rende compte à le mieux de l ensemble des observations faites sur le site. cette étude indique que l assemblage lithique originel a subi un appauvrissement sélectif en petits éléments sous l action de le ruissellement. simultanément il est possible qu une partie de le matériel de plus grande taille initialement présent ait été soustrait de le site par les mécanismes sédimentaires. ces modifications ont eu des répercussions sur la distribution spatiale des vestiges. celle ci se caractérise par une absence de concentration claire tant lorsqu on considère la répartition de l ensemble de le matériel que celle de catégories particulières d objets. une diffusion progressive des vestiges par le ruissellement ou les phénomènes périglaciaires rend bien compte des transformations observées. en revanche les déplacements n ont pas entraîné d altération physique importante des pièces dont la majorité ne porte pas de stigmate postérieur à sa production ou son utilisation par les aurignaciens. les transformations décrites ici pour le site de combemenue sont probablement représentatives de celles subies par un grand nombre de sites paléolithiques localisés sur une pente négligeable dans un contexte géomorphologique peu favorable à un enfouissement rapide.
termith-eval,test_archeologie_08_0169477_tei,les occupations néolithiques de monéteau  sur macherin  yonne  données préliminaires. le site de monéteau sur macherin exploré en 1999 a livré de nombreuses traces d occupations de le néolithique ancien à l époque gallo romaine. le néolithique est particulièrement bien représenté le villeneuve saint germain avec sept unités d habitation le néolithique récent avec d énigmatiques structures funéraires une petite tombe multiple datée de le néolithique final et surtout le néolithique moyen chasséen avec une nécropole associée à une enceinte. ce cimetière se compose de deux ensembles disjoints structurés différemment et associés à des dispositifs monumentaux. les pratiques funéraires notamment la prépondérance des coffres rapprochent cet ensemble de le domaine chamblandes de suisse occidentale. le mobilier qui comprend des éléments méridionaux comme de le bassin parisien reflète la position géographique de la nécropole.
termith-eval,test_archeologie_08_0169734_tei,une figuration inédite de léporidé dans la couche 3 de l abri duruthy sorde l abbaye landes france. dans le cadre de la réorganisation de le musée de l abbaye d arthous landes  le réexamen rapide des collections issues des fouilles de r arambourou à l abri duruthy sorde l abbaye landes france a été l occasion de découvrir une figuration de léporidé sur une baguette demi ronde. à titre de comparaison les figurations de ce thème dans l art paléolithique sont recensées. l attribution chronologique et culturelle de la couche 3  niveau de provenance de cette pièce est ensuite discutée mais il demeure difficile de trancher entre magdalénien moyen et supérieur.
termith-eval,test_archeologie_08_0202212_tei,ploemeur kerham la nn porz menec h morbihan  un monument funéraire de le premier âge de le fer. connu par les archives de le commandant le pontois qui l avait fouillé en 1891 et remis à le jour en 2004 le monument à parement circulaire de lann porz menec h a fait l objet d un sondage d évaluation. malgré son mauvais état de conservation et par comparaison avec les tumulus dits à muret circulaire répertoriés dans la péninsule armoricaine il semble possible de l attribuer à le premier âge de le fer et en l absence de charbons de bois et d ossements incinérés à une phase où l inhumation prédomine en bretagne occidentale antérieurement à le développement des cimetières à incinérations de le hallstatt d 3 et de la tène a si l on tient compte de le laps de temps écoulé entre la construction de le tertre parementé et l aménagement de deux tombes adventices dans les étalements de sa dégradation peut être plusieurs décennies plus tard  on peut proposer une création de le site à le vie siècle av. j c à le plus tard.
termith-eval,test_archeologie_08_0202215_tei,un ensemble funéraire de la transition âge de le fer antiquité en contexte karstique la grotte rochefort à saint pierre sur erve mayenne. dans le cadre de la fouille programmée de la grotte rochefort l étude préalable des niveaux récents a permis d identifier de nombreux restes osseux humains disséminés sur la totalité de la surface de la salle des troglodytes. sans connexions anatomiques et intimement mêlés à des tessons de céramiques à le sein d une unité stratigraphique perturbée ces os correspondent à le démantèlement d un dépôt funéraire primaire pour lequel une attribution à la tène finale ou à le début de l antiquité est avancée. l article se propose d établir un inventaire de ces restes osseux et de comprendre le dépôt initial en liaison avec le mobilier céramique et métallique retrouvé qui devait accompagner les défunts. nous replacerons cet ensemble dans l inventaire plus large des sites funéraires gaulois en grotte pour lesquels les données commencent à se préciser.
termith-eval,test_archeologie_08_0202236_tei,habitats nécropoles et lieux de culte des pertes de la venelle à lux côte d or. à lux côte d or  la photographie aérienne prouve que la rive gauche de la tille fut le siège d une intense activité depuis le néolithique. trois sites majeurs ont été déterminés de l amont à l aval  une enceinte circulaire fossoyée doublée d une enceinte curviligne sur fond de fosses et de trous de poteaux  un village avec maisons à trous de poteaux et silos  un vaste ensemble d enceintes dont la plus ancienne est doublée d une palissade externe une porte clairement organisée est traversée par les fossés parallèles d une avenue qui conduit à les pertes de la venelle lieu de culte vraisemblablement néolithique.
termith-eval,test_archeologie_08_0202252_tei,typo chronologie des céramiques de le groupe rhin suisse france orientale r s f o dans la région dijonnaise étude stratigraphique des dépotoirs de matériaux céramiques en contexte d habitat sur le site de le pré du plancher à varois et chaignot côte d or. le site de le pré du plancher se localise dans l est de la région dijonnaise bourgogne côte d or. il s agit d un habitat ouvert formé de trois bâtiments en matériaux périssables associés à des structures annexes implanté à le pied d un petit coteau calcaire dominant la vallée de le basmont bassin hydrographique de la saône. son occupation est datée de le bronze final plus particulièrement de la période moyenne de le groupe r s f o ce site est le premier habitat de la période à avoir livré une séquence stratigraphique associée à un mobilier abondant illustrant les trois phases de l habitat. cette séquence est obtenue par l étude typo chronologique des différentes phases de dépotoir domestique se trouvant stratifiées dans le remplissage d une grande fosse polylobée utilisée sur toute la durée de l habitat. l étude complète de ce mobilier céramique trouvé en abondance permet de jeter les bases d une chrono typologie de le r s f o en bourgogne orientale et constitue le premier échelon d une réflexion à plus grande échelle comprenant notamment la périodisation de le bronze final dans la région.
termith-eval,test_archeologie_08_0202253_tei,occupations domestique et funéraire de l âge de le fer à lavau aube. cet article présente les résultats d une fouille préventive inrap effectuée sur la commune de lavau dans l aube. deux occupations distinctes ont été clairement identifiées une portion de ferme de la fin de l âge de le bronze début de le hallstatt ainsi qu une petite nécropole de la tène moyenne. si la ferme est emblématique d une exploitation rurale de cette époque la nécropole se démarque de ce que l on en attendrait son emplacement son organisation ainsi que certaines pratiques funéraires la rendent insolite.
termith-eval,test_archeologie_08_0202254_tei,l environnement protohistorique de le mont afrique données inédites sur des fouilles de tumulus exécutées à la fin de le xixe s et à le début de le xxe s à couchey côte d or. cette notice présente le mobilier de plusieurs tertres funéraires anciennement repérés. deux d entre eux étaient totalement inédits trois autres tumulus avaient été partiellement publiés l un en 1905 le second en 1925 et 1961 et le troisième en 1926. la fin de l article présente les découvertes également inédites de deux fibules protohistoriques et la description d une butte imposante qui a longtemps attiré l attention des archéologues à le début de le xxe s encore non fouillée.
termith-eval,test_archeologie_08_0463626_tei,tendances actuelles dans la caractérisation des obsidiennes pour les études de provenance. les recherches de provenance des obsidiennes de sites paléolithiques et néolithiques connaissent actuellement une grande expansion notamment par leur intégration dans les études de chaînes opératoires qui nécessitent de déterminer l origine de la matière première de séries importantes de pièces archéologiques. il existe par ailleurs une forte demande de mesures peu à non destructives et éventuellement à effectuer in situ. d où un certain nombre de développements méthodologiques récents. le but de cette contribution est d en présenter le statut actuel.
termith-eval,test_archeologie_08_0463629_tei,stratégies d approvisionnement en eau dans l agglomération gallo romaine de cassinomagus chassenon charente. le but de cette étude était de retrouver les ressources en eau en contexte de métamorphisme de choc astroblème de rochechouart chassenon  de reconstituer l organisation spatiale des structures gallo romaines de cassinomagus implantées à chassenon et de tenter de comprendre les relations entre les constructions gallo romaines et les ressources en eau. nous avons répondu à cette problématique par la réalisation de prospections géophysiques. la réalisation de prospections électriques et magnétiques à maille fine couplées à des mesures de susceptibilité magnétique ont permis d entrevoir l extension de le bâtiment thermal l agencement des quartiers privés à proximité de le complexe monumental ainsi que l extension de le réseau hydraulique superficiel. le traitement des sondages électromagnétiques à maille large a permis de produire des cartes de résistivité électrique pour différentes profondeurs de terrains ces cartes ont révélé la présence d un aquifère dans les impactites et ont montré d étroites relations entre la position de le captage des galeries drainantes et l extension des formations aquifères.
termith-eval,test_archeologie_08_0463630_tei,l environnement de le site ibérique de la alcudia et les carrières antiques de la dame d elche province d alicante espagne. le site ibérique célèbre de la alcudia l illici antique est situé dans la dépression tectonique d elche secteurs de le bas vinalopo et de le bas segura à l extrémité orientale des chaînes bétiques. l environnement de le site est envisagé sous ses aspects géologiques et géographiques reconstitution de le paysage ibérique et des rivages marins proches ressources minérales de l arrière pays. l essentiel de l étude concerne l extraction et l utilisation des matériaux lithiques employés notamment pour la statuaire à l époque ibérique. l ensemble des carrières d où fut extraite la pierre de la fameuse dame d elche est localisé. un début d inventaire pétrographique permet de repérer la diffusion dans les régions avoisinantes des oeuvres sculptées produites à la alcudia.
termith-eval,test_archeologie_08_0463635_tei,le mobilier en verre de le site de la grotta piatta aregno haute corse  composition chimique et chronotypologie. la grotta piatta est un site funéraire protohistorique découvert sur la côte nord occidentale de la balagne. un nombre important de perles en verre y a été révélé. sur les trois cent soixante neuf pièces recueillies une vingtaine a fait l objet d analyses pour déterminer leur composition ainsi que leur provenance. l analyse a mis en évidence l origine proche orientale de la pâte de verre utilisée comme matière première trois grands groupes ont été distingués par rapport à les fondants et à les sables utilisés dans leur composition. cependant certains éléments ont montré des particularités. chronologiquement ce mobilier peut être rattaché à un contexte postérieur à le iie siècle av. j c et postérieur à le iersiècle de notre ère pour trois éléments se distinguant.
termith-eval,test_archeologie_09_0062861_tei,à les origines de le magdalénien classique  les industries de la séquence inférieure de l abri gandil bruniquel tarn et garonne. la séquence stratigraphique de l abri gandil bruniquel tarn et garonne documente l évolution des premiers temps de le magdalénien. cet article fait le point sur les industries lithiques et osseuses de la séquence inférieure couches 25 23 et 20  datée de la fin de le dernier pléniglaciaire 17 500 15 000 bp. la caractérisation de le magdalénien inférieur de l abri gandil s appuie sur une analyse de le sous système lithique et de l équipement en matière dure animale. les matières premières siliceuses sont préférentiellement locales dans l ensemble même si on note une évolution en c 20 avec l augmentation des silex régionaux de meilleure aptitude à le débitage laminaire. concernant les productions lithiques il s agit essentiellement de débitages lamellaires et microlamellaires mis en oeuvre selon une diversité de modalités. le débitage laminaire peu investi en c 23 25 prend une place plus importante en c 20 en relation avec la confection de pointes à cran. l équipement en matière dure animale montre également des changements à le sein de la séquence inférieure et se distingue assez fortement de le matériel des fouilles chaillot ensemble supérieur. l étude des séries c 23 25 et c 20 permet donc non seulement de mieux caractériser les traits techno économiques de le magdalénien inférieur de le sud ouest européen d envisager une évolution interne de le magdalénien inférieur marquée notamment par le développement des débitages laminaires dévolus à les pointes à cran et à les outils et par une augmentation des grandes lamelles mais également de réfléchir à la genèse de le magdalénien classique.
termith-eval,test_archeologie_09_0062862_tei,contribution des méthodes magnétiques a l étude de le remplissage de le site préhistorique de l abri pataud les eyzies de tayac dordogne france. le site de l abri pataud daté de le pléistocène supérieur stade isotopique 3 à 2  est caractérisé par une grande richesse en faune et en industrie et par la succession de plusieurs niveaux d habitats riches en éléments brûlés et en matériel archéologique. l étude magnétique a permis de faire la distinction entre deux types d ensembles magnétostratigraphiques d une part les éboulis caractérisés par un faible pourcentage en grains magnétiques et par de faibles valeurs des paramètres magnétiques et d autre part des niveaux sablo limoneux riches en foyers et présentant de fortes valeurs magnétiques. dans les éboulis les grains magnétiques sont plutôt grossiers poly domaines  essentiellement d origine détritique hématite sidérite et goethite. à le contraire les niveaux archéologiques présentent des grains magnétiques de taille fine md pmd et sp  résultant de la transformation sous l effet de la température des foyers d oxydes d hydroxydes goethite et de carbonates de fer feco 3 en oxydes de fer secondaires de taille fine magnétite et maghémite.
termith-eval,test_archeologie_09_0062863_tei,l exploitation de le lièvre variable a la madeleine dordogne france et le statut d un petit gibier à le dryas ancien. cette étude présente les résultats de l analyse des restes osseux et dentaires de lepus timidus issus des couches de le magdalénien iv de la madeleine fouilles peyrony et bouvier. il s agissait de caractériser l exploitation de le lièvre variable et c est pourquoi l ensemble des restes transformés ou non a été pris en compte à le sein d une étude intégrée. la représentativité des deux collections ancienne et récente est variable ce qui ne limite pas nécessairement le potentiel informatif des deux séries. la part de le lièvre à le sein des espèces chassées difficile à apprécier se situe probablement entre 7 et 20  en nr. si l étude de l exploitation des carcasses met en évidence le prélèvement de plusieurs produits alimentaires ou non leur part respective et leur consommation sont plus difficiles à préciser. l hypothèse d une éventuelle recherche prioritaire de la fourrure est discutée.
termith-eval,test_archeologie_09_0062864_tei,étude typo technologique et spatiale de remontages lithiques de canaule ii site châtelperronien de plein air en bergeracois creysse dordogne. fouillé par jean guichard en 1968 et 1969 le site de plein air de canaule ii creysse dordogne présente un unique niveau archéologique attribué à le châtelperronien par la présence de pièces à dos caractéristiques. ce gisement fut interprété comme étant un atelier de débitage directement implanté sur les gîtes de silex maestrichtien de le bergeracois. nous le présentons ici à travers l approche taphonomique techno économique et spatiale de cinq remontages lithiques. cette étude montre l exceptionnelle conservation de le site et explore le potentiel qu il révèle pour la définition de le châtelperronien et la caractérisation des comportements humains à le début de le paléolithique supérieur.
termith-eval,test_archeologie_09_0062865_tei,les équidés des grottes des combarelles les eyzies de tayac dordogne france  étude morphométrique. un outil informatique utilisant la géométrie morphométrique est testé sur la forme des équidés de diverses catégories et races actuelles. l étude est appliquée à les figurations équines des grottes des combarelles qui semblent démontrer une grande unité de forme parmi les individus analysés. cette méthode pourrait offrir la possibilité de comparaisons à grandes échelles de manière précise et statistique.
termith-eval,test_archeologie_09_0062866_tei,la grotte des fées châtelperron allier ou une interstratification chatelperronien aurignacien illusoire. histoire des fouilles stratigraphie et datations. dans une publication récente gravina et collaborateurs 2005 admettent qu une interstratification entre industries châtelperroniennes et aurignaciennes est avérée à la grotte des fées phénomène qui implique une longue contemporanéité entre les populations porteuses de ces deux technocomplexes. cette interprétation qui s appuie essentiellement sur des datations numériques réalisées à partir d échantillons provenant des fouilles de delporte a été vivement critiquée par zilhao et al 2006. elle a cependant été maintenue par les premiers auteurs qui réfutent l ensemble des arguments avancés par zilhao et collaborateurs mellars et al 2007 dans cet article nous exposons en détail les informations et les arguments qui nous conduisent à rejeter l idée d une interstratification sur le site de la grotte des fées. les questions soulevées par mellars et collaborateurs sont discutées. de nouveaux éléments sont également pris en compte. l historique des travaux conduits sur le site depuis le xixe siècle les incohérences concernant la localisation des fouilles différente selon les sources la signification des datations 14 c l analyse de l industrie lithique et de la parure recueillie par h delporte montrent que ce site livre en fait un mélange de pièces châtelperroniennes et aurignaciennes sur l ensemble de sa séquence et qu il ne peut donc servir à étayer l hypothèse d une contemporanéité entre ces deux populations. l analyse de la faune associée à les industries met en évidence une accumulation par des carnivores. sur cette base les différentes possibilités d association entre vestiges fauniques et lithiques sont discutées. la signification des dates 14 c est également évaluée à partir des différents modes de formation possibles de le site. l interprétation la plus rigoureuse des données recueillies incite à penser que les dépôts fouillés par delporte correspondent pour l essentiel à des déblais de fouilles pratiquées à le xixe siècle. seule une petite partie de le site en particulier à la base de la séquence pourrait réellement correspondre à des témoins en place. sur les treize dates obtenues par mellars et collaborateurs 2007  dix ont été réalisées à partir de vestiges provenant de ce témoin. elles suggèrent une occupation châtelperronienne autour de 39 40 ka 14 c bp et une occupation par les seuls carnivores dans l intervalle 36 5 ka 34 5 ka 14 c bp. la présence d objets typiquement aurignaciens à le sein des déblais fouillés par delporte atteste d une fréquentation sporadique de le gisement par les porteurs de cette industrie. ces vestiges aurignaciens sont susceptibles de provenir d un niveau surmontant les dépôts moustériens et châtelperroniens.
termith-eval,test_archeologie_09_0062867_tei,l émergence de le paléolithique supérieur en europe mutations culturelles et rythmes d évolution. la mise en place de le paléolithique supérieur est traditionnellement envisagée sous l angle de la rupture. de ce point de vue l aurignacien est interprété comme la culture qui consacrerait la généralisation de nombreuses innovations et représenterait l instrument de la conquête européenne de l homme moderne et de le remplacement des populations néandertaliennes. cet article fait le point sur la définition actuelle des débuts de l aurignacien européen et essaie de les restituer dans un processus évolutif. l un des moteurs de l évolution technologique des groupes humains entre 45 000 et 30 000 bp pourrait correspondre à la recherche de solutions techniques pour armer des projectiles. de ce fait une plus grande profondeur temporelle et une relative arythmie dans le développement des caractères constitutifs de le paléolithique supérieur sont mises en avant. a ce titre la distinction chronologique et technologique d à le moins deux grandes traditions le protoaurignacien et l aurignacien ancien est évoquée conduisant à modifier substantiellement les schémas d évolution classiques de le paléolithique moyen à le paléolithique supérieur.
termith-eval,test_archeologie_10_0039789_tei,la molaire d enfant néandertalien de genay côte d or france. réflexions sur la variabilité dentaire des néandertaliens. en 1985 un germe isolé d une molaire inférieure était mis à le jour par y pautrat dans le site de genay en côte d or france durant des fouilles de sauvetage. ce germe a été trouvé avec de le matériel lithique attribué à le moustérien et des vestiges fauniques qui pourraient être rapportés à le stade isotopique 4. toutefois il n est pas possible d établir précisément la position spatiale de ce nouveau vestige numéroté genay 3 avec le crâne fragmentaire de genay 1 et la dent isolée de genay 2 mis à le jour lors des fouilles de j joly et j j puisségur en 1955 joly 1955. le fossile genay 3 est identifié comme un germe de première molaire permanente droite ayant appartenu à un enfant de 2 3 ans étant donné la calcification de la couronne dentaire. les diamètres mésio distal et vestibulo lingual sont importants avec des valeurs voisines de celles de la série de krapina ou d autres néandertaliens. cette pièce se caractérise par ses dimensions et une morphologie assez tourmentée de sa face occlusale avec sept cuspides une fossette mésiale profonde et bien individualisée comme cela est documenté chez d autres néandertaliens immatures. l étude de ce germe permet de mieux connaître la variabilité des populations qui peuplaient la bourgogne à le moustérien. cela nous conduit aussi à présenter des réflexions préliminaires quant à celle de certains traits morphologiques la mid trigonid crest et métriques des membres de la lignée néandertalienne.
termith-eval,test_archeologie_10_0039790_tei,nouveaux restes humains moustériens rapportés à le squelette néandertalien de regourdou 1 regourdou commune de montignac dordogne france. le présent article fait état de la découverte de nouveaux ossements néandertaliens issus des collections fauniques de le site moustérien de regourdou. après une présentation de le gisement situant rapidement le cadre chrono culturel l accent est mis sur l aspect historiographique rappelant les travaux de roger constant la découverte de la sépulture néandertalienne regourdou 1 en 1957 les fouilles qui suivirent et les mouvements des vestiges découverts. ces précisions montrent que le contexte n a pas joué en faveur de la préservation idéale de le matériel exhumé. pour preuve des travaux de récolement et une étude en cours ont permis d isoler plusieurs ossements humains parmi les vestiges fauniques acquis en 2002 par le musée national de préhistoire. ils sont a priori tous attribuables à la sépulture qu ils complètent de façon significative. ces pièces sont issues de la couche 4 qui a livré la sépulture humaine mais elles ne sont pas toutes à rapporter à le tumulus iva auquel correspond cette sépulture. les caractéristiques anatomiques de ces nouvelles pièces mettent en évidence leur appartenance soit à le squelette regourdou 1 soit à la lignée néandertalienne. le squelette original regourdou 1 découvert en 1957 présentait un contraste très net entre la présence de deux chaînes articulaires assez complètes pour les membres supérieurs et la quasi absence de restes pour les membres inférieurs en dehors des pieds. les nouvelles découvertes viennent en partie combler ce manque. des travaux plus approfondis sur chacune des pièces nouvellement identifiées compléteront nos connaissances de la variabilité de le squelette infra crânien des néandertaliens regourdou 1 devenant un des squelettes moustériens les plus complets mis à le jour dans le sud ouest de la france. quant à l absence totale de le calvarium compte tenu de le contexte général il faut peut être aussi envisager une nouvelle hypothèse selon laquelle il se trouverait encore à le sein de le remplissage sédimentaire non fouillé de le site.
termith-eval,test_archeologie_10_0039791_tei,interprétation technologique et discussion autour de le statut culturel des pièces de la bertonne  l exemple de la série lithique de seyresse landes france. le site de plein air de seyresse landes france  fouillé à la fin des années soixante par r arambourou a livré une série lithique originale bien que quantitativement faible. rapproché lors de sa publication à le proto solutréen cet assemblage a fait l objet dès le milieu des années quatre vingt de nouvelles expertises conduisant à une révision de cette interprétation chronoculturelle. en effet certaines pièces qui comportant des enlèvements plans inverses d extrémité avaient été rapprochées d outils solutréens correspondent plus vraisemblablement à les pièces de la bertonne décrites par m lenoir à partir de sites girondins attribués pour leur plus grande part à le badegoulien magdalénien ancien 0 1. les données acquises ces dernières années par le biais des travaux menés sur les industries lithiques comprises entre 19 500 et 15 000 bp dans la moitié sud de la france sont venues préciser le cadre chronologique post solutréen validant notamment une succession badegoulien à raclettes magdalénien inférieur  permettant alors d appréhender ces industries à pièces de la bertonne sous un angle nouveau. à la suite d une présentation générale de l industrie de seyresse une lecture technologique de ces éléments particuliers est proposée conduisant à confirmer une hypothèse souvent évoquée consistant à les intégrer à le sein d un schéma opératoire de production de lamelles. si les comparaisons effectuées nous permettent en l état actuel des données de rejeter l hypothèse magdalénienne elles conduisent à privilégier l attribution de la série à le badegoulien.
termith-eval,test_archeologie_10_0039793_tei,description odontométrique comparée de le campagnol souterrain d orgnac microtus terricola mariaclaudiae chaline 1972  rodentia arvicolinae  de le gisement pléistocène moyen d orgnac 3 ardèche france. le campagnol souterrain d orgnac microtus terricola mariaclaudiae chaline 1972 a été décrit de le gisement pléistocène moyen d orgnac 3 ardèche france. la comparaison de différentes variables de la première molaire inférieure avec celles d autres espèces de le sous genre terricola permet de caractériser la morphologie dentaire de m t mariaclaudiae et de discuter sa position phylogénétique dans le sous genre.
termith-eval,test_archeologie_10_0039796_tei,la diffusion des silex crétacés dans le centre de le massif central durant la préhistoire paléolithique mésolithique néolithique  contribution à l étude de la circulation des matières premières lithiques sur de longues distances. depuis plusieurs années nous tentons avec d autres chercheurs de préciser l origine géographique des silex utilisés par les populations préhistoriques de le centre de le massif central. les études antérieures avaient permis de confirmer les hypothèses émises notamment par a masson quant à l importation de silex crétacés à partir de gîtes de la région centre. nous avons tenté à le travers d un programme de recherches interrégional 2006 2007 de déterminer plus précisément les lieux de provenance. dans un premier temps nous avons réalisé l inventaire des gîtes présents dans les départements de l indre indre et loire cher nièvre loir et cher loiret et yonne en nous appuyant sur les travaux déjà effectués th. aubry j primault et les cartes géologiques et en excluant le secteur de le grand pressigny. cela nous a permis de constituer une lithothèque complète qui a servi de référentiel pour les études analytiques postérieures. la prospection a également montré que des silex d aspect et d âge identiques tels que les fameux silex blonds si prisés des populations préhistoriques pouvaient se retrouver en divers points de l auréole crétacée supérieure de le sud de le bassin parisien. puis nous avons cherché à caractériser ces matériaux et à les rapprocher de silex provenant de séries préhistoriques. la méthode retenue a été celle de la géochimie éléments traces et isotopes de le strontium. ce marqueur isotopique utilisé traditionnellement pour les déterminations d âge est un élément de discrimination beaucoup plus fiable que celui de la simple comparaison des teneurs en éléments traces. 72 échantillons ont été analysés à le total. ils se partagent à parts presque égales entre silex issus de séries archéologiques 36 et matériaux issus de gîtes naturels 36 échantillons. pour ce qui est des silex archéologiques notre choix s est porté sur un nombre substantiel de gisements allant de le début de le paléolithique supérieur gravettien ancien à le bronze ancien dans six départements de le centre de le massif central puy de dôme cantal haute loire et dans une moindre mesure allier loire et cher. l analyse géochimique réclame un traitement des échantillons qui est entièrement réalisé manuellement et est très lourd. les résultats sont plutôt décevants sur le plan des indices géographiques mais néanmoins instructifs. nous avons la confirmation que la majeure partie des matériaux archéologiques provient bien de gîtes de le centre de la france et plus précisément de le berry. en effet tous les rapprochements étroits entre matériaux archéologiques et géologiques concernent des gîtes de le nord de l indre de le sud de le loir et cher ou de le nord ouest de le cher. il s agit là d un résultat important qui corrobore les théories antérieures émises à partir de simples études microfaciologiques masson 1981 surmely et al 1998. les silex blonds de le sud est de la france ne semblent pas avoir été importés à l exception peut être de quelques pièces découvertes dans le gisement chasséen de chastel sur murat cantal. l origine géographique précise des matériaux archéologiques reste plus difficile à déterminer. beaucoup de silex peuvent être rapprochés de plusieurs gîtes géologiques situés certes dans le même secteur géographique. les propositions d attribution géographique précise basée sur la similitude parfaite des signatures géochimique et isotopique et pétrographique sont rares. en dehors de ces quelques cas les rapprochements parfaits ne peuvent être faits. notre étude a alors pour résultat de montrer que les correspondances présumées par le biais de l examen visuel ne sont pas pertinents. ces incertitudes ne sauraient surprendre et tiennent assurément à la nature trop restreinte de notre corpus. une petite trentaine d échantillons ne peuvent suffire à rendre compte de la diversité faciologique des matériaux de l auréole de le crétacé supérieur de le bassin parisien. notre réflexion a également porté sur la place modeste des silicifications marines crétacées dans le façonnage des lames de haches polies et surtout sur les stratégies mises en oeuvre pour l approvisionnement et la diffusion. l étirement des distances de transports jusqu à 300 km et le caractère pérenne de la présence des silex crétacés allochtones dans les séries préhistoriques de le massif central à partir de le gravettien ancien plaident en faveur d un véritable phénomène d importation probablement lié à des échanges voire à des colportages.
termith-eval,test_archeologie_10_0039798_tei,la frise sculptée de l abri reverdit sergeac dordogne  première approche analytique des oeuvres. dans le cadre de notre doctorat nous avons réalisé en 2007 le relevé analytique de la frise sculptée de l abri reverdit sergeac dordogne  abri sous roche occupé et orné à le magdalénien moyen. l art pariétal de cet abri peu étudié jusqu ici a donné lieu à des interprétations diverses voire contradictoires tant dans le nombre que dans la nature des sujets delage 1935 laming emperaire 1962 leroi gourhan 1965 roussot 1984. il a en effet subi de multiples et profondes dégradations qui rendent son déchiffrement particulièrement complexe. notre intervention visait à discerner et à comprendre la nature des oeuvres paléolithiques en tenant compte des facteurs d altérations naturels anthropiques de le support. cette analyse met en avant quatre sculptures principales regroupées en frise. elle reconnaît la réalité des trois entités graphiques cheval bison bison admises par tous et en donne cependant des lectures nouvelles. elle révèle également une oeuvre inédite cheval. sur un autre panneau à proximité des autres représentations. deux de ces bas reliefs montreraient des phénomènes de retailles de sculptures de bisons antérieures. trois moments d intervention sur la frise ont été repérés à les premiers bisons très vestigiels font suite les imposants bas reliefs de chevaux et de bisons très épais. puis l un des bisons est retouché. la frise reste inachevée. le registre rencontré est uniquement sculpté aucune gravure ni trace de peinture n a pu être isolée. des liens se manifestent avec d autres abris ornés de la même période. les oeuvres de l abri reverdit montrent de profondes similitudes technique de mise en relief composition avec les sculptures de le cap blanc marquay dordogne  distant de quelques kilomètres. des rapprochements plus ténus apparaissent aussi avec le roc aux sorciers angles sur l anglin vienne  nettement plus éloigné. reverdit garde néanmoins une identité propre notamment dans le traitement formel de ses bisons.
termith-eval,test_archeologie_10_0039799_tei,nouvelles données chronologiques sur l enfant de la grotte de fauroux lugasson gironde. la grotte de fauroux a fourni deux ensembles stratigraphiques attribuables à le magdalénien et à l azilien. des vestiges humains d un adulte et d un jeune enfant ont été découverts dans l un des niveaux de l azilien et ont ainsi été attribués à cette culture. cependant une confirmation de cette attribution par une datation directe semblait nécessaire à le vu des perturbations subies par le site suite à des effondrements et de la présence d éléments post paléolithiques. le fémur gauche de l individu immature a été retenu et a livré une date de 5035 30 ans bp gra 38080 3948 3761 ans av. j c qui place finalement ce vestige dans la période de le néolithique.
termith-eval,test_archeologie_10_0136513_tei,la nécropole de le second âge de le fer de saint benoît sur seine  la perrière  aube  étude synthétique. la nécropole de saint benoît sur seine aube  partiellement fouillée par j bienaimé entre 1965 et 1971 constitue un ensemble funéraire remarquable qui n avait jusqu alors jamais bénéficié d une étude exhaustive. l occupation principale de la nécropole correspond à le second âge de le fer par l implantation de quarante six sépultures datées de la tène b 2 à la tène c 2. elle est ensuite réutilisée à les périodes gallo romaine et mérovingienne. l analyse de le mobilier métallique laténien a permis de mettre en évidence l évolution et l organisation interne de la nécropole. composée d une imbrication d enclos quadrangulaires et circulaires fréquentée par une petite communauté locale elle s est développée de manière polynucléaire par l installation successive de tombes dans les diverses structures fossoyées ou à leur proximité constituant ainsi pour certaines des sortes de concessions familiales. l étude des pratiques et de le costume funéraires illustre les liens étroits qui existent avec les contextes régionaux et suprarégionaux. à travers l analyse de la nécropole certaines caractéristiques de la culture matérielle de l aube alors insuffisamment connues ont pu être présentées.
termith-eval,test_archeologie_10_0136514_tei,le brassot à étigny yonne  un établissement rural de la tène finale de la vallée de l yonne. l habitat de le brassot à étigny situé à peu de distance de sens dans la vallée de l yonne est installé en fond de vallée en bordure d un paléochenal. établissement ouvert le site occupe une bande linéaire de 130 m de long pour 30 m de large. les structures bâtiment à quatre poteaux grenier à plateforme silo atelier fosses et le mobilier permettent d interpréter l établissement comme une installation rurale. des activités de production d appoint petite métallurgie tissage filage confection de baguettes en bois de cerf sont attestées. l analyse de le mobilier céramique qui comporte des importations méditerranéennes coupe en dérivée de campanienne a amphores dr 1 et celtiques céramique de type besançon  montre que l occupation de courte durée de l ordre d une génération  est centrée sur la tène d 2 b cet établissement dont des parallèles sont connus en territoire sénon à la tène d permet d illustrer un type d installation rurale peu documenté. les données conduisent à s interroger sur la place d un tel site dans le réseau d occupation de la vallée après la conquête sur son statut le nombre d amphores vinaires contraste avec la modestie des aménagements  mais aussi sur les conditions de son abandon peut être en relation avec la réorganisation des campagnes à la période augustéenne.
termith-eval,test_archeologie_10_0136515_tei,des lames en silex rubané tertiaire de la collection des fouilles anciennes de le camp de chassey saône et loire. le réexamen de la collection loydreau conservée à le musée rolin à autun et provenant de ses fouilles menées à le camp de chassey à la fin de le xixe siècle a permis de reconnaître onze supports laminaires en silex lacustre provenant de le sud de la france. une étude complète des pièces qui intègre la pétrographie la technologie la typologie et la tracéologie est présentée. les lames proviennent presque toutes de la même formation géologique mais montrent une certaine variabilité technologique et n ont pas toutes été consommées de la même manière. l attribution chronologique de ces importations et la mise en perspective des résultats sont discutées en dernière partie.
termith-eval,test_archeologie_10_0138174_tei,le clos henry une ferme de la tène finale à château gontier mayenne. la fouille de le site de le clos henry à château gontier outre la découverte d une fosse de le néolithique ancien vsg a permis de mettre en évidence une ferme de la tène finale d emprise très modeste. son enclos rectangulaire à partition interne n occupe en effet que 2 400 m 2. malgré un nombre restreint de structures en creux moins de quarante trous de poteau quatre bâtiments sur poteaux y ont été relevés. l occupation relativement courte de le site une ou deux générations permet d y distinguer une unité agricole constituée d un bâtiment principal associé à quelques bâtiments annexes de type grenier. l ensemble est établi à le cours de la seconde moitié de le second siècle avant j c et abandonné à le milieu de le siècle suivant.
termith-eval,test_archeologie_10_0138177_tei,des gaulois sur l île guennoc landéda finistère. à le cours des fouilles menées sur l île guennoc à landéda dans les années 1960 p r giot s intéressa principalement à une série de cairns mégalithiques mais reconnut plusieurs autres phases d occupation humaine. le réexamen systématique des collections des publications ainsi que l exploitation d un mémoire universitaire demeuré inédit montrent aujourd hui la richesse des données de terrain et de le mobilier de le second âge de le fer. la présentation des contextes naturels et historiographiques de l étude sera suivie par l exposé de la démarche d enquête débouchant sur une analyse des vestiges laténiens la structuration de l espace les constructions et l ensemble mobilier céramique en particulier alimenteront une réflexion synthétique sur l occupation gauloise de l île qui projetée dans une perspective plus large montre des points de comparaison avec d autres sites insulaires finistériens et contribue à caractériser les populations côtières de l ouest de la gaule.
termith-eval,test_archeologie_10_0139966_tei,une ferme de la tène finale à l époque gallo romaine sur la zac de beaulieu à caen calvados. l extension de l agglomération caennaise sur le quartier de beaulieu a généré une fouille préventive qui a été entreprise en 1997 sur un vaste établissement rural de le dernier siècle avant j c et des deux premiers siècles après. l occupation a connu deux grandes phases. la première jusqu au début de le ier siècle après j c comprend un enclos fossoyé de faible surface et un espace plus vaste clôturé par deux portions de fossés profonds complétés de fossés de faibles dimensions. plusieurs constructions sur poteaux des fosses diverses et des fours occupent les aires internes. la seconde phase des deux derniers tiers de le ier siècle à la fin de le iie est matérialisée par un enclos quadrangulaire de plus d un hectare abritant entre autres deux bâtiments l un maçonné et l autre en bois ainsi que plusieurs fosses. le caractère discontinu de la clôture de l habitat laténien ainsi que la fréquentation de le lieu lors de la période de transition et son évolution à le début de l antiquité constituent les particularités de ce site.
termith-eval,test_archeologie_10_0213427_tei,entre signe et symbole les fonctions de le mobilier dans les sépultures collectives d europe occidentale à la fin de le néolithique. les sépultures collectives de la fin de le néolithique sont un terrain privilégié pour l étude de la valeur des objets sépulcraux et de leur différentes fonctions à le sein des pratiques funéraires mais aussi des pratiques sociales. l analyse de 203 tombes fouillées récemment et bien documentées se répartissant géographiquement entre le nord de l allemagne et le sud de la france et la confrontation des résultats avec les données issues de plus de 1000 autres sépultures collectives ont permis de définir la pluralité des fonctions de le mobilier funéraire. le mobilier des sépultures collectives est un mobilier de le quotidien souvent usagé que l on peut diviser en mobilier collectif et en mobilier individuel. le mobilier collectif correspond à les objets que l on retrouve à distance des défunts. il témoigne de plusieurs moments essentiels dans l utilisation des tombes dépôts de fondation dépôts cultuels restes de cérémonies funéraires voire de banquets et dépôts de commémoration ou de condamnation. la valeur symbolique de deux objets la hache et la céramique et leur attachement à le sacré et à le religieux représentations gravées de haches et de divinités funéraires dans les mêmes espaces  sont particulièrement fortes. le mobilier individuel désigne quant à lui les objets qui sont portés par le défunt parure armes en position fonctionnelle sur le corps ou déposés à côté de lui vases haches. véritable signe social  il affiche les différences entre les individus en fonction de leur groupe d appartenance lignage famille  de leur âge de leur sexe ou de leur rang dans la pyramide sociale. létude des sépultures collectives nous amène donc à identifier deux fonctions essentielles de le mobilier funéraire des fonctions symboliques et des fonctions de signe l une n excluant pas forcément l autre.
termith-eval,test_archeologie_10_0215363_tei,un dépôt associé à une sépulture de la fin de le néolithique ancien à buthiers boulancourt seine et marne france  approche tracéologique et techno fonctionnelle de le mobilier lithique. une sépulture de la fin de le vsg 4900 4600 av. n è. mise à le jour sur le site de buthiers boulancourt seine et marne france était accompagnée d un dépôt funéraire comprenant une carapace de tortue et plusieurs pièces lithiques 4 grattoirs un racloir et six pièces non retouchées. il convient de rappeler que ce type de mobilier est assez rare dans les tombes de la fin de le néolithique ancien dans lesquelles céramiques bracelets en schiste et parure en coquillage prédominent. après une présentation de le site de la sépulture et de son mobilier sépulcral une analyse typo fonctionnelle et tracéologique de le mobilier lithique ainsi qu une comparaison avec l assemblage lithique recueilli dans les structures d habitat fosses dépotoirs structures liées à la combustion de le site sont proposées. l assemblage lithique et en particulier l outillage associé à la tombe est caractéristique de cette étape de le néolithique avec une majorité de grattoirs mais il diffère sensiblement de celui des fosses détritiques par les dimensions des pièces et le fait qu elles ont été peu ou pas utilisées.
termith-eval,test_archeologie_10_0215367_tei,les grandes lames de silex de le mobilier funéraire des proto éleveurs de le sud de l europe orientale. depuis la découverte des sites funéraires attribués à les éleveurs de la steppe de l ukraine sur la berge gauche de le dniepr le problème de leur synchronisation avec les différentes communautés énéolithiques distinguées dans la région balkano danubienne est vivement débattu de même que la question de leur rôle dans la disparition soudaine de ces cultures. les sépultures mises à le jour dans la région de lugansk en ukraine sont parmi les découvertes les plus intéressantes. l outillage de silex y constitue une part importante de le mobilier funéraire à le sein duquel se distinguent de très grandes lames. les expérimentations conduites par différents chercheurs montrent que la production de telles lames requérait des techniques de débitage particulières telles que la pression à le levier toutes ces lames sont ocrées et leur analyse tracéologique révèle des usures semblables à celles observées expérimentalement sur les couteaux à viande. le manque de données sur des ateliers énéolithiques de taille de le silex dans la steppe de l ukraine ne nous permet pas de dire si les lames qui composent le mobilier des sites funéraires par lesquels sont identifiés les éleveurs de la région ont été produites localement ou importées.
termith-eval,test_archeologie_10_0215369_tei,connotation fonctionnelle de le mobilier funéraire en silex exemple de la bulgarie. l article fait le point sur la problématique dévoilée par une des nécropoles bien connues de la bulgarie de le nord est celle de durankulak l unique qui soit étudiée et publiée entièrement. sur la base empirique de la détermination fonctionnelle des mobiliers funéraires en silex fondée sur l analyse des traces d utilisation des artefacts quelques observations et réflexions sur la valeur cognitive de mobilier en silex sont présentées à propos d objets de silex rituels provenant d un contexte sacré. ces résultats sont intégrés dans le contexte des données interprétatives et révèlent la dichotomie des connotations fonctionnelles des offrandes lithiques dont la partie évidente la fonction utilitaire et profane représente seulement une des trajectoires vers la considération adéquate de la valeur sémiologique de le mobilier en silex dans le contexte mortuaire global.
termith-eval,test_archeologie_10_0500453_tei,regards sur le premier mésolithique en charente maritime fontbelle villars les bois. suite à les prospections de j et f blanchet une série de sondages a été réalisée à fontbelle villars les bois charente maritime pour définir plus clairement l occupation de ce site. l étude de la série lithique a mis en évidence sur des matériaux siliceux locaux une production intégrée à le sein d une unique chaîne opératoire les lamelles servant essentiellement à la confection d armatures et plus particulièrement de triangles isocèles.
termith-eval,test_archeologie_10_0500454_tei,le dépôt de l âge de le bronze moyen de keravel en lannilis finistère. le dépôt de le bronze moyen de keravel en lannilis finistère fut mis à le jour lors d une opération de diagnostic archéologique en 2007. une dizaine d objets ou fragments d objets fut découverte probable reflet d un dépôt partiellement détruit par une petite carrière d arène granitique creusée à une époque indéterminée. une pointe de lance décorée et des fragments de haches à talon ou à rebord se rattachent à le groupe typologique de tréboul. ils sont accompagnés de fragments d une grande hache de type breton. l ensemble datable de le xve siècle avant j c s insère dans un état des connaissances déjà richement documenté en bretagne à propos de ce type de dépôts.
termith-eval,test_archeologie_10_0500455_tei,la série céramique de la tène moyenne de l habitat de la corneille à putot en bessin calvados. le site de la corneille à putot en bessin a été découvert en 1995 à le cours d un diagnostic archéologique réalisé pour la création d un échangeur routier. en dépit d une fouille extrêmement sommaire imposée par les délais d exécution le site a livré une abondante série céramique des iiie et iie siècles avant notre ère. si cet habitat enclos figure à le sein d une série maintenant très étoffée en normandie son corpus céramique continue d en composer l une des rares références pour cette période. avec une majorité de formes à profils sinueux il montre des analogies avec les séries de la tène moyenne déjà étudiées sur le bessin dans une zone globalement située à l ouest de l orne. plus largement l intérêt de cette série céramique est le champ d obédiences chrono culturelles qu elle montre avec le domaine armoricain. toutefois d autres comparaisons en normandie mais aussi au delà de la vallée de la seine y montrent une plus grande unité culturelle qu attendu sur un large quart nord ouest de la france de le moins pour ce domaine particulier de la culture matérielle.
termith-eval,test_archeologie_10_0500456_tei,de retour à guennoc. l étude technologique de la collection lithique d enez guennoc landéda finistère a permis de compléter l analyse et l attribution chrono culturelle proposée dans les années 1980. loin d être homogène cette série témoigne d un mélange entre azilien et premier mésolithique auquel il faut rajouter le matériel néolithique lié à les cairns. la situation géographique de l occupation mise en relation avec la transgression flandrienne et ses conséquences sur la disponibilité des ressources naturelles nous a permis d esquisser l organisation socio économique de ces groupes de chasseurs collecteurs en zone péri côtière.
termith-eval,test_archeologie_10_0505472_tei,l environnement tardiglaciaire préalpin essai de restitution basée sur le potentiel climatique et écologique des microvertébrés. chaque chercheur dans sa spécialité tente de définir et d affiner les conditions climatiques et environnementales de le site qu il étudie. la comparaison à les résultats obtenus par d autres méthodes permet une insertion dans le réseau chronologique traditionnel de référence telle que la variation isotopique de l oxygène o 18 o 16 des fonds marins ou des glaces de le groenland l innovation n est plus désormais dans la création de nouvelles méthodes mais dans leur adaptation à les problématiques variées de chaque site prédation taphonomie saisonnalité consommation des proies et plus largement écologie climatologie et biochronologie etc. ce principe nous offre donc la possibilité de reprendre des études anciennes dans une version différente élargie à divers groupes de microvertébrés et quantifiée facilitant les comparaisons entre les niveaux et les sites ainsi que le rapprochement avec les courbes climatiques de référence. après avoir rassemblé les listes de microfaune chaque espèce étant définie quantitativement par les moyennes climatiques de son domaine géographique le gisement peut alors présenter par la succession de ses niveaux l évolution des courbes des divers paramètres climatiques et environnementaux. en imbriquant chronologiquement les niveaux des divers sites et les valeurs paramétriques il est possible d élaborer des diagrammes de synthèse régionale où les biozones tardiglaciaires sont assez clairement mises en évidence.
termith-eval,test_archeologie_11_0115751_tei,contribution méthodologique à l analyse fonctionnelle des céramiques d un habitat néolithique l exemple de kovačevo 6 200 5 500 av. j c bulgarie. l analyse d une centaine de vases parmi les plus complets a été réalisée afin d appréhender leurs fonctions et modes d utilisation. une approche interdisciplinaire située à la frontière de l archéologie de la chimie et de la tracéologie a dès lors été développée. elle combine analyse morphométrique des céramiques caractérisation des résidus et observation des traces d usure. les récipients en terre cuite de l habitat néolithique de kovačevo ont semble t il connu un usage fréquent usure prononcée de certains fonds bases et préhensions de vases  des fonctions variées préparation cuisson consommation et stockage et ce dès le début de l occupation de le site. ils forment un assemblage fonctionnel tout à fait cohérent de récipients. cette batterie de cuisine fut par ailleurs conçue par des potiers qui lors de la phase de fabrication des vases ont opéré des choix dont une partie relève indiscutablement de facteurs fonctionnels. pleinement intégrées à les diverses activités ces toutes premières productions céramiques de le néolithique balkanique se différencient de le point de vue de leur statut de celles de le néolithique grec. ces dernières sont en effet considérées comme un bien de prestige. les recherches futures viseront à comprendre les raisons de cette frontière culturelle reflète t elle l existence de deux courants diachroniques de néolithisation effectués par des populations attribuant une valeur différente à leurs récipients ou traduit elle une évolution chronologique de la fonction des plus anciennes céramiques grecques.
termith-eval,test_archeologie_11_0115759_tei,archéologie préventive et évolution de le paysage végétal de l âge de le fer à le moyen âge dans le gâtinais mise en évidence de culture de chanvre et d activités de rouissage courcelles et sceaux en gâtinais loiret france. dans le cadre de la construction de l autoroute a 19 des fouilles archéologiques préventives ont été menées dans le gâtinais et deux d entre elles ont été associées à des études paléoenvironnementales. le premier site se localise dans la vallée de la rimarde courcelles loiret. les prélèvements jouxtent une occupation de le néolithique ancien des cercles funéraires de l âge de le bronze final et une nécropole carolingienne mais la séquence sédimentaire ne débute qu à le cours de l hallstatt. le paysage est très ouvert dominé par les pratiques agro pastorales qui connaissent un important essor et une diversification à le bas empire céréales noyer et chanvre  puis leur apogée à le haut moyen âge. à le moyen âge central la culture de le seigle et celle de le lin apparaissent dans le paysage agricole. le second sondage se localise près de le ruisseau de maurepas sceaux du gâtinais loiret  à les abords d une voie et de restes de bâtiments de l époque gallo romaine. dès le début de l âge de le fer la céréaliculture et les activités pastorales sont très présentes. la végétation de ripisylve d abord entretenue subit ensuite des coupes importantes à le bas empire probablement en relation avec le fort développement des activités agricoles notamment celui de la culture de le chanvre et des pratiques de rouissage. avec le net recul de ces activités chanvrières le site est envahi par la cariçaie et devient tourbeux.
termith-eval,test_archeologie_11_0341888_tei,chronique des recherches sur le mont beuvray 2006 2008. cet article propose un bilan des principales recherches effectuées sur le mont beuvray et dans ses environs entre 2006 et 2008 dans le cadre de le programme international de recherche consacré à l oppidum de bibracte. à le terme de ce programme plusieurs opérations de terrain s achèvent et livrent des résultats inattendus c est le cas de la fouille entre les remparts ou de celles de la minière de la pâture des grangerands. signalons également les acquis importants issus de la fouille de l ensemble monumental pré augustéen de la pâture de le couvent et les recherches sur l environnement de bibracte qui apportent régulièrement de nouvelles données.
termith-eval,test_archeologie_11_0421541_tei,occupations de le néolithique moyen et de l âge de le bronze à le champ de le château à kervignac morbihan. le site concerne deux occupations distinctes pour lesquelles les résultats obtenus sont disparates. l occupation néolithique délicate à interpréter est contemporaine de le premier mégalithisme. l âge de le bronze est quant à lui représenté par quelques structures excavées et un petit corpus céramique. par ailleurs la présence de perrières ainsi que de gros blocs dans les structures néolithiques et protohistoriques a permis une approche des techniques d extraction et de le travail de la pierre domaine d étude si peu abordé et publié jusqu ici.
termith-eval,test_archeologie_11_0421542_tei,un site de la tène à le cœur des mauges le pinier à beaupréau maine et loire. découvert à l occasion de prospections aériennes le site de le pinier a été le premier dans la région à livrer un ensemble mobilier dont une partie date de le ive siècle av. n è. le site occupé pendant à le moins deux siècles se présente sous la forme d un double enclos à plan rectilinéaire avec fossés massifs. on ne sait pas si les deux enclos sont contemporains ou si ce plan résulte d une évolution dans le temps. si sa fonction reste à confirmer habitat ou sanctuaire. on y trouve en tout cas un mobilier riche et jusqu alors peu fréquent dans les contextes régionaux contemporains fibule passoire céramique décorée .
termith-eval,test_archeologie_11_0501275_tei,construction et destruction des monuments mégalithiques. sauf pour l exploitation des roches en carrières la fouille apporte peu d indication sur la façon dont furent jadis construits les monuments mégalithiques. on est réduit à des démarches indirectes qui sont d ailleurs suggestives ne serait ce que sur le plan des structures sociales concernées. la destruction de ceux d entre eux qui étaient utilisés comme sépulcres s est montrée riche d enseignements. leurs propriétaires néolithiques n hésitaient pas lors de le passage d une phase d utilisation à une autre à extraire ou à renverser des piliers voire à faire effondrer le plafond d une cavité. des remaniements de plus grande ampleur intervenaient en fin d utilisation incendies fractures élimination ou à le contraire apport de dalles de couverture démontage ou érection de tumulus etc. décevante pour le préhistorien qui remonte difficilement de ces ruines délibérément léguées par les néolithiques à les sépulcres originels ces destructions livrent en revanche des témoignages d ordre technique.
termith-eval,test_archeologie_12_0023826_tei,histoires de bisons et de chevaux regard sur l évolution de la frise pariétale de cap blanc marquay dordogne à travers l analyse de le panneau de l alcôve. la reprise partielle de l étude de l art pariétal de l abri de cap blanc a mis en lumière de profondes modifications de la frise à le cours de le temps. le relevé analytique de la partie droite de la frise panneau de l alcôve révèle une stratigraphie graphique complexe illustrant deux phases distinctes dans la construction de le panneau. celles ci sont liées à la création de deux ensembles graphiques successifs bien individualisés un premier ensemble de deux sculptures monumentales de profil gauche bisons. retaillées et partiellement détruites pour laisser place à un second ensemble de deux bas reliefs monumentaux de chevaux de profil droit auxquels ont été associés deux petits bisons dans le registre inférieur l un de profil gauche en relief gravé et l autre de profil droit en relief modelé. cette évolution de le dispositif pariétal permet de jeter un nouveau regard sur la dynamique d occupation de l abri et sur le cadre chrono culturel des œuvres par des termes de comparaison affinés et renouvelés avec les autres sites sculptés de le sud ouest de la france.
termith-eval,test_archeologie_12_0023828_tei,le moustérien à denticulés de la couche 20 de combe grenal implications techniques économiques et fonctionnelles à le sein de le système de production quina en périgord. le gisement de combe grenal célèbre pour son implication dans l histoire de la recherche sur le paléolithique moyen aquitain offre une imposante séquence moustérienne contemporaine de le dernier glaciaire couches 1 à 37. celle ci se caractérise notamment par une série de couches attribuée à le moustérien de type quina couches 26 à 17  à le sein de laquelle s intercale la couche 20 attribuée par f bordes à le moustérien à denticulés. en apparence antinomique dans l assise diachronique de le moustérien de type quina l industrie de la couche 20 fait l objet de cette contribution. à le regard des résultats obtenus par le biais d une démarche d analyse mettant l accent sur la caractérisation des modes de débitage et surtout sur la gestion des éclats matrices  l industrie de la couche 20 s avère constituer un exemple singulier de le potentiel techno économico fonctionnel offert par le système de production quina.
termith-eval,test_archeologie_12_0023829_tei,le plus ancien enfant d aquitaine combe grenal 31 domme france. le récolement des collections de le musée national de préhistoire a permis lors de le travail sur la faune découverte à le cours des fouilles de f bordes à combe grenal site de référence l identification d un nouveau fossile humain combe grenal 31. il provient de la couche 60. en fonction des vestiges archéologiques et paléontologiques qu elle livre et de comparaisons avec des niveaux aussi anciens de différents gisements cette couche s est probablement formée lors de le dernier tiers de le stade isotopique 6. combe grenal 31 correspond à une incisive inférieure droite de la dentition déciduale d un enfant d environ 3 ans 12 mois. sa couronne présente de grandes dimensions malgré une forte attrition de la face occlusale. la courbure de la face vestibulaire ainsi que le tubercule lingual sont bien marqués. les crêtes marginales sont un peu saillantes. ses caractères morphologiques et leur comparaison avec d autres fossiles européens ainsi que l ellipse d équiprobabilité réalisée à partir des dimensions de la couronne nous permettent de souligner des similitudes avec les dents équivalentes d autres enfants néandertaliens des stades isotopiques 5 4 ou 3 et deux spécimens européens rapportés à le stade 6.
termith-eval,test_archeologie_12_0135607_tei,les sites protohistoriques d erstein grasweg pae  alsace bas rhin  l occupation rhin suisse france orientale. implanté sur une terrasse lœssique à une trentaine de kilomètres à le sud de strasbourg le site protohistorique d erstein grasweg pae connaît des installations humaines depuis la deuxième moitié de le iiie millénaire jusqu à la première moitié de le ixe siècle av. j c à le cours de l étape moyenne de le bronze final. l occupation rsfo qui fait l objet de le présent article se caractérise par la présence d une dizaine de structures excavées associées à un puits monoxyle dont certains bois sont datés par dendrochronologie des années 1026 et 1010 av. j c en s appuyant sur ces datations absolues l ensemble céramique d erstein grasweg pae vient compléter les connaissances acquises récemment sur le bronze final iiia en alsace. outre la céramique les fosses d habitat ont livré un mobilier diversifié objets métalliques perles en verre  et un assemblage faunique original dans lequel la faune chassée occupe une place particulière.
termith-eval,test_archeologie_12_0135609_tei,une sépulture de guerrier celte à chens sur léman haute savoie. l article porte sur la sépulture d un guerrier celte datée entre les ive et iiie siècles avant j c la tène b 2  fouillée lors d un diagnostic mené à chens sur léman haute savoie  à le lieu dit véreître. plusieurs sépultures datées de le second âge de le fer et découvertes anciennement sont connues à les abords méridionaux de le lac léman mais cette tombe est la première à faire l objet d une véritable analyse. le corps a été placé dans un cercueil monoxyle avec à sa droite un fer de lance et une grande épée dans son fourreau décoré et portait un bracelet massif en fer à le poignet gauche deux fibules enfer et une fibule en bronze.
termith-eval,test_archeologie_12_0217485_tei,la fracturation en split une technique de production dans l industrie lithique des tares sourzac dordogne. a partir de le ré examen de l industrie de le gisement des tares et d une expérimentation une description de la fracturation en split est proposée. elle se caractérise par une percussion rentrante sur appui plus ou moins ferme de direction strictement verticale avec des percuteurs présentant une touche rectiligne.
termith-eval,test_archeologie_12_0217486_tei,comment ont été fendus les nodules ovoïdes de silex de la minière de ri orne. une reconstitution expérimentale de la fracture en split sur percuteur dormant à touche linéaire. une minière de silex néolithique à haches a été récemment fouillée sur près de deux hectares à ri dans le nord de l orne par une équipe de l inrap dirigée par c marcigny. les centaines de structures d extraction fouillées depuis de simples fosses jusqu à des puits et galeries de six mètres de profondeur ont exploité un banc de calcaire crayeux jurassique riche en nodules de silex arrondis et à cortex épais. parallèlement à l étude en cours de le riche mobilier osseux et lithique des programmes de reconstitution expérimentale ont été initiés dont l un porte sur les aspects qualitatifs et quantitatifs de la fabrication des têtes de haches. l entame de tels nodules s est avérée poser un réel problème devant l échec de la solution la plus évidente consistant à jeter un nodule comme percuteur contre un autre placé à le sol. il a été alors imaginé de les fendre en les projetant sur l arête d une enclume en silex l arête jouant comme un coin dans l épaisseur de le cortex. cette technique s est révélée efficace moyennant une bonne stabilité de l enclume et un surhaussement de le tailleur pour assurer un impact suffisamment violent. l incision de l arête de l enclume sur plusieurs centimètres provoque le fendage franc de le nodule projeté selon un plan de fracturation équatorial bien régulier comme cela a été observé sur le matériel archéologique. le mécanisme de cette technique est celui de la fracture en split avec la spécification d une arête faisant coin dans un cortex épais. en cela elle rappelle la percussion lancée verticale à touche linéaire observée dans le moustérien ancien des tares faivre et al 2009  de même que la technique de taille de meules en silex meulière turq 2009.
termith-eval,test_archeologie_12_0217487_tei,percussion bipolaire sur enclume choix ou contrainte. l exemple de le paléolithique d ounjougou pays dogon mali. encore trop souvent considérée comme relevant d une production lithique expédiente la percussion bipolaire sur enclume occupe cependant une place majeure dans les industries de certaines régions. ainsi à ounjougou pays dogon mali  ce mode de taille est régulièrement présent à le sein des industries d une séquence chronoculturelle qui s étale sur plus de 100 000 ans couvrant l essentiel de le paléolithique moyen régional. le recours à ce mode de taille pourrait être simplement explicité par la faible diversité des ressources en matières premières et par la place qu y occupe le quartz. cependant la percussion bipolaire sur enclume est totalement absente dans certaines industries de la séquence et le déterminisme des matières premières n apparaît ainsi pas seul en jeu. la profondeur diachronique de la séquence d ounjougou donne l opportunité de s interroger sur le rôle technique le statut économique et la charge culturelle de ce mode de taille original qu est la percussion bipolaire sur enclume.
termith-eval,test_archeologie_12_0217488_tei,la percussion sur enclume en italie centrale tyrrhénienne. en italie sur la base de la littérature existante la percussion sur enclume semble être présente dans des industries lithiques qui couvrent une période extrêmement longue de le début de le pléistocène moyen jusqu à l holocène. dans ce travail nous allons essayer d examiner en détail la présence et les caractéristiques de la percussion sur enclume dans quelques sites de le latium certains moustériens comme grotta guattari grotta breuil et grotta del fossellone niv. 27 β  d autres de le paléolithique supérieur initial grotta del fossellone niv. 21 et final riparo salvini et riparo palidoro. une activité expérimentale nous a permis de définir les paramètres morphologiques utiles à la reconnaissance des artefacts taillés sur enclume à le sein de le matériel archéologique. l influence des conditions environnementales et en particulier de la matière première sera discutée dans les conclusions.
termith-eval,test_archeologie_12_0313892_tei,paysages productions et collectes végétales en limousin massif central occidental de la tène finale à la fin de le moyen âge 100 bc 1400 ad. entre 1996 et 2004 plusieurs sites archéologiques de le limousin ont fait l objet d une analyse carpologique. bien que le nombre de sites et de structures analysés soit modeste près de 219000 restes carbonisés imbibés ou minéralisés et environ 300 taxons de plantes cultivées et sauvages ont été déterminés permettant l élaboration d une première synthèse pour une période allant de la tène finale à le bas moyen âge. ce travail intègre également la publication de plusieurs études carpologiques de nécropoles gallo romaines ainsi que les acquis régionaux des recherches anthracologiques palynologiques et sédimentologiques. la synthèse sur les plantes cultivées et utilitaires met en évidence une modification des productions céréalières entre la fin de l époque gallo romaine et le haut moyen âge caractérisée par la montée en puissance de le seigle secale cereale. elle rend compte aussi d un développement de l arboriculture à partir de l époque gallo romaine puis à le haut moyen âge notamment en contexte urbain. des importations ont également été mises en évidence comme le poivre piper nigrum à le haut empire.
termith-eval,test_archeologie_12_0313893_tei,stratégies de prélèvement et de mise en œuvre de la terre à bâtir des structures de combustion néolithiques de le site de dikili tash grèce à partir d une étude micromorphologique. la terre crue ou terre à bâtir constitue le matériau de construction le plus utilisé par les sociétés égéennes pendant le néolithique de le viie à le ve millénaire av. j c. lobjectif de cet article est de mettre en lumière les stratégies d exploitation des ressources naturelles et les techniques mises en oeuvre par ces sociétés protohistoriques dans la construction des structures de combustion vestiges particulièrement bien conservés grâce à l action de le feu sur le site de dikili tash macédoine orientale grecque. les méthodes de recherche ont consisté à combiner des observations macroscopiques à une étude micromorphologique de fragments archéologiques et expérimentaux. dans un premier temps cette étude a permis de caractériser la pétrographie des sédiments employés et de déterminer leur provenance en les comparant à les résultats de l étude géomorphologique des formations superficielles environnant le site. dans un second temps ces méthodes analytiques ont permis la caractérisation précise des matériaux élaborés qui sont révélateurs des choix techniques réalisés pour la fabrication et la mise en oeuvre des structures de combustion. cette recherche met ainsi en évidence la complexité mais également une certaine standardisation des processus de production des structures de combustion en contexte domestique dès le néolithique.
termith-eval,test_archeologie_12_0313896_tei,apport de le lidar à la connaissance de l histoire de l occupation de le sol en forêt de haye. le potentiel archéologique des forêts est fort notamment en raison de la bonne conservation des vestiges sous forme de micro reliefs mais les prospections archéologiques sont gênées par le couvert forestier ce qui freine l étude des sites. une méthode de télédétection assez récente le scanneur laser aéroporté ou lidar permet de s affranchir d une partie des contraintes physiques et permet le repérage et la cartographie des vestiges. cette technique a été appliquée à le massif forestier de haye qui couvre 116 km 2 à côté de nancy durant l hiver 2006 2007. elle a permis des apports considérables par rapport à les méthodes de prospection traditionnelles à le sol jusque là utilisées pour étudier les structures agraires et parcellaires et les habitats antiques qui y sont conservés. ces apports ont porté sur de nombreux points nette augmentation de le nombre de vestiges découverts amélioration de la localisation des vestiges initialement cartographiés à le topofil et à la boussole ou à le gps apports morphologiques et chronologiques etc. nous avons mis à le point une méthode de cartographie et élaboré un référentiel de vestiges archéologiques et de structures morphologiques diverses adaptés à l analyse et à l interprétation des données lidar. à le final cette technique rend possible un véritable changement d échelle dans l étude des sites archéologiques et permet d esquisser dans ses grandes lignes l histoire de l occupation de le sol de l actuel massif forestier de haye.
termith-eval,test_archeologie_12_0337826_tei,la série céramique de le bronze final ii iii de le site de le petit souper à saint hilaire saint florent maine et loire. la fouille de le site de le petit souper à saint hilaire saint florent maine et loire  réalisée à le mois de janvier 2008 par une équipe de l inrap sous la responsabilité scientifique de y viau viau et al 2008  a mis à le jour une série de structures fossoyées contenant de nombreux fragments de céramiques attribuables à la fin de la phase ancienne et à la phase moyenne de le bronze final. ce site d habitat est établi à le bord d un plateau dominant la loire en surplomb de le site de le bronze final de l alleu fouillé par le docteur gruet à la fin des années 1970. le corpus céramique bronze final ii iii de le petit souper constitue à ce jour le référentiel le plus documenté pour la région des pays de la loire. en outre la fouille a fourni une importante série lithique associée à ce contexte. ce site est le point le plus occidental de la diffusion de la céramique de tradition rsfo le long de l axe ligérien vecteur majeur de diffusion des cultures voire aire d identité culturelle.
termith-eval,test_archeologie_12_0337828_tei,les bracelets protohistoriques en verre de bretagne. d après les sources bibliographiques et des échanges directs avec des archéologues les bracelets protohistoriques en verre de bretagne ont pu être recensés. dans le corpus des 43 objets ainsi répertoriés certains ont pu être associés à les typologies existantes haevernick et gebhard. les autres n y trouvant pas de correspondances il nous a fallu mettre en place un nouveau codage typologique. présenté ici il prend en compte à la fois la forme de la section la couleur et le décor. 17 de ces bracelets ont également bénéficié d analyses chimiques ce qui a permis de déterminer l origine probable de leurs matières premières. de plus ces résultats ouvrent de nouvelles perspectives de recherche.
termith-eval,test_archeologie_525_02_11060_tei,étude préliminaire de la céramique non tournée micacée de le bas languedoc occidental typologie chronologie et aire de diffusion. l étude présente une variété de céramique non tournée dont la typologie et l analyse des décors permettent de l identifier facilement. la nature de l argile enrichie de mica donne un aspect pailleté à la pâte sur laquelle le décor effectué selon la méthode de le brunissoir apparaît en traits brillant sur fond mat. cette première approche se fonde sur deux séries issues de fouilles anciennes menées sur les oppidums de le cayla à mailhac aude et de mourrel ferrat à olonzac hérault. la carte de répartition fait état d échanges ou de commerce à l échelon macrorégional rarement mis en évidence pour de la céramique non tournée. s il est difficile de statuer sur l origine des décors il semble que la production s insère dans une ambiance celtisante. la chronologie de cette production se situe dans le deuxième âge de le fer. la fourchette proposée entre la fin de le ive et la fin de le iie s av. j c reste encore à préciser.
termith-eval,test_archeologie_525_02_11109_tei,protohistoire de la commune de saint maximin la sainte baume var. le potentiel archéologique de la commune de saint maximin la sainte baume qui se résumait pratiquement à quelques habitats groupés et fortifiés de hauteur de l âge de le fer n a pu être évalué que grâce à les tranchées pratiquées pour l installation de canalisations d eau. le schéma de la structuration spatiale de l occupation des sols dans les plaines et de son évolution doit donc tenir compte désormais de l occultation des gisements par les dépôts alluvionnaires. le territoire objet de notre étude apparaît très occupé depuis l âge de le bronze final ii iii jusqu au i s av. j c l habitat ouvert de plaine et de piedmont y occupe une large place.
termith-eval,test_archeologie_525_02_11129_tei,un bloc sculpté de l oppidum de le cayla à mailhac aude. cette note rappelle la découverte ancienne d un bloc sculpté et de la probable localisation de la carrière d extraction. mis à le jour sur un clapas situé sur la partie orientale de l oppidum de le cayla à mailhac aude par o et j taffanel il s agit d un fragment de pilier avec deux têtes sculptées en bas relief. à partir d éléments comparables trouvés en languedoc oriental et en provence l hypothèse d un monument cultuel sur le cayla est envisagée. les conditions de découverte ne permettent pas de le localiser avec précision et sa datation ne peut être que suggérée. la présence de ce témoin de l art indigène renvoie une image homogène pour l exploitation de le thème des têtes coupées dans le sud de la france même si la documentation disponible en languedoc occidental ne permet pas encore de synthèse.
termith-eval,test_archeologie_525_02_11796_tei,étude préliminaire des cerfs de le gisement pleistocene inférieur de ceyssaguet haute loire. le gisement de ceyssaguet haute loire a livré de nombreux fossiles dont un grand nombre de restes de cervidés ceux ci se répartissent en quatre espèces deux de grande taille eucladoceros ctenoides praemegaceros obscurus et deux de taille moyenne metacervoceros rhenanus dama cf vallonnetensis. de nombreux problèmes de systématique et de synonymie sont discutés afin de comprendre la position systématique des cerfs de ceyssaguet. a l occasion de cette étude les auteurs replacent ces quatre espèces de cervidés dans l histoire des cervidés villafranchiens d europe et analysent leur distribution géographique.
termith-eval,test_archeologie_525_02_11797_tei,la parure de l enfant de la madeleine fouilles peyrony. un nouveau regard sur l enfance à le paléolithique supérieur. l analyse taphonomique technique et morphométrique des objets de parure de la sépulture de l enfant de la madeleine tursac dordogne permet de reconstituer les techniques de fabrication les modes d assemblage et le degré d utilisation de ces objets. les dentales ont été tronçonnés par flexion et sciage pour produire des tubes de 6 7 mm de longueur et à le moins 1 8 mm de diamètre. la morphométrie des aiguilles découvertes dans les couches d habitat et la présence de fractures et usures caractéristiques sur les dentales indiquent que ces derniers ont été brodés à l aide d aiguilles fines sur l habit de l enfant et portés de son vivant. la petite taille des tronçons de dentales et des autres objets de parure en coquillage turritelles néritines cyclopes et glycymeris  significativement différente de celle des mêmes espèces découvertes dans les sites d habitat et dans les sépultures contemporaines démontre que cette ornementation a été spécialement conçue pour l enfant et semble indiquer que cette classe d âge jouissait d un statut social propre dans les sociétés de la fin de le paléolithique supérieur. le grand nombre d objets impliqués et le grand investissement de temps nécessaire à la réalisation de cette parure évoquent une motivation qui dépasse l affection parentale et pourraient constituer l indice d une stratification sociale à base héréditaire. malgré la date tardive récemment obtenue pour cette sépulture 10 190 100 bp  son mobilier funéraire s enracine dans le monde magdalénien comme ceci est démontré par la comparaison avec le mobilier issu des couches d habitat.
termith-eval,test_archeologie_525_02_11798_tei,une statuette en ivoire de 30000 b p trouvée à le hohle fels près de schelklingen baden württemberg allemagne. en 1999 les fouilles menées par l équipe de l université de tübingen à le hohle fels près de schelklingen ont permis de découvrir une statuette en ivoire de mammouth représentant une tête d animal vraisemblablement de cheval. l objet provient de le niveau géologique 3 d dans une position intermédiaire entre des niveaux riches de le gravettien et de l aurignacien. ce niveau est daté d environ 30 000 b p avec cette découverte le hohle fels est après le vogelherd le hohlenstein stadel et le geissenklösterle le quatrième site en grotte dans le sud ouest de l allemagne à avoir livré des statuettes en ivoire de le paléolithique supérieur ancien. cet ensemble d objets d art mobilier fait partie des oeuvres d art les plus anciennes de le monde et il est très important pour l interprétation de l évolution culturelle de cette époque des derniers néandertaliens et des premiers hommes modernes en europe.
termith-eval,test_archeologie_525_02_11799_tei, le sansonnet et les agnels  vaucluse  un exemple de fragmentation thermique intentionnelle de le silex à le sauveterrien. l observation des stigmates de chauffe de le silex parallèlement à les remontages partiels de plusieurs blocs à permis de démontrer la pratique de l étonnement des blocs fracturation par choc thermique pour l obtention de nucléus sur fragments dans deux ensembles lithiques sauveterriens de le vaucluse. la mise en évidence de cette pratique marginale pour cette période apporte un éclairage nouveau sur les pratiques liées à les modalités de débitage des chasseurs sauveterriens.
termith-eval,test_archeologie_525_02_11807_tei,nouvelles figures féminines schématiques de type lalinde gönnersdorf dans la vallée de l aveyron. lors d un sondage réalisé en 1994 sur le site magdalénien supérieur de la magdeleine la plaine plusieurs plaquettes gravées ont été mises à le jour. l une d elles porte quatre figures féminines schématiques de type lalinde gοnnersdorf.
termith-eval,test_archeologie_525_02_11810_tei,informatisation d une fouille réalisation et déploiement de le logiciel d acquisition de données fractool  fressignes acquisition tool. depuis maintenant environ trois ans une équipe pluridisciplinaire de le muséum national d histoire naturelle m n h n travaille à l informatisation de la fouille et de l analyse de le gisement solutréen de fressignes indre france. cette activité pilote est également suivie dans le cadre d un groupe de recherche le projet collectif de recherche préhistoire de la vallée moyenne de la creuse avec pour objectifs d étendre ses résultats à d autres sites de la région centre. l été dernier à le cours de la campagne de fouilles 2000 le logiciel d acquisition fractool a été pour la première fois déployé et utilisé par les préhistoriens dans le cadre de le relevé de le matériel archéologique de fressignes. cet article s attache à décrire les différentes étapes qui ont abouti à la conception et réalisation de le logiciel fractool et plus particulièrement les réflexions méthodologiques menées relativement à les problématiques d acquisition de gestion et d exploitation de données archéologiques informatisées.
termith-eval,test_archeologie_525_04_10198_tei,le gisement épipaléolithique à pointes de malaurie de champ chalatras  les martres d artière puy de dôme. le site épipaléolithique de champ chalatras se caractérise par la présence de trois concentrations de vestiges archéologiques répartis autour de plusieurs foyers construits. les analyses spatiales ont permis de mettre en évidence la structuration de l espace domestique des locus avec des aires d activités spécifiques liées à le débitage de le silex à le façonnage des outils à le rejet d une partie des déchets de taille et à l utilisation de certains types d outils en relation avec les vestiges osseux. les données fournies par l étude archéozoologique montrent la prédominance des bovinés aurochs sur les autres espèces. l étude technologique de l industrie lithique a permis de déterminer les modes d introduction des différentes matières premières jurassiques crétacées et tertiaires en fonction de leur origine géographique. le débitage est orienté vers la production de supports laminaires rectilignes obtenus à le percuteur de pierre tendre à partir de nucléus à un ou deux plans de frappe opposés. l outillage se caractérise par la présence de pointes à dos rectiligne et base tronquée pointes de malaurie  de pièces tronquées de rectangles de grattoirs et de pièces esquillées. les données techno typologiques permettent de rapprocher le site de champ chalatras des niveaux laboriens des sites de la borie del rey et de pont d ambon dans le sud ouest de la france. les datations à le radiocarbone 10 000 100 bp 9920 120 bp et 9580 140 bp confirment également cet état de fait tout comme l assemblage faunique.
termith-eval,test_archeologie_525_04_10200_tei,à propos des burins de le raysse de le flageolet i dordogne france. comme pour un certain nombre d outils en silex de le paléolithique supérieur pièces carénées pièces esquillées la possibilité de la fonction de nucléus pour les burins de le raysse n a été soulevée que tardivement. par l étude technologique des burins de le raysse de la couche v de le flageolet i cet article a pour objectif de contribuer à la clarification de cette question importante en termes d interprétation fonctionnelle de l assemblage.
termith-eval,test_archeologie_525_04_10202_tei,présence de panthera gombaszoegensis kretzoï 1938 à la grotte xiv cénac et saint julien dordogne. panthera gombaszoegensis a vécu dès la fin de le pléistocène ancien jusqu au milieu de le pléistocène moyen. la présence de ce félin en france est peu documentée mais il ne s agit peut être que d un manque de sites. après un rappel des quelques travaux relatifs à cette espèce cet article aborde l étude de la série de vestiges recueillie ces dernières années dans la grotte xiv dordogne  fouilles j l guadelli. on y trouvera la description de ces vestiges et quelques remarques sur la répartition géographique et la phylogénie de ce félin.
termith-eval,test_archeologie_525_04_10203_tei,la redécouverte de le nouveau né néandertalien le moustier 2. en 1996 des ossements d un périnatal sont retrouvés dans les réserves de le musée national de préhistoire avec les collections des abris de le moustier dordogne. certains sont isolés d autres sont pris dans de petites mottes de sédiment. assez vite il apparaît que ces vestiges peuvent être ceux mis à le jour par d peyrony dans l abri inférieur. en 1997 le musée national de préhistoire nous confie la fouille des mottes et l étude des vestiges. a l issue de la fouille fin 2000  nous proposons la reconstitution d un squelette de périnatal exceptionnellement bien conservé. l étude morphologique et métrique préliminaire des vestiges osseux nous assure que nous sommes en présence d un néandertalien. considérant sa classe d âge certains de ses ossements sont uniques dans les annales de la paléontologie humaine. de surcroît la fouille des mottes de sédiment s est accompagnée de l enregistrement de données qui permettront de préciser la position de segments de le corps dans la tombe. enfin cette découverte remet en cause le nombre d individus présents dans le gisement de la ferrassie et l existence de l unique sépulture double de le moustérien d europe. en ce qui concerne les prédécesseurs des hommes modernes d europe le moustier 2 représente donc la plus importante découverte paléoanthropologique faite en france depuis ces vingt cinq dernières années et en périgord depuis 1961. son étude permettra de nombreuses avancées en anthropologie biologique sur l ontogénie des néandertaliens et les pratiques funéraires moustériennes.
termith-eval,test_archeologie_525_04_10656_tei,nouvelles données sur l occupation protohistotique de beaucaire gard. c est à le fond d une cave de la ville de beaucaire qu ont été par hasard exhumés les vestiges d une installation protohistorique de bas de pente située à le pied de l oppidum de le château et de la redoute. le matériel recueilli témoigne de deux grandes phases d occupation les vie ve siècles av. n è. d une part les iiie ier siècles av. n è. d autre part. la céramique locale côtoie les importations méditerranéennes caractérisant chaque période. par leur localisation ces vestiges sont intéressants pour la connaissance de la topographie antique d ugernum puisqu il s agit de l installation la plus proche de le rhône repérée jusqu à présent.
termith-eval,test_archeologie_525_04_10657_tei,meules à grains de provenance septentrionale coirons massif central sur deux sites protohistoriques de le languedoc oriental le marduel ive ier s et nages iiie ier s. l analyse pétrographique microtexturale appliquée à les meules basaltiques des oppida de le marduel et de nages met en évidence le rôle de gisements volcaniques septentrionaux dans l approvisionnement de ces sites. dans le cas de le marduel entre le ve s et le ier s av. n é. près de 80 de ce mobilier provient de le massif des coirons ou de gisements de le massif central et on y observe des formes typologiques inconnues dans les productions méridionales. dans le cas de nages pourtant plus proche des débarcadères méditerranéens la proportion de ces meules d origine septentrionale reste conséquente 23  entre le iieet le ier s av. n é. cette constatation contraste fortement avec ce qu on observe sur nombre d autres sites de le languedoc oriental et de provence où les productions d embonne cap d agde s imposent en quasi exclusivité pendant la même période. ces résultats permettent de localiser assez loin vers le sud une limite d influence de centres de production septentrionaux et de matérialiser dans l axe rhodanien un transit nord sud de produits manufacturés spécifiques.
termith-eval,test_archeologie_525_04_10660_tei,l habitat de le bronze final des courtinals à mourèze hérault. fouilles de le c r a des chênes verts en 1961. cet article présente le matériel découvert lors des premières fouilles sur le site des courtinals à mourèze réalisées par le c r a des chênes verts en 1961. ces lieux offrent une succession de niveaux datés par le mobilier de le néo chalcolithique de le bronze final iib de le bronze final iiia et des ve ive s av. j c le matériel de le bronze final iib rare et très fragmenté permet de souligner la disjonction entre le faciès de l arrière pays de le languedoc oriental et celui de le littoral. celui de le bronze final iiia très abondant et très bien conservé contribue à définir le fonds typologique de cette phase en languedoc oriental à partir duquel va se former le faciès mailhacien i un développement particulier concerne une figurine de terre cuite dans laquelle on reconnaît aisément l oie la fonction de cet objet et le statut possible de cet oiseau à le sein de ce groupe humain où il ne paraît pas avoir été consommé.
termith-eval,test_archeologie_525_06_10675_tei,le renne l aurochs et les volcans. hommes gibiers et reconquête forestière en grande limagne entre 12 300 bp et 7 500 bp. les données relatives à l économie de chasse des groupes humains entre l extrême fin de le pléistocène et le début de l holocène sont rares dans le massif central puisque seulement six gisements ont livré des corpus fauniques attribués à cette période un site de le magdalénien final trois sites épipaléolithiques et deux sites mésolithiques. cette étude devait permettre d appréhender l évolution de le choix des espèces chassées en rapport avec la recomposition des cortèges fauniques entre la fin de le pléistocène et le début de l holocène comme on la connaît dans d autres régions. or elle a mis en évidence l existence en grande limagne d une particularité inédite. en effet si les données des secteurs méridionaux de moyenne montagne sont comparables à ce que l on connaît dans d autres régions à des époques semblables chasses à le cerf chevreuil sanglier bouquetin  les données des sites septentrionaux de limagne témoignent exclusivement de chasses à l aurochs. l hypothèse d environnements particuliers est discutée en intégrant les données paléobotaniques et les données liées à les éruptions volcaniques de la chaîne des puys. ces six séries étant situées dans des secteurs différents de le massif et réparties sur une période d environ 5000 ans leur représentativité tant régionale que chrono culturelle est discutée.
termith-eval,test_archeologie_525_06_10676_tei,impact de la solifluxion sur les niveaux archéologiques simulation à partir d une expérience en milieu actif et application à des sites paléolithiques aquitains. l étude taphonomique de deux sites de le paléolithique moyen petit bost et croix de canard récemment découverts dans des colluvions près de périgueux dordogne france à l occasion de travaux d archéologiepréventive a mis en lumière la difficulté d apprécier le rôle respectif des facteurs anthropiques et naturels en l occurrence la solifluxion sur la répartition spatiale des vestiges. de manière à mieux appréhender les transformations occasionnées par la solifluxion périglaciaire c est à dire par la lente reptation de le sol provoquée par les alternances de gel dégel une simulation informatique a été réalisée à partir de mesures de déplacement enregistrées dans un milieu actif à la mortice alpes françaises méridionales 3100 m d altitude dans le cadre de le programme transit. les résultats de la simulation montrent que pour une concentration d objets de type amas de débitage les premiers stades de la déformation se traduisent à la fois par une translation vers l aval de le centre de gravité de la concentration et par une diffusion anisotrope des objets. l amas prend alors une forme d ellipse allongée dans la pente avec une forte densité relique d objets dans la partie amont. ce type de configuration est obtenu après 100 à 200 ans de fonctionnement dans les conditions de le site expérimental de la mortice. dans les stades ultérieurs de la déformation la répartition de le matériel tend à s homogénéiser et s apparente à une distribution aléatoire sur une grande surface. la comparaison entre la simulation et les configurations archéologiques rencontrées sur les sites de petit bost et croix de canard montre une bonne adéquation. en ce qui concerne le premier l hypothèse d un déplacement limité par la solifluxion rend notamment bien compte de la coexistence de traits anthropiques présence de concentrations d objets et de traits manifestement naturels orientation préférentielle des objets dans la pente. pour le second site l hypothèse d une action prolongée de la solifluxion ayant conduit à une homogénéisation de la répartition des vestiges peut être proposée.
termith-eval,test_archeologie_525_06_10677_tei,la faune de la grotte chauvet vallon pont d arc ardèche  présentation préliminaire paléontologique et taphonomique. au delà des quelque 450 peintures et gravures datées de le paléolithique supérieur ancien la grotte chauvet vallon pont d arc ardèche a livré d abondants vestiges paléontologiques près de 4 000 ossementsjonchent le sol des différents secteurs de la cavité ainsi qu une riche palette de bioglyphes d origine animale bauges pistes griffades et polis en pied de paroi ou humaine tracés digités empreintes. un premier inventaire de la faune identifiée ossements sur les sols souligne l extrême prédominance de l ours des cavernes 99 9 de la faune. les interactions entre l homme et l ours sont présentées et discutées brièvement.
termith-eval,test_archeologie_525_06_10678_tei,l industrie lithique de la couche iii de le roc de marsal dordogne  le problème de l attribution d une série lithique à le moustérien à denticulés. l industrie de la couche iii de le roc de marsal a été attribuée à le moustérien à denticulés. un réexamen de l outillage nous a permis de mettre en évidence la présence de pseudo outils encochés à le sein decet assemblage. cette révision a eu pour conséquence une nette diminution de la proportion de le groupe des denticulés. au delà de le problème de l attribution de certaines industries altérées par des agents naturels ou des actions accidentelles à le moustérien à denticulés nous nous interrogeons sur la pertinence des caractéristiques uniquement typologiques de ce faciès et par delà sur le rattachement systématique d une industrie à l un des faciès décrits par f bordes.
termith-eval,test_archeologie_525_06_10679_tei,la production des outils à le paléolithique moyen comparaison diachronique des occupations de riencourt lès bapaume pas de calais france. le gisement de riencourt lès bapaume comporte cinq niveaux principaux ii ca c b 2 et b 1 correspondant à des occupations de plein air de le pléistocène supérieur. ces assemblages lithiques ont servi de base à une approche diachronique des stratégies de production des outils. par la confrontation des données observées il a été possible de mettre en évidence de nombreux points communs concernant le comportement économique des artisans néandertaliens les types de débitage mis en oeuvre la composition typologique de l outillage la nature et les critères morphométriques des supports d outils et les techniques de retouche employées. ces similitudes pourraient résulter de la pratique d activités semblables induites par des facteurs environnementaux et climatiques stables durant les différentes occupations ainsi que par l omniprésence de gîtes de matière première de bonne qualité. quant à les singularités observées elles seraient plutôt imputables à des influences culturelles propres à chacun des groupes humains.
termith-eval,test_archeologie_525_06_10680_tei,le mobilier funéraire de la dame de saint germain la rivière gironde et l origine paléolithique des inégalités. l analyse archéozoologique et technologique de le mobilier funéraire de la dame de saint germain la rivière 15 570 200 bp et sa comparaison avec les objets de parure et la faune découverts dans ce même gisementainsi que dans les sites et sépultures contemporains révèlent le caractère exceptionnel de cette inhumation. le grand nombre de craches perforées et la préférence pour des craches de jeunes cerfs mâles qui caractérisent le mobilier de la sépulture contrastent avec l extrême rareté de cette espèce dans les sites contemporains de le sud ouest de la france. la rareté et l origine probablement exotique des craches le faible nombre de craches appariées et l homogénéité technique et morphologique de la collection suggèrent que ces dents ont été acquises par échange sur longue distance et qu elles devaient représenter des objets de prestige. a l instar de ce que l on observe chez certaines populations de chasseurs cueilleurs et en contradiction avec le caractère supposé égalitaire des sociétés paléolithiques ces objets pourraient avoir été utilisés pour marquer l appartenance de cette femme à un groupe social privilégié.
termith-eval,test_archeologie_525_07_10018_tei,mobilier céramique et faciès culturel de l habitat gaulois de l île de martigues. cet article présente l analyse de l ensemble de le mobilier céramique des niveaux anciens de trois habitations de le premier village gaulois de l île de martigues dont l occupation s étend de 440 av. j c à 190 av. j c de bonnes conditions stratigraphiques et un découpage chronologique précis de la période étudiée 440 375 360 av. j c favorisent l analyse de l évolution quantitative et typologique de le matériel. deux couches d incendie dans les niveaux étudiés l une dans la seconde moitié de le ve s l autre dans le second quart de le ives. fournissent un matériel bien conservé et en place. la deuxième particulièrement bien conservée pour deux des habitations autorise une approche ethnographique des espaces étudiés par la remise en contexte des objets et l analyse de leur répartition spatiale.
termith-eval,test_chimie_00_0081160_tei,adsorption de le trichlorure d azote gazeux sur charbon actif. en atmosphère humide la trichloramine gazeuse s adsorbe dissociativement sur le charbon actif avec formation d azote moléculaire gazeux et d espèces chlorure irréversiblement chimisorbées. la loi cinétique d adsorption est de le type θ 1 exp  k ncl 3 t. le charbon actif utilisé peut adsorber plus de 13 de sa masse en ncl 3 en atmosphère humide. l addition de ki augmente son efficacité 15  mais celle de na 2 co 3 la diminue 25 . les capacités d adsorption sont remarquablement diminuées en absence de vapeur d eau division par 30 à 40 fois.
termith-eval,test_chimie_00_0261916_tei,dépôt de revêtements peu rugueux de diamant sur un alliage de titane. un nouveau procédé de dépôt chimique assisté par plasma permet de déposer à 600 c des revêtements de diamant de rugosité faible sur des alliages de titane. la microscopie électronique à balayage la diffraction des rayons x et la spectroscopie raman dans le visible et l ultra violet montrent que les revêtements obtenus sont peu rugueux et essentiellement composés de diamant cristallisé avec une morphologie à grains fins. les résultats sont comparés à ceux obtenus sur les revêtements en diamant polycristallin classiques. la spectroscopie d émission montre d importantes différences entre les espèces émissives de le plasma employé et celles qui conduisent à le diamant polycristallin ou à les films nanocristallins.
termith-eval,test_chimie_00_0268317_tei,étude ab initio des structures électroniques et magnétiques des systèmes yfe 2 et yfe 2h3 à le sein de la théorie de la fonctionnelle de la densité dft. les structures électroniques et magnétiques de yfe 2 et d un hydrure yfe 2h3 sont calculées à le sein de la théorie de la fonctionnelle locale de la densité de spins utilisant la méthode de l onde sphérique augmentée. l analyse des résultats obtenus quant à les densités d états dos et à les populations de recouvrement coop permet d expliquer le rôle joué par l hydrogène tant à le niveau de l augmentation de l aimantation globale que de celui de la liaison chimique contractée avec y et fe.
termith-eval,test_chimie_00_0327784_tei,un nouveau dimère hétéropolytungstique  siw 10 o 37 2 fe 4 oh 4 12 formé par la réunion par deux ponts hydroxo de deux unités α siw 10 fe 2 o 39. synthèse et structure de son sel de rubidium. l hétéropolyanion  siw 10 o 37 2 fe 4 oh 4 12 est obtenu par action d une solution de nitrate sur l undécatungstosilicate de potassium. cette réaction conduit dans un premier temps à un ferri undécatungstosilicate qui se dimérise probablement en milieu neutre dans un deuxième temps en milieu légèrement alcalin il y a substitution d un fer à un tungstène et formation d un double pont hydroxo. le composé isolé sous la forme d un sel de rubidium rbe 12 siw 10 o 37 2 fe 4 oh 4 28 h 2 o a été caractérisé par analyse élémentaire spectroscopie infra rouge et polarographie. ce nouveau polyoxoanion dimère est formé par l union de deux ions de keggin deux unités lacunaires α siw 10 o 37 10 fixent chacune deux ions fe 3 et sont reliées entre elles par deux groupes hydroxo pontants. la présence de groupes hydroxo a été montrée par le calcul des somes des valences de liaision des atomes d oxygène impliqués. le composé décrit cristallise v 10 538 8 a avec z 4. la structure a été déterminée par la méthode directe et les affinements ont conduit à les facteurs d accord r 0 0775 et rw 0 0870.
termith-eval,test_chimie_00_0374823_tei,synthèse et étude structurale de le polyanion asiii 4 mo 6 w 14 o 72 h 2 o 2 12 isomorphe de asiii 4 w 20 o 72 h 2 o 2 12. par analogie avec la formation de asiii 4 w 20 o 72 h 2 o 2 12  l addition d un excès de molybdate moo 4 2 sur as 2 iiiw 8 o 30 oh  7 conduit à ph 4 à le polyanion mixte asiii 4 mo 6 w 14 o 72 h 2 o 2 12. la structure de le sel de sodium de ce polyanion a eté résolue par diffraction des rayons x a 11 183 4 å b 13 432 3 å c 19 626 5 å α 77 87 2  β 73 57 3  γ 67 44 3  v 2 594 1 å 3 p 1. les facteurs de confiance sont r 7 89 et rw 9 97 ce composé est isomorphe de na 12 asiii 4 w 20 o 72 h 2 o 2 42 h 2 o le composé de départ a subi une isomérisation β α accompagnée de la substitution formelle d un tungstène par un molybdène et de l addition de deux molybdènes. le polyanion est constitué de deux entités αb asiiimo 2 w 7 o 33 reliées par deux chaînons asiiiomoo 2 h 2 o  dans lesquels l arsenic et le molybdène sont liés chacun à deux octaèdres wo 6 d une entité asiiimo 2 w 7 o 33 avec deux atomes de molybdène contigus.
termith-eval,test_chimie_00_0464460_tei,structure cristalline d un nouvel hydroxyphosphate naturel de strontium fer et aluminium lulzacite  sr 2 fe fe 0 63 mg 0 37 2 al 4 po 4 4 oh 10. la structure cristalline d un nouvel hydroxyphosphate naturel de strontium fer et aluminium lulzacite a été résolue par étude d un monocristal à les rayons x  symétrie triclinique p 1  paramètres de maille a 5 457 1 å b 9 131 2 å c 9 769 2 å α 108 47 3  β 91 72 3  et γ 97 44 3   formule structurale  sr 0 96 ba 0 04 2 fe fe 0 63 mg 0 37 2 al 4  p 0 98 v 0 02 o 4 4 oh 10 z 1. la structure montre l alternance selon l axe b d une part de chaînes infinies parallèles à l axe a dont le motif se compose d un octaèdre fe 2 o 6 suivi d une paire d octaèdres alo 6 et d autre part de trimères formés d un octaèdre alo 6 encadré par deux octaèdres fe 2  mg o 6. trimères et chaînes sont liés par les sommets d un octaèdre alo 6 et de deux tétraèdres po 4. les ions strontium occupent les tunnels formés par la structure. cette structure est isotype de celle de la jamésite arséniate de plomb. des sous motifs analogues se retrouvent dans certaines espèces minérales les trimères dans la ludlamite phosphate de fer  les chaînes dans différents hydroxosels.
termith-eval,test_chimie_00_0466594_tei,greffage de modèles de lignines sur polystyrène par lien imino. la synthèse d oligolignols fixés sur polymère lfp a été entreprise afin d étudier les propriétés physicochimiques et les mécanismes de dégradation des différentes sous unités structurales constitutives des lignines dans des conditions plus proches de celles auxquelles le polymère naturel est soumis. dans ce travail des modèles simplifiés de lignine greffés par des liens imino et amino sur une résine fonctionnalisée à 1 d aminométhylpolystyrène sans protection préalable des fonctions hydroxyle sont proposés.
termith-eval,test_chimie_00_0491251_tei,amélioration de la tenue à la corrosion atmosphérique de matériaux utilisés en connectique nickel doré. traitements de surface par implantations d ions. des essais de corrosion d un matériau utilisé en connectique constitué de laiton recouvert d un dépôt de nickel électrochimique de 5 μm et d un dépôt d or de 0 4 μm ou de 1 μm ont été conduits dans de l air synthétique humide contenant de faibles quantités de no 2 0 2 vpm  so 2 0 2 vpm et cl 2 0 01 vpm. les résultats obtenus montrent que les produits de corrosion croissent sous forme d amas bien localisés constitués principalement de nitrates sulfates et chlorures basiques de nickel et de zinc. ces études ont montré que la corrosion de le matériau est due à la présence de porosités dans les dépôts d or et de nickel. les analyses effectuées à le meb ont montré qu il existait probablement dans ces porosités des composés organiques liés à l élaboration de ces dépôts et que lors de l attaque galvanique de le nickel et de le zinc le carbone était rejeté à la périphérie des amas. la quantité de carbone présent dans les dépôts d or et de nickel a pu être déterminée par des analyses par réaction nucléaires d p. des traitements de surface par implantation en titane ou en titane et azote ou en hélium de ce matériau ont été réalisés afin d essayer de supprimer les défauts d étanchéité dans le dépôt d or. ces différents traitements ont montré une efficacité certaine quant à la suppression des porosités confirmée par les tests de corrosion qui montrent une nette amélioration de le comportement de le matériau vis à vis de la corrosion atmosphérique.
termith-eval,test_chimie_01_0085473_tei,de l hydrogénation catalytique à la théorie chimique de la catalyse paul sabatier chimiste de génie apôtre de la décentralisation. c est à partir de ses réflexions sur la genèse des métaux carbonyles que paul sabatier a progressivement été amené à découvrir l hydrogénation catalytique. a partir de cette dernière réaction à les multiples applications il échafauda une théorie de la catalyse dont l essentiel est toujours d actualité. ses découvertes doivent être attribuées à ses mérites propres et à la formation qu il avait reçue de le laboratoire de marcellin berthelot.
termith-eval,test_chimie_01_0088866_tei,hypothèse cristallochimique des mécanismes de formation de cuo s et de cu oh 2 s à partir de na 2 cu oh 4 s. l addition d eau à des systèmes contenant le solide na 2 cu oh 4 s en équilibre avec sa solution saturée peut conduire à la formation de deux solides différents cuo s et cu oh 2 s. l oxyde est obtenu lorsque l addition est lente il correspond à l état d équilibre l hydroxyde est obtenu par addition rapide d une grande quantité d eau et est une phase métastable de le système. pour expliciter ces comportements différents nous proposons des hypothèses de mécanismes réactionnels. lors de la dilution lente les ions na quittent la structure de na 2 cu oh 4 s et passent en solution. parallèlement les deux liaisons cu o les plus longues de l environnement octaédrique de le cuivre se brisent pour donner naissance à les ions complexes cu oh 4 2  aq  stables en solution et qui constituent les briques élémentaires permettant la formation de cuo s. en revanche la synthèse de cu oh 2 s à partir de na 2 cu oh 4 s n est possible que si la dilution est effectuée en introduisant une grande quantité d eau dans le but de diminuer très rapidement la concentration des ions oh  cette opération permettant d éviter la formation des ions complexes cu oh 4 2  aq  précurseurs de cuo s dans ces conditions na 2 cu oh 4 s donne naissance à l hydroxyde de cuivre divalent cu oh 2 s par une réaction supposée topotactique.
termith-eval,test_chimie_01_0202294_tei,propriétés catalytiques de la montmorillonite intercalée à le titane dans l oxydation de l alcool allylique e  hex 2 én 1 ol oxydations catalytiques. des argiles intercalées à le titane sont synthétisées par insertion dans le domaine interfoliaire d espèces cationiques de le titane obtenus par hydrolyse de ticl 4 avec hcl. les résultats dépendent de le ph de la solution d intercalation pour un rapport h  ti 0 24. l argile intercalée présente un cspacement basal de 2 6 nm et une surface spécifique de 316 m 2 g 1 stable jusqu à 773 k ce solide catalyse la réaction d oxydation de l alcool allylique e  hex 2 èn 1 ol par l hydroperoxyde de tertio butyle en présence de tartrate de diéthyle. le produit principal de la réaction dépend de le mode d activation de le catalyseur et de la température de réaction le solide non calciné est inactif en époxydation. l argile calcinée à 773 k fournit l acide hex 2 ènoique pour une réaction à t 273 k et le trans 2 3 epoxyhexanol à température ambiante avec un rendement de 50  voisin de celui décrit avec des catalyseurs ti polymères.
termith-eval,test_chimie_01_0326702_tei,élaboration de ciments apatitiques composites pour la rétention de le césium et de l iode. l aptitude d un ciment apatitique constitué d hydroxyapatite et des charges ajoutées phosphate tri calcique β phosphate de zirconium et charbon actif a été élaboré et testé en tant que matériau de blocage de l iode et de le césium. ce matériau pourrait être utilisé en tant que matériau de blocage des assemblages de combustibles nucléaires usés dans l option de leur stockage direct afin de freiner la dissémination des produits de fission labile césium et iode lors d un contact de le combustible avec de l eau.
termith-eval,test_chimie_01_0338963_tei,caractérisation par émission acoustique de l adhérence et de l endommagement d un revêtement cas d un revêtement wc co sur acier. cette note présente une méthode de caractérisation par émission acoustique de l adhérence d un revêtement sur son substrat. lors de tests de flexion quatre points des mesures in situ de l émission acoustique exploitées en termes d amplitude d énergie absolue et de position des événements.. ont été réalisées sur des éprouvettes revêtues de cermet wc co par hvof high velocity oxy fuel. l observation microscopique des éprouvettes a mis en évidence la présence de deux types de fissuration une fissuration transverse fissures régulièrement espacées à la surface et une fissuration interfaciale délaminage. les résultats d émission acoustique ont révélé deux types différents d événements en termes d amplitudes et d énergies  représentatifs des deux modes de fissuration observés.
termith-eval,test_chimie_01_0339796_tei,oxydation à haute température d un nouvel alliage de titane α β. l alliage ti mo 4 84 ta 4 34 noté tmt a été oxydé sous pression atmosphérique d oxygène pour des températures supérieures à la température de transformation a β. l augmentation de la résistance à l oxydation voisine de 50 de celle de le titane pur est attribuée à les différents éléments d alliages qui stabilisent la phase β. la dissolution de l oxygène implique la précipitation de la phase a riche en oxygène à les dépens de la phase β alors enrichie en ta et mo. la diffusion de l oxygène survient préférentiellement dans la direction des précipités α elle est discutée notamment à le regard de la stabilité des différentes phases.
termith-eval,test_chimie_01_0371027_tei,une famille d aimants bimétalliques cuiimniià précurseurs moléculaires et contre cations chiraux synthèse et propriétés magnétiques. une famille de trois composés de formule générale mn 2 cu opba  3 cat x solv y où opba  solv et cat représentent respectivement l ortho phenylenebis oxamato  des molécules de solvant et les contre cations chiraux n n dimethyl nicotinium nicot  diméthyl hydroxyméthyl 2 éthyl hydroxyméthyl 1 propyl ammonium ambutol et n n dimethyl éphédrinium dmeph  a été synthétisée. les propriétés magnétiques des trois composés sont caractéristiques d entités ferrimagnétiques avec un minimum dans la courbe xm t en fonction de t et une transition vers un ordre magnétique à les alentours de 20 k l utilisation de l expansion de la fonction de partition à haute température et de le modèle de le champ moléculaire a permis de montrer que ces composés adoptent une structure bidimensionnelle.
termith-eval,test_chimie_02_0099856_tei,diffusion macroscopique dans un tuffeau et un alginate mesure irm. bien que les séquences de gradients pulsés permettent de mesurer un coefficient de diffusion à différentes échelles de temps et de longueur l intérêt des méthodes macroscopiques demeure. nous visualisons ici par irm de le proton le résultat d une diffusion macroscopique. dans le cas de l eau dans un tuffeau l analyse des profils de concentration après un dépôt superficiel permet une mesure précise. dans le cas d un ion divalent qui diffuse dans un gel d alginate et dans la solution initiale d alginate la position de le front de réaction permet de comparer la tortuosité des deux milieux. l originalité de cette dernière mesure est de visualiser la synérèse. de plus on peut calculer un temps maximum pour la réaction de chélation 1 ms.
termith-eval,test_chimie_02_0137965_tei,synthèse et résolution structurale d un nouveau sel à transfert de charge associant l anion organique abts 2 et son radical abts. avec le cation inorganique la 3  la 3 abts 5 h 2 o 31. la synthèse par électrocristallisation d un nouveau sel à transfert de charge entre l anion organique abts 2  le radical anion abts.  abts est le 2 2 azinobis 3 éthyl benzothiazoline sulfonate sous la forme de le sel d ammonium abts  nh 4 2 2 h 2 o et le cation inorganique la 3 a permis d obtenir des monocristaux noirs en forme de plaquettes correspondant à une phase de formulation la 3 abts 5 h 2 o 31. la résolution structurale à 200 k a montré que cette phase était de symétrie triclinique avec pour groupe spatial p 1. les paramètres de la maille cristalline sont a 18 342 4 å b 17 720 4 å c 20 394 4 å a 87 97 3  β 79 08 3  y 85 21 3  v 6 850 2 å 3 et z 2. la structure cristalline présente un caractère bidimensionnel basé sur une alternance de plans organiques et inorganiques. un calcul de valence de liaison est en accord avec le degré d oxydation de le lanthane la 3. ce composé est un complexe à valence mixte anionique puisque sa formule tenant compte de l équilibre des charges peut se mettre sous la forme  la 3  3 abts 2  4 abts.  1 h 2 o 31.
termith-eval,test_chimie_02_0138971_tei,modélisation des temps de réponse des capteurs chimiques. le principe de la modélisation consiste à considérer les temps de réponse et de recouvrement expérimentaux d un capteur à l espèce chimique à détecter comme la somme d un temps intrinsèque  qui serait indépendant des conditions expérimentales et d un temps extrinsèque  lié à le volume de l enceinte de mesure et à le débit de le fluide. les temps de réponse et de recouvrement expérimentaux étant presque toujours dominés par les temps extrinsèques  il en résulte pour les capteurs dont la réponse n est pas linéaire avec la concentration de l espèce chimique à détecter une dissymétrie entre le signal de réponse et celui de recouvrement.
termith-eval,test_chimie_02_0138972_tei,étude de le type structural de γ feo oh  s et comparaison avec la structure de cu oh 2 s. malgré leur stœchiométrie différente cu oh 2 s et γ feo oh  s présentent une analogie structurale. elle se manifeste essentiellement dans le mode d enchaînement des polyèdres qui aboutit à une structure bidimensionnelle composée de feuillets ondulés. l oxy hydroxyde γ feo oh  s  appelé lépidocrocite est obtenu probablement par une réaction topotactique pour laquelle nous proposons une hypothèse à partir de l hydroxyde de fer divalent fe oh 2 s  qui possède également une structure feuilletée isotype de la brucite. la structure de type lépidocrocite ainsi obtenue peut tolérer des déformations importantes de l environnement octaédrique des cations contrairement à le type structural de la brucite. cette déformation est due à une dissymétrie entre les oxygènes induite par l absence d un hydrogène pour l oxy hydroxyde ou à l effet jahn teller important présenté par le cuivre divalent dans la structure de l hydroxyde de cuivre. si une isotypie est impossible entre cu oh 2 s et la brucite comme c est le cas pour fe oh 2 s  il existe en revanche une analogie structurale avec la lépidocrocite même si le cuivre divalent se trouve dans un environnement pentaédrique alors que le fer trivalent est dans un environnement octaédrique. les deux structures sont caractérisées par un atome d oxygène possédant un environnement particulier constitué par deux cations seulement et un atome d hydrogène ce qui a pour conséquence de rendre relativement instables ces deux structures.
termith-eval,test_chimie_02_0310033_tei,le calcul de le déplacement chimique un outil de validation des structures d acides nucléiques. la grande majorité des analyses de spectres rmn en chimie ou en biochimie repose sur la qualité en dispersion de leur déplacement chimique. l objectif de ce travail est de montrer que le calcul en retour de le déplacement chimique théorique à partir de structures peut être utilisé pour sélectionner des structures issues de la modélisation moléculaire afin de différencier plusieurs possibilités conformationnelles. nous présentons ici le résultat de le calcul de déplacement chimique effectué sur deux structures originales deux kissing complexes d adn de 46 nucléotides analogue désoxyribose de la séquence d arn impliquée dans le phénomène de dimérisation de le virus d hiv 1 lai. il est remarquable de constater que même dans des cas très éloignés de la structure hélicoïdale interaction boucle boucle paire aa stacking mésappariement  le déplacement chimique théorique est en bon accord avec le déplacement chimique expérimental  0 25 ppm. les résultats satisfaisants obtenus nous permettent de conclure que la comparaison des déplacements chimiques de le proton est un outil précieux permettant de sélectionner ou de valider des structures d oligonucléotides.
termith-eval,test_chimie_02_0311652_tei,rôle des ponts disulfure dans le repliement en épingle à cheveux de l androctonine. relations structure activité. l androctonine est un peptide antibactérien de 25 résidus extrait de l hémolymphe de le scorpion androctonus australis. afin de mettre en évidence les déterminants structuraux nécessaires pour le maintien de le repliement en épingle à cheveux et pour l interaction avec la membrane bactérienne nous avons analysé les déplacements chimiques et les noes de trois mutants synthétiques de l androctonine dans lesquels les ponts disulfure ont été sélectivement supprimés.
termith-eval,test_chimie_84_0013924_tei,rôle de l alcool dans les microémulsions. ii volumes et capacités calorifiques molaires apparents de le système eau dodécylsulfate de sodium isopropanol à 298 15 k. les masses volumiques et les capacités calorifiques par unité de volume de le systeme ternaire eau dodécylsulfate de sodium nads  isopropanol iproh ont été mesurés en fonction de la concentration en alcool et en tensioactif à 298 15 k les volumes et les capacités calorifiques molaires apparents ou partiels de l alcool dans le système ternaire en sont dérivés. leur évolution en fonction de la composition reflète le comportement de l alcool. en milieu dilué il se solubilise partiellement dans les micelles et contribue a la formation de micelles mixtes. en milieu concentré il se solubilise dans des microagrégats de nature très proche de celle de l alcool. la variation de la capacité calorifique molaire apparente à dilution infinie del isopropanol en fonction de la concentration en nads révèle l existence d une transition dans la structure micellaire vers 0 3 m.
termith-eval,test_chimie_84_0017603_tei,la photolyse de le cyclohexène gazeux à 184 9 nm. photolyse en présence ou absence d intercepteur radicalaire tel que o 2 no h 2 s ou hi entre 1 et 70 torr. produits majeurs observés c 2h4 et butadiène 1 3 avec des rendements quantiques supérieurs à 0 5. mécanisme.
termith-eval,test_chimie_84_0048710_tei,réaction entre solvant et espèces intermédiaires apparues lors de l électroréduction acylation de la fluorénone et de la fluorénone anil dans l acétonitrile. etude de le comportement des différents acylates de fluorénols 9 vis à vis des anions ch 2 cn électrogénérés par réduction de l azobenzène en son dianion dans l acétonitrile. réduction de la fluorénone dans l acétonitrile en présence de chlorures d acides ou d anhydrides.
termith-eval,test_chimie_84_0075032_tei,spectre de vibration de quelques n méthyl halogénotriazoles 1 2 4. attribution des modes normaux de vibration à partir des spectres ir et raman de le composé de le titre.
termith-eval,test_chimie_84_0108067_tei,la dissolution de l anode de cuivre dans les solutions faiblement chlorurées. usage de plus en plus répandu de solutions contenant l ion cl dans les procédés d usinage et de polissage de le cuivre par voie électrochimique et d autre part rôle prédominant de cl dans la corrosion de cu d où les recherches sur la dissolution de cu en présence de cl. etude particulière de la dissolution anodique de cu en solution aqueuse de ph 4 dans le domaine de concentration en cl de 0 005 m à 0 1 m technique expérimentale. résultats.
termith-eval,test_chimie_84_0147675_tei,complexes des ions hg 2 avec le monomère et le dimère de la thymine 5 methyl 2 4 1 h 3 h pyrimidinedione. etude faite de ph 2 à 11. mise en évidence des complexes hg tm  et hg tm 2  tm monomère et de hg td   hgh 1 td  et hgh 2 td  2  td dimère.
termith-eval,test_chimie_84_0152657_tei,etude polarographique de le niobium dans les mélanges eau fluorure d hydrogène. l analyse de certains minerais requiert leur dissolution dans hf. une méthode d analyse directement applicable à les mélanges eau hf est décrite.
termith-eval,test_chimie_84_0154104_tei,etude par spectroscopie infrarouge de l action de mgbr 2 anhydre sur le n méthylacétamide en solution dans ccl 4. formation progressive d un composé d addition bromure de bromo méthyl amino 1 éthoxy magnésium.
termith-eval,test_chimie_84_0291725_tei,destruction des oxydes d azote à pression atmosphérique. utilisation d une décharge microonde pour l amélioration de le coût énergétique de destruction des oxydes d azote par l azote activé à pression atmosphérique.
termith-eval,test_chimie_84_0341886_tei,etude théorique de la structure de le phosphate d isaxonine. les auteurs étudient les protonations de le phosphate d isaxonine à le moyen des méthodes quantiques cndo 2 et cndo s et comparent les résultats théoriques à les résultats expérimentaux publiés précédemment. les indices de wiberg et les pourcentages de caractère s calculés à partir des populations électroniques permettent de prévoir correctement les variations des longueurs et des angles de liaisons ainsi que les valeurs des constantes de couplage j 13 c h. enfin le calcul de la constante d écran conduit à une bonne prédiction des variations des déplacements chimiques des protons lors des protonations de la molécule.
termith-eval,test_chimie_84_0341889_tei,calcul des intensités des transitions laser dans 12 c 16 o 2 et ses molécules isotopiques. calcul théorique des intensités des ions à 9 et 10 μm de 12 c 16 o 2. comparaison à les résultats expérimentaux on discute de le rôle de l anharmonicité ainsi que des erreurs dues à la méthode de transformation de contact dans le calcul des niveaux d énergie.
termith-eval,test_chimie_84_0353537_tei,l électrodissolution de le cuivre dans les solutions bromurées. etude des divers paramètres entraînant cette dissolution en présence de nabr. dans la zone où l accumulation de le produit de corrosion sur cu est inexistante ou marginale le courant de dissolution est décomposable en un phénomène de surface d une part et en un phénomène de diffusion des ions dans la solution d autre part.
termith-eval,test_chimie_85_0004702_tei,etude par activation collisionnelle des ions c 4h7 o  provenant des ions penténols et méthylcetones c 5h10 o. métastables. spectres activation par collision mike des ions c 4h7 o formés dans la source à partir de butyrate et isobutyrate de méthyle butène 3 one 2 méthyl 2 ou 3 pentène 1 ols 3 butène 2 al et isobuténal. structure des ions c 4h7 o provenant de pentanone 2 pentène 3 ol 2 méthyl 3 butène 3 ol 2.
termith-eval,test_chimie_85_0006473_tei,etude de la dissolution de le bromure cuivreux formé sur le cuivre. etude de la dissolution de le bromure cuivreux formé par oxydation électrochimique de le cuivre immergé dans une solution aqueuse de nabr 0 1 m 1 2 m  à ph 4. l utilisation d une électrode à disque tournant montre que la dissolution est entièrement dominée par la diffusion des ions en phase liquide.
termith-eval,test_chimie_85_0052026_tei,structures cristallines des  oxy 2 β bis bromo 3 α phényl 5 β tétrahydrofuranne   oxy 2 β bis bromo 3 α méthyl 4 α phényl 5 β tétrahydrofuranne et  oxy 2 β bis bromo 3 α triméthyl 2 4 6 phényl 5 β tétrahydrofuranne. les trois éthers formés à le cours de l hydrolyse des dérivés dibromés tétrahydrofuranniques ont une structure racémique. dans les trois cas la sélectivité de la réaction correspond donc à une association entre énantiomères de même configuration absolue. conformation de le cycle furanne avec le groupe aromatique d autant plus équatorial qu il est volumineux.
termith-eval,test_chimie_85_0117538_tei,etudes des complexes métalliques de ac asp val asp ala oh par potentiométrie et résonance magnétique nucléaire de le 1 h. constantes de stabilité des complexes de ca cd co cu mn ni zn divalents et pr 3. spectres rmn. il y a interaction spécifique entre le tétrapeptide et les cations ca 2 ou pr 3 à le niveau des groupes carboxylates des restes aspartyl en milieu neutre.
termith-eval,test_chimie_85_0144410_tei,orientation et dynamique moléculaire de sondes paramagnétiques en phase lamellaire dibutylephosphate de sodium eau. etude par rpe de l orientation et de la dynamique moléculaire dans la phase lamellaire de sondes paramagnétiques telles que l ion vanadyle et les radicaux nitroxydes tempoamines tempone et tempobutanamide.
termith-eval,test_chimie_85_0176517_tei,mécanisme des réactions de le chlorite et de le dioxide de chlore. ii cinétique des réactionsdu chlorite en présence d ortho tolidine. en présence d o tolidine utilisée pour éliminer les complications dues à les réactions des produits intermédiaires de la dismutation de le chlorite la stœchiométrie est hclo 2 rnh 2 rnh 2 cl  h 2 nhrnh 2 h 2 o loi cinétique.
termith-eval,test_chimie_85_0204071_tei,correlation pka activité catalytique des thiols dans la réaction d hydrolyse de l acétate de p nitrophényle. l anion thiolate est l espèce catalytique.
termith-eval,test_chimie_85_0218123_tei,complexation de le cuivre ii par les phénylsérines thréo et érythro étude thermodynamique. mesures conductimétriques et potentiométriques en solution aqueuse en fonction de la température. constantes de stabilité des complexes cu l  cu l 2 h 1  cu l 2 h 2. paramètres thermodynamiques.
termith-eval,test_chimie_85_0256379_tei,mécanisme des réactions de le chlorite et de le dioxyde de chlore. iii la dismutation de le chlorite. etude de la dismutation dans des solutions d hclo 4 de 0 01 à 1 m il y aurait à le moins 3 chemins réactionnels le 1er est catalysé par les ions cl  le 2 ème donne une loi de vitesse à le 2 ème ordre le 3 ème est catalysé par fe.
termith-eval,test_chimie_85_0365968_tei,electrochimie dans l oxydipropionitrile étude des systèmes de le mercure en milieu complexant et non complexant. l ensemble des résultats obtenus montre qu en milieu fortement complexant le mercure s oxyde en mercure ii avec formation des complexes supérieurs hgx 4 2 hgx 3. il n en est plus de même en milieu peu complexant où l on doit envisager la formation de complexes avec le hg i. ceci complique l exploitation des courbes de titrage par suite de la transformation progressive des complexes de le mercure ii en complexes de le mercure i à le contact de le mercure métallique. les systèmes de le mercure ne montrent cependant pas un comportement fondamentalement différent de celui observé dans de nombreux solvants organiques.
termith-eval,test_chimie_85_0397642_tei,photoélectrochimie des phtalocyanines sans métal de cuivre et de fer. le comportement cathodique et photocathodique d électrodes de phtalocyanine sans métal de cuivre et de fer h 2 pc cupc et fepc a été étudié en solutions acide neutre et alcaline. dans le noir la courbe de polarisation de l électrode de fepc présente deux pics de réduction qui n ont pas été observés avec les autres phtalocyanines ils sont associés à la réduction de le cation central. l illumination des électrodes semiconductrices n a produit aucun effet sur la réaction de le dégagement de l hydrogène. l analyse des courbes capacité tension a révélé la présence de niveaux intermédiaires localisés à l intérieur de la bande interdite des semiconducteurs et recouvrant environ 1 de leurs sites de surface. les résultats sont expliqués en considérant les phtalocyanines comme des électrodes semiconductrices de type p l énergie des bandes et des états de surface a été illustrée dans un modèle d interphase semiconducteur électrolyte et la nature des transferts de charges inhibés par la présence de ces états interfaciaux a été discutée.
termith-eval,test_chimie_86_0024852_tei,etude de l anharmonicité électrique dans 12 c 16 o 2. le développement de le moment dipolaire dans la molécule 12 c 16 o 2 en fonction des coordonnées normales est déterminé jusqu au quatrième ordre par ajustement sur les valeurs expérimentales des intensités de transition. la convergence de le développement est rapide mais les termes d ordre trois jouent un rôle très important si on veut obtenir une précision de l ordre de 20.
termith-eval,test_chimie_86_0051297_tei,etude structurale et thermodynamique des intéractions entre des dérivés chlorés et bromés de le méthane et des amides tertiaires. une étude par polarisation diélectrique microcalorimétrie et spectrométrie infrarouge a permis de mettre en évidence le rôle joué par l halogène dans les interactions entre des représentants d anesthésiques halogénés et un modèle de constituant de la membrane des cellules nerveuses respectivement cités dans le titre.
termith-eval,test_chimie_86_0055977_tei,volumes molaires partiels de composés tensioactifs dans les milieux salins concentrés eau kcl. les volumes molaires apparents de quatre détergents cationiques ch 3 ch 2 nn ch 3 3 br pour n 9 11 13 et 15 ont été déterminés dans les mélanges eau chlorure de potassium à 298 k pour des concentrations en électrolyte support comprises entre 0 5 et 3 5 mol l 1. la très faible dépendance des volumes molaires apparents des tensioactifs une fois micellisés avec la concentration de le sel de fond laisse supposer que les interactions entre les amphiphiles eux mêmes et entre les amphiphiles et leur environnement ne sont pas fondamentalement modifiées par l addition de sel. l utilisation de résultats antérieurs obtenus pour ces mêmes milieux concernant le comportement des sels d ammonium symétriques permet d accéder à les volumes intrinsèques des amphiphiles et par conséquence d estimer le volume réel occupé par la phase micellaire dans la solution. des mesures des volumes molaires apparents de le bromure de dodécyltriméthylammonium et de le dodécylsulfate de sodium dans les mélanges eau nacl permettent de confirmer les rôles dissymétriques joués par les anions et les cations en milieu salin concentré.
termith-eval,test_chimie_86_0056100_tei,polymérisation de le chloroformiate de vinyle et de ses dérivés. polymérisation radicalaire dans le chlorure de méthylène à 35 c avec le peroxydicarbonate de dicylohexyle comme amorceur étude cinétique par dilatométrie polymères nouveaux préparés soit par polymérisation radicalaire de monomères dérivés de le chloroformiate de vinyle soit par modification chimique de le polychloroformiate de vinyle par des amines des alcools des thiols des acides carboxyliques kcn  par catalyse de transfert de phase. structure et propriétés thermiques de ces polymères.
termith-eval,test_chimie_86_0118063_tei,isomérisation des radicaux insaturés. iii radicaux α α β  α β γ et α α g triméthallyles. les radicaux de le titre conduisent à la formation de divers diènes 1 3 et de petites quantités de diènes 1 2 ou 2 3.
termith-eval,test_chimie_86_0181567_tei,capacité calorifique de polyélectrolytes en solution. acide polyméthacrylique acide polyacrylique polystyrènesulfonate de sodium en solution aqueuse sans addition d électrolyte.
termith-eval,test_chimie_86_0193921_tei,pressions de vapeur des mélanges eau nitrate d éthylammonium à 298 15 k propriétés thermodynamiques des milieux eau sel fondu. détermination de l activité et à le coefficient d activité de l eau dans les mélanges eau nitrate d éthyl ammonium entre l eau pure et le sel pur fondu.
termith-eval,test_chimie_86_0248850_tei,réduction photochimique des polytungstates. mise en évidence d un effet photogalvanique. pile réalisée avec une solution de décatungstate de tétrabutylammonium dans l acétonitrile à la concentration 0 2 m en atome gramme de tungstène. le décatungstate excité par la lumière est réduit réversiblement. le mécanisme fait intervenir vraisemblablement deux photons. rendement voisin de 1.
termith-eval,test_chimie_86_0329986_tei,sélectivité de le transport de ca 2  mg 2 à travers une membrane liquide par a 23187 calcimycine et son dérivé n méthyle. le transport préférentiel de ca 2  mg 2 par a 23187 est mis en évidence dans une cellule eau chcl 3 eau. par des mesures de flux d extraction et de flux de libération dans une demi cellule eau chcl 3 on montre que la sélectivité de le transport est liée à une cinétique de libération nettement différente pour les deux ions qui pourrait s expliquer par la structure des complexes dimériques formés si on se réfère à les études cristallographiques correspondantes. la méthylation de le groupement nhch 3 entraîne une inversion de la sélectivité de transport.
termith-eval,test_chimie_86_0384134_tei,etude physico chimique spectres de vibration et structure de le sulfaméthoxazole. caractérisation de deux polymorphes et d une forme solvatée en utilisant plusieurs méthodes thermiques et spectrales. détermination structurale de la forme ii.
termith-eval,test_chimie_87_0042802_tei,propriétés de solvation des solutions concentrées en acide phosphorique. solvatation d halogénures ferrocyanures de cations métalliques.
termith-eval,test_chimie_87_0044237_tei,synthèses et analyses structurales de perchlorates anhydres d in iii et de tl iii m clo 4 3 et clo 2 m clo 4 4  m in tl. présentation de le mode de préparation des perchlorates anhydres d indium et de thallium et proposition d une analyse structurale des composés obtenus réalisée par spectres de vibration ir et raman diffraction rx et exafs.
termith-eval,test_chimie_87_0071824_tei,utilisation de l ortho tolidine pour l étude des réactions des halogénates et halogénites. l o tolidine simplifie l étude cinétique des réactions redox à le chlorite en réagissant avec les produits intermédiaires et en supprimant les réactions secondaires.
termith-eval,test_chimie_87_0247714_tei,hydrodésazotation de l indole sur catalyseur fer supporté sur amiante. l augmentation de la température et de la pression et la préréduction des matériaux favorisent la désazotation. la présence de particules de fer 0 en surface des fibres formées à partir de le matériau de départ joue un rôle dans la première coupure des liaisons c n et dans l hydrogénation des cycles.
termith-eval,test_chimie_87_0254813_tei,mécanisme des réactions de le chlorite et de le dioxyde de chlore. v cinétique de la réaction chlorite bromure. dans les solutions acides on observe simultanément la dismutation à le chlorite et une réaction autocatalytique conduisant à une production de clo 2. effet de l o tolidine.
termith-eval,test_chimie_87_0254814_tei,etude des complexes fluorés et chlorés de le plomb dans les mélanges eau hf. etude par polarographie. l obtention de 2 formes cristallines de pbf 2 selon le domaine de concentration en hf est en accord avec l existence de 2 complexes en solution.
termith-eval,test_chimie_87_0263259_tei,chimie des radioprotecteurs synthèse d alkylamino 2 éthanethiols encombrés sur l atome d azote. synthèse par réaction de bromure d allyl magnésium avec des dialkyl 2 2 thiazolidines alkyl 2 thiazolines 2 et méthylthio 2 thiazolines 2.
termith-eval,test_chimie_87_0422147_tei,interactions de le cu ii  de le hg ii et de le pt ii avec les formes monomères et dimères de la thymine de la thymidine et de l acide orotique. constantes de protonation des coordinats et de stabilité des complexes.
termith-eval,test_chimie_87_0468978_tei,etude des mélanges eau hf par spectroscopie infrarouge à transformée de fourier. etude de l évolution des espèces ioniques de hf selon la concentration. jusqu à 50 hf en poids présence de h 3 o f  h 3 o  f et h 2 o au delà présence de hf 2 et de polymères hf n dans les solutions à hautes concentrations en hf.
termith-eval,test_chimie_88_0011624_tei,cellules photoélectrochimiques de phtalocyanine d hydroxyaluminium déposées par rotation. le comportement spectral et électrique des cellules nesa pcaloh bq hq pt est étudié et comparé à celui de cellules où les films de pcaloh sont produits par sublimation. la cellule est optimisée et un diagramme des niveaux d énergie est élaboré.
termith-eval,test_chimie_88_0069540_tei,effets de solvants sur les complexes par transfert de charge iode composés thiocarbonylés. ces effets sont comparés à les effets de solvant sur les complexes iode composés carbonylés. l inversion de l effet des solvants donneurs de liaison hydrogène en passant d une série à l autre résulte de le caractère dur des bases carbonylées et mou des bases thiocarbonylées.
termith-eval,test_chimie_88_0149260_tei,etude de le comportement d un alliage cu ni 70 30 dans une solution de nacl à 3 par la détermination de sa résistance de polarisation. l utilisation d une méthode galvanostatique permet de suivre l évolution de la résistance de polarisation d un alliage cuivre nickel 70 30 en fonction de le temps malgré la présence d une couche de produits de corrosion formée à la surface de l échantillon à le bout de plusieurs jours d immersion. la résistance de polarisation de l alliage qui est à le début comparable à celle de le cuivre se rapproche à le fur et à mesure de celle de le nickel pur.
termith-eval,test_chimie_88_0197962_tei,etude cinétique et thermodynamique de l intéraction d un complexe de pd ii avec l inosine et l acide polyinosinique. dans les 2 cas le métal se lie d abord à le site n 7 de la base hypoxanthine. il y aurait 2 voies réactionnelles. la réaction initiale à le site n 7 est suivie d une redistribution lente de le métal vers n 1 thermodynamiquement plus stable.
termith-eval,test_chimie_88_0221226_tei,cinétique et mécanismes des réactions bromate chlorite et bromate dioxyde de chlore. en solution acide on observe 2 réactions consécutives l oxydation de l acide chloreux en clo 2 suivie de l oxydation de le clo 2. constantes d équilibre.
termith-eval,test_chimie_88_0221227_tei,etude des complexes fluorés et chlorés de le cadmium dans les mélanges eau hf. etude polarographique. on observe une diminution de l ordre des complexes fluorés de cdf 3 à cdf. formation de complexes chlorés de degré 3 et 4.
termith-eval,test_chimie_88_0242516_tei,la dissolution anodique de le cuivre en présence d ions f dans des solutions aqueuses acides. etude de l influence des ions f sur la dissolution anodique de le cuivre dans des solutions aqueuses acides ph 1 6 6 en présence de kf 0 1 m mise en évidence de la nature des changements se produisant à l électrode durant l oxydation par voltammétrie cyclique et différentes techniques d analyse de surface sem xps aes. etablissement de le mécanisme d oxydation électrochimique de le cuivre à ph 5 à partir d études avec électrode tournante à disque dans des conditions où la dissolution de le cuivre est généralisée.
termith-eval,test_chimie_88_0408004_tei,etudes des propriétés adsorbantes des fibres d amiante modifiées et de fibres proposées comme substitut à l amiante par chromatographie en phase gazeuse. etude des tracés des isothermes d adsorption de le benzène sur les fibres d amiantes brutes et modifiées par traitement thermique et chimique ainsi que sur des fibres proposées comme substitut à l amiante kevlar carbone. comparaison de leur pouvoir adsorbant et de la possibilité de chimisorption.
termith-eval,test_chimie_89_0145232_tei,etude thermodynamique de le mélange chlore acide isocyanurique en milieu aqueux. mode de calcul permettant d obtenir les concentrations à l équilibre en solution aqueuse des dérivés n chlorés de la triazine 1 3 5 trione 2 4 6 en fonction de le ph de le rapport chlore acide cyanurique et de la concentration en ions chlorures.
termith-eval,test_chimie_89_0333831_tei,etude des courants périodiques observés lors de la dissolution électrochimique de le nickel en présence d 1 ions iodure et chlorure en milieu aqueux. etude réalisée par voltamétrie à faible balayage  2 mv s. on observe que la dissolution de le nickel est liée à la concentration en chlorure et que l addition d iodure modifie la forme des courbes. influence de la concentration en iodure sur les oscillations de courant observées. discussion de l effet produit par l addition d agents de surface.
termith-eval,test_chimie_91_0048510_tei,solvatation et complexation des métaux dans les mélanges eau fluorure d hydrogène. sn cd pb et tl. le comportement électrochimique de l étain et de le thallium dans les mélanges eau hf a été étudié sur toute la gamme de concentration. le thallium ne forme pas de complexes fluorés. l étain sn 2 forme deux complexes fluorés snf 2 et snf  dans les mélanges contenant moins de 60 en hf. le complexe snf 2 est suffisamment fort pour empêcher la formation de complexes chlorés. la formation de snf 6 2 et snf 5 a aussi été démontrée pour l étain sn 4.
termith-eval,test_chimie_91_0130015_tei,etude cinétique de la n chloration de l acide cyanurique en phase aqueuse. nous présentons une étude des mécanismes et déterminons les constantes de vitesse des n chlorations d acide cyanurique en milieu aqueux basique. les énergies d activation des processus mis en cause ont été déterminées. ces cinétiques rapides ont été étudiées sur spectrophotomètre à écoulement bloqué. dans le domaine de ph étudié nos résultats expérimentaux sont en accord avec un modèle cinétique comprenant la contribution de deux couples de processus indiscernables.
termith-eval,test_chimie_91_0530134_tei,etude chimique et cinétique de l oxydation homogène en phase gazeuse d alcanes légers. ii propane et mécanisme généralisé. une étude expérimentale détaillée de l oxydation de le propane en phase gazeuse homogène à 350 c et à pression subatmosphérique a été entreprise dans le but d identifier et de séparer les produits primaires principaux de la réaction. les résultats expérimentaux ont été interprétés par un mécanisme radicalaire en chaînes s appuyant sur ces résultats et sur l évaluation des constantes de vitesse des processus éléméntaires proposés par les méthodes de la cinétique thermochimique.
termith-eval,test_chimie_97_0394148_tei,la résistance de transfert d électrons d une réaction électrochimique peut elle être négative. on montre que la résistance de transfert de la réaction électrocatalytique de koper sluyters ne peut jamais être négative et qu il n est pas nécessaire qu elle le devienne pour qu existe une bifurcation de hopf. on discute de manière plus générale de le signe de la résistance de transfert des réactions électrochimiques.
termith-eval,test_chimie_97_0469487_tei,sur la synthèse de c 3 n 4 de structure graphitique par voie solvothermale. β c 3 n 4 annoncé à le travers de calculs ab initiο semble difficile à préparer de le fait de la stabilité de la molécule n 2 lorsque de hautes températures sont requises par la synthèse. utilisant un procédé solvothermal p 130 mpa t 250 c mettant en jeu deux précurseurs organiques la mélamine et le chlorure de cyanuryle en présence d une base très peu nucléophile  ch 3 2 ch 2 nc 2h5 comme solvant un solide brun orangé est obtenu. différentes techniques physico chimiques de caractérisation microsonde de castaing microscopie électronique à balayage spectroscopie de photoélectrons x spectroscopie raman et diffraction des rayons x confirment la stabilisation de la forme graphitique de c 3 n 4 à l échelle macroscopique. ce matériau ouvre la voie à la synthèse des diverses formes denses 1 de c 3 n 4 à l aide de hautes pressions.
termith-eval,test_chimie_97_0519640_tei,etude des propriétés acido basiques et énergie interfaciale des oxydes et hydroxydes métalliques. la chromatographie gazeuse inverse cgi à dilution infinie a été utilisée pour déterminer la composante dispersive γs d de l énergie de surface de quelques oxydes et hydroxydes métalliques. le point de charge nulle pcn de ces solides a été déterminé par potentiométrie alors que leurs points isoélectriques pie ont été calculés par des mesures de leur potentiel zéta en milieu aqueux. cette étude a permis également de déterminer les propriétés acido basiques à le sens de brönstedt des surfaces étudiées dont l énergie interfaciale y a été appréciée d après les travaux de söhnel. les nouvelles corrélations linéaires trouvées entre γs d des solides et leurs pcn ou leurs pie ou encore le ph de leurs suspensions aqueuses ont permis de connaître la composante polaire de leur énergie de surface en fonction de pcn ou de pie de ces solides.
termith-eval,test_chimie_97_0547348_tei,contrôle magnétique de la mouillabilité. un film de caoutchouc comportant des grains ferromagnétiques durs avec un axe d aimantation privilégié est préparé avec des régions en ruban alternées en aimantation. si un tel film fixé sur un support solide est soumis à un champ magnétique tangentiel h il doit déformer la surface libre en crêtes et vallées et devenir de ce fait plus mouillable.
termith-eval,test_chimie_98_0026981_tei,l apport des hautes pressions en chimie de le solide. les hautes pressions apparaissent comme un outil important pour le développement de la chimie de le solide notamment en ce qui concerne la synthèse de nouveaux matériaux l accès à des maté iaux originaux étant toujours riche d enseignements tant à le niveau de la liaison chimique que des corrélations entre liaison chimique structure et propriétés physico chimiques observées. le développement des hautes pressions durant le xxe siècle peut schématiquement être décrit en trois périodes celle de la maîtrise de le paramètre pression celle postsynthèse de le diamant et celle initiée par la mise à le point de la cellule à enclumes de diamant. les principaux concepts gouvernant la synthèse de matériaux sous hautes pressions sont ensuite traités et quelques illustrations sont données. il apparaît que la seconde période 1955 1980 ait été particulièrement féconde l intérêt suscité par la cellule à enclumes de diamant ayant plutôt initié des recherches en physique des solides. le développement à l aube de le xxe siècle de la chimie de le solide sous hautes pressions nécessiterait probablement à la fois une formation de base appropriée la maîtrise de le paramètre pression impliquant un élargissement des connaissances vers d autres disciplines et des progrès à le niveau de la conception de nouveaux équipements.
termith-eval,test_chimie_98_0054157_tei,influence de quelques facteurs sur la photodégradation catalytique de l acide acétique en solution aqueuse par le tio 2. la photodégradation catalytique de l acide acétique en solution aqueuse par le tio 2 a été étudiée. l influence de tio 2  de ch 3 cooh et de le temps d irradiation sur la vitesse de dégradation a été démontrée. nous avons mis en évidence que la disparition de l acide acétique suivait le modèle de langmuir hinshelwood. enfin nous avons observé l effet de la granulométrie et de la forme cristalline de le catalyseur qui montre bien que la dégradation se fait à la surface de le tio 2.
termith-eval,test_chimie_98_0258257_tei,synthèse de matériaux mésoporeux de type mcm à base d oxyde de fer. la caractérisation des solides synthétisés par réaction de le chlorure ferrique hydrolysé avec une phase micellaire d hexadécylsulfonate de sodium révèle des changements importants avec le taux d hydrolyse. pour des rapports d hydrolyse r oh fe 1 0 une phase lamellaire est obtenue. pour r 1 5 une structure hexagonale apparaît. les isothermes d adsorption désorption d azote effectuées sur cette phase calcinée à 300 c révèlent une surface spécifique importante 130 m 2 g 1 et quelques mésopores calibrés. l ajout d alcools aliphatiques dans le milieu de synthèse modifie les produits obtenus. dans le cas de le propanol on obtient des solides purement mésoporeux à pores calibrés avec des surfaces spécifiques atteignant 250 m 2 g 1.
termith-eval,test_chimie_98_0258336_tei,etude de la photolyse de sels de sulfonium photoamorceurs cationiques. les sels d arylonium ont permis l essor de la photopolymérisation cationique. de nombreuses études portent sur la photolyse de sels de triarylsulfonium. ce travail traite de la cinétique de photofragmentation de ces sels étudiée par rtuv real time ultraviolet  de la visualisation de le phénomène de photolyse grâce à des mesures de ph en temps réel et de la cinétique de photolibération d acide par titrages potentiométriques.
termith-eval,test_chimie_98_0258764_tei,origine de n 2 o en réduction de no par nh 3 sur cu zéolithes. entre 300 et 800 k n 2 est toujours le produit majoritairement formé en oxydation de nh 3 sur des catalyseurs à base de zéolithe faujasite nay et de cuivre cu x  nay x étant le taux d échange théorique. les vitesses de conversion de nh 3 en réduction catalytique sélective scr de no par nh 3 nh 3 o 2 no  et en oxydation de nh 3 nh 3 o 2 sont similaires sur cu 195  nay. elles diffèrent sur cu 76  nay à basse température  610 k mais en revanche sur cu 25  nay la vitesse de conversion de nh 3 en scr est toujours très supérieure à celle de l oxydation. en scr de no sur cu 76  nay deux vagues de formation de n 2 q sont observées vers 500 k et au delà de 600 k tandis que sur cu 25  nay aucune trace de n 2 o n est détectée. la formation de n 2 o à basse température est attribuée à la décomposition de nitrate d ammonium formé sur des agrégats d oxyde de cuivre. la formation de n 2 o à plus haute température résulterait de l oxydation de nh 3 et serait reliée à la présence d ions cuivre isolés proches voisins ou de dimères cuocu 2.
termith-eval,test_chimie_98_0275528_tei,deux nouveaux bismutho iii polytungstates na 10 bi 2 ni 2 w 20 o 70 h 2 o 6 26 h 2 o et na 8 bi 2 w 22 o 70 oh 6 31 h 2 o. deux nouveaux bismutho iii polytungstates na 10 bi 2 ni 2 w 20 o 70 h 2 o 6 26 h 2 o 1 et na 8 bi 2 w 22 o 70 oh 6 31 h 2 o 2 ont été préparés et étudiés par diffraction des rayons x ils contiennent deux unités biw 9 o 33 de type β b dans chacune desquelles un groupe w 3 o 13 a tourné de 60. ces unités sont connectées par quatre octaèdres. alors que les octaèdres des groupes biw 9 w 33 n ont qu un oxygène terminal deux de ces quatre octaèdres de liaison ont deux ogygènes terminaux et les deux autres comportent trois ligands faciaux des molécules d eau ou des anions hydroxydes soit nio 3 h 2 o 3 pour 1 et wo 3 oh 3 pour 2.
termith-eval,test_chimie_98_0284564_tei,amorphisation sous haute pression de la variété quartz α de l oxynitrure de phosphore pon. on a préparé la phase quartz α de l oxynitrure de phosphore pon à partir de la phase de type cristobalite par un traitement à 4 5 gpa et 750 c son comportement a été étudié dans une cellule à enclumes de diamant jusqu à 48 gpa par diffraction angulaire des rayons x sur poudre. le rapport cla des paramètres cristallins augmente avec la pression mais plus lentement que pour la silice. vers 20 gpa ce rapport augmente brusquement de 2  indiquant une transformation de phase de le premier ordre. l amorphisation progressive est importante au dessus de 30 gpa. elle est complète au dessus de 42 gpa et reste irréversible à la décompression. les comportements sous pression des phases de type quartz α de la silice et de pon sont similaires.
termith-eval,test_chimie_98_0296824_tei,décontamination chimique. ii. oxydation de composés soufrés en milieu micellaire rôle de la lipophilie des substrats. la décontamination chimique de composés toxiques pesticides ou toxiques de guerre est d une importance croissante. dans le cas de l oxydation en milieu micellaire aqueux ou dans un binaire de solvants de modèles de toxiques soufrés on a étudié les relations entre la réactivité sélectivité de la réaction de décontamination et la lipophilie log p  de le modèle. deux substrats modèles de lipophilies proches de l ypérite semblent les mieux adaptés pour mimer la dégradation de le toxique. dans ces deux cas un milieu micellaire constitué de chlorure de cétylpyridinium et d un binaire de solvants eau formamide conduit à les meilleurs résultats rendements quantitatifs et pourcentages de sulfoxyde supérieurs à 90.
termith-eval,test_chimie_98_0485659_tei,structures type oignon et structure d équilibre de le carbone. des nanodiamants obtenus par détonation d explosifs surcarbonés dans un confinement d eau ont été soumis à un chauffage progressifsous vide jusqu à 1500 c et se sont intrégralement transformés à le cours de ce traitement en une structure de type graphitique turbostratique selon le spectre de rayons x pic principal correspondant à d 002 0 344 nm. l examen à le microscope à haute résolution révèle la transformation en coquilles fermées concentriques formées par six à neuf couches. des cycles à cinq atomes de carbone sur les structures type oignon  résultant de l évolution thermique de nos nanodiamants ont été observés. ainsi le retour sp 3 sp 2 peut former des structures en couche concentrique type fullerène et non de le graphite comme le prévoit le classique diagramme d équilibre de le carbone. nos résultats ainsi que les résultats d autres auteurs nous conduisent à penser que la structure d équilibre de le carbone en hybridation sp 2 n est pas nécessairement le graphite plan mais une structure en coquilles concentriques structure type oignon.
termith-eval,test_chimie_98_0486235_tei,une famille originale de complexes hétérodinucléaires co ii  ln iii  synthèse et étude magnétostructurale. le complexe de le cobalt ii avec le 3 méthoxy 2 hydroxybenzaldéhyde l 2 co h 2 o 2 réagit avec les nitrates de lanthanides pour conduire à un complexe dinucléaire l 2 co h 2 o 2 ln no 3 3. une étude structurale par diffraction des rayons x a été réalisée sur le complexe l 2 co h 2 o 2 pr no 3 3. il cristallise dans le groupe d espace monoclinique p 21 c avec une maille élémentaire de dimension à 9 4832 11 å b 18 319 2 å c 14 6226 13 å et β 106 121 12  et quatre motifs par maille. le complexe l 2 co h 2 o 2 gd no 3 3 a fait l objet d une étude magnétique qui révèle que l interaction d échange entre les ions co 2 et gd 3 est ferromagnétique.
termith-eval,test_chimie_99_0124526_tei,structure cristalline sur monocristal de la zéolithe lia totalement échangée et déshydratée. la compréhension et l exploitation des capacités sélectives d adsorption et des propriétés catalytiques des zéolithes nécessitent une bonne connaissance de leurs caractéristiques structurales en particulier les dimensions des canaux et des cages le positionnement des cations échangeables et leurs interactions avec le squelette alumino silicaté. la présente étude a pour objet la détermination précise par diffraction x sur monocristal de la structure cristalline d une zéolithe lia totalement échangée et déshydratée de composition chimique li 96 al 96 si 96 o 384 cette étude montre que l échange cationique déforme le squelette en particulier à le niveau des angles reliant les tétraèdres alo 4 et sio 4.
termith-eval,test_chimie_99_0176593_tei,caractérisation structurale d asphaltènes pétroliers par spectroscopie infrarouge irtf. application à la photo oxydation. les asphaltènes sont les fractions pétrolières les plus récalcitrantes à les agents naturels de dégradation et le rôle de la photo oxydation qui est l un de ces agents sur leur devenir est extrêmement mal connu. nous avons étudié dans ce travail les effets de la photo oxydation 5 et 11 mois sur l évolution d asphaltènes de dix bruts pétroliers d origines géographiques et géochimiques différentes. les spectres irtf des différents asphaltènes pétroliers présentent les mêmes caractéristiques sauf dans la région 1800 1600 cm 1 qui dépend de l état d oxydation de chaque asphaltène. pour mieux différencier et caractériser ces asphaltènes nous avons déterminé différents indices structuraux obtenus par intégration d aires de bandes irtf caractéristiques indices caractéristiques de l oxydation de l aromaticité de l aliphaticité de la ramification de le taux en groupement sulfoxyde de la longueur de chaînes de la teneur en ch aromatique et de la condensation. après photo oxydation des asphaltènes seuls les indices d oxydation et d aliphaticité montrent des variations significatives.
termith-eval,test_chimie_99_0197478_tei,origine moléculaire de l enroulement des lamelles cristallines de le poly fluorure de vinylidène  phase γ. les lamelles cristallines formant les sphérolites de la phase γ de le poly fluorure de vinylidène  γpvdf ont une forme originale elles sont enroulées en spirale et forment un rouleau de type parchemin dont le grand axe est parallèle à le rayon de le sphérolite. cette géométrie est expliquée dans la présente note par une différence de composition chimique des plis dans les faces de repliement opposées des lamelles cristallines. la différence de structure traduit la polarité de la structure cristalline de la phase γ et les contraintes géométriques imposées à les repliements.
termith-eval,test_chimie_99_0232104_tei,synthèse par broyage mécanique de cefe 4 sb 12 et des composés substitués cefe 3 5 ni 0 5 sb 12 et cefe 4 sb 11 te. le broyage mécanique permet de synthétiser des composés sous forme de poudre nanocristalline. dans le cas des composés thermoélectriques cette faible taille de grains peut conduire à une amélioration de le facteur de mérite par diminution de la conductivité thermique de réseau. nous présentons ici l application de cette technique à le cas de cefe 4 sb 12 composé de type skuttérudite dont les potentialités d application dans le domaine de la thermoélecricité ont été récemment mises en évidence et des composés substitués cefe 3 5 ni 0 5 sb 12 et cefe 4 sb 11 te.
termith-eval,test_chimie_99_0232110_tei,diagramme de phases lino 3 kno 3. le diagramme de phases de le système li k no 3 a été déterminé en utilisant la technique des analyses thermiques directe et différentielle entre 323 et 630 k le système est caractérisé par une eutexie 58 mol kno 3 407 1 k  une péritexie à 412 1 k un palier dû à la transition solide solide de kno 3 à 403 1 k et un composé intermédiaire incongruent kli no 3 2 qui apparaît à 393 1 k et fond à 412 1 k ce composé présente deux transitions de phase à 402 1 et 406 1 k les nitrates de potassium et de lithium semblent posséder une miscihilité très faible ou nulle à l état solide.
termith-eval,test_chimie_99_0234521_tei,comportement chimique de quelques atomes de rutherfordium rf z 104 et dubnium db z 105 produits à orsay. les isotopes 261 rf et 262 db ont été produits par irradiation de 248 cm par des ions 18 o et 19 f respectivement à l aide de l accélérateur mp tandem d orsay et isolés en milieu hf grâce à le dispositif rachel. une nouvelle voie de synthèse de le radionucléide 262 db a été mise en œuvre.
termith-eval,test_chimie_99_0339718_tei,hydrogénation de le dioxyde de carbone en méthanol en présence de catalyseurs à base de molybdène. l hydrogénation de le dioxyde de carbone en méthanol est effectuée en présence de catalyseurs à base de molybdène supportés ou massiques préparés par imprégnation ou coprécipitation. en effet selon l état redox de cet élément on peut avoir une complexation activation de le co 2 qui couplée à l activation de l hydrogène peut permettre la synthèse de méthanol. l étude comparative des systèmes molybdène support cérine charbon actif oxyde de titane oxyde ou carbonate de zinc  a montré que l oxyde de zinc augmentait sensiblement la sélectivité en méthanol. en revanche la vitesse et la sélectivité de la réaction co 2 h 2 ne sont pas très dépendantes d additifs tels que des éléments alcalins ni des procédures d activation comportement inverse de celui observé dans la réaction co h 2. cela montre bien que les étapes déterminantes des deux réactions nc sont pas identiques. la stabilisation de l état redox de le molybdène et l activation de l hydrogène sont favorisées par l association de le cuivre à le molybdène et ou à l oxyde de zinc. il en résulte bien une vitesse de formation de le méthanol plus importante. la formation d entités mixtes cu mox  favorisée par zno est confirmée par les caractérisations massiques drx rtp et de surface xps.
termith-eval,test_chimie_99_0374841_tei,un nouveau polytungstate as 4 w 20 o 72 h 2 o 2 12 formé par la réunion de deux unités α b asw 9 o 33 par deux ponts originaux o 2 asowo 4 h 2 o. l hétéropolytungstate as 4 w 20 o 72 h 2 o 2 12 est obtenu par la réaction d un excès de tungstate de sodium sur une solution de as 2 w 8 o 30 oh  7 qui contient un assemblage de huit octaèdres préfigurant le groupe β b asw 9. cependant la réaction conduit à la formation d une espèce contenant deux unités α b asw 9 o 33 qui sont reliées par deux ponts originaux o 2 as o w h 2 o o 4 constitués d une pyramide aso 3 et d un octaèdre wo 5 h 2 o partageant un sommet. le composé décrit cristallise avec une maille triclinique centrée dont les paramètres sont a 11 194 3  b 13 516 3  c 19 533 3 å α 77 99 1  3 77 1  γ 67 43 2  v 2603 1 å 3.
termith-eval,test_chimie_99_0419603_tei,étude cristallographique et par résonance magnétique nucléaire de le bismuthooctadécatungstate na 7 h 2 biw 18 o 60 24 h 2 o. l hétéropolytungstate hnbiw 18 o 60  9 n  cristallise dans un groupe d espace rhomboédrique r 3 a 19 575 4  c 18 112 4 å avec sept cations sodium identifiés par diffraction des rayons x cela implique la présence de deux protons afin d assurer l électroneutralité d où la formule na 7 h 2 biw 18 o 60 24 h 2 o les deux moitiés w 9 o 30 sont reliées par un centre d inversion. la résonance magnétique nucléaire de le proton avec le triiodométhane comme étalon a permis de retrouver ces deux protons par molécule de bismuthooctadécatungstate. ils résonnent à 6 18 ppm par rapport à le tétraméthylsilane.
termith-eval,test_chimie_99_0434755_tei,description de défauts paramagnétiques fondamentaux observés dans une argile brute un indice pour la datation par rpe de céramiques anciennes. deux défauts paramagnétiques le centre peroxy et le centre e  sont mis en évidence dans une argile brute en utilisant la résonance paramagnétique électronique. la raie intense due à les oxydes de fer observée dans le spectre rpe de l argile a pu être en grande partie éliminée ce qui a permis l émergence des signaux dus à ces centres. ces derniers associés à le silicium sont localisés soit dans le quartz contenu dans l argile brute soit dans la matrice de l argile. corrigés par un effet thermique et sensibles à le rayonnement radioactif ils pourraient être utilisés pour la datation par rpe des céramiques anciennes.
termith-eval,test_linguistique_08_0265302_tei,termes techniques et marqueurs d argumentation pour débusquer l argumentation cachée dans les articles de recherche. les articles de recherche présentent les résultats d une expérience qui modifie l état de la connaissance dans le domaine concerné. le lecteur néophyte a tendance à considérer qu il s agit d une simple description et à passer à côté de l argumentation à le cours de laquelle le scientifique cherche à convaincre ses pairs de l innovation et de l originalité présentées dans l article et de le bien fondé de sa démarche tout en respectant la tradition scientifique dans laquelle il s insère. ces propriétés spécifiques de le discours scientifique peuvent s avérer un obstacle supplémentaire à la compréhension surtout lorsqu il s agit d un article en langue étrangère. c est pourquoi il peut être utile d incorporer dans l enseignement des langues de spécialité une sensibilisation à les marqueurs linguistiques terminologiques et argumentatifs  qui permettent de dépister le développement de cette rhétorique. les auteurs s appuient sur deux articles dans le domaine de la microbiologie.
termith-eval,test_linguistique_08_0265420_tei,milieux professionnels et fasp médicale de l autre côté de le miroir. le but de cette étude est de mettre en lumière les relations entre les milieux professionnels de la médecine et la fiction à substrat professionnel fasp et de les analyser. il est convenu de dire que les medical thrillers dont les caractéristiques principales en tant que sous groupe générique de la fasp sont présentées ici offrent un reflet plutôt fidèle de le monde de la médecine l auteur montre l intégration en profondeur de le discours et des pratiques de la communauté médicale dans la trame paratextuelle narrative et linguistique des romans à suspense à dominante médicale. afin de mieux comprendre les relations entre l environnement professionnel et l oeuvre de fiction l auteur présente les résultats d un questionnaire soumis à quatre médecins devenus écrivains r cook m palmer l r robinson et t gerritsen.
termith-eval,test_linguistique_09_0344044_tei,les mission statements des grandes entreprises cotées en bourse prélude à l étude d un genre particulier de textes dictés par plusieurs contextes. le but de cette étude préliminaire des déclarations officielles des entreprises quant à leurs valeurs principes croyances ou mission principale est de prendre la mesure de l influence des contextes sur ces textes à travers l analyse des choix lexicaux et linguistiques. les entreprises retenues entrent dans la composition de deux indices boursiers prestigieux le dow jones industrial average djia 30 et le ft 30 financial times. il s agit d abord de déterminer ce qu il faut entendre par mission statement et d examiner s il y a lieu de parler d un genre particulier. l analyse de le corpus part de données chiffrées d ordre lexical puis replace les éléments de le lexique dans leur contexte textuel immédiat pour élargir ensuite l horizon à d autres contextes contexte d activité contexte économique social et idéologique contexte de la mondialisation. c est en cherchant au delà des textes les motivations profondes qui les ont inspirés que l on parvient à les lire comme la réponse à les préoccupations des citoyens à une époque donnée d où la nécessité de considérer les axes diachronique et synchronique.
termith-eval,test_linguistique_09_0344047_tei,évaluation de le potentiel d apprentissage d une tâche médiatisée. quand elle s inscrit dans le modèle de la recherche développement la conception de tâches médiatisées pour l apprentissage de l anglais gagne à être étayée par des connaissances théoriques existantes émanant en particulier de la psycholinguistique. la conception fournit l occasion de tester une hypothèse et de lui donner corps dans un scénario pédagogique. toutefois le cycle de la recherche développement n est complet que lorsque le potentiel d apprentissage est évalué par rapport à les hypothèses initiales. cette dernière étape est déterminante pour vérifier d une part la validité de le cadre théorique et d autre part l adéquation de la proposition pédagogique à les besoins des apprenants. ce processus en trois temps choix théoriques conception et évaluation est illustré dans cet article qui vise à montrer comment une théorie psycholinguistique celle de l output compréhensible émise par swain a nourri l écriture de le scénario pédagogique de virtual cabinet un site d apprentissage pour développer la compréhension de l anglais oral et a fourni les critères pour son évaluation.
termith-eval,test_linguistique_09_0345265_tei,l impact de l utilisation de le portfolio européen des langues en cycle de licence de sciences économiques. le conseil de l europe et les enseignants qui utilisent le portfolio européen des langues pel avec leurs étudiants font le pari que cet instrument favorisera l autonomie et accroîtra la motivation. quel est le point de vue des utilisateurs étudiants. cette étude se propose de l examiner à le moyen d un questionnaire portant sur l ergonomie de le pel les changements qu il induit dans leur apprentissage par son utilisation en semi autonomie la valorisation de leur multilinguisme leur intérêt pour le pel et les effets de le pel sur leur motivation. le questionnaire a été administré en 2004 2005 à 158 étudiants de cycle de licence de sciences économiques 1 e et 2 e années. son analyse suggère une réaction mitigée des étudiants face à le pel plutôt favorables à son introduction mais il reste globalement sans effet sur leur motivation.
termith-eval,test_linguistique_10_0051839_tei,le xénisme français laïcité en finnois contemporain l emprunt et sa glose. le mot français laïcité apparaît de plus en plus souvent dans les médias et les conversations courantes en finlande. les différentes équivalences sémantiques employées par les locuteurs pour rendre ce xénisme compréhensible à les finlandais montrent la difficulté de saisir le concept de laïcité. l observation des réactions des locuteurs aussi bien envers ce concept qu envers le mot français nous incite à nous interroger sur l avenir de ce mot en finnois.
termith-eval,test_linguistique_10_0057827_tei,l évolution des conditionnelles en arabe égyptien contemporain. cet article tend à montrer comment à partir d oeuvres littéraires de le début de le siècle passé à le début de le nouveau oeuvres rédigées tout ou partie en arabe égyptien les systèmes hypothétiques propres à cette variété d arabe ont évolué selon un double processus synonymisation des opérateurs de la conditionnelle  in  iza et law et parallèlement recul très marqué de iza et désuétude de in à le profit de l emploi quasi exclusif de law pour l expression de la conditionnelle. ce dernier joue alors le même rôle que notre si français ou que le if anglais l indication de le cadre conditionnel de l énoncé sans présupposer de son identitié potentielle ou irréelle présente ou passée. la distinction entre ces différents ordres de la conditionnelle relève désormais nécessairement de syntaxes verbales contrastives bien loin des modèles classiques.
termith-eval,test_linguistique_10_0146691_tei,grammaticalisation lexicalisation et degrammaticalisation des relations complexes. prenant comme point de départ la grammaticalisation l article vise à éclaircir les rapports complexes qu entretiennent la grammaticalisation la lexicalisation et la dégrammaticalisation. on envisage pour cela les points de rencontre et de séparation entre ces différents processus ainsi que certaines des approches qui tentent de les appréhender et dont les divergences tiennent souvent à la pluralité des perspectives et des critères d analyse. il est montré que les relations entre les trois processus ne se réduisent assurément pas à une simple opposition et ou recouvrement.
termith-eval,test_linguistique_10_0146946_tei,le défigement un nouvel indicateur des marques de le figement. cet article tente de montrer que l étude de le défigement représente une source d informations sur le figement en postulant que la déformation discursive préserve certaines marques de fixité. celles ci s observent à l intérieur et à l extérieur de la formule figée. la morpholexicalité la structuration syntaxique l effet paronomastique et le contexte participent conjointement ou non à re former l expression figée et à en actualiser le sens ainsi si la définition de le figement repose avant tout sur des propriétés morphologiques syntaxiques et sémantiques qui ressortissent prioritairement de la langue elle gagne à être complétée par les propriétés discursives relevant de l observation de le défigement.
termith-eval,test_linguistique_10_0147025_tei,changement dans le lexique changement de le lexique lexicalisation figement catachrèse. cet article se donne pour objectif de cerner les acceptions des trois termes lexicalisation figement et catachrèse comme processus et comme résultat de le processus et sous le terme générique de phénomène de fixation  de préciser leurs points communs et leurs divergences. après avoir défini les termes et présenté le panorama de leur exploitation dans les sciences de le langage on s intéresse à ce qui rapproche les notions en choisissant trois axes phénomènes de fixation et lexique phénomènes de fixation et créativité phénomènes de fixation et discours. enfin on propose une application des trois phénomènes de fixation à le cas particulier des noms propres.
termith-eval,test_linguistique_10_0210002_tei,l identification des menaces dans le discours militaire argentin de la revista militar 1996 2002. il s agit d étudier la conception de la menace véhiculée par les militaires argentins entre 1996 et 2002 à partir de l analyse de la revista militer. à partir de le sens et de l emploi de le terme amenaza s  menace s  on montrera que l approche militaire de la menace tend à recycler des cadres de pensée et des doctrines hérités de le passé la caractérisation extensive et décloisonnée des menaces a pour point d ancrage une menace pour l ordre et les valeurs et pour corollaire la réactualisation d un savoir faire militaire en matière de sécurité tout particulièrement en matière de renseignement.
termith-eval,test_linguistique_10_0210765_tei,ancien régime. pour une approche comparatiste de le vocabulaire historiographique. l histoire de l expression ancien régime forgée à le moment même où ce qu elle désigne et constitue peut être en partie disparaît est désormais bien connue. mais cette historicisation qui souligne les effets de la révolution de le discours sur le cours de la révolution n est que l une des opérations d objectivation à laquelle il faut la soumettre. cet article entend évoquer à travers l analyse des formes de circulation internationale de l expression ancien régime quelques uns des enjeux historiographiques et des inconscients académiques que son usage recouvre.
termith-eval,test_linguistique_10_0210766_tei,une démocratie illégitime. la década infame dans le discours populiste argentin. en argentine les années trente sont connues sous le nom de década infame. cette désignation péjorative est une construction sémantique dont la fonction a été par contraste de présenter le régime populiste de perón comme un âge d or. les ressemblances entre ces deux périodes notamment l instabilité économique et la fragilité des institutions pluralistes ont été occultées par le chrononyme qui les a départagées en faveur de la décennie péroniste et dont les effets sur la structure de l espace public argentin sont encore perceptibles.
termith-eval,test_linguistique_10_0210799_tei,quand le 11 septembre s approprie le onze septembre. entre dérive métonymique et antonomase. la circulation de l expression 11 septembre pour dénommer le coup d état de le 11 septembre 1973 à le chili et les attentats de le 11 mars 2004 en espagne ont abouti à un changement de statut sémantique. par dérive métonymique et par antonomase l expression s approprie l espace symbolique de le onze septembre. sa nomination par leur seule date renvoie à l incapacité des journalistes de trouver une autre dénomination pertinente.
termith-eval,test_linguistique_11_0057593_tei,les proverbes un figement de le deuxième type. contrairement à les idées reçues le figement n est pas un trait caractéristique de la catégorie des proverbes les critères généralement invoqués à l appui de la thèse de le figement ne sont pas satisfaits par les proverbes. ceux ci sont en revanche formés sur un nombre limité de moules rythmiques fixes dans un état donné d une langue et qui représentent une métrique naturelle. ces moules varient diachroniquement avec les états de la langue de même que les structures syntaxiques et le lexique des formes sentencieuses en général.
termith-eval,test_linguistique_11_0057861_tei,sur les constructions causatives figées de le français. les dictionnaires et les glossaires de le français recensent environ 150 expressions causatives figés ou semi figées de le genre léa fait bouillir la marmite  paul a fait avaler la pilule à léa  luc s est fait enguirlander  etc. l analyse syntaxique permet de dégager trois grands types de construction pour ces phrases identique à ceux des phrases libres à savoir  la construction direct  léa fait cuire le poulet léa fait bouillir la marmite  la construction à groupe verbale coalescent faire v inf dans laquelle le sujet de la phrase élémentaire est représenté par un complément en à  léa a fait boire le sirop à luc léa a fait avaler la pilule à paul  la construction à groupe verbale coalescent faire v inf dans laquelle le sujet de la phrase élémentaire est représenté par un complément en par  léa a fait traduire le texte par paul paul s est fait enguirlander par léa  l a montre les spécificités des phrases figées par rapport à les phrases libres.
termith-eval,test_linguistique_11_0057862_tei,expression compositionnelle ou locution ça craint vs ça barde. l une des propriétés de le pronom ça  à savoir sa valeur impersonnelle se constate quand il commute avec le pronom impersonnel il  comme support de verbes météorologiques  il gèle vs ça gèle . or au delà de cette fonction impersonnelle ce déictique semble responsable de le caractère figé de certaines expressions en exerçant sur elles des contraintes multiples. les expressions sont alors qualifiées de figées car elles sont peu susceptibles de variations syntaxiques. mais comme tous les verbes ne sont pas contraints de la même manière on peut parler de semi figement. il apparaît en effet que beaucoup d expressions dites idiomatiques restent compositionnelles. dans cet article l a se propose d analyser et de comparer différents exemples tels que ça va ça y est ça rime à rien ça craint ça barde.
termith-eval,test_linguistique_11_0057863_tei,pédaler dans la semoule. approches des constructions verbales figées de structure v dans gn. si l application des critères syntaxiques traditionnels permet d identifier des structures dans lesquelles le verbe vient sous catégoriser la préposition elle ne permet pas en retour de distinguer les différents types de constructions verbales construction à verbe ou nom prédicatifs constructions verbales figées. notre contribution vise d une part à pallier ce manque en proposant les critères syntaxiques propres à l identification de chaque construction verbale d autre part à avancer dans l étude lexicale et sémantique des constructions verbales figées en dans telle que pédaler dans la semoule  et enfin à mettre en avant les implications que peut avoir le figement sur des activités telles que la traduction l enseignement le traitement automatique.
termith-eval,test_linguistique_11_0058884_tei,le problème central de le figement est le semi figement. cet article dresse le bilan de tous les critères de figement invoqués dans la littérature ceux généralement admis comme l opacité sémantique ex. porter le chapeau et d autres moins souvent appliqués tels la défectivité de certaines formes l infraction des restrictions sélectionnelles ou des contraintes lexicales et morpho syntaxiques ex. avoir avalé son parapluie. on y analyse de plus près l idée que le figement est un concept graduel pour insister sur le fait 1 que le véritable problème ne correspond pas à la limite supérieure mais à la limite inférieure de le figement c est à dire les expressions semi figées 2  que le problème provient de ce que le figement est un phénomène à la fois synchronique et diachronique et 3 que la gradation est due à ce que les critères peuvent s appliquer simultanément ou séparément. la présentation d une base de données qui réunit environ 45000 expressions figées de le français commun et des variétés belge française québécoise et suisse appelée bfqs permet de discuter différents cas de figure de figement et de semi figement.
termith-eval,test_linguistique_11_0058885_tei,phonologie et construction syntaxique la liaison un test de cohésion et de figement syntaxique. en phonologie générative et post générative la liaison est un phénomène strictement phonologique. cette position jamais défendue auparavant apparaît extrêmement réductrice. dans une approche de type grammaire de construction bybee 2000  un grand nombre de liaisons dites obligatoires relèvent de l organisation complexe de le lexique et de la morphologie. dans le modèle présenté trois dynamiques agissent contradictoirement simplifier par allègement les codas syllabiques finales conserver les finales portant une indication de genre de nombre ou de personne et assurant le liage interne des constructions enclitiques  intégrer la forme visuelle de le mot en contexte. c est l équilibre synchroniquement complexe et diachroniquement instable entre ces trois dynamiques qui explique le caractère hétérogène composite et variable de la liaison en français contemporain. outre son caractère explicatif une telle approche permet d arborer la phénoménologie de la liaison dans un cadre renouvelé et conduit à traiter la question globale des consonnes finales qu elles soient fixes ou de liaison dans une perspective cognitive où vision phonologie morphologie syntaxe et sémantique interagissent.
termith-eval,test_linguistique_11_0078430_tei,verbes causatifs discours causaux et coréférence événementielle. l a s intéresse à les discours causaux comprenant deux phrases l une décrivant la cause l autre décrivant l effet par le trébuchement d un verbe causatif. il distingue les verbes causatifs psychologiques qui admettent un sujet référent soit à un évènement soit à un fait soit à une entité et les verbes causatifs non psychologiques qui admettent un sujet référent à une entité. il aborde ainsi les relations de coréférence événementielle.
termith-eval,test_linguistique_11_0079309_tei,les sémantèmes de causation en français. le but de cette étude est strictement et purement linguistique une description de le sens langagier causer  ou plus précisément de le ou des sens de le verbe causer en français ainsi que des verbes exprimant une causation. l a commence son article par une étude psycho philosophique et logico psychologique de le concept de causation.
termith-eval,test_linguistique_11_0080461_tei,les quatre questions de tinbergen. l a présente un article fondateur de nicolaus tinbergen publié en 1963 qui s intitule on aims and methods of ethology. ce dernier a écrit cet article pour clarifier la nature de questions posées par l éthologie. il fait une brève étude de la causalité en éthologie et aborde l étude de le comportement animal et son évolution.
termith-eval,test_linguistique_11_0080462_tei,aperçu de l évolution des conceptions de la cause dans les sciences et particulièrement dans les sciences économiques. l a part de l affirmation de platon tout ce qui naît naît nécessairement d une cause. dans un premier temps l a fait quelques rappels généraux à le travers d une brève histoire de la notion de causalité pour dans un deuxième temps recentrer son propos sur les sciences sociales avant de se focaliser pour terminer sur la science économique sa propre discipline.
termith-eval,test_linguistique_11_0080463_tei,abduction et prise en charge énonciative de la causalité. l a traite quelques expressions de causalité trouvées à le travers de textes. il insiste sur quelques aspects en particulier sur la relation entre l abduction et la causalité d une part et d autre part la nécessaire prise en charge des relations causales par un énonciateur lorsqu on examine leur expression dans des textes. ainsi dans un premier temps l a reprécise la notion d abduction à le sens de pierce. ensuite il met en œuvre le raisonnement abductif sous jacent à un énoncé et opposé à des énoncés où la prise en charge énonciative est plus explicitement manifestée. enfin il insiste sur la construction d une relation causale telle que l on peut l observer à travers sa mise en texte.
termith-eval,test_linguistique_11_0080464_tei,la cause linguistique. l objectif est de fournir une définition de base de le concept linguistique de la cause en observant son expression. dans un premier temps l a se demande si un tel concept existe en langue. puis il part des formes de son expression principale et directe les verbes et les conjonctions de cause pour caractériser linguistiquement ce qui fonde une telle notion.
termith-eval,test_linguistique_11_0080465_tei,de la concession à la cause et de la cause à la condition. a quelle opération syntactico sémantique doit on relier le phénomène de permutation des arguments de le connecteur concessif. c est un des problèmes que veut résoudre l a il a recourt à la notion logique de contraposition. la contraposition jouant un rôle important dans la syntaxe et la sémantique d autres connecteurs que concessifs l a définit autour de cette notion un ensemble de régularités linguistiques liant les éléments de toute une classe de structures concessives causales et conditionnelles. enfin il explique son choix de décrire en syntaxe et en sémantique des phénomènes que beaucoup de linguistes rapportent à la logique ou à la structure de le monde.
termith-eval,test_linguistique_11_0104626_tei,argumentation et discours politique. peut on analyser le discours politique sans tenir compte de l argumentation. l objet d étude va ainsi de la parole professionnelle des politiciens à tous les discours qui traitent de la chose publique dans l espace public. c est dans cette perspective que l a explore l argumentation à travers divers travaux.
termith-eval,test_linguistique_11_0106457_tei,sémantique lexicale et langages de le politique. le paradoxe d un mariage difficile. l a réfléchit sur l apport de la sémantique lexicale à les langages de le politique dans les trente dernières années. cette jonction interdisciplinaire n ayant rien d évident il essaie d apporter un éclairage à cette problématique en passant par les champs lexicaux et la polysémie. il met ainsi en contraste une approche onomasiologique et semasiologique.
termith-eval,test_linguistique_11_0137725_tei,susciter le dialogue interculturel en ligne rôle et limites des tâches. dans cet article nous aborderons le rôle et les limites des tâches pour susciter et soutenir le dialogue interculturel entre groupes alloglottes à distance. cette problématique nous amène à formuler les questions suivantes en quoi les tâches proposées favorisent ou inhibent elles à le contraire les échanges interculturels. quels types d interactions permettent de forger la compétence interculturelle en ligne. comment scénariser ce type de situations dans le cadre de l apprentissage d une langue étrangère via internet. l analyse de quelques échanges s étant produits à le sein d un projet mettant en relation des groupes allophones  le français en première ligne  apportera des éléments de réponse à cette problématique peu documentée jusqu à présent.
termith-eval,test_linguistique_11_0139729_tei,communication électronique et construction de compétences en langue autre hors contexte pédagogique pratiques et représentations éléments de réflexion. a partir de données diversifiées tant à le plan des pratiques que des représentations ce texte propose plusieurs pistes de réflexions concernant la construction de compétences en français par des alloglottes dans le cadre de situations de communication électronique exolingues hors contexte pédagogique et qui sont elles mêmes diversifiées correspondant à divers dispositifs. ces pistes à l interface de la didactique et de la sociolinguistique ont une visée essentiellement exploratoire mais aboutissent déjà à quelques résultats intéressants.
termith-eval,test_linguistique_11_0139731_tei,échanges exolingues et interculturalité dans un environnement informatisé plurilingue. comment les compétences interculturelles s expriment elles dans un environnement de formation sur internet réunissant plusieurs groupes d apprenants de différents pays et utilisant plusieurs langues romanes. dans la pratique de l intercompréhension plurilingue c est à dire quand chacun comprend les langues des autres et se fait comprendre dans sa ses première s langue s  nous identifions dans cet article plusieurs types de manifestations interculturelles en référence à les travaux sur la communication exolingue et à la place et à le rôle de l interculturalité dans la perspective actionnelle de le cadre européen commun de référence. cette catégorisation est ensuite exemplifiée et discutée en prenant appui sur des extraits choisis d interactions en ligne tirés de la plateforme galanet.
termith-eval,test_linguistique_11_0173551_tei,fonctionnements sociolinguistiques de la dénomination toponymique toponymes. instruments et enjeux. on cherche dans cette contribution à cerner dans sa dimension sociolinguistique la dénomination toponymique et à illustrer la modalité dans laquelle la fonction identitaire prend ostensiblement le pas sur la fonction de localisation il est alors question de revendiquer l inscription de le toponyme dans une communauté linguistique et ou culturelle nationale régionale. dans cette perspective on envisage deux cas de conflit d ordre toponymique où il est question d affirmation identitaire. le premier concerne l aventure politico médiatique de le toponyme septimanie que georges frêche nouveau président de le conseil régional a tenté d imposer en 2005 à l opinion publique régionale comme substitut de le toponyme en vigueur depuis 1960 languedoc roussillon et de l opposition manifestée contre ce qui est apparu comme un coup de force pour une bonne partie de cette opinion via la presse locale. on observe un deuxième cas de conflit à propos d une communauté autonome de l état espagnol la galice en situation de normalisation sociolinguistique et donc toponymique de sa langue propre  le galicien.
termith-eval,test_linguistique_11_0173553_tei,la turquie terre eurasiatique et république bicéphale. ankara et istanbul dans la presse française toponymes. instruments et enjeux. l analyse des toponymes ankara et istanbul dans les gros titres de la presse quotidienne française entre le 1 er mai et le 31 décembre 2004 permet de mettre à le jour des différences significatives concernant l emploi des désignants référentiels ou métonymiques et les représentations liées à l évocation des deux principales villes turques. elle révèle que les effets et les enjeux de l émergence de ces noms dans le corpus sont asymétriques et que l actualisation récurrente et spécifique d ankara contribue à l éloignement de la turquie dans l imaginaire européen.
termith-eval,test_linguistique_11_0173555_tei,le discours patronal un exemple de discours économique. pour répondre à la question de savoir si le discours patronal constitue un exemple de discours économique nous devons d abord poser l hypothèse qu il existe un genre le discours économique  qui possède certaines caractéristiques linguistiques auxquelles nous pourrons comparer celles de le discours patronal. après avoir présenté les travaux existant sur le discours économique nous nous demandons comment les discours des grands patrons français se situent sur le plan thématique dans quelle mesure ils expriment une vision de l économie si cette vision est explicitée et à quels experts économiques ils renvoient.
termith-eval,test_linguistique_11_0182811_tei,prédicats et quasi prédicats sémantiques dans une perspective lexicographique. la notion de prédicat sémantique permet de distinguer deux classes de sens lexicaux ou sémantèmes 1 les prédicats qui tous dénotent des faits à le sens le plus large évènements actions activités états caractéristiques relations etc  et 2 les noms sémantiques qui dénotent des entités à le sens large êtres vivants objets physiques substances etc. nous nous intéressons tout particulièrement à le fait qu il existe une troisième classe de sémantèmes ni prédicats véritables ni noms sémantiques il s agit des quasi prédicats. ces derniers dénotent tout comme les noms sémantiques des entités et non des faits. cependant comme les prédicats ils ne peuvent être modélisés sans tenir compte de positions actancielles qu ils contrôlent. l ensemble des quasi prédicats d une langue est très hétérogène et chaque type de quasi prédicat pose ses propres problèmes à le niveau de la modélisation. nous examinons différents types de quasi prédicats présents dans les langues en adoptant une perspective lexicographique. plus précisément nous nous situons dans le cadre de la lexicologie explicative et combinatoire en empruntant nombre de nos illustrations à les données de la base lexicale dico des dérivations sémantiques et collocations de le français ainsi qu à les données publiées dans le lexique actif de le français.
termith-eval,test_linguistique_11_0197418_tei,contribution à une linguistique néo saussurienne des genres de la parole 1  une grammaire de le morphème on. cet article constituant un triptyque avec ceux de denise malrieu et de créola thénault entend contribuer à le programme épistémologique qui se précise aujourd hui à la lecture des textes saussuriens originaux le programme d une linguistique double unissant dans un lien de complémentarité linguistique de la langue et linguistique de la parole. dans cette perspective le présent article propose une grammaire différentielle de le morphème on l article de denise malrieu analyse l actualisation des traits de cette grammaire différentielle dans un corpus de textes de marguerite duras et stendhal linguistique de la parole et dont l article de créola thénault étudie la traduction en roumain dans un sous ensemble de le corpus de denise malrieu linguistique de la parole.
termith-eval,test_linguistique_11_0197419_tei,contribution à une linguistique néo saussurienne des genres de la parole 2  analyse des valeurs d indexicalité interlocutoire de on selon les genres textuels. l article cherche à opérationnaliser les propositions programmatiques de bakhtine sur la notion de genre textuel et ses apports à une linguistique de la parole. s appuyant sur une grammaire différentielle de on proposée dans l article de s bouquet la démarche consiste à projeter cette arborescence sur un corpus de textes eux mêmes définis par une hiérarchie de traits différentiels de genres articles de presse de différents genres entretiens discussions romans. la méthodologie mise en oeuvre est celle de le balisage tei xml des séquences et discours rapportés. les résultats exposés ici montrent que les genres situation interlocutive et normativité des modes d adresse influencent fortement les différents types d indexicalité interlocutoire qu il existe de grosses différences entre genres oraux comme des différences diachroniques entre la chartreuse de parme et les romans de duras. sont discutés plus en détail les problèmes de l accessibilité de la valeur référentielle selon les modalités d interlocution dans l indexicalité interlocutoire de le locuteur amplifié. ce travail oriente vers une définition de traits de genre qui soit autorisent ou interdisent certaines valeurs indexicales soit gèrent des héritages de valeurs soit favorisent l accessibilité de certaines valeurs. ces traits sont de portée variable certains portant sur le texte entier type de narrateur  d autres sur des séquences brèves modalité interlocutive variable à l intérieur d une séquence de discours direct par exemple.
termith-eval,test_linguistique_11_0201948_tei,l emploi exclamatif de comme proforme qu de manière. cette étude est consacrée à comme exclamatif en regard des autres morphèmes qu exclamatifs section 1 d une part des autres proformes qu d autre part section 2. l exclamation peut être provoquée par un degré anormalement élevé ou par une manière de faire inhabituelle et ou inattendue. dans ce dernier cas les propriétés syntaxico sémantiques de le prédicat verbal auquel comme est incident contraignent les interprétations possibles de le morphème section 3.
termith-eval,test_linguistique_11_0201949_tei,le mot comme problèmes et perspectives en synchronie. cette contribution constitue une synthèse des principaux problèmes théoriques liés à l étude de le morphème comme. dans un premier temps nous nous interrogeons sur les réponses apportées dans la littérature à le problème de la classification de le mot à le sein des catégories morphosyntaxiques traditionnelles puis nous examinons les études ayant choisi de s affranchir ou à le moins de s écarter de ce problème en adoptant une lecture polysémique de le morphème. enfin nous rendons compte des travaux attachés à l analogie ou à la comparaison qui inscrivent le morphème dans des systèmes fonctionnels beaucoup plus vastes. nous concluons en évoquant quelques scénarios possibles de la recherche sur le morphème comme.
termith-eval,test_linguistique_11_0204053_tei,ellipses dans les constructions comparatives en comme. la construction comparative en comme présente tantôt une phrase pleine tantôt une phrase elliptique mais cette variation interne ne change ni sa distribution fonctions et placements dans la phrase matrice ni sa sémantique. bien qu elles connaissent des contraintes de parallélisme syntaxiques et sémantiques similaires les phrases elliptiques des constructions comparatives montrent des propriétés distinctes de celles des constructions coordonnées. enfin contre une approche par copie et effacement qui se révèle inadéquate nous montrons que les contraintes liées à la résolution de l ellipse nécessitent un traitement qui dissocie les informations fonctionnelles catégorielles et sémantiques et qui autorise des syntagmes phrastiques constitués de syntagmes fragmentaires aboutissant ainsi à la linéarisation requise.
termith-eval,test_linguistique_11_0204054_tei,un adverbe disparu cumfaitement. il s agit dans un premier temps d étudier un terme dont l existence s est limitée à l ancien français. formé à partir de comme il apparaît en français à la même époque que comment mais ne connaît qu un nombre bien plus restreint d emplois. de fait cette contemporanéité avec cet adverbe ajoutée à une certaine redondance de l expression de la manière ainsi qu à une existence limitée dans le temps en font un terme intéressant à plus d un titre. dès lors resitué dans le cadre de l évolution de le microsystème qu il forme avec comment des éléments apparaissent qui semblent susceptibles d informer à la fois le point de vue guillaumien de la diachronie des synchronies et le problème théorique de la disparition des formes linguistiques.
termith-eval,test_linguistique_11_0218968_tei,l envers de le décor le discours d une firme transnationale d équipement de loisirs. le cas d intrawest. à l heure d un accroissement constant des flux touristiques dans les pays industrialisés cet article vise à analyser le discours marketing d une firme transnationale nord américaine d équipement de loisirs intrawest entreprise canadienne fondée en 1976. son activité principale fut en premier lieu le développement immobilier elle est aujourd hui une des entreprises dominantes dans le développement touristique en particulier en montagne dans des stations telles que whistler blackcomb tremblant copper mountain mammoth sur le territoire américain. elle a également ouvert un village dans la station savoyarde des arcs baptisé arc 1950. l approche retenue pour cette analyse articule la langue le discours et la culture et intègre la dimension esthétique. en effet l analyse de le discours construit autour de réalisations architecturales particulièrement en ce qui concerne l architecture commerciale peut révéler les grands principes qui gouvernent une société et sont reconnus par tous comme tels.
termith-eval,test_linguistique_11_0218974_tei,proximité et distance intratextuelles deux concepts clés expliquant les phénomènes de reformulation en sciences humaines. une reformulation se définit comme la modification d une première formulation. deux segments sont mis en relation généralement par un introducteur. le segment reformulé se comprend généralement comme un doublon informationnel de le premier segment. cette équivalence correspond d ailleurs à l instruction sémantique véhiculée par certains introducteurs. il s avère toutefois qu il n existe pas de vrais synonymes en langue. l étude se fonde sur un corpus d anglais contemporain relevant des sciences humaines sociologie psychologie linguistique histoire. les concepts de proximité et distance permettent d évaluer l écart existant entre les segments. cet examen cherche plus précisément à déterminer dans quelle mesure les instructions de l introducteur indiquant une proximité sémantique  de même que les contenus propositionnels pouvant présenter un fort écart une forte distance sur le plan informationnel interviennent dans l interprétation. nous examinons enfin la fonction pragmatique des reformulations et précisons leur rôle dans l économie discursive.
termith-eval,test_linguistique_11_0218975_tei,l évaluation en langues à l entrée de la fonction publique en france et à le canada. cet article se propose de comparer les modalités de l épreuve de langue à les concours d accès à la fonction publique en france et à le canada. concernant la france l étude concerne les concours des fonctions publiques d état et territoriale. une typologie des épreuves laisse apparaître un nombre restreint de types d épreuves dominées à l écrit comme à l oral par la version accompagnée voire remplacée à l oral par une conversation. ceci reflète une organisation des épreuves extrêmement décentralisée. les besoins en langues sont rarement envisagés par poste ils le sont plutôt par corps. à le canada l évaluation de le niveau de compétence dans la seconde langue officielle vient d être revue. les candidats sont évalués en fonction d un référentiel qui pallie certains points problématiques de le référentiel établi par le conseil de l europe le cadre européen commun de référence cecr  comme par exemple la place des langues de spécialité. les besoins en langues par postes sont analysés grâce à ce référentiel. nous proposons enfin quelques pistes pour améliorer la validité des épreuves de langues à les concours administratifs en france.
termith-eval,test_linguistique_11_0251500_tei,la pauvreté multidimensionnelle. la dynamique sémantique dans le discours de la banque mondiale. l analyse conceptuelle de la pauvreté telle que présentée dans le discours des organisations internationales plus particulièrement la banque mondiale se révèle compatible avec les politiques de ces mêmes organisations. l affirmation de le caractère multidimensionnel de la pauvreté permet de reléguer à l arrière plan la question de le revenu et d éviter une analyse de ses causes structurelles. les mécanismes discursifs utilisés sont l introduction de termes nouveaux à le sens technique gouvernance stakeholders  et la redéfinition de concepts existants développement protection sociale . la stratégie de réduction de la pauvreté ainsi définie se présente comme un thème consensuel ce qui lui permet d échapper à une évaluation critique des politiques imposées.
termith-eval,test_linguistique_11_0251515_tei,stéréotype emblème mythe. sémiotisation médiatique et figement représentationnel. la réflexion proposée concerne trois modalités de sémiotisation le stéréotype l emblème le mythe dont les médias sont les principaux pourvoyeurs. il s agit de trois types de figement représentationnel qui opèrent selon deux ordres de cognition sociale la catégorisation stéréotypage et la symbolisation emblématisation mythification. pour reprendre la qualification de roland barthes dans mythologies il y a bien dans les trois cas une parole dépolitisée. on peut également parler d avatars médiaculturels  éric macé qui sont selon des caractéristiques propres autant d indicateurs de premier choix pour l observation des tendances lourdes d un imaginaire ethno socioculturel donné et de la société avec laquelle il est en interaction.
termith-eval,test_linguistique_11_0255099_tei,langue de le droit et harmonisation terminologique multilingue l exemple de lexalp. la question de la sélection des termes et celle de l harmonisation figurent parmi les problèmes classiques de la terminologie. le cadre multilingue de le projet lexalp adossé sur la convention alpine conduit à reposer ces questions à partir des problèmes posés par la constitution d une base terminologique intégrant quatre langues français allemand italien et slovène et visant à harmoniser la terminologie juridique utile à l aménagement et à la protection de l arc alpin. l article montre que la notion de terminologie juridique doit être envisagée sur plusieurs plans celui des concepts proprement juridiques celui de termes issus des vocabulaires techniques scientifiques mais ayant des implications juridiques celui enfin des termes empruntés à le lexique commun mais devant être spécifiés juridiquement. le processus d harmonisation décrit dans la deuxième partie de l article est présenté comme ayant une influence directe sur le traitement terminologique l harmonisation oblige en effet à préciser les concepts et conduit parfois aussi à des compromis en fonction des enjeux institutionnels et politiques. l établissement de la terminologie juridique nécessaire à le projet intègre donc nécessairement une dimension pragmatique et institutionnelle.
termith-eval,test_linguistique_11_0255101_tei,décrire et prescrire l harmonisation de la terminologie juridique multilingue. dans cet article nous présentons un point de vue sur le projet interreg lexalp relatif à l harmonisation de la terminologie juridique dans les quatre langues de la convention alpine italien français slovène allemand. nous y démontrons la nécessité et l utilité de l harmonisation juridique et expliquons le procédé suivi ainsi que les outils utilisés. cette activité a requis le développement d une méthodologie nouvelle et soulève des problèmes intéressants de légitimation politique de théorie de le droit et de philosophie des langues. notre démonstration est agrémentée d exemples de termes harmonisés pour illustrer ces problèmes.
termith-eval,test_linguistique_11_0255102_tei,apprendre à décrire le document juridique à l heure de le web 2 0. l inflation documentaire dans le domaine de le droit est un phénomène indéniable auquel sont confrontés tous les acteurs juridiques à le sens large. malgré les initiatives de le gouvernement français pour faciliter l accès à certaines sources juridiques légifrance en est un exemple  l accès à l information et à le document juridiques est de plus en plus complexe d autant plus complexe qu il existe une forme d illettrisme informationnel parmi les professionnels de le droit. en contrepoint de cette complexité exponentielle force est de constater que les entreprises font jouer la concurrence des systèmes juridiques de le point de vue de leur attractivité économique. devant la nécessité d améliorer l identification et la gestion des documents juridiques nous proposons une feuille de route pour améliorer la boite à outil primordiale pour toute construction et ou de tout raisonnement juridique.
termith-eval,test_linguistique_11_0315832_tei,dislocation et conjugaison en français contemporain. la reprise pronominale  double marquage  est souvent considérée comme caractéristique des constructions disloquées. cet article vise à mettre en cause la corrélation de ces deux phénomènes. dans la première partie l auteur montre d une part que nombre de formulations présentant un double marquage ne sont pas des constructions disloquées d autre part que le phénomène de la dislocation avec double marquage serait plus adéquatement décrit si on analyse le clitique sujet non comme un pronom mais comme un morphème flexif préfixé. cette analyse conduit l auteur à formuler l hypothèse suivant laquelle la flexion verbale est le lieu d une variation libre mettant en jeu deux variantes de grammaire. la seconde partie de l article examine le cas où la reprise pronominale concerne un complément.
termith-eval,test_linguistique_11_0315836_tei,la construction pseudo clivée dans l organisation d activités complexes questions de portée. dans cet article je présenterai une étude de la construction pseudo clivée pc en français basée sur un corpus de données interactives. la pc est communément décrite comme construction marquant explicitement un constituant comme focus p ex. lambrecht 2004. or force est de constater que dans beaucoup d occurrences attestées cette description pose problème cf aussi hopper 2001. l analyse montrera que dans ces cas les locuteurs se servent de la pc pour gérer l accomplissement d activités complexes dans un tour de parole étendu plutôt que pour focaliser un constituant précis.
termith-eval,test_linguistique_11_0319734_tei,ségolène royal entre françois bayrou et nicolas sarkozy. approche lexicométrique. deux émissions télévisées ont opposé lors de la campagne présidentielle de 2007 ségolène royal candidate de la gauche d une part à françois bayrou leader centriste et d autre part à nicolas sarkozy candidat de la droite. le premier face à face est un duo  une tentative de rapprochement le second est un duel  un combat verbal. des statistiques comparatives sur le vocabulaire permettent de spécifier et d illustrer certains thèmes de clivage ou surtout les stratégies discursives des énonciateurs tout particulièrement celles de ségolène royal face à un partenaire à séduire puis face à un adversaire à combattre.
termith-eval,test_linguistique_11_0353955_tei,formation des enseignants à l éducation bi  plurilingue point de vue et réflexions sur quelques expériences valdôtaines. cette contribution est un récit. le récit de la mise en place d une école bilingue italien français dans un contexte politique et socioéducatif le val d aoste qui valorise le plurilinguisme mais qui connait une question linguistique relativement chaude par rapport à le statut de le français à le sein de l école et plus largement dans cette région qui doit son statut d autonomie à le fait que le français y est aussi langue officielle à côté de l italien. l inventaire des actions de formation entreprises à les différents niveaux de le système éducatif et pour les différents enseignants depuis les années 1980 permet de contempler avec un certain recul le chemin parcouru mais aussi de mieux cerner les obstacles les difficultés rencontrées dans la mise en place d un projet aussi ambitieux faire que tous les enseignants des disciplines non linguistiques se sentent suffisamment en sécurité pour alterner l italien et le français dans leur enseignement tout en ne dépossédant pas les professeurs de français langue étrangère de leur savoir de spécialistes.
termith-eval,test_linguistique_11_0353956_tei,paysans artisans enseignants mobilité des savoirs pour une compréhension inter culturelle et une transformation sociale. le présent article décrit le travail de réflexion et d action didactique et sociale entrepris par une équipe de futurs enseignants de langues étrangères suivant leur formation à le sein de l antenne rurale oriente de l université publique d antioquia en colombie. ces jeunes enseignants partagent l espoir de contribuer à les processus de développement durable de leur région en proposant des ateliers linguistiques et pratiques en français. ce projet a pour ambition de favoriser la dynamique de diffusion culturelle de techniques artisanales par le biais d échanges de savoir faire en français et en espagnol entre la colombie et la france.
termith-eval,test_linguistique_11_0368544_tei,limites et ambiguïtés rhétoriques de le discours pamphlétaire. vers l abandon d une pratique sociale. que devient le pamphlet. le propos de cet article est double. il s agit d abord de renouveler la définition de le pamphlet en précisant ses fondements théoriques mais aussi de mettre en lumière les modalités spécifiques de sa mise en pratique dans le but d établir son autonomie discursive face à le polémique avec lequel il est trop souvent confondu. l autre volet de cette enquête invite à analyser les conséquences rhétoriques de l avènement des droits de l homme comme topique dominante sur le registre pamphlétaire et s efforce de montrer en quoi l introduction de le concept de dignité a profondément transformé la place autant que la figure de le dénonciateur solitaire.
termith-eval,test_linguistique_11_0368550_tei,le cas turc  révélateur d une exception française. la dimension identitaire de la candidature européenne de la turquie à travers la presse quotidienne. dans cet article l auteur analyse un corpus de presse tiré des trois quotidiens nationaux que sont libération le monde et le figaro en s intéressant à les autoreprésentations qui traversent l imaginaire des français vis à vis de la turquie pays candidat à l intégration dans l union européenne. l étude de ces articles d opinion met en valeur le fait que l ouverture des négociations avec ce pays renforce en france un sentiment de vulnérabilité et révèle également une interrogation cruciale sur l identité européenne.
termith-eval,test_linguistique_11_0368557_tei,la violence verbale après la violence de masse. le procès de slobodan milošević devant le tribunal pénal international. ce texte traite de cette forme particulière d interaction qu est la violence verbale à partir d un corpus constitué de transcriptions d audiences de le procès de slobodan milošević à le tribunal pénal international à la haye. l ancien dirigeant tente devant ses victimes indirectes d inverser les rôles impartis et de s ériger de la position d accusé planificateur de la violence de masse à celle de procureur en mettant en place diverses stratégies discursives déstabilisatrices que nous proposons d analyser d un point de vue linguistique pragmatique et en tenant compte de le contexte sociohistorique de production des énoncés.
termith-eval,test_linguistique_11_0409488_tei,mise en cohérence de l anglais de spécialité et de le cecrl en france difficultés et enjeux. l anglais de spécialité se développe notamment grâce à les objectifs en langues motivants ils sont directement liés à la spécialité des étudiants. le cadre européen commun de référence en langues cecrl  d autre part est devenu un standard européen pour la politique des langues. le but de cet article est de montrer que bien que l anglais de spécialité et le cadre partagent les mêmes pré supposés théoriques les descripteurs de le cadre ne s adaptent pas facilement à des objectifs spécifiques. ce point est illustré par une expérience menée à l université joseph fourier de grenoble. dans cette expérimentation les étudiants sont évalués grâce à des tâches directement liées à les disciplines scientifiques qu ils étudient ce qui leur permet de s appuyer sur leurs connaissances scientifiques pour améliorer leurs compétences en anglais. à le lieu de cibler le niveau b 2 complet les évaluations sont recentrées sur les spécifications pour le monde des études à le niveau b 2 définies par l association des certificateurs européens alte dans l annexe d de le cecrl.
termith-eval,test_linguistique_11_0409491_tei,polyphonie dans le discours journalistique une étude comparative de la presse anglophone et francophone. le discours journalistique est le lieu privilégié de la polyphonie et de l expression culturelle. la présente communication se propose d explorer les traces laissées par un genre spécialisé l article de presse et par des imaginaires collectifs dans la presse francophone et anglophone. un corpus bilingue est soumis à une analyse de contenu puis à une analyse de discours. ensuite est examiné le rapport dialogique qu entretiennent les articles avec leurs sources. dans le cas de ce corpus l homogénéité et le nombre limité de sources induit d incontournables similitudes dans le contenu des articles. on part en outre de le postulat que la mémoire collective occidentale de le terrorisme construite par les médias rapproche les discours journalistiques de différents pays. par ailleurs il est important de se demander dans quelle mesure les différences entre l histoire le contexte sociopolitique et les pratiques journalistiques de chaque pays peuvent influencer la représentation d un même événement. s appuyant sur un corpus comparable bilingue donc sans traductions  la méthode comparative permet d étudier les pratiques textuelles communes à un type de discours précis ou spécifiques à une communauté culturelle.
termith-eval,test_linguistique_11_0409942_tei,la diphtongaison romane et la métaphonie le paradoxe de le faible à le fort. classiquement la métaphonie consiste dans l action de la voyelle désinentielle atone sur la voyelle tonique précédente. les auteurs remettent en question cette vue et posent que les voyelles désinentielles hautes  i et u ne provoquent pas la diphtongaison de la voyelle tonique dans les langues romanes. l approche adoptée phonologie particulaire permet de montrer par une ionisation phonologique que cette évolution peut s interpréter de même que tout changement spontané comme une modification de l interprétation de la sous spécification segmentale. ce processus a suivi la déphonologisation de la quantité vocalique en latin tardif. dans la métaphonie le nombre et le genre se réalisent parasitiquement sur la voyelle tonique. la marque morphologique interne peut être réduite à un élément qui est interprété par combinaison avec d autres matériaux vocaliques. cet élément agit en bloquant une évolution spontanée la diphtongaison dans le vocalisme tonique. l italoroman se situe donc entre deux types morphologiques concaténatif et non concaténatif il se comporte comme les langues sémitiques à morphologies internes ou à interdigitation. cet article montre que les divers types morphologiques attestés dans les langues peuvent n être que des modalités de réalisation d une même organisation sous jacente. on s interroge aussi sur les modalités de mise en relation entre une structure abstraite nécessaire des têtes fonctionnelles ou catégorielles et leurs compléments et sa réalisation phonologique. la syllabation garantit une réalisation linéaire successive des éléments morphologiques mais elle est en mesure aussi de provoquer leur co réalisation dans un format de fusion. de cette manière le contenu phonique des morphèmes spécifie l interprétation de la dépendance structurale.
termith-eval,test_linguistique_11_0409970_tei,des variantes invisibles à la fragmentation des langues romanes. cet article propose un modèle descriptif de l émergence des changements phonémiques morphosyntaxiques et lexico sémantiques. il s agit d un modèle alternatif dans la mesure où le principe d économie et l axiome deux formes deux fonctions sont mis en cause. l alternative proposée qui plaide pour le polymorphisme ainsi que pour l indéterminisme des descriptions grammaticales s appuie sur la notion de variante invisible un locuteur donné peut utiliser pour une fonction donnée des variantes non contrôlées et non perçues en tant que telles par l allocutaire. les variantes invisibles sont dans cette démarche considérées comme la source des changements qualitatifs dans l histoire d une langue ainsi que de la fragmentation ayant lieu dans un espace langagier donné. les sauts qualitatifs changement de grammaire sont décrits comme l intériorisation par induction de nouvelles règles par les locuteurs règles dont dérivent des variantes non reliées entre elles à l origine. ce modèle illustré par quelques exemples concernant certains phonèmes les clitiques la subordination les négatives et les interrogatives permet de formuler des hypothèses falsifiables à propos des règles innovatrices.
termith-eval,test_linguistique_11_0409971_tei,la dérivation en  de  et en  dis  en protoroman. contribution à la morphologie constructionnelle de l ancêtre commun des langues romanes. cet article propose sur la base des étymons à astérisque de le romanisches etymologisches wörterbuch rew  une modélisation de la préfixation en  de  et en  dis  de le protoroman bases sélectionnées classe grammaticale des dérivés valeur sémantique. les résultats convergent en partie avec ce que l on sait de la morphologie constructionnelle de le latin classique mais ils montrent aussi l originalité de l ancêtre commun des langues romanes à le sein de le latin global.
termith-eval,test_linguistique_11_0432682_tei,les langues des voisins des langues toujours appréciées. sur la base d une étude européenne le présent article s intéresse à les langues que les élèves souhaitent apprendre en plus de celles qu ils étudient déjà ainsi qu à leurs attitudes face à les langues des pays voisins. les réponses des jeunes interrogés montrent que si la présence de certaines langues dans la zone à le travers de l immigration ou dans des régions géographiquement proches peut contribuer à renforcer la motivation à les apprendre c est apparemment d une façon très limitée. par ailleurs si la majorité des élèves reconnaissent l utilité de connaitre les langues de leur pays et de pays proches les pourcentages d avis positifs sont néanmoins plus faibles et les attitudes nettement plus mitigées que dans le cas de l anglais. finalement les résultats obtenus conduisent à nuancer la vision selon laquelle les langues les plus proches de l environnement de vie des élèves langues nationales langues de l immigration ou langues des pays voisins seraient d office celles qu ils jugeraient les plus dignes d intérêt.
termith-eval,test_linguistique_11_0438768_tei,premiers éléments de définition d un type émergent de fasp l ecothriller. une profusion de discours sur la crise écologique actuelle semble se manifester à tous les niveaux de la société dans l univers des médias des entreprises de l éducation dans la sphère politique  il peut donc paraître naturel qu elle se manifeste également dans le domaine de la fiction. c est ce dont témoigne le développement récent d un nouveau genre de fiction spécialisée l ecothriller dont l auteur souhaite présenter les premiers éléments d une définition. tout d abord l origine de cette nouvelle étiquette générique est étudiée puis elle est définie à travers l analyse des points communs entre les différentes fictions qualifiées comme telles. cette étude amène aussi à s interroger sur le lien qui existe entre fiction et réel dans ce type de fiction à substrat professionnel. ce lien peut être comparé à celui d un double effet de miroir tant la production d ecothrillers semble découler de faits réels et tant les auteurs de ces romans semblent viser à jouer un rôle politique ou éducatif dans le monde réel.
termith-eval,test_linguistique_11_0438769_tei,l expression de la cause en anglais journalistique essai de caractérisation à travers l exemple de le financial times. l écriture journalistique se caractérise par l établissement fréquent de relations causales. les journalistes cherchent à varier la forme de ces relations en recourant d une part à des procédés explicites et d autre part à des procédés implicites. parmi les procédés explicites figure l emploi des connecteurs because since as et for. les relations causales implicites sont établies par le biais de connecteurs marquant une relation de postériorité de concomitance temporelle ou encore par des procédés marquant une concomitance non temporelle mais notionnelle. cette étude qui débute par une présentation des procédés explicites d expression de la cause est ensuite consacrée à les phénomènes implicites examinés sur la base d exemples extraits de deux cents articles de le financial times parus en 2009. l objectif est double d une part l auteur cherche à expliquer les mécanismes interprétatifs qui sous tendent l emploi de tels procédés. d autre part il se penche sur les stratégies discursives visées par l emploi de ces procédés et tente ainsi de saisir certaines spécificités de la langue de le financial times.
termith-eval,test_linguistique_11_0481559_tei,un lieu discursif  nous ne pourrons pas dire que nous ne savions pas. étude d une mise en discours de la morale. cet article vise à illustrer la notion de lieu discursif et son utilité pour l analyse des discours politiques. le cas étudié est l association lexico syntaxique ne pas pouvoir dire que ne pas savoir telle qu on la rencontre par exemple dans la formulation nous ne pourrons pas dire que nous ne savions pas  à le sujet de conflits armés ou de crises extrêmes mais aussi à propos de thématiques environnementales. l analyse qui met l accent conjointement sur les dimensions pragmatique énonciative et sémantico référentielle permet de dégager les différents dits et non dits et les enjeux de valeurs émotionnelles et morales que supportent les énoncés considérés.
termith-eval,test_linguistique_12_0027446_tei,dans cet article nous souhaitons montrer que lexique verbal et positionnement de l auteur dans les articles en sciences humaines. dans cet article nous abordons la question de la présence auctoriale et de le positionnement de l auteur à travers l étude des verbes de positionnement associés à un pronom sujet exemple je cherche à démontrer nous pensons que . l étude basée sur corpus compare les introductions et conclusions de trois disciplines des sciences humaines et sociales la linguistique la psychologie et les sciences de l éducation. les résultats montrent que la mention explicite de l auteur locuteur n est pas fréquente dans les articles de sciences humaines examinés et de ce point de vue le genre de l article de recherche dans ces disciplines se caractérise bien par un certain effacement énonciatif. cependant on observe une très grande variation disciplinaire à le sein des sciences humaines examinées qui montre que cette famille de disciplines est extrêmement diversifiée et qu il n est pas pertinent de l appréhender comme un ensemble homogène.
termith-eval,test_linguistique_12_0027450_tei,l éthos auto attribué d auteurs doctorants dans le discours scientifique. le propos principal de le présent article est d examiner la construction de l éthos auto attribué dans des articles scientifiques écrits par des doctorants français et de comparer cette construction à celle observée chez des chercheurs confirmés. la construction de l éthos est examinée à travers différents types de manifestations auctoriales à savoir les rôles de scripteur de chercheur et d argumentateur. les observations montrent que les doctorants se présentent comme des chercheurs sérieux  respectant les normes de le genre et comme étant très explicites dans leur rédaction de le processus de recherche conscients de leur tâche de guider le lecteur.
termith-eval,test_linguistique_12_0043022_tei,la locution ainsi que en moyen français questions sur l évolution des conjonctions. l article décrit les emplois de ainsi que en moyen français en soulignant leur diversité sémantique comparaison temps conséquence  syntaxique phrase complète ou elliptique et catégorielle subordonnant instaurant divers degrés d intégration et de cohésion marqueur d approximation voire préposition. cette description permet de dresser le bilan dans la diachronie de le français des points de différence et de permanence dans l évolution de ce marqueur d identité similative en comparant cette évolution à celles d autres mis. on montre alors en quoi l évolution diachronique s inscrivant dans un mouvement de grammaticalisation renforce le sens prototypique de la locution conjonctive en relation avec la persistance sémantique de son constituant de base à la jonction des valeurs sémantiques et discursives.
termith-eval,test_linguistique_12_0043023_tei,des concessives extensionnelles à les concessives simples contribution à l étude de la genèse sémantique et historique des locutions conjonctives concessives de le français. cette contribution vise à rendre compte de le rapport historiquement observable entre concessives extensionnelles et concessives simples à partir de l étude des emplois des morphèmes quoi que combien que et ja soit que.
termith-eval,test_linguistique_12_0043024_tei,les locutions conjonctives en question s. nous essayons d évaluer la pertinence théorique de le concept de locution conjonctive. l évaluation épistémologique à laquelle nous soumettons ce concept nous permet de mesurer la complexité de l objet décrit. notre étude est sous tendue par deux axes le premier propose quelques éléments de réflexion sur les problèmes de délimitation et de définition linguistiques que pose le concept en tant qu outil méthodologique. l autre axe fait le point sur le statut déviant de l objet tant sur le plan morpho syntaxique que sémantique. en corollaire nous proposons une nouvelle conception des locutions conjonctives.
termith-eval,test_linguistique_12_0043025_tei,sur la genèse des locutions participiales. dans cet article nous nous intéressons à la genèse d un ensemble de locutions conjonctives encore peu étudié celui des locutions mettant en jeu une base participiale. nous montrons d abord que cette genèse est ordinairement appréhendée par le recours à une phase prépositionnelle mais qu une telle appréhension présente quelques limites en ce sens qu elle ne peut parvenir à rendre compte de l ensemble des formations reposant sur ce modèle. dès lors c est par un recours à le mécanisme analogique tel qu il est défini dans le cadre de la théorie cosérienne qu une explication alternative peut être proposée.
termith-eval,test_linguistique_12_0043027_tei,la grammaticalisation de l adverbe plutôt et l évolution de le système grammatical. cet article présente une étude de l évolution de l adverbe plutôt. il propose une réflexion sur le passage de le sens temporel attesté dès le xii e siècle et même avant à le sens préférentiel puis rectificatif employés bien plus tard. ces nouveaux signifiés apparaissent dans des contextes linguistiques qui permettent une nouvelle interprétation de la structure plus tost. par ailleurs ce cas de grammaticalisation est présenté comme étant en rapport avec d autres changements qui se produisent en parallèle dans le micro système des expressions adversatives. ces changements ont aussi un impact sur le système grammatical.
termith-eval,test_linguistique_12_0063658_tei,l adjectif bolivariano dans la presse vénézuélienne. entre langue et positionnements politiques. cet article traite de l utilisation de l adjectif bolivariano dans le langage politique vénézuélien. il s agit d interroger son signifié en s arrêtant tout d abord sur son histoire et ses aspects linguistiques puis en observant comment circule ce terme et avec lui le mythe de simón bolívar  de le discours de le président hugo chávez à celui de la presse. l analyse discursive porte plus particulièrement sur un corpus de presse vénézuélienne constitué autour de la tentative de coup d état contre hugo chàvez afin d examiner les enjeux politiques liés à cet adjectif. l étude montre d abord l ambigüité inhérente à ce terme puis son glissement vers un nouveau signifié se rapportant à l origine à la figure de bolívar il se rapporte désormais à celle de hugo chàvez et sa révolution bolivarienne.
termith-eval,test_linguistique_12_0063660_tei,émergence d un nouveau péronisme. analyse des discours à la nation de néstor kirchner 2003 2007. l étude des discours de néstor kirchner permet d identifier les représentations sociales qu il a mobilisées et de montrer comment il s inscrit dans le contexte de le virage à gauche qui singularise aujourd hui l amérique latine. ses allocutions devant l assemblée nationale peuvent s analyser sous l angle de l héritage péroniste et particulièrement de l imaginaire de la génération des années soixante dix et lui ont permis de transformer son image d homme politique non charismatique en celle d un leader providentiel.
termith-eval,test_linguistique_12_0078142_tei,gestes verbalisations et combinaisons bimodales dans les productions d enfants français âgés de 18 mois à 4 ans et demi. dans le présent article nous étudions les productions langagières de jeunes enfants français en situation de jeu quasi naturelle avec un adulte. nous savons que les enfants âgés de 17 à 41 mois qui commencent à mobiliser leurs ressources verbales produisent des combinaisons geste mot. le rôle de ces combinaisons bimodales a déjà été bien étudié chez les enfants italiens et américains mais ce n était pas encore le cas chez l enfant français. notre premier objectif est donc d analyser les productions langagières verbales gestuelles et bimodales d enfants français pour vérifier qu on y retrouve bien les évolutions constatées ailleurs. notre deuxième objectif consiste à réfléchir à une représentation de le développement langagier précoce qui à la différence d indices telles la lme prenne en compte l ensemble des productions gestuelles bimodales et verbales des jeunes enfants. à cette fin nous proposons une analyse qui met sur le même plan gestualité et verbalisations ainsi que l ébauche d un modèle bimodal qui reste à affiner par la suite.
termith-eval,test_linguistique_12_0078201_tei,structuration physiologique de la gestuelle modèle et tests. la gestuelle coverbale est trop souvent associée à contaminée par. la parole co occurrente. elle relève pourtant d une modalité non linéaire. la compositionnalité possible de la gestuelle ouvre sur une voie d expression multilinéaire de le sens en dehors des emblèmes aucun inventaire lexical ne permet d étudier les productions gestuelles. une approche physiologique répond à ce préalable inventorier pour éclairer la composition. après avoir présenté la structuration articulaire de la gestualité les résultats d un test d assignation d étiquettes montrent la validité d une catégorisation structurée par les degrés de liberté ddl de la physiologie articulaire. des proximités formelles sont explorées elles forment une typologie qu il reste à informer. en outre des relations formelles et sémantiques émergent entre ces ddl. elles seront abordées ici.
termith-eval,test_linguistique_12_0078204_tei,traitement automatique de la métrique arabe réalisations et perspectives. cette communication commence par un bref rappel de l histoire des recherches en matière de traitement automatique de la métrique arabe et notamment des premières réalisations en la matière qui remontent à 1979 et qui malgré leur lourdeur ont eu le grand intérêt de montrer qu un tel objectif était réalisable. elle aborde ensuite la présentation de le programme al xalîl  capable de réaliser automatiquement le découpage syllabique et l analyse métrique de n importe quel texte poétique arabe quelle que soit sa longueur en ne demandant en entrée que le texte arabe systématiquement et rigoureusement vocalisé. l exploitation de la base de données textuelle générée par le logiciel à partir de chaque texte analysé permet de mettre en évidence un certain nombre de propriétés métriques générales ou spécifiques à le texte analysé.
termith-eval,test_linguistique_12_0078214_tei,nouvelle contribution à l histoire de la métrique arabe la terminologie primitive l analyse statistique et le répertoire des mètres de la poésie ancienne. tout laisse à penser que la typologie et la taxinomie des mètres de la théorie d alalīl et non uniquement la théorie elle même dans son organisation et son fonctionnement sont en grande partie originales et en rupture avec les conceptions les catégories et la terminologie métriques des arabes avant l islam. un certain nombre d auteurs classiques nous disent que les arabes divisaient la poésie en à le moins trois catégories le qd le rağaz et le ramal. la tentative de reconstitution de ce système permet notamment de montrer que la distinction entre vers simples rağaz et vers doubles qīd et ramal ne tient pas seulement à la forme extérieure de le vers mais aussi à sa structure interne et à les limites assignées à la variation quantitative et l examen des mètres en usage dans les différentes régions de le monde arabe entre 450 et 6 70 d observer une nette différence entre poètes d arabie orientale et d al  maîtres de le ramal et poètes d arabie centrale et occidentale  spécialistes de le q.
termith-eval,test_linguistique_12_0090064_tei,grammaire et degré de spécialisation. cette étude s interroge sur la réalité de langues transversales transcendant les langues de spécialité et fondées sur la notion de degré de spécialisation. existe t il une grammaire propre à les textes de vulgarisation et une grammaire propre à les textes spécialisés quelle que soit la discipline envisagée. quels marqueurs grammaticaux sont susceptibles de coder les différences linguistiques entre les divers degrés de spécialisation. l hypothèse examinée est que les marqueurs référentiels comme les temps sont plutôt révélateurs des différences entre les disciplines alors que les marqueurs intersubjectifs comme les modaux sont plutôt sensibles à le degré de spécialisation d un discours donné. l analyse d un corpus composé de textes spécialisés et de textes de vulgarisation en histoire et en philosophie ne confirme que partiellement cette hypothèse de départ les marqueurs qu ils soient référentiels ou intersubjectifs semblent dans tous les cas plus liés à la discipline qu à le degré de spécialisation. de nouvelles pistes sont alors proposées pour parvenir à cerner les traces linguistiques des divers degrés de spécialisation.
termith-eval,test_linguistique_12_0107865_tei,quelle place occupe l anglais juridique dans les offres de stages proposés par les cabinets d avocats en angleterre et à le pays de galles. le présent article analyse des documents mis en ligne par les cabinets d avocats anglais pour recruter des étudiants ou des diplômés en droit et en matières non juridiques dans le cadre de stages d observation et d apprentissage. il s agit de déterminer quelle place occupe l anglais juridique dans ces offres en étudiant les termes emblématiques à la fois de la formation suivie par les aspirants solicitors de leur milieu professionnel ainsi que de leurs pratiques. de plus l étude de cette langue spécialisée peut occuper une place à part entière dans le cursus linguistique suivi par les étudiants français en droit dans la mesure où il peut leur faire prendre conscience des différences essentielles existant entre les cursus pour devenir avocat et solicitor des deux côtés de la manche et ainsi élargir leur horizon professionnel.
termith-eval,test_linguistique_12_0107886_tei,parole rapportée et positionnement discursif dans la presse américaine analyse de l utilisation des citations dans des commentaires politiques. cet article présente une analyse de le rôle de le discours rapporté dans trente et un articles de presse à propos de le discours prononcé par le président obama devant le congrès en septembre 2009 le corpus est tiré de cinq journaux différents. l auteur a tenté de comprendre les différences entre le discours utilisé dans les citations celles ci émanant aussi bien de b obama que d autres sources commentant le discours et le discours produit directement par le journaliste ainsi que la manière dont le discours rapporté est intégré dans les articles. il apparaît que le journaliste sélectionne certaines formes de discours rapporté discours direct ou combinaisons de formes  à le détriment d autres formes discours indirect  et que les citations sont généralement plus personnalisées que le texte encadrant ce qui permet à le journaliste d exprimer des opinions sans le faire en son nom propre. malgré ces différences l auteur suggère que l utilisation de le discours rapporté est conforme à certaines conventions journalistiques telles que l objectivité ou la légitimation de le discours.
termith-eval,test_linguistique_12_0116611_tei,le sigle comme modalité de dissociation énonciative. le cas des alternances d usage pma pays les moins avancés sigles et acronymes en politique. l analyse des alternances d usage de le sigle pma et de son développement syntagmatique pays les moins avancés montre que les deux formes n offrent pas les mêmes potentialités signifiantes car elles n activent pas les mêmes référents expérientiels. alors que l énoncé des unités lexicales de le syntagme est susceptible de produire l écho d une mémoire discursive infériorisante la forme opaque et figée de le sigle n est pas chargée d autre sémantisme que celui d une catégorisation institutionnelle. son actualisation permet ainsi à le locuteur de se dissocier énonciativement des potentiels effets de sens de son acte de nomination.
termith-eval,test_linguistique_12_0116620_tei,le détournement de sigles. entre jeu de mots et expression contestataire sigles et acronymes en politique. la prolifération des sigles dans le monde contemporain s est accompagnée d une pratique accrue de leur détournement qui consiste à substituer d autres mots commençant par les mêmes lettres à ceux qui composent le sigle original développé. cette créativité langagière prétend le plus souvent à l humour mais elle se donne aussi pour objectif de dénoncer la face cachée de l objet désigné par le sigle. en ce sens le détournement est éminemment politique.
termith-eval,test_linguistique_12_0116624_tei,le paradoxe de la preuve en histoire. une approche rhétorique de l écriture d arlette farge. si selon aristote la validité de toute argumentation se fonde autant sur des preuves techniques que sur des preuves extratechniques ces dernières semblent être les seules sur lesquelles l historien puisse légitimement fonder son propos. le fait que les champs de validité de l argumentation en histoire et en rhétorique ne se recoupent pas peut placer les historiens devant une situation paradoxale ils peuvent être contraints à avoir recours à les preuves techniques de la rhétorique alors que de telles preuves sont réputées non valides en histoire.
termith-eval,test_linguistique_12_0173336_tei,la stagiaire sage femme devant sa cliente un double rapport à le savoir. un double statut d étudiant et d expert caractérise la situation de le stagiaire. posant l hypothèse que la tension qui s exerce entre ces deux statuts est repérable dans le discours nous avons analysé dans une perspective interactionniste le discours de deux stagiaires sages femmes québécoises lors de consultations de suivi prénatal. un double rapport à le savoir acquis et à transmettre apparait qui est étroitement lié à l histoire récente de la profession de sage femme à le québec. les sages femmes québécoises fondent leur identité professionnelle sur un ensemble de valeurs distinctives parmi lesquelles le partage de le savoir médical avec la cliente occupe une grande place. l analyse montre l adhésion de la stagiaire à cette valeur en cela elle est déjà sage femme. mais le partage de le savoir suppose une évaluation de la pertinence des informations à transmettre. sur ce plan la stagiaire reste une étudiante et doit encore acquérir un élément important de l expertise la souplesse dans le maniement de ce savoir.
termith-eval,test_linguistique_12_0207991_tei,individualisme. de le producteur à tocqueville. cet article retrace le trajet de le mot individualisme de son émergence durant la restauration à son usage par tocqueville et interroge les raisons d une signification incertaine maintes fois évoquée. il prend appui sur les relations sémantiques de le néologisme celles entretenues avec les mots socialisme et égoïsme pour expliciter ces difficultés et inscrit la définition qu en donne tocqueville dans l histoire de la genèse des usages de le mot.
termith-eval,test_linguistique_12_0207997_tei,sionisme. oppositions militantes autour d un terme à géométrie variable. le conflit israélo palestinien rejaillit peut être plus que nulle autre guerre dans le domaine de le langage. le terme sionisme est de ceux qui suscitent des tensions entre militants pro israéliens et pro palestiniens. les premiers ont une vision très positive de le sionisme tandis que les seconds le considèrent comme une forme de colonialisme et accusent les militants pro israéliens de chercher à assimiler l antisionisme à de l antisémitisme.
termith-eval,test_linguistique_12_0208009_tei,la dénomination comme trace de le passé et enjeu. l exemple des universités parisiennes. la dénomination des universités est à le cœur des préoccupations de l enseignement supérieur comme en témoignent les récents changements de noms dans le champ académique français. les dénominations académiques s avèrent plurielles traces de l histoire des établissements des mutations et des réformes qui touchent à le supérieur regroupements d établissements. elles sont également à le centre des logiques de référencement qui comptabilisent les signatures et contribuent à leur visibilité. c est ce que cet article examine à partir d une étude diachronique et synchronique des dénominations des treize universités d île de france.
termith-eval,test_linguistique_12_0283036_tei,quand les côtes du nord sont devenues les côtes d armor. le département entre identité et attractivité les collectivités territoriales en quête d identité. le changement de nom de le département des côtes du nord devenues côtes d armor en 1990 est un processus complexe d action publique porté par les élus et les professionnels de le tourisme. les discours sur ce changement ceux de l époque et ceux tenus aujourd hui pour les vingt ans de l événement montrent la double prégnance des logiques de marketing territorial et d attractivité d un côté d identité de l autre. le changement de nom est censé favoriser le développement touristique de le département mais aussi rendre à les costarmoricains l identité qui leur avait été usurpée.
termith-eval,test_linguistique_12_0301504_tei,réflexions pour l analyse de le discours populiste. cet article envisage le populisme de le point de vue de le discours car c est à travers celui ci que se construisent les opinions publiques. après avoir observé l emploi de le terme populiste dans l usage courant et chez les acteurs politiques on établit un bref état des différentes explications qui circulent à propos de le populisme pour en percevoir les points communs et les différences. c est alors qu est proposé en matière d outil d analyse un questionnement permettant de mettre en lumière les caractéristiques de ce type de discours sur fond de crise sociale comment est décrite la source de le mal comment sont exaltées les valeurs défendues par le politique quelles images le populiste construit de lui même. ce questionnement permet d aboutir à une réflexion sur le rapport entre populisme et démocratie.
termith-eval,test_linguistique_12_0328634_tei,insécurité linguistique et réseaux sociaux denses ou isolants le cas de femmes maghrébines dans la tourmente. chez certaines femmes migrantes les structures denses ou isolantes des réseaux sociaux semblent aller de pair avec plusieurs formes d insécurité linguistique. cet article essaie donc de montrer qu il existe des liens importants entre le capital social des personnes et leurs représentations et pratiques langagières.
termith-eval,test_linguistique_12_0328640_tei,présentation de soi et projection en contexte homoparental la construction langagière d un projet de famille. à partir d une ethnographie multi sites menée dans une association de parents et de futurs parents gay et lesbiens j analyserai les modalités discursives de présentation de soi. mon attention se focalisera sur la façon dont les participants tout en imaginant à le futur une présentation de soi en tant que père ou mère de x mettent en scène un réseau intersubjectif à le sein duquel des dialogues entre les parents les enfants et les proches ont lieu. ce point me permettra de souligner la dimension réflexive entre désir d enfant et pratiques langagières et de conclure avec un retour réflexif sur mon statut d observateur participant à le sein de l enquête.
termith-eval,test_linguistique_12_0328642_tei,vitalité de le francique en lorraine germanophone. dans notre article nous examinons la vitalité de le francique rhénan parlé à freyming merlebach dans le centre de le bassin houiller de lorraine. nous nous intéressons particulièrement à les raisons de le déclin de cette langue régionale de france et afin de répondre à nos questions de recherches nous avons conjugué méthodes quantitatives et qualitatives. les résultats montrent que le déclin de le francique dans le bassin houiller lorrain est particulièrement marqué la langue maternelle des jeunes générations dans la plupart des cas étant aujourd hui le français. c est la politique linguistique de l état français qui a joué un rôle décisif dans ce déclin de le francique en lorraine germanophone. nous limitant à la période de l après guerre nous avons pu constater que les conditions générales étaient favorables à la francisation et que les interventions étaient particulièrement efficaces dans le domaine éducatif.
termith-eval,test_linguistique_12_0328645_tei,retour sur le débat autour de l identité nationale en france quelles places pour quelle s langue s. c est une nouvelle lecture de le grand débat sur l identité nationale que nous nous proposons d effectuer notamment sous l angle des liens existant entre langue et identité. à travers l analyse de quelques contributions d internautes sur le site mis en place à cet effet nous souhaitons nous pencher de plus près sur la les place s occupée s par la les langue s dans les discours de citoyens sur l identité.
termith-eval,test_linguistique_13_0046627_tei,l enseignement supérieur en contexte anglophone envisagé comme domaine spécialisé aspects théoriques et méthodologiques. dans cet article il est proposé d envisager le monde de l enseignement supérieur britannique comme un domaine spécialisé dans le cadre de la recherche en anglais de spécialité désormais asp. on sait que l enseignement supérieur à le royaume uni est appréhendé dans différents champs disciplinaires à l intérieur et hors de l anglistique mais ces points de vue disciplinaires dont il est proposé un bref panorama aboutissent le plus souvent à une vision partielle et éclatée de le domaine. la perspective disciplinaire de l asp permet pour sa part de caractériser l enseignement supérieur britannique de façon globale en tant qu il constitue un domaine spécialisé. dans cet article cette démarche est adossée à une théorie de l interdisciplinarité des éléments d ordre théorique et méthodologique sont proposés pour la caractérisation des domaines spécialisés en contexte anglophone et ils sont appliqués à l étude de l enseignement supérieur britannique.
termith-eval,test_linguistique_13_0078102_tei,la politique de la fiction d actualité. l argumentation par émersion dans le faux journal télévisé de la rtbf fictions politiques. l article prend pour objet d analyse et de réflexion le faux journal télévisé diffusé par la rtbf en décembre 2006 annonçant fictivement la fin de la belgique. l émission est brièvement contextualisée et décrite pour être ensuite analysée en tant que dispositif argumentatif emboîtement énonciatif procédés fictionnels et dédoublement communicationnel constituent les trois instruments majeurs d un mouvement d émersion fictionnelle qui affecte le téléspectateur. cette analyse s ouvre ensuite sur une discussion théorique des oppositions entre information et fiction argumentation et narration qui vise à revoir la qualification réflexive et politique des objets médiatiques.
termith-eval,test_linguistique_13_0088781_tei,les emprunts discursifs entre politique et publicité. des échanges inégaux publicité et politique. le monde politique comme indiqué dans la présentation de le dossier emprunte très largement à la publicité commerciale ses méthodes et techniques mais moins souvent ses mots. s il arrive que des locuteurs politiques s approprient des éléments de discours issus de l univers de la publicité ou des marques les cas restent assez limités. peut être les politiques rechignent ils à puiser massivement dans le répertoire marchand par crainte de rendre trivial leur objet. il est sans doute plus valorisant de nourrir un discours politique de références réputées plus nobles par exemple historiques ou littéraires. en tout cas les importations de ce genre exigent que les expressions publicitaires recyclées appartiennent à une culture assurément partagée parles publics visés et bénéficient d une notoriété suffisante. leur avantage comme pour les emprunts à le lexique sportif barbet 2007  est alors de parler à le plus grand nombre. si la communication politique emprunte largement ses méthodes à la publicité commerciale elle s inspire plus rarement de ses mots sinon en recyclant quelques slogans de marques à succès. en revanche les agences publicitaires s inspirent massivement des discours politiques à des fins de promotion marchande. depuis les années soixante dix la tendance de le marketing à le rebond sur l actualité politique s est amplifiée démultipliée par l usage de l internet. les annonceurs rivalisent désormais en détournements de formules politiques en simulacres de vote ou en parodies de campagne électorale parfois audacieuses visant à faire élire des produits. cette mise en dérision par décalage s appuie sur la désacralisation politique tout en la confortant. pourtant elle ne porte pas atteinte à le principe électif lui même qui s étend ainsi à des domaines toujours plus variés.
termith-eval,test_linguistique_13_0088783_tei,les casseurs de pub contre la société de consommation. stratégies de détournement pour convaincre publicité et politique. dans une approche sémio discursive l article analyse les discours publicitaires détournés par l association casseurs de pub à des fins persuasives. avant d examiner les différentes stratégies discursives mises en œuvre à les niveaux icono graphique logico linguistique rhétorico sémantique textuel interdiscursif et rhétorique  l article définit le contrat de communication et la double visée argumentative de ces discours politico médiatiques.
termith-eval,test_sciencesInfo_02_0446400_tei,proust kolb kolb proust emboîtement d écritures autour de l écriture. la bibliothèque de l université d illinois développe depuis 1994 un outil hypertexte qui rassemble des sources secondaires sur la vie littéraire artistique et mondaine en france pour la période 1870 1925 à partir des 40 000 fiches de recherche constituées par le professeur kolb pour son édition de la correspondance de marcel proust. l insertion de métadonnées de liens hypertextes et de nouvelles informations nécessaires à la constitution de cette base apporte un niveau supplémentaire à cet édifice déjà formé par la superposition des écrits de proust et de kolb.
termith-eval,test_sciencesInfo_02_0447872_tei,enseigner la lecture intime de le texte littéraire grâce à l édition hypertextuelle. ce travail se situe à la croisée de trois grands domaines l informatique éducative la didactique de la littérature et la lecture. l informatique et en particulier la technologie de l hypertexte permettent désormais à le travers de dispositifs de lecture électronique d appréhender les textes dans leur épaisseur intra extra et intertextuelle. après les théories de la réception ces nouveaux environnements réaffirment à leur manière l interactivité de la lecture. lire n est pas une activité linéaire mais donne lieu à de multiples actions sur le texte comparaisons rapprochements annotations etc. transposée dans le champ de l enseignement apprentissage de la lecture littéraire cette réflexion est le fondement d une expérience visant à démontrer que l édition hypertextuelle d un texte en classe peut aider mieux que tout autre moyen à faire prendre conscience à les élèves de la nature intime de la lecture littéraire.
termith-eval,test_sciencesInfo_02_0463856_tei,samovar ou comment capitaliser les traces de la coopération entre acteurs d un projet véhicule avec une mémoire de projet utilisation des ontologies pour la recherche d information dans le domaine de l automobile. dans cet article nous présentons samovar système d analyse et de modélisation des validations des automobiles renault  un outil de capitalisation de connaissances dans le domaine de l automobile. basé sur la construction et l exploitation d une mémoire de projet en particulier la mémoire des problèmes rencontrés à le cours d un projet  samovar repose sur un ensemble d ontologies qui structurent les connaissances et guident la recherche d informations dans la mémoire de projet par le moteur de recherche corese. ces ontologies ont été construites en exploitant un outil de traitement linguistique sur un corpus textuel et en définissant des règles heuristiques sur les candidats termes obtenus grâce à cet outil. nous généralisons notre approche à la construction d une mémoire de projet de conception d un système complexe quelconque.
termith-eval,test_sciencesInfo_02_0464532_tei,représentation des connaissances dans une mémoire de projet. une mémoire de projet est une représentation de l expérience acquise pendant la réalisation de projets dieng et al 1998. elle peut être obtenue à travers une capitalisation à le fil de l eau de l activité de l entreprise notamment de la logique de conception design rationale. la plupart des méthodes définies à ce propos ne permettent pas une structuration en temps réel de la logique de conception. nous proposons dans cet article un processus dynamique de modélisation des connaissances offrant une démarche de traçabilité en deux étapes retranscription directe et structuration et introduisant une dynamique que ce soit dans la démarche ou dans la structure de la mémoire.
termith-eval,test_sciencesInfo_03_0023746_tei,certification et archivage légal de dossiers numériques. la certification et l archivage légal des données alliées à la signature électronique des documents ouvrent de nouvelles perspectives à la sécurisation des documents. ainsi ces technologies offrent des capacités d identification d authentification de certification qui concourent à la capacité globale d archivage sécurisé des dossiers numériques. cependant il apparaît que la certification et la signature électronique ne répondent pas complètement à les besoins des entreprises en ce qui concerne l authentification et le stockage des données sécurisées. dans la suite de cet article nous proposons une solution à ces problèmes.
termith-eval,test_sciencesInfo_03_0024520_tei,une méthode générique de rétroconversion de documents pour la constitution de dossiers numériques. dans un certain nombre de cas les dossiers numériques sont constitués par rétroconversion de documents papier. or jusqu à présent ces rétroconversions impliquent de développer pour chaque type de documents un système spécifique de reconnaissance. nous proposons donc une approche générique la méthode dmos description avec modification de la segmentation  qui permet d engendrer le système de reconnaissance adapté à partir de la description de la structure de chaque document. cette méthode qui a déjà été utilisée sur différents types de documents partitions musicales formules mathématiques  permet entre autres de repérer les structures tabulaires contenues dans une page. elle vient d être validée sur plus de 5 000 fiches nominatives d incorporation militaire de le xixe siècle. en produisant une description xml extensible markup language de le document la méthode permet d appliquer ensuite d autres traitements comme la constitution de pages d index visuels ou le masquage de champs confidentiels.
termith-eval,test_sciencesInfo_03_0024667_tei,essai de définition universelle de le dossier. le dossier est souvent définit par son objet dossier de subvention dossier de patient dossier de presse sans que l on s appesantisse davantage sur ce que recouvre la notion de dossier ce qu elle sous entend à quoi elle fait référence. ce numéro de document numérique sur la numérisation de dossiers papier et la production de dossiers électroniques est une occasion d essayer de définir ce qu est un dossier et d observer si le changement de support affecte le contenu de le dossier.
termith-eval,test_sciencesInfo_04_0290034_tei,accès par le contenu à les documents manuscrits d archives numérisés. cet article présente l accès par le contenu à les documents d archives manuscrits. cet accès doit s appuyer sur des informations annotations associées à les images de documents. nous proposons deux manières complémentaires de produire ces annotations automatiquement en utilisant la reconnaissance de documents et collectivement sur internet par une saisie manuelle effectuée par les lecteurs eux mêmes. une plate forme de gestion de ces annotations est présentée ainsi que des exemples d annotations automatiques sur des registres paroissiaux et d état civil des formulaires militaires registres matricules et des décrets de naturalisation en utilisant une méthode générique de reconnaissance de documents. cette méthode a été validée sur plus de 60 000 pages de documents. des exemples d annotations collectives construites sur des annotations automatiques sont donnés.
termith-eval,test_sciencesInfo_04_0290035_tei,documents manuscrits et recherche d information. nous présentons un modèle de recherche d information visuelle adapté à la navigation et l interrogation de bases de documents manuscrits numérisés. nous considérons ces documents de le point de vue de leur contenu graphique ce qui inscrit cette problématique dans un cadre d identification de le scripteur. un certain nombre de travaux ont abordé ce problème d identification de le scripteur le plus souvent en s appuyant sur des techniques d analyse de textures pour caractériser les écritures. l originalité des travaux que nous présentons tient à le fait que nous fondons notre démarche sur une technique de recherche d information en utilisant une description spécifique à l écriture manuscrite. l approche est évaluée sur deux bases de documents manuscrits une base créée à le laboratoire et une base de le patrimoine littéraire constituée des correspondances de zola.
termith-eval,test_sciencesInfo_04_0592889_tei,instrumenter l informel dans les phases amont des projets de conception innovante. les phases amont des projets de conception peuvent être des périodes propices à l introduction d innovations technologiques dans les produits. lors de ces phases les processus de coopération et de confrontation des différents points de vue entre les acteurs impliquent des échanges d informations qui sont parfois informels non contractuels et peu ou pas structurés. pourtant ces phases de négociation et de prospective constituent des enjeux très stratégiques pour la diffusion de l innovation. dans le cadre d une étude de terrain industriel l observation participante de l émergence de solutions innovantes nous a conduits à élaborer un environnement collaboratif spécifique dénommé id 2 innovation développement et diffusion. cet outil propose une structuration semi formelle des informations manipulées afin de favoriser les interactions entre les acteurs et la diffusion de l innovation. dans cet article nous étudions dans quelle mesure les principes proposés dans id 2 peuvent être mis en oeuvre dans une configuration particulière d un système de gestion de données techniques sgdt générique. nous appuyons alors notre propos sur le maquettage de le sgdt windchill ptc et nous montrons les limites des deux outils proposés.
termith-eval,test_sciencesInfo_04_0592890_tei,démarche de modélisation d une situation de conception collaborative. le caractère collectif des activités de conception nécessite le développement de méthodes et d outils pour la maîtrise des processus de conception et des activités collaboratives. le groupe de travail est assimilé à un système constitué d entités en interactions de différentes natures et régi par des mécanismes de régulation et de coordination. nous nous intéressons ici à la modélisation d une situation de conception collaborative. après une définition de la situation et la description de différentes perceptions de ce concept nous proposons un modèle de situation dans lequel nous caractérisons les entités de différentes natures qui sont en interactions. une classification des relations entre ces entités est proposée. les perspectives de ce travail sont de contribuer à l amélioration d outils permettant de supporter une situation de conception collaborative et de capitaliser ces connaissances en vue d une réutilisation efficace.
termith-eval,test_sciencesInfo_05_0035869_tei,documents numériques à la recherche d une typologie perdue. l auteur s attache à développer les prérequis d une typologie des documents numériques à partir de ses composantes données forme de codage structure forme de validation et métadonnées. cette typologie ne se veut pas académique mais pratique en vue de le processus d ingestion de ces documents dans des systèmes d archivage électroniques tels qu ils sont définis par la norme iso 14721 2003 open archival information system oais. après une analyse des différentes typologies existantes on définit les critères qualitatifs pour une typologie praticable. chacune des composantes de le document fait l objet d une typologie propre qui est examinée pour sa pertinence discriminatoire. en conclusion il apparaît que les notions de données et de documents ne sont actuellement pas assez précises pour permettre une typologie univoque.
termith-eval,test_sciencesInfo_05_0035974_tei,les tiers de confiance sont ils les archivistes de l avenir. la nouvelle législation sur la signature électronique a favorisé la naissance d une nouvelle profession les tiers de confiance. ce que ces derniers disent d eux mêmes et de leur rôle a beaucoup de points communs avec les compétences et les missions des archivistes et l on peut donc se demander comment s opérera la répartition des rôles entre les uns et les autres à le fur et à mesure que se développera la production de documents sous une forme exclusivement numérique. l état actuel de le droit ne permet pas de trancher mais l économie et la sociologie fournissent en revanche des pistes intéressantes le succès ou l échec de le modèle économique adopté par les tiers de confiance sera un élément décisif mais l évolution des mentalités à le sein des deux communautés professionnelles comptera ensuite beaucoup.
termith-eval,test_sciencesInfo_05_0036214_tei,le groupe pin lieu d échange lieu de réflexion lieu d action. le groupe de travail pin pérennisation de l information numérique a été créé en 2000 à l occasion de la diffusion en france de la norme oais open archival information system. il regroupe des représentants de grandes institutions publiques cnes bnf cea etc et d entreprises qui mettent en commun leurs réflexions et leurs expérimentations concernant l archivage de données scientifiques patrimoniales ou opérationnelles. pin s efforce de développer une culture commune à les différents acteurs de l archivage.
termith-eval,test_sciencesInfo_05_0094317_tei,une technique de réétiquetage dans un contexte de catégorisation de textes. par essence l apprentissage supervisé nécessite que chaque individu de l ensemble d apprentissage soit préalablement étiqueté. dans un contexte de catégorisation de textes l étiquetage consiste à affecter les catégories d appartenance d un document. cette opération est réalisée par un expert et peut être perçue comme subjective puisque basée sur l interprétation de le document. ainsi l étiquetage peut être considéré comme inconsistant dans certain cas. par exemple deux experts peuvent étiqueter différemment un même document ou encore un même expert peut étiqueter différemment un même document soumis à deux instants différents. cette inconsistance peut affecter l efficacité de le classifieur. pour atténuer ces inconvénients nous considérons que certains individus de l ensemble d apprentissage sont mal étiquetés et doivent être réétiquetés. dans cet article nous utilisons une méthode de relaxation afin d optimiser la cohérence de l étiquetage. nous appliquons cette technique sur un corpus bien connu dans la communauté de la catégorisation de textes la collection reuters 21578 aptemod. nous montrons sur ces données que ce type de prétraitement apporte de large bénéfices.
termith-eval,test_sciencesInfo_05_0094350_tei,construction et utilisation de contextes autour des noeuds d un hypertexte pour la recherche d information. nous faisons l hypothèse que la mise sous forme hypertexte d un document atomise l information dans le sens où les noeuds de l hypertexte qui sont créés ne sont pas auto suffisants pour pouvoir être appréhendés. sous cette hypothèse le contenu seul de le noeud n est pas suffisant pour l indexer dans un but de l insérer dans un système de recherche d information. nous avons implémenté et testé une méthode de construction de contextes autour des noeuds d un hypertexte en utilisant une méthode de classification automatique. cette dernière est basée sur une mesure de similarité entre les noeuds prenant en compte à la fois les aspects structurels de l hypertexte à savoir les liens entre les noeuds et le contenu textuel des nœuds. notre système de recherche d information indexe à la fois les noeuds et leurs contextes. le modèle de requête que nous utilisons est à deux niveaux niveau sujet et niveau contexte.
termith-eval,test_sciencesInfo_05_0351076_tei,documents statiques et multimodalité l alignement temporel pour structurer des archives multimédias de réunions. cet article illustre le rôle central que peuvent jouer les documents statiques dans des applications multimodales et en particulier dans l analyse et l indexation d enregistrements de réunions. l article montre ainsi l apport des structures de documents pour segmenter des réunions tâche complexe en utilisant uniquement l audio et la vidéo et propose quatre étapes afin de lier temporellement les documents et des données multimédias de réunions. d abord une installation permet d enregistrer toutes les modalités d une réunion audio vidéo document etc. une méthode hybride d analyse crée ensuite une représentation multicouche des documents électroniques. les documents ainsi représentés sont ensuite alignés avec la parole et la vidéo. finalement une interface utilisateur basée sur les documents et bénéficiant de tous les liens temporels construits permet de naviguer sur des archives multimédias de réunions.
termith-eval,test_sciencesInfo_05_0351805_tei,le temps dans les documents audiovisuels. cet article présente différents aspects de la structure temporelle des documents audiovisuels émissions télé ou radiodiffusées principalement. il décrit tout d abord les spécificités de ces documents quant à la notion de temps avant d examiner la manière dont ces aspects peuvent être exploités automatiquement à des fins d analyse et de documentation et les problèmes que cela pose.
termith-eval,test_sciencesInfo_06_0253613_tei,caractères codage et normalisation de chappe à unicode. la transmission de l information s est faite d abord de façon visuelle fanions de la marine télégraphe chappe morse etc avant d être électrique télex puis informatique. nous présentons l évolution des divers codages de caractères liés et les normes associées iai télex bcd ascii latin n et enfin unicode. cet aperçu historique nous permet de préciser à l occasion divers concepts tels que codage caractère glyphe norme standard etc.
termith-eval,test_sciencesInfo_06_0253614_tei,introduction à unicode et à l iso 10646. cet article présente les points saillants de la version 3 2 de le standard unicode et son pendant iso la norme internationale iso cei 10646. l article répond tout d abord à quelques questions fréquentes qu est ce qui a poussé à le développement de cette norme. quels en sont les principes de conception. quels caractères normalise t elle. qu est ce qu un caractère un glyphe. comment doit on coder les suites de caractères les caractères accentués. suit un bref examen de le modèle de codage des caractères et des formes normalisées de représentation des données. enfin l article conclut par une description de deux processus fondamentaux et leur rapport avec unicode le tri et le rendu.
termith-eval,test_sciencesInfo_06_0253617_tei,apports d unicode à l édition numérique multilingue une étude de cas à le niger. cet article met en évidence l apport d unicode à le traitement des documents multilingues en afrique à partir d une expérience concrète à le niger. nous analysons d abord les liens entre l informatisation des langues et leur écriture puis nous donnons un aperçu des difficultés que pose le multilinguisme à l édition assistée par ordinateur en étudiant le processus éditorial dans un institut de documentation nigérien. nous montrons alors en quoi le standard unicode peut rendre ce processus plus efficace avant de décrire plusieurs solutions à les difficultés rencontrées en fonction des outils informatiques disponibles actuellement et à l avenir.
termith-eval,test_sciencesInfo_06_0278930_tei,calcul de pertinence basée sur la proximité pour la recherche d information. le domaine de la recherche d information bien connu à travers les moteurs de recherche sur le web utilise différents modèles comme le modèle booléen le modèle vectoriel et la recherche de passage. d autres approches prenant en compte la proximité des termes de la requête retrouvés dans les documents ont aussi prouvé leur efficacité. dans ce contexte nous posons l hypothèse suivante plus les termes de la requête se retrouvent proches et ceci le plus grand nombre de fois dans un document alors plus ce document doit être positionné en tête de la liste des réponses retournée par le système de recherche d information. tout d abord nous rappelons les diverses approches liées à notre recherche ensuite nous proposons une méthode de calcul de pertinence basée sur la proximité floue en chaque endroit de le texte d un document nous attribuons un degré de proximité floue à la requête puis nous montrons que notre méthode peut simuler le comportement des méthodes classiques. avant de conclure nous présentons les résultats des expériences ménées sur la collection clef 2004.
termith-eval,test_sciencesInfo_06_0278931_tei,catégorisation de textes en domaines et genres complémentarité des indexations lexicale et morphosyntaxique. cet article traite de le choix de descripteurs linguistiques appropriés pour caractériser et classifier les textes. on considère généralement que les domaines sont corrélés à le niveau de le contenu mots termes etc tandis que les genres sont discriminés à le niveau morphosyntaxique. malgré les bons résultats obtenus par ces choix méthodologiques peu de travaux ont cherché à mesurer l impact et la complémentarité des deux niveaux de description pour la classification. cette étude vise ainsi à évaluer l intérêt discriminant des descripteurs morphosyntaxiques et thématiques pour classer les genres et les domaines. des résultats encourageants sont obtenus sur un corpus pilote de textes scientifiques français.
termith-eval,test_sciencesInfo_07_0339588_tei,la mise à disposition des ressources électroniques dans les bibliothèques européennes. l apparition de ressources électroniques a constitué pour les bibliothèques une profonde révolution les incitant à travailler davantage en réseau et à développer de nouveaux outils et compétences. cette étude analyse les modalités de mise à disposition de ces ressources dans les bibliothèques universitaires et de recherche en europe. elle se penche sur les outils d accès portails et bibliothèques numériques  puis sur les systèmes d acquisition consortiums et agences nationales et sur le problème de l archivage et de la préservation des données. pour aborder enfin les perspectives en matière de nouveaux services et la situation des bibliothèques par rapport à les autres acteurs sur le marché de l édition scientifique.
termith-eval,test_sciencesInfo_07_0417635_tei,interactions et métadonnées riches pour les bibliothèques numérisées. les interfaces des bibliothèques numériques d aujourd hui ne transcrivent qu une partie des activités qu effectue un usager de bibliothèque. nous présentons dans cet article quelques expériences visant i à étudier l intérêt de métaphores d interaction 3 d pour la lecture et la navigation dans de grands corpus textuels numérisés 2 à permettre l acquisition de métadonnées décrivant l aspect physique des ouvrages.
termith-eval,test_sciencesInfo_07_0502530_tei,la longue marche de l information publique de la liberté d accès à les documents administratifs à la réutilisation commerciale des informations publiques. transposant en droit français une directive européenne de 2003 une ordonnance de juin 2005 a mis fin à l interdiction faite à les citoyens d utiliser à des fins commerciales des documents d origine administrative et consacré un droit à la réutilisation des données publiques. cette initiative est l aboutissement d une réflexion engagée depuis plus de vingt ans en france et dans l union européenne sur les modalités de réutilisation des informations de le secteur public. après avoir rappelé cette évolution de la loi française de 1978 sur la liberté d accès à les documents administratifs à les dispositions les plus récentes cet article analyse les acquis de la nouvelle législation ses insuffisances et sa mise en oeuvre.
termith-eval,test_sciencesInfo_07_0504918_tei,bâtir un portail de bibliothèque ou de centre de documentation un morceau de bravoure. depuis quelque temps des grands services et établissements documentaires proposent à leurs usagers des portails supports d une offre de services en ligne attrayante et diversifiée. la mise en oeuvre de tels portails est une opération délicate qui exige des moyens importants quelques précautions et une bonne maîtrise des composantes des outils logiciels disponibles sur le marché le système de gestion de contenu aide à la publication sur le web et la recherche fédérée consultation simultanée de plusieurs sources.
termith-eval,test_sciencesInfo_07_0514619_tei,rendu de polices sur écrans à cristaux liquides précision d affichage sur écran à faible définition et conseils de conception. les écrans lcd sont de plus en plus souvent utilisés pour afficher de le texte destiné à une lecture immersive. la précision d affichage et la possibilité accrue de le contrôle de l image de ces écrans restent encore bien inférieures à celles des procédés d impression papier. le processus de conception numérique de fontes permet une précision peut être jamais égalée dans l histoire de la typographie. cependant l affichage final sur écran comporte de multiples facettes qui doivent être comprises et maîtrisées pour exploiter à le mieux ce support. cet article ne parle pas de lisibilité mais concerne uniquement la précision et les limitations de l affichage écran. les termes processus et contraintes techniques nécessaires à la compréhension de le sujet sont préalablement expliqués sont ensuite effectués des tests d affichage basés sur quelques caractéristiques fondamentales comme le rendu des variations de graisses l inclination les courbes et finalement la qualité des glyphes dans toute leur complexité. finalement sur la base de ces observations sont élaborés des conseils pour le dessin de caractères destinés à l affichage sur écran à cristaux liquides.
termith-eval,test_sciencesInfo_07_0514620_tei,systèmes typographiques intelligents et souples. l incertitude concernant la guerre des polices est révolue. nous avons aujourd hui de puissants ordinateurs des systèmes de visualisation et d impression à différentes définitions et une kyrielle de programmes pour saisir et formater les textes. nous avons aussi désormais accès à des fonctionnalités typographiques subtiles programmables et sensibles à le contexte. ces documents peuvent être diffusés sur la toile dans de nombreuses langues et dans des fichiers multiplateformes. mais nous avons peut être perdu quelque chose en chemin. il est temps d évaluer le travail effectué par les grands pionniers de la typographie numérique et d appliquer leurs belles idées à notre domaine de recherche. les formats de police standard postscript truetype et opentype sont parfois trop rigides pour certains concepteurs de police c est pourquoi nous nous penchons dans cette communication sur les systèmes typographiques intelligents et souples comme metafont et les expériences de la fin des années 80 jacques andré letterror hermann zapf parmi d autres et les développements intéressants de le milieu des années 90 ares chameleon incubator intellifont qui ont malheureusement disparu sous la pression de le marché. selon nous ces idées ne devraient pas être oubliées c est pourquoi nous présentons ci dessous quelques progrès récents réalisés dans la mise à le point d un nouveau système nommé constructor particulièrement destiné à la création directement en langage postscript de polices paramétrées à l aide de connaissances calligraphiques similaires à celles utilisées dans metafont.
termith-eval,test_sciencesInfo_08_0071169_tei,quelle veille stratégique pour les pme de suisse romande. l objectif principal de le projet de recherche appliquée que présente cette étude était de sensibiliser des pme de suisse romande à la pratique de la veille en ligne et d évaluer les conditions de réussite de plusieurs expériences de veille stratégique sur les réseaux. après une présentation de la démarche et de la méthode adoptées par l équipe de la haute école de gestion de genève chaque phase de le cycle de le renseignement est analysée en détail et ses résultats évalués. à le terme de cette recherche exploratoire l auteure en tire des enseignements méthodologiques et dégage des perspectives pour concevoir des actions de soutien à la mise en place à le sein des entreprises d une veille permanente et réellement stratégique.
termith-eval,test_sciencesInfo_08_0113837_tei,indexation collaborative et folksonomies. à l heure où de multiples façons les consommateurs d information deviennent acteurs sur le web ils s approprient peu à peu les techniques et les outils qui étaient auparavant l apanage des professionnels de l i d. élie francis et odile quesnel présentent ici quatre modes d indexation et de classification sur la toile la classification personnelle l indexation par l auteur l indexation par l utilisateur et la classification globale. ils précisent ensuite les propriétés le fonctionnement et les raisons de le succès des folksonomies systèmes d indexation collaborative libre décentralisée et spontanée qui peuvent apporter le meilleur qualité d information mais dont on peut redouter le pire désinformation.
termith-eval,test_sciencesInfo_08_0113842_tei,de la compatibilité à l interopérabiiité en matière de repérage d information pertinente la problématique et l exemple d otaren. a partir de l exemple de l information pour et sur l éducation  cette dernière étude aborde la délicate question de la compatibilité et de l interopérabilité des langages documentaires conditions d un juste repérage de l information pertinente dans des sources de plus en plus nombreuses et volumineuses. françois feyler explique ici que lorsqu on est confronté à une multiplicité de systèmes d indexation il faut envisager un système d équivalence terminologiques entre les représentations de concepts présentes dans des langages contrôlés sans passer obligatoirement par une phase de modification de l indexation initiale. ce qu illustre le projet otaren développé par le cndp pour l éducation nationale.
termith-eval,test_sciencesInfo_08_0133293_tei,interprétation vague des contraintes structurelles pour la ri dans des corpus de documents xnl évaluation d une méthode approchée de ri structurée. nous proposons des algorithmes dédiés à l indexation et à la recherche approximative d information dans les bases de données hétérogènes semi structurées xml. le modèle d indexation proposé est adapté à la recherche de contenu textuel dans les contextes xml définis par les structures d arbres. les mécanismes de recherche approchée mis en oeuvre s appuient sur une distance de levenshtein modifiée et des heuristiques de fusion d information. une implémentation exploitant simultanément l information structurée i e l arborescence des éléments xml et le contenu des documents indexés est décrite. les performances obtenues dans le cadre de la campagne d évaluation inex 2005 sont présentées et analysées. celles ci positionnent l approche proposée parmi les meilleurs systèmes évalués sur la tâche de recherche approximative de contenu en contexte structurel vague.
termith-eval,test_sciencesInfo_08_0148089_tei,journee d etude adbs gestion de contenu diversité des approches. dans le cadre de le forum des acteurs de le numérique organisé par l aproged l adbs proposait le 9 octobre 2007 une demi journée d étude centrée sur la gestion de contenu. de plus en plus souvent utilisée dans les entreprises cette notion concerne la chaîne de l information le cycle de vie de le document la production d information pour le web. après un examen approfondi des fonctions nécessaires pour qu un outil puisse être considéré comme capable d assurer une fonction globale ont été présentées deux applications récemment mises en œuvre par l oppbtp et par le cniel.
termith-eval,test_sciencesInfo_08_0226813_tei,accès à le contenu des thèses numériques par leur structure sémantique. les projets de bibliothèques numériques actuels offrent à l utilisateur l accès à les thèses à partir d une recherche qui ne permet pas d extraire les parties pertinentes de la thèse et ne renvoie que la thèse intégrale. ainsi l utilisateur doit lire des chapitres entiers pour connaître les parties qui correspondent à son besoin. le projet cither consultation en texte intégral des thèses en réseau de l insa de lyon dans lequel s inscrit cette étude porte sur la mise en ligne des thèses. nous proposons de permettre un accès pertinent à le contenu des thèses grâce à l utilisation de tags sémantiques rajoutés par le doctorant à le sein de sa thèse lors de la rédaction. l exploitation de ces tags permet de cibler la recherche et ainsi mieux satisfaire l utilisateur. notre travail porte d une part sur la constitution d une base de concepts utilisés pour le tagage de la thèse et d autre part sur la définition d un nouveau modèle de documents à partir des différentes structures de la thèse.
termith-eval,test_sciencesInfo_08_0277606_tei,le document numérique entre préservation et usage application à le document technique support à les activités de le cycle de vie produit. la documentation technique de systèmes complexes est aujourd hui issue d un ensemble de bases de données et de documents édités numériquement et cet ensemble est mis à jour et enrichi pendant le cycle de vie de le produit. après une description de le contexte de la documentation technique et un rappel des résultats d enquêtes sur l utilisation de la documentation numérique nous présentons un cadre théorique pour mieux appréhender le système documentaire en relation avec ses utilisateurs et avec le système technique. nous proposons un modèle uml de référentiel numérique pour satisfaire les exigences de préservation à long terme et mieux supporter les besoins d utilisation de ce référentiel.
termith-eval,test_sciencesInfo_08_0479826_tei,tendances de la recherche nord africaine en science de l information entre théorie et application. étude quelle est la physionomie de la recherche en bibliothéconomie et science de l information en afrique de le nord. wahid gdoura étudie dans cet article 1 l évolution récente et la situation de ce secteur de recherche dans ses rapports avec les mutations de celui de l information. après s être penché sur les conditions et les moyens de la recherche et de la publication scientifiques dans six pays il analyse les caractéristiques de base de leur production. le volume de celle ci est encore modeste et son contenu est marqué par la prédominance des études appliquées et la relative absence de travaux théoriques et méthodologiques. des propositions pour développer une recherche théorique nord africaine concluent cette étude.
termith-eval,test_sciencesInfo_09_0148886_tei,stratégies de recherche dans la blogosphère. cette communication présente les principaux problèmes liés à la recherche d information dans la blogosphère. recourant à le modèle vectoriel tfidf ainsi qu à trois approches probabilistes et un modèle de langue cet article évalue leur performance sur un corpus trec extrait de la blogosphère et comprenant 100 requêtes. les raisons expliquant les faibles performances sont exposées. basés sur deux mesures de performance nous démontrons que l absence d enracineur s avère plus efficace que d autres approches enracineur léger ou celui de porter. imposer la présence côte à côte de deux mots recherchés dans la réponse fournie permet d accroître significativement la performance obtenue.
termith-eval,test_sciencesInfo_09_0148889_tei,un tour d horizon des approches pour la manipulation des données de le web. le passage à le web 2 0 a renforcé le principe selon lequel les données doivent être séparées de leurs présentations. en même temps le nombre des formats de documents xml a largement évolué sur le web. les bases de données sont également utilisées pour le fonctionnement des sites. ces constats impliquent la mise en oeuvre d approches et d outils associés dédiés à la manipulation des données de le web. certaines de ces approches travaillent directement sur les données tandis que d autres se basent sur les schémas de ces mêmes données. l ingénierie dirigée par les modèles idm forme également une approche candidate à la manipulation des données de le web. dans cet article nous présentons et comparons les différentes techniques majeures de manipulation de données afin de mettre en exergue leurs avantages et leurs inconvénients pour le problème des données de le web.
termith-eval,test_sciencesInfo_09_0255892_tei,un format de partitions interactives. nous présentons dans cet article un format xml créé pour coder les partitions interactives générées via le système iscore. le développement de iscore est l aboutissement de travaux de recherche menés à le labri en collaboration avec l ircam visant à aboutir à un système de partitions interactives pour la composition et l interprétation basé sur des contraintes temporelles. la question de le format de sauvegarde des documents édités à le travers de ce système s est rapidement posée et devant les évolutions récentes vers les technologies xml nous avons décidé d y répondre par la rédaction d une dtd document type définition. pensé à la base comme support pour le système de sauvegarde de iscore ce format pourrait également servir d interface avec d autres formats xml et participer à l élaboration d un format général de partitions numériques.
termith-eval,test_sciencesInfo_09_0255895_tei,gsharp un éditeur de partitions de musique interactif et personnalisable. dans cet article nous présentons gsharp un projet dont le but est la création d un éditeur de partitions de musique traditionnelles. le logiciel gsharp est écrit en common lisp et utilise clim common lisp interface manager comme bibliothèque pour l interaction avec l utilisateur. de nombreux algorithmes et structures de données ont été inventés afin d assurer une performance acceptable pour de simples interactions comme l insertion ou la suppression d une note ou d un accord.
termith-eval,test_sciencesInfo_09_0295423_tei,l ancrage des savoirs des professeurs documentalistes en sic question de professionnalisation et d identité. qu est ce qui permettrait de faire avancer le métier des professeurs documentalistes de l enseignement secondaire français vers une plus grande professionnalisation et vers une stabilisation identitaire. c est cette question que cet article tente d éclairer en rapprochant les résultats de deux recherches menées à le sein de l éducation nationale et de l enseignement agricole. après un rappel de l histoire de la documentation scolaire et un examen de la situation des documentalistes à la fois gestionnaires et enseignants dans l enseignement secondaire viviane couzinet et cécile gardiès se penchent ici sur le territoire scientifique des professeurs documentalistes et sur leur identité disciplinaire face à les sciences de l information et de la communication.
termith-eval,test_sciencesInfo_09_0474880_tei,quand les moteurs de recherche appellent à le jeu usages ou detournements. moteurs de recherche. usages et enjeux. certains internautes utilisent les moteurs de recherche non pas pour chercher de l information mais pour d autres buts. dans cette contribution nous nous intéressons à les applications ludiques créées par le moteur commercial google et autour de lui. à partir d une analyse de l interface nous identifions d abord dans le moteur de recherche les traces de l appel à le jeu. dans un second temps nous analysons certains jeux créés par ou autour de le moteur les caractéristiques qu ils mettent en exergue et les représentations sous jacentes. loin d être anecdotiques ces exploitations ludiques permettent d analyser plusieurs aspects des dispositifs sous jacents ainsi que la manière dont le moteur transforme l activité de recherche d information.
termith-eval,test_sciencesInfo_09_0474882_tei,vie privée et quête de la perfection des moteurs de recherche audiovisuels moteurs de recherche. usages et enjeux. l internet devient de plus en plus une plateforme de création de stockage et de partage de contenus multimédias produits par les utilisateurs. par conséquent les fournisseurs de moteurs de recherche s efforcent d étendre les fonctionnalités et la portée de leurs technologies pour rendre ces contenus audiovisuels aussi universellement accessibles et utiles que leurs homologues textuels. cependant l émergence d outils de recherche audiovisuels puissants suscite de nouvelles inquiétudes quant à la façon dont les moteurs de recherche s immiscent dans la vie privée. cette contribution fait le point sur certaines technologies émergentes de recherche dans les données audiovisuelles comme l intégration des images produites par les utilisateurs dans les index des moteurs le marquage et les métadonnées enrichies des photographies ainsi que les outils de reconnaissance faciale destinés à les utilisateurs. en outre elle montre comment dans le contexte de la quête de la perfection des moteurs de recherche ces technologies sont une source de préoccupation croissante pour la protection de la vie privée.
termith-eval,test_sciencesInfo_09_0474883_tei,attentes versus réalité. les fonctionnalités nécessaires à les moteurs pour la recherche web en 2008 moteurs de recherche. usages et enjeux. les chercheurs qui analysent le web s appuient sur des données qui sont souvent collectées à l aide des moteurs de recherche. dans une précédente contribution bar ilan 2005  l auteur a proposé une liste d objectifs pour le moteur de recherche idéal en expliquant le besoin de fonctionnalités spécifiques pour ce type d activité. ici il revisite cette liste et examine si les principaux moteurs de recherche actuels peuvent répondre à le moins partiellement à les exigences de l outil de recherche idéal. les principaux outils de recherche sont commerciaux et destinés à l utilisateur moyen et non à le chercheur scientifique qui analyse le web ils ne peuvent donc pas satisfaire toutes les demandes.
termith-eval,test_sciencesInfo_10_0023556_tei,l écoute de la radio en france. hétérogénéité des pratiques et spécialisation des auditoires. les pratiques radiophoniques sont assez peu étudiées par la sociologie y compris d un point de vue statistique. cet article revient sur la suspicion qui entoure leur mesure et défend une évaluation de l audience entendue comme jeu de langage. il se propose ensuite de décrire la structuration des usages et des liens à ce média à partir d une exploitation originale des données source de l enquête panel de médiamétrie de 2000 2001 sur 21 jours. en s appuyant sur une série de données de fréquence d écoute et de structure des auditoires on montrera que la consommation radiophonique est une pratique très typée temporellement mais que cette régularité recouvre une hétérogénéité tout aussi structurante de l auditoire de chaque radio. enfin revenant sur ce que michel souchon disait de le grand public de la télévision on attestera qu il y a en radio une logique de spécialisation des auditeurs sur les stations. tout porte ainsi à considérer la forte structuration des pratiques radiophoniques pour mieux comprendre dans quel cadre structuré risquent de s inscrire internet et le podcast comme nouvelles modalités d écoute de ce média.
termith-eval,test_sciencesInfo_10_0023559_tei,les règles de le médiateur de le monde ou la mise en scene d une ecriture de presse. le médiateur de le monde a suscité un certain intérêt des chercheurs en sciences sociales. pourtant les analyses ont laissé de côté une dimension importante de l écriture de médiation la propension de son titulaire à appuyer son argumentation sur le langage de la règle. le vocable règle  il y a des règles à respecter lorsque l on fait de le journalisme répète le médiateur revient avec une relative insistance. en appuyant son raisonnement sur des règles il a recours à une métaphore de type juridique. le médiateur laisse par là percevoir que le travail journalistique est un travail tendanciellement codifiable. il présente le journalisme comme une activité faites de limites ou de frontières. finalement médiateur paraît construire une grammaire qui concerne d abord l écriture de presse et ses agencements dans les rubriques de le journal.
termith-eval,test_sciencesInfo_10_0023560_tei,à propos de l institutionnalisation des sic. pour une histoire localisée. l article se propose de revenir sur les travaux récents que robert boure a consacrés à l histoire des sic pour en expliciter les principaux apports mais aussi pour dégager de nouvelles pistes de réflexion sur l institutionnalisation de cette discipline. l idée directrice qui sous tend le propos consiste à montrer que la compréhension de son édification comme celle d autres disciplines d ailleurs nécessite le recours à des études monographiques sur les lieux d enseignements et de recherche qui ont concouru à ce processus. pour ce faire il s agit de neutraliser les conceptions idéalistes et essentialistes de la discipline qui entravent le travail d objectivation et faussent le regard que l on porte sur son passé comme sur sa réalité présente.
termith-eval,test_sciencesInfo_10_0032248_tei,pour une conception éthique des débats politiques dans les medias. répondre de devant pour ou les défis de la responsabilité collective la responsabilité collective dans la presse. la responsabilité collective distincte de la culpabilité collective correspond à la façon dont un individu ou un groupe prend en compte les problèmes d une communauté qui aspire à faire société. cette notion est interrogée de le point de vue des journalistes et des responsables politiques en tant qu ils sont des médiateurs censés idéalement donner une forme argumentée à les conflits sur la scène publique. cette interrogation sera menée à propos de le deuxième débat entre prétendants à la candidature socialiste lors de la pré campagne des élections présidentielles françaises. elle mettra en avant l insuffisance des approches déontologiques journalistiques avec leurs rituels d objectivité et montrera que ces médiateurs sont profondément responsables de leurs discours et de leur mise en scène mais aussi de le choix ou de le non choix d exprimer les points de vue des différentes fractions de le corps social devant le corps social tout entier bref dans la façon dont ils portent la parole et témoignent dans le but de faire émerger un nous refondé à le terme de la représentation des conflits.
termith-eval,test_sciencesInfo_10_0065090_tei,agrégats de mots clés validés sémantiquement pour de nouveaux services d accès à l information sur internet. a l heure de le web social nous présentons une solution destinée à définir de nouveaux services tels que la construction automatique et dynamique de communautés d utilisateurs l agrégation de mots clés. ces agrégats de mots clés sont issus des recherches antérieures des utilisateurs réalisées à le travers d un moteur de recherche. nous présentons la démarche que nous avons suivie pour obtenir un algorithme de regroupement des mots clés provenant de fichiers de traçage log  nous illustrons cet algorithme à le travers de son application à le fichier de traçage de le moteur de recherche aol com. a des fins d évaluation et de validation nous proposons de comparer les résultats obtenus par le moteur de recherche à partir des agrégats de mots clés ainsi créés et de définir un coefficient de cohérence sémantique de ces agrégats. nous mesurons dans une expérimentation la perte de cohérence sémantique liée à l augmentation de la taille des agrégats. l intérêt de notre approche réside dans le fait qu elle peut être considérée comme une brique de base pour un grand nombre de systèmes communautaires et ainsi exploitée pour offrir encore plus de services à l usager.
termith-eval,test_sciencesInfo_10_0227867_tei,une apostille sur les images. le présent texte est une participation à les échanges avec daniel dayan suite à une entrevue réalisée avec le chercheur en 2005 par béatrice fleury et jacques walter pour la livraison 8 de la revue questions de communication. plutôt qu une reprise systématique des propos de celle ci centrée sur le traitement télévisuel l auteur propose de prolonger les réflexions de daniel dayan en s appuyant sur un choix d images relevant d autres genres ou médias en rapport elles aussi avec les représentations de la guerre. les quatre problèmes retenus sont la pauvreté informationnelle et l hostilité des représentations la composition des images devant l identité des victimes le contexte pragmatique de la monstration les relations entre le regard et le retrait de le regard.
termith-eval,test_sciencesInfo_10_0227890_tei,mise en scène des débats télévisés vers une socio sémiopolitique des plateaux de télévision. en tant que genre télévisé le débat peut donner lieu à des analyses longitudinales et historisantes destinées à cerner l évolution de l imaginaire de parole qui s y déploie. à l aide d une approche socio sémiopolitique il est possible de prendre pour repère non pas les thématiques arguments ou indicateurs langagiers à l œuvre dans ces débats mais les données situationnelles qui les structurent et les instituent. sur la base d un travail empirique prenant appui sur des débats diffusés par la télévision suisse romande tsr  une analyse de la scénographie et des mises en scène des espaces des plateaux de télévision a été menée. on propose alors un modèle d analyse de la situation de communication qui rend compte d une grammaire de l espace fondée sur un découpage de le territoire en unités d analyse lieu scènes emplacements  le postulat avancé étant que cette situation préfigure les interactions à venir et confère à les plateaux de télévision une portée symbolique.
termith-eval,test_sciencesInfo_10_0232427_tei,surveiller à distance et prévenir. une nouvelle économie de la visibilité. l usage de la vidéosurveillance a t il accru les capacités de l appareil policier pour contrôler et surveiller la population. cette étude tend à montrer que la réponse est négative. l éclatement de l espace urbain et l essor des agences locales polices privées et municipales  engagées dans la lutte contre l insécurité ont abouti à une fragmentation des connaissances acquises grâce à ces dispositifs techniques sur les populations à surveiller et ou à protéger. plus fondamentalement la diffusion de la vidéosurveillance dans les territoires urbains marque l émergence d une nouvelle économie de la visibilité dans l exercice de l ordre dont les principales caractéristiques sont décrites ici.
termith-eval,test_sciencesInfo_10_0245713_tei,la construction de l obésité dans l espace public suédois malades et maladies dans l espace public. partant de le constat que l espace public n a pas nécessairement toujours un rapport explicite avec les idéaux civiques et que les médias ont la responsabilité d accompagner les publics dans des choix pouvant influer sur leur santé cette contribution étudie la manière dont la presse quotidienne présente le thème de l excès de poids ou obésité en suède. après une prise en compte des multiples perspectives de recherche concernant le problème de l obésité deux cadrages dominants de la construction de l obésité sont ensuite traités raison et rationalité émotions et affects. enfin l importance de le genre masculin féminin et l opposition structurante divertissement vs information dans la construction médiatique de le surpoids sont analysées. à le terme de cette étude se dessinent les difficultés d une collaboration fructueuse entre journalistes et membres des professions médicales sur le problème de l obésité. pourtant  it takes two to tango  il faut être deux pour danser le tango. médecins et chercheurs doivent mieux adapter leurs manières de s adresser à le public et apprendre comment collaborer avec les journalistes de façon productive. mais journalistes et médias ont aussi une responsabilité si le public fait davantage confiance à les professionnels de la santé en ce qui concerne leur information ce n est pas de ceux ci que les individus reçoivent l information mais bien des médias.
termith-eval,test_sciencesInfo_10_0245714_tei,la santé à la télévision émergence d une question sociale malades et maladies dans l espace public. la place de la santé à la télévision française a évolué. un temps cantonnée à les émissions spécialisées la thématique a lentement irradié les émissions de société puis toute la grille de programmation. la santé a ensuite quitté la sphère scientifique et médicale ce qui est analysé ici à travers l utilisation et le rôle des témoignages. ces mutations sont révélatrices de deux phénomènes d une part des enjeux socioprofessionnels tant pour les médecins que pour les journalistes mais aussi pour les hommes politiques les malades et les associations d autre part de le phénomène de socialisation de la maladie notamment sous l action des médias de masse.
termith-eval,test_sciencesInfo_10_0245724_tei,les logiques d une consécration journalistique. l exemple des 50 meilleurs hôpitaux de france  malades et maladies dans l espace public. depuis bientôt une dizaine d années paraissent à le moins une fois par an des palmarès des meilleurs hôpitaux de france qui pour leur majeure partie sont produits par une équipe de trois journalistes. le succès qu ils rencontrent est tel qu une société d assurances s est récemment associée à eux pour proposer à ses clients un service téléphonique d orientation vers le meilleur hôpital. si d une manière générale ces classements sont révélateurs d une extension continue des personnes autorisées à parler des choses de santé et d une évolution dans les représentations de l hôpital on questionnera ici plus précisément les logiques de la consécration journalistique. en rappelant dans un premier temps les conditions de production des critères de classification on montrera que ce pouvoir de consécration médiatique réside d abord dans la capacité des journalistes à coordonner les différentes logiques médicale économique et juridique en présence. on pourra alors en prenant l exemple d un hôpital prédisposé à la consécration journalistique rappeler que ces logiques de consécration doivent être appréhendées comme un processus dynamique et comme le résultat d interactions entre classeurs et classés.
termith-eval,test_sciencesInfo_10_0280742_tei,le malentendu comme structure de la communication pathologies sociales de la communication. dans les modèles télégraphiques on considère que la communication fonctionne si les messages de départ et d arrivée sont identiques. sinon cela signifie que le récepteur a mal compris ou que l émetteur s est mal fait comprendre. dans ce cadre la pathologie de la communication est l incompréhension. ce que nous proposons ici à partir de l analyse de situations de communication très particulières des rencontres enchantées avec des dauphins sauvages  c est que à l inverse la structure fondamentale de la communication est le malentendu. or c est le refus de reconnaître ce fait dû notamment à le désir vain et désastreux de contrôler le partenaire qui engendre des pathologies. admettre à le contraire qu émetteur et récepteur disposent nécessairement de versions différentes de l interaction et qu il n y a pas de version plus objective qu une autre c est replacer l altérité à le cœur d une communication qui est réussie parce qu on accepte de mal se comprendre.
termith-eval,test_sciencesInfo_10_0286329_tei,censure répressive et censure structurale comment penser la censure dans le processus de communication ş pathologies sociales de la communication. la censure est elle sur le point de disparaître de le paysage des pays occidentaux. il semble que oui tant ses manifestations font de plus en plus figure de scandale alors que son but principal à le xixe siècle était précisément d éviter le scandale cette explosion dangereuse et coûteuse pour l ordre politique et social. pourtant la censure a moins disparu qu elle ne s est transformée prenant d autres formes en particulier judiciaires et même invisibles. dans cette contribution nous interrogeons donc la portée heuristique de l élargissement de le sens de la censure pour déterminer si celle ci est une pathologie de le processus de communication ou bien à le contraire l une de ses composantes essentielles.
termith-eval,test_sciencesInfo_10_0286330_tei,l artthérapie à le secours de la communication. diagnostic d une médiation manquée pathologies sociales de la communication. l utilisation de l art en psychiatrie recouvre actuellement une multitude de pratiques dont les visions entrent souvent en conflit. ces pratiques impliquent néanmoins une conception commune de l art comme outil de communication. une perspective selon laquelle la création se voit investie de le rôle de médiateur  capable de rétablir le contact entre par exemple le malade et le personnel soignant ou entre l aliéné mental l aliéné social qu a fait de lui l internement et l extérieur. approcher l art thérapie à travers le prisme de la communication ne revient pas seulement à ouvrir un angle de recherche nouveau mais conduit surtout à interroger ce dispositif dans ses fondements et donc à le mettre en question.
termith-eval,test_sciencesInfo_10_0300848_tei,pour une histoire genrée des médias. cet article voudrait montrer l importance de la prise en compte de l histoire dans l étude des rapports entre le gender et les médias. ce retour en arrière est plein d enseignements. d abord il confirme et valide historiquement que la presse constitue généralement un instrument qui conforte et fait circuler les discriminations et les préjugés sexués en même temps ces recherches permettent de mettre à le jour un rôle certain de la presse et pas seulement de la presse féministe dans la transgression progressive de certaines barrières. ceci est particulièrement vrai dans le domaine des écritures de presse où les quelques femmes à le xixe siècle qui ont réussi à s introduire dans les milieux journalistiques ont parfois innové. ultimement cela invite à remettre en cause les histoires traditionnelles de la presse qui ont notamment occulté les inventions médiatiques et poétiques des femmes journalistes.
termith-eval,test_sciencesInfo_10_0302457_tei,un modèle de grille d analyse des documents scientifiques application à la veille sanitaire de défense. élude un service de veille scientifique est amené à collecter une masse importante de documents de qualité variable. pour identifier les plus pertinents d entre eux l unité de veille sanitaire de l institut de médecine tropicale de le service de santé des armées imtssa a élaboré une grille d analyse en sept étapes. en tenant compte de la rigueur de le contenu et dans le cas d un article de le facteur d impact de la revue de publication et de le niveau de preuve de l étude cette grille permet d estimer la valeur scientifique d un document. marc tanti en collaboration avec christian hupin jean paul boutin et parina hassanaly présente dans cet article la grille qu ils ont conçue fondée sur des critères définis et quantifiables puis expose et discute les résultats qu ils ont obtenus dans le domaine de la veille sanitaire de défense. un modèle qui pourra être transposé avec profit dans d autres secteurs de recherche.
termith-eval,test_sciencesInfo_10_0305510_tei,l intelligence collective  anatomie d un poncif pathologies sociales de la communication. il y a plus d une quinzaine d années les discours d accompagnement de l internet ont consacré le retour des conceptions de marshall mc luhan réactualisées et recyclées mais également de la mystique développée par pierre teilhard de chardin dont participe le concept malléable d intelligence collective. reposant sur l analogie entre le fonctionnement de le cerveau la structure de le réseau de télécommunications et la représentation de le corps humain comme un réseau sanguin et nerveux l intelligence collective résulterait de l interconnexion des cerveaux et des ordinateurs à l échelle planétaire. si le concept de système nerveux appliqué à l internet ne fait pas figure de nouveauté son usage permet de lire tout concept juridique à le miroir de l analogie avec le cerveau à le service de propositions politiques puisant dans la doxa néo libérale déréglementation libéralisation effacement de l état .
termith-eval,test_sciencesInfo_10_0351924_tei,contribution d une démarche quantitative à l analyse des flux médiatiques d information. comment appréhender les flux médiatiques d information qui fabriquent l actualité. cette contribution propose de restituer à l information une partie de son sens en la replaçant dans le flux dont elle procède et qu elle produit. l attribution standardisée de descripteurs rédactionnels permet de multiplier les prises sur des corpus volumineux de sujets le matériau devenu descriptible dans le temps gagne en intelligibilité par le recours à l inférence statistique. une saisie macroscopique et diachronique de l information est rendue possible qui invite à découvrir les structures les dynamiques et les événements saillants à partir desquels se fabrique l actualité médiatique et au delà l espace public. cette méthode est présentée par les résultats qu elle a fournis pour analyser dix ans d information sportive dans les journaux télévisés hertziens français. pour autant l outil n explique pas par lui même et suppose de multiplier les questions de recourir à d autres savoirs pour rendre intelligible ce qu il donne à lire autrement. cette forme de travail ouvre ainsi moins des questions que de nouvelles voies pour produire des indicateurs permettant d y répondre.
termith-eval,test_sciencesInfo_10_0351927_tei,construction d un dispositif méthodologique et de ses outils savoir commun et savoir scientifique de l induction à les hypothèses. nous désirons expliciter la construction de le dispositif méthodologique mis en place dans la phase de récolte des matériaux nécessaires à notre travail de thèse portant sur les rites d interaction et les logiques d action mises en place à le sein de groupes interdisciplinaires. nous commencerons par une réflexion sur le choix d une démarche tendant vers l induction. nous expliquerons notre choix de travailler dans un mouvement de continuel va et vient entre le terrain et les approches théoriques pouvant éclairer notre problématique. dans un second temps nous discuterons de notre position face à la rupture épistémologique à le sens classique de le terme qui voudrait que savoir commun et savoir scientifique soient séparés par des frontières étanches. nous défendrons l idée que l acteur produit une connaissance réflexive sur lui même et sur ses propres expériences. approcher ce type de savoir nécessite de solides outils méthodologiques. nous expliquerons pourquoi nous avons choisi de croiser trois méthodes l observation participante la méthode d analyse en groupe et les entretiens semi directifs en justifiant ce choix en fonction de notre objet de recherche et des savoirs que ces différentes méthodes permettent d appréhender.
termith-eval,test_sciencesInfo_10_0384087_tei,usages de l innovation interactive. l analyse d usages de l interactivité non conventionnelle proposée par les sites de netart permet de saisir un désir d agir déstabilisé. en effet les internautes revendiquent une posture interactive selon les normes standard hypermédiatiques. cependant ils ne se bornent pas à réagir à les propositions en ligne ils tâtonnent cherchent des repères et s engagent dans des interprétations des critiques tant des technologies que des situations de communication. ils apprécient alors la désorientation qui provoque de nouvelles compétences ou émotions dans l environnement numérique. entre l envie de l inconnu et l exigence de repères les usagers se retrouvent dans une ambivalence qui met en tension l expérience interactive.
termith-eval,test_sciencesInfo_10_0384089_tei,campus numériques retour sur une politique ambitieuse d enseignement supérieur à distance. cet article est construit autour de deux points forts. il porte d abord un regard critique sur la modernisation de l enseignement supérieur par le recours à l enseignement à distance pour aborder par la suite les problèmes de déploiement de ce mode d enseignement à le sein des universités. au delà des aspects technopédagogiques souvent évoqués pour expliquer ces difficultés l article défend la thèse selon laquelle les orientations politiques des établissements et les préoccupations économiques ont fortement pesé sur les structures et sur les stratégies de l insertion de ce mode de formation dans les universités. pour conforter cette hypothèse l article s appuie sur les résultats d études menées sur le consortium e miage et sur le dispositif de formation à distance de l université de picardie.
termith-eval,test_sciencesInfo_11_0000205_tei,la culture de l information et l héritage documentaire. étude avec la société de l information est apparue la notion de culture de l infor mation qui bien au delà des professionnels concerne aujourd hui tout un chacun. en s appuyant sur la littérature scientifique et sur une enquête menée auprès des acteurs de terrain olivier le deuff montre dans cet article l influence de la documentation et des professionnels de l information documentation sur ce concept de culture de l information. il évoque notamment l héritage des techniques documentaires en tant que technologies de l intelligence et l influence des associations professionnelles dans l émergence et la construction de le concept. ce dernier s inscrit dans la poursuite pédagogique et scientifique d une politique de rationalisation dont relève désormais la didactique de l information.
termith-eval,test_sciencesInfo_11_0025183_tei,les journalistes comme scientifiques. notes pour une classification professionnelle journalistes et sociologues. retour sur des luttes pour écrire le social. ces notes tentent de définir la profession journalistique à le moyen d une comparaison avec les professions libérales et les professions scientifiques. comme les professions libérales les journalistes ont le sens de le service public et s occupent des désordres vécus par les individus. cependant ils n ont pas de contacts directs avec leurs clients et ne proposent ni diagnostic ni traitement. la comparaison avec les scientifiques en particulier les sciences appliquées parait plus pertinente. les journalistes ont une théorie intuitive de le monde social une théorie volontariste de l action avec des grands hommes et des événements décisifs  ils connaissent la dynamique des événements et parviennent à anticiper sur l inattendu. cependant bien qu ils produisent une forme de vérité socialement construite ils manquent de méthodes scientifiques éléments que les écoles formant à la communication pourraient mieux leur transmettre.
termith-eval,test_sciencesInfo_11_0029020_tei,médias et milieux d affaires. des vieilles polémiques à le renouvellement de la problématique. une approche scientifique des relations entre médias et milieux d affaires ne peut se réduire à les déclarations d intentions des professionnels de la presse concernant l autonomie présumée de leur sphère d activités à l égard des puissances d argent  à la description de prétendus réseaux de collusion occultes auxquels participerait l élite des médias vision par trop instrumentaliste de la question ou encore à cette littérature anglo saxonne tout à la fois ultra globalisante et hyper individualiste consacrée à les media moguls et autres tycoons. le renouvellement de la problématique en question exige à le contraire que l on opère une rupture avec ces représentations psychologisantes et moralisatrices des pratiques sociales. la sociologie critique des administrateurs des groupes médiatiques s avère être à cet égard un point d entrée particulièrement précieux pour repenser les articulations entre information économie et société et cela en évitant l écueil d une certaine forme d académisme en matière de sciences sociales.
termith-eval,test_sciencesInfo_11_0031650_tei,d un no u turn en sciences de l information et de la communication. le genre théorie études ou point de vue. si les sciences de l information et de la communication sic ont manqué le turn peut être ce dernier n est il pas celui auquel on pense dans la dernière livraison des échanges de questions de communication. à le tournant de le genre nous opposerons celui de la philosophie de la phénoménologie de l anthropologie et de la sociologie. en effet la première série des échanges sur le genre invite à distinguer en retour de ces contributions inaugurales une approche fondée sur l objet en l occurrence le genre et plus trivialement ici la femme d un courant théorique le constructivisme et ce faisant à pointer une des limites mêmes de ce courant ou en tout cas de ses non appropriations abusives l amalgame de la théorie des études et de l opinion. pour finir de se demander si par le biais de le genre  les sic ne réclameraient pas tout simplement l usage des théories concepts et méthodes promus et portés par la philosophie l anthropologie et la sociologie. si le genre devait se fonder en discipline autonome il conviendrait alors sans doute de renverser la direction de l analyse et plutôt que de se demander ce que le genre apporterait à les sic se demander ce que les sic apporteraient à le genre.
termith-eval,test_sciencesInfo_11_0031651_tei,de le genre à le sénégal. un objet de recherche émergent. l objet de cet article est de montrer l historicité de le genre en sciences humaines et sociales à le sénégal via la manière dont certaines chercheuses l ont intégré dans le champ universitaire et par conséquent ses applications très récentes dans certaines formations diplômantes. par ailleurs plusieurs approches de le genre seront explorées quelques unes montrant un détachement absolu de toute empreinte occidentale d autres évacuant l aspect dualiste masculin féminin voire l éventuelle opposition homme femme. enfin les nuances et complexités conférées à ce terme tant dans la recherche que dans la vie quotidienne seront questionnées. à l identique le genre sera repensé à le vu de ce que des femmes immigrées vivant en france et originaires de le sénégal expriment via des actions publiques et collectives.
termith-eval,test_sciencesInfo_11_0059500_tei,documents électroniques et soins de santé. l utilisation de documents cliniques à le cours de la pratique médicale ne répondra à les besoins réels des praticiens que dans la mesure où elle correspondra véritablement à leur démarche clinique. plutôt qu à un dispositif de gestion électronique de documents ou à un empilement de documents figé un clinicien doit pouvoir accéder en un temps très court à les données précises à jour et exactes dont il a immédiatement besoin. l organisation des systèmes d information et la structure des documents doivent permettre la sélection et l extraction des seules données jugées nécessaires par le clinicien accompagnées de la description de le contexte de leur recueil. ce sont des données granulaires qu il s agit à la demande en toute sécurité et en plein respect de la confidentialité d identifier et d extraire d un système réparti.
termith-eval,test_sciencesInfo_11_0059503_tei,gestion décentralisée des documents médicaux des patients un système de recherche et d accès à les données. depuis plus de 20 ans plusieurs pays ont essayé de mettre en place un dossier médical standardisé centralisé à le niveau régional ou national. la plupart de ces tentatives ont échoué principalement pour deux raisons liées à les difficultés de mise en place d un identifiant unique pour le patient et à l absence de standardisation des dossiers médicaux. dans cet article nous discutons l intérêt d une solution pragmatique reposant sur l accès à les données déjà collectées et stockées de façon décentralisée grâce à la mise en place d un système de recherche et d accès à les données réparties de le patient. l originalité de cette procédure repose sur des avancées technologiques notamment les techniques de grille et de tatouage. les données déjà standardisées pourraient bénéficier d une gestion centralisée. ceci conduirait à mettre en place un système mixte décentralisé pour les données standardisées et centralisé pour les données déjà standardisées.
termith-eval,test_sciencesInfo_11_0282257_tei,le tri de cartes une méthode d investigation des catégories mentales à le service de l architecture de l information. la présente contribution entend proposer une présentation des alternatives possibles concernant l utilisation des épreuves de tri de cartes dans un contexte de conception de systèmes interactifs ou de documents numériques. notre présentation suit le déroulement d une série de tests que nous avons réalisés afin de guider la définition de l architecture d information de le site web d un département universitaire. au delà de l état de la littérature l objectif est de proposer à le départ de cette expérience empirique une méthode de recueil d analyse et d interprétation des résultats d épreuves de tri de cartes située dans le paysage des pratiques existantes combinant analyses qualitative et quantitative des données recueillies dans le but de mieux cibler les représentations des usagers.
termith-eval,test_sciencesInfo_11_0296234_tei,les collégiens et la recherche d information sur internet entre imaginaires pratiques et prescriptions. étude considérant que l acculturation à internet est intimement liée à le contexte dans lequel est utilisé ce médium de recherche d information anne cordier adopte une approche écologique pour mettre en lumière une opposition entre les recherches menées dans un cadre formel et prescriptif et celles effectuées dans un cadre non formel et familier. elle insiste sur les dangers qu il y aurait à creuser l écart constaté entre la recherche d information opérée à l école et chez soi. appuyé sur une minutieuse étude de terrain cet article sur les pratiques informationnelles des élèves de collège aborde plus largement la question de l appropriation de la culture numérique et celle de la fonction des professionnels de l information en milieu scolaire. au delà de cet environnement particulier il intéressera l ensemble des médiateurs confrontés à l évolution des outils des références et des pratiques.
termith-eval,test_sciencesInfo_11_0402694_tei,des usages limités des tic chez des professionnels de l éducation et de le conseil dans le social. constatant l existence d usages restreints ou de non usages des tic chez des travailleurs sociaux lors de travaux précédents les auteurs ont mené une étude qualitative portant sur des professionnels de l éducation et de le conseil dans le social éducateurs spécialisés éducateurs de jeunes enfants conseillers conjugaux et familiaux pour comprendre les raisons de la limitation de leurs usages des outils informatiques et en particulier de l internet. au delà d une simple juxtaposition de causes l analyse montre comment se construisent certaines interactions entre différents facteurs besoins compétences représentations valeurs et environnement. cette approche croisée se révèle heuristique car elle offre de nouvelles clés de compréhension de la complexité des situations d usage limité ou de non usage.
termith-eval,test_sciencesInfo_11_0404253_tei,analyse de le discours et champ disciplinaire. cet article commente un texte de patrick charaudeau précédemment paru dans questions de communication  pour une interdisciplinarité focalisée dans les sciences humaines et sociales. il ne s agit pas d une critique à le sens étroit car j exprime mon accord avec les thèses défendues. après en avoir résumé les idées essentielles je discute certains points qui me semblent insuffisamment développés ou qui ne sont pas abordés par patrick charaudeau. en particulier le statut singulier de l analyse de le discours qui est interdisciplinaire par nature et les problèmes que pose la définition de ce que patrick charaudeau appelle un champ disciplinaire  les sciences de le langage ou les sciences de l éducation par exemple  j insiste sur la diversité de ces champs disciplinaires et sur leur caractère hétérogène. cette discussion est illustrée par l exemple des études littéraires.
termith-eval,test_sciencesInfo_11_0404255_tei,de l infra conceptuel à des données à horizon de pertinence focalisé. les propositions que patrick charaudeau avance dans pour une interdisciplinarité focalisée dans les sciences humaines et sociales sont mises en dialogue avec les travaux de mioara mugur schächter qui explicitent et organisent la genèse et la structure de le contenu de l entier volume de le conceptualisé en particulier de la connaissance scientifique. partant de l infra conceptuel qui se présente comme un magma de perçus indistincts les processus d élaboration de représentations transforment les perçus en entités signifiantes. des procédures agréées de légitimation permettant une normalisation de le sens conduisent à des significations c est à dire de le sens négocié et partageable détaché de son contexte communicable enseignable apte à circuler dès lors institué en objet social. en montrant comment s entrelacent des concepts des opérations des données factuelles une sémantique symbolique et une syntaxe qui assurent la communicabilité le canon descriptionnel instauré met en relief les diverses composantes d un horizon de pertinence que se doivent de partager des disciplines cherchant à se construire des espaces interdisciplinaires focalisés.
termith-eval,test_sciencesInfo_11_0471917_tei,vers une recherche d information adaptée à les utilisateurs dyslexiques. nous proposons de prendre en compte des indices non purement informationnels tels que la lisibilité en recherche d information. nous montrons sur les données des évaluations trec clef et duc que cette prise en compte peut être efficace dans un cadre général. enfin nous proposons une estimation automatique de la lisibilité adaptée à des personnes dyslexiques.
termith-eval,test_sciencesInfo_11_0471925_tei,bm 25 t une extension de bm 25 pour la recherche d information ciblée. cet article traite de l intégration des balises xml dans la fonction de pondération des termes pour la recherche d information ri xml ciblée. notre modèle permet de considérer un certain type d information structurelle les balises qui représentent la structure logique des documents titre section paragraphe etc  ainsi que les balises liées à la mise en forme gras italique centré etc. nous prenons en compte l influence des balises sous forme d un poids en estimant la probabilité pour une balise de mettre en évidence les termes pertinents. ensuite ces poids sont intégrés à la fonction de pondération des termes. des expérimentations sur une collection de grande taille dans le cadre de la compétition de ri xml inex 2008 ont montré une amélioration de la qualité des résultats en ri ciblée.
termith-eval,test_sciencesInfo_11_0484931_tei,gestion des connaissances et systèmes d organisation de connaissances premier modèle et retours d expérience industriels. cet article met en avant les enjeux importants de la gestion de connaissances pour le producteur d énergie qu est edf. ces enjeux et les besoins auxquels ils répondent conduisent à des démarches pouvant avoir plusieurs objectifs opérationnels. à le cœur de la conception des solutions envisagées se trouvent la mise en œuvre de systèmes d organisation des connaissances adaptés et la manière de prendre en compte gérer ou produire des documents. cet article propose une analyse de démarches de gestion de connaissances existant à edf en préalable à la spécification d une méthodologie de gestion des connaissances incluant la caractérisation des systèmes d organisation de connaissances soc associés.
termith-eval,test_sciencesInfo_12_0000962_tei, la forme c est le fond. la une comme outil marketing de modernisation de la presse quotidienne. depuis les années 90 la presse quotidienne française multiplie les rénovations graphiques. en soi pourtant une nouvelle formule n est pas quelque chose d inédit. mais ces adaptations sont désormais réalisées dans un but stratégique gagner des nouveaux lecteurs. ce n est qu à partir de ces réformes que la première page d un quotidien devient en france la une  véritable vitrine de le journal chargée d attirer le lecteur par sa diversité par le choix des photos ou des illustrations par des titres plus courts. la une apporte désormais une valeur ajoutée à la qualité de le journal. la forme c est le fond  explique la direction de la rédaction de le monde en 1996. pour faire face à la crise les rédactions font appel à deux groupes de professionnels qui vont amener avec eux ce discours des managers de presse et des professionnels de le graphisme. mais ces changements de forme ont aussi des effets sur l organisation de le travail de ce journalisme de communication.
termith-eval,test_sciencesInfo_12_0000963_tei,féminin masculin question s pour les sic. réflexions théoriques et méthodologiques. venant provisoirement clore le débat engagé par la revue questions de communication sur le développement actuel des études de genre cette contribution revient sur quelques points fondamentaux de cette réflexion ainsi de le binôme sexe et genre qu il confronte à celui de genre et sexualités  et de l apport de la pensée de le genre à la théorie des savoirs l exemplarité de la démarche intellectuelle mobilisée par cette approche constituant une contribution décisive à toute réflexion épistémologique. il s efforce enfin de poser quelques jalons méthodologiques pour l étude des médias définis comme une technologie de genre.
termith-eval,test_sciencesInfo_12_0293268_tei,e gen traitement automatique d informations de ressources humaines. l internet est à le cœur de le marché de le travail et son utilisation s étend à mesure qu augmente le nombre d internautes. la recherche d emploi à le travers des bourses à l emploi électroniques et l e recrutement se sont banalisés. cette explosion d informations pose divers problèmes pour leur traitement rapide et efficace. nous présentons le projet e gen qui permet d analyser les offres d emploi de manière automatique ou assistée. basé sur des classifieurs pilotés par un automate de markov le système obtient de très bons résultats. nous proposons également une stratégie afin d assister les recruteurs dans la tâche difficile et d une grande subjectivité de classement de candidatures. nous évaluons différentes mesures de similarité afin d effectuer un classement pertinent des candidatures. l utilisation d un modèle de relevance feedback a permis de surpasser nos résultats.
termith-eval,test_sciencesInfo_12_0420382_tei,apprentissage automatique de la propagation des étiquettes dans les réseaux sociaux multirelationnels. nous considérons le problème consistant à apprendre à annoter des documents avec des concepts ou des mots clefs dans des réseaux d information avec contenu où les documents peuvent partager plusieurs types de relation. ces concepts associés à le document dépendent à la fois de son contenu et de ses voisins dans le graphe à travers les différentes relations. nous formalisons ce problème comme de la classification multiétiquette dans un multigraphe les nœuds étant les documents et les arcs représentant les différentes relations. nous introduisons une nouvelle méthode d étiquetage des nœuds qui exploite à la fois le contenu et la structure multirelationnelle de le graphe. l algorithme apprend également à pondérer les différents types de relations selon leur importance pour la tâche d annotation. les expériences sur les différents corpora correspondent à différentes tâches d annotation sur des articles scientifiques des emails et des images de flickr et montrent que le modèle est capable de tirer parti de l information relationnelle riche.
termith-eval,test_sciencesInfo_12_0420385_tei,application à l autocomplétion de requêtes dans les folksonomies. le tagging social s est récemment imposé dans le paysage de le web collaboratif web 2 0 comme un support à l organisation des ressources partagées permettant à les utilisateurs de catégoriser leurs ressources en leurs associant des mots clefs appelés tags. la structure ainsi créée baptisée sous le nom de folksonomie est assimilée à un hypergraphe triparti d utilisateurs de tags et de ressources. dans ce papier nous exploitons ces triplets pour introduire une nouvelle définition d une base générique de règles d association triadiques appelée bgrt. nous montrons que l utilisation de ces règles génériques pour l autocomplétion de requêtes permet de mettre en exergue la pertinence des folksonomies et leur intérêt réel pour la recherche d information. les premiers résultats obtenus sur une folksonomie réelle s avèrent prometteurs et ouvrent de nombreuses perspectives.
termith-eval,test_sciencesInfo_13_0053290_tei,co conception multidisciplinaire d une plateforme de débat en ligne. cet article présente l organisation d un projet multidisciplinaire portant sur la co conception d une plateforme de débats en ligne. nous décrivons les interactions entre les acteurs des différentes disciplines de le projet. nous analysons ce cas d étude concret et soulignons les difficultés rencontrées ainsi que les points positifs.
termith-eval,test_sciencesInfo_13_0053291_tei,pour une approche interdisciplinaire des tic le cas des réseaux socionumériques. l analyse des réseaux sociaux est menée dans le domaine des sciences sociales depuis les années 1930. l avènement de le web social et le développement des réseaux socionumériques ont la particularité de fournir des environnements propices pour l accès à des masses importantes de données utiles pour la caractérisation d un réseau social à le moyen d outils de fouille de données d analyse de graphes etc. pour autant ces nouveaux espaces ne se réduisent pas à une reproduction des réseaux sociaux hors ligne. dès lors une analyse interdisciplinaire exploitant les possibilités d outils informatisés d analyse de données tout en éclairant les résultats obtenus à la lumière de ceux issus d une analyse ethnographique se révèle judicieuse. cet article présente les résultats d une enquête sur les principaux usages des internautes sur les réseaux socionumériques en suivant cette approche interdisciplinaire.
termith-eval,test_sciencesInfo_13_0053292_tei,recherche et représentation de communautés dans un grand graphe une approche combinée. ce travail concerne l analyse la compréhension et la représentation de grands graphes. la progression des moyens de recueil et de stockage des données rend la taille de ces graphes croissante le développement de méthodes permettant leur analyse et leur représentation est donc un domaine de recherche dynamique et important. dans cet article nous développons une méthode de représentation de graphes basée sur une classification préalable des sommets avant sa représentation complète. la phase de classification consiste en l optimisation d une mesure de qualité spécialement adaptée à la recherche de groupes denses dans les graphes. la représentation finale est basée sur un algorithme de forces contraint. deux exemples issus de l analyse de réseaux sociaux sont présentés.
termith-eval,test_sciencesInfo_13_0090563_tei,la construction polyphonique des pétitions en ligne. le cas des appels contre le débat sur l identité nationale. à travers l exemple de trois pétitions électroniques demandant l arrêt de le débat sur l identité nationale ou la suppression de le ministère éponyme à son origine l article interroge certaines façons contemporaines d intervenir dans l espace public et de mettre en visibilité une cause une organisation ou des personnalités. l étude de le contexte des dispositifs sociotechniques et de la construction sociale de ces pétitions en ligne héritières d une forme traditionnelle de mobilisation la pétition papier  révèle des objets marqués par une énonciation polyphonique co construite par des voix multiples et bâtis autour d objectifs parfois très différents.
termith-eval,test_sciencesInfo_13_0090565_tei,médias et migrations dans le bassin méditerranéen. l internationalisation des savoirs. 10 questions de communication. à partir d une présentation des résultats intermédiaires d un projet de recherche consacré à les médias et migrations dans l espace euro méditerranéen  financé par l agence nationale de la recherche anr  l article propose une étude de cas des complexités scientifiques et pratiques caractérisant l internationalisation des savoirs. en se penchant sur les réalités de l espace euro méditerranéen ligne de front nord sud l objectif de le projet est d appréhender la contribution des médias tout à le long de le circuit migratoire depuis l émigration jusqu à l immigration. il s agit dans ce cadre en combinant les perspectives de l économie politique et des études sur la réception d articuler l analyse de le rôle que jouent les médias et les nouveaux médias en amont de la dynamique migratoire dans les pays de le sud avec l étude de leur rôle en aval de cette dynamique dans les pays de le nord de la méditerranée.
termith-eval,test_sciencesInfo_13_0090567_tei,les jeux vidéo en ligne un miroir de la personnalité des internautes. 10 questions de communication. dans cet article nous explorons la possibilité de détecter la personnalité des utilisateurs de jeux vidéo à partir de leur comportement dans le monde virtuel. un questionnaire administre à 1 040 joueurs de world of warcraft permet d établir leur profil sociodémographique ainsi que leur personnalité grâce à le modèle à cinq facteurs. nous utilisons ensuite des logiciels de collecte de données automatisées pour suivre les comportements virtuels de ces mêmes joueurs pendant quatre mois en mesurant quotidiennement 3 500 variables comportementales pour chacun de leurs personnages. sur la base de cet échantillon nous montrons que malgré le sentiment populaire selon lesquels les jeux sont un échappatoire permettant de créer une nouvelle identité fantastique la personnalité des joueurs persiste lorsqu ils enfilent leur corps virtuel les jeux vidéo en ligne sont en fait un miroir de la personnalité de leurs utilisateurs.
termith-eval,test_sciencesInfo_13_0090576_tei,la télévision la critique et les sciences sociales. cette réponse à l article que brigitte le grignou et érik neveu 2011 ont consacré à le jeu de la mort relève que ceux ci concentrent leur critique sur l incapacité de la psychologie sociale à fonder scientifiquement un discours critique sur le pouvoir de la télévision. ce faisant ils renoncent à analyser le documentaire en tant que tel. pour y remédier nous montrons comment le documentaire procède pour remplir son objectif à la fois pédagogique et critique. nous signalerons d abord que les procédés mis en œuvre par le documentaire sont similaires à ceux observés dans des émissions de télé réalité. ils consistent à filmer des personnes ordinaires alors qu elles effectuent des actions humiliantes ou qu elles commettent des actes moralement condamnables et à diffuser ces images sans interroger les conséquences que cela peut avoir pour elles. ensuite nous mettrons en évidence des convergences entre les manières dont sont articulées les critiques portées par le documentaire et par l article de brigitte le grignou et érik neveu. le documentaire s appuie sur une science la psychologie sociale pour révéler le pouvoir de la télévision et instruire des téléspectateurs ordinaires naïfs. à ce sujet brigitte le grignou et érik neveu s appuient sur une autre science la sociologie pour dénoncer la naïveté de la psychologie sociale qui ignore les mécanismes sociaux propres à expliquer les rapports de domination. nous proposons comme alternative à ces deux formes de critique une démarche pragmatiste attentive à le travail herméneutique des acteurs en situation. une telle démarche ne revient pas à abandonner la critique mais à le contraire à la fonder sur une phénoménologie des conditions pratiques de son exercice.
termith-eval,test_sciencesInfo_13_0090578_tei,web et participation politique quelles promesses et quels pièges. 10 questions de communication. ici la principale préoccupation est le rôle d internet dans la participation des citoyens à la démocratie. en particulier ce qui concerne le web en tant qu environnement de plus en plus intégré à le quotidien. il s agit d abord de situer le web dans le contexte troublé de la démocratie contemporaine. ensuite sont retracés plusieurs points clés de le débat opposant optimistes et pessimistes à le sujet de ce que le web peut faire à la démocratie avant que ne soit pointé un certain nombre de caractères relatifs à l environnement web et à la culture des médias le tout en lien avec thème de la participation. quant à la dernière section elle tente de revenir sur la logique de réseau et sa signification positive en termes de participation offre à cet égard deux tendances problématiques entravant ce potentiel. la discussion finale accentue le caractère ambivalent de rôle démocratique de le web et l importance de l analyser dans des contextes spécifiques.
termith-eval,test_sciencesInfo_13_0090579_tei,aristote dit il encore quelque chose à le xxie siècle. 10 questions de communication. dans cet article on défend le point de vue que le modèle de la rhétorique aristotélicienne est plus pertinent que jamais pour comprendre le débat public. on s en rend compte si l on veut bien retourner à les racines culturelles de l antique discipline celle humaniste et naturaliste de la culture de l artisanat qui sait mêler théorie et pratique nature et culture. il y va d un élargissement de la notion de rationalité.
termith-eval,test_sciencesInfo_13_0090580_tei,jeu de la mort ou jeu avec le feu. les leçons d une prétérition télévisuelle. bien qu il fût l objet d un battage médiatique exceptionnel le jeu de la mort a été un échec relatif. cette contribution en examine les causes depuis la promotion jusqu à la réception. d un bout à l autre de la chaîne ce programme vise d abord à créer de l émotion chez le téléspectateur et à lui faire peur devant les conséquences possibles de le pouvoir de la télévision. en revanche son examen détaillé empêche de le considérer comme une transposition juste de l expérience de stanley milgram. en particulier il néglige de prendre en compte la présence de le public. ce dispositif de jeu épistémologiquement critiquable est pourtant à la base de jugements de valeur qui touchent très vite ce point godwin où le raisonnement n a plus aucune prise. la quête de le spectaculaire a finalement décrédibilisé le message scientifique. à sa manière ce documentaire témoigne de la crise d identité de le service public de la télévision française.
termith-eval,test_sciencesInfo_13_0090584_tei,dire la mort écrire la vie. re présentations de la mort dans les nécrologies de presse annoncer la mort. cet article procède à une analyse de discours énonciative des nécrologies de la presse française contemporaine afin de montrer sous quelles formes la mort y est représentée. il s agit en premier lieu de montrer comment la mort est dite dans les colonnes des nécrologies le décès y est mis en scène comme une rupture entre les vivants et le défunt ce lien coupé étant manifesté par divers indices concordants qu on étudiera de façon détaillée notamment lexique de la perte forme négative temps de le passé aspect accompli. mais tout en disant cette coupure irrémédiable entre celui qui est parti et ceux qui restent la nécrologie vise aussi à re présenter le mort à le sens littéral à le rendre présent à nouveau par le biais de le discours à le travers de divers phénomènes tels que l attention portée à la postérité de le défunt ou encore la mise en scène d un dialogue avec le disparu notamment grâce à le dialogisme interlocutif et à les choix de mise en page. ce faisant la nécrologie fait partie des rituels de le deuil moderne visant à la fois à faire mémoire à le disparu et à faire société pour les vivants.
termith-eval,test_sciencesInfo_13_0090586_tei,facebook mort ou vif. deuils intimes et causes communes annoncer la mort. facebook compte 500 millions d inscrits. à le premier regard exposition de la vie le réseau social montre la prégnance de la mort. trois genres d annonces sont analysés. les faire part un membre annonce la mort d un proche les malaises dans la communication quelqu un est mort sa page existe encore et les commémorations consécutives à des catastrophes à des accidents à des crimes à des maladies. l étude rend compte des débats sur le statut des données numériques des morts enjeu affectif et symbolique. elle s attache à le rôle des mémoriaux qui montrent à l œuvre une morale des réseaux sociaux la sensibilité et la responsabilité. en devenant un cimetière global facebook se constitue comme un lieu de socialisation numérique auquel personne ne peut se soustraire. de ce fait les morts sous leur forme numérique ou par leurs banques de données constituent une force d influence dont on peut se demander comment elle sera orientée.
termith-eval,test_sciencesInfo_13_0090593_tei,l interdisciplinarité n existe pas. l interdisciplinarité est une notion d apparence sympathique brandie fréquemment comme un fétiche d ambition scientifique de surcroît appréciée des autorités universitaires et des agences qui donnent des crédits. pourtant pour parler d interdisciplinarité il faudrait que nous disposions de disciplines clairement définies. or nous n avons aucun critère clair de ce qui constitue une discipline la tension entre le domaine social considéré avec les aléas historiques et épistémologiques de le découpage est insoluble. les disciplines sont souvent des conglomérats d intérêts instables ayant eux mêmes grand besoin de dialogue intra disciplinaire. de plus les luttes de pouvoir entre disciplines sont légion elles considèrent volontiers leurs rivales comme des préalables ou des sciences auxiliaires pour leur propre travail. on pourrait à la rigueur parler de petite interdisciplinarité ou plus modestement d interméthodologie comme objectif souhaitable et souvent nécessaire à le sein d une discipline donnée. ce sont des méthodologies que nous combinons avec fruit et cela à le sein d une discipline spécifique. abandonnons donc l interdisciplinarité concept qui ne sert qu à lutter et ou qu à obscurcir à le mieux à décrocher des crédits de recherche.
